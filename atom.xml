<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>LoveZhy</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://blog.lovezhy.cc/"/>
  <updated>2020-05-17T07:40:51.320Z</updated>
  <id>https://blog.lovezhy.cc/</id>
  
  <author>
    <name>zhy</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>论文翻译 - Kafka~a Distributed Messaging System for Log Processing</title>
    <link href="https://blog.lovezhy.cc/2020/05/14/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91%20-%20Kafka~a%20Distributed%20Messaging%20System%20for%20Log%20Processing/"/>
    <id>https://blog.lovezhy.cc/2020/05/14/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91%20-%20Kafka~a%20Distributed%20Messaging%20System%20for%20Log%20Processing/</id>
    <published>2020-05-13T16:00:00.000Z</published>
    <updated>2020-05-17T07:40:51.320Z</updated>
    
    <content type="html"><![CDATA[<p>原文地址：<a href="http://notes.stephenholiday.com/Kafka.pdf" target="_blank" rel="noopener">http://notes.stephenholiday.com/Kafka.pdf</a></p><p>太长不看：</p><p>相对于JMS等其他的消息系统，Kafka舍弃了很多功能，以达到性能上的提升。</p><p>论文讲述了Kafka设计上的取舍，以及提升性能的很多点。</p><a id="more"></a><h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>日志处理已经成为消费互联网公司数据管道的重要组成部分。</p><p>我们将开始介绍Kafka，这是一个我们开发出用于收集和传递大批量的日志数据，并且具有低延迟的分布式消息传递系统。</p><p>Kafka融合了现有的日志聚合器和消息传递系统的思想，适用于消费离线和在线消息。</p><p>我们在Kafka中做了不少非常规但又实用的设计，使我们的系统具有高效和扩展性。</p><p>我们的实验结果表明，与两种流行的消息传递系统相比，Kafka具有优越的性能。</p><p>我们在生产中使用Kafka已经有一段时间了，它每天要处理数百GB的新数据。</p><h1 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1. 介绍"></a>1. 介绍</h1><p>任何一家大型互联网公司都会产生大量的 “日志 “数据。</p><p>这些数据通常包括：</p><ul><li><p>用户活动事件，包括登录、页面浏览、点击、”喜欢”、分享、评论和搜索查询</p></li><li><p>运营指标，如服务调用堆栈、调用延迟、错误，以及系统指标，如CPU、内存、网络或磁盘利用率等。</p></li></ul><p>长期以来，日志数据一直是分析的一个组成部分，用于跟踪用户参与度、系统利用率和其他指标。</p><p>然而最近互联网应用的趋势使得活动数据成为产品数据管道的一部分，直接用于网站功能中。</p><p>这些用途包括：</p><ul><li>搜索相关性</li><li>活动流中的受欢迎或共同出现的项目产生的推荐</li><li>广告定位和报告</li><li>防止滥用行为的安全应用，如垃圾邮件或未经授权的数据爬取</li><li>新闻联播功能，将用户的状态更新或行动汇总起来，供其 “朋友 “阅读。</li></ul><p>这种生产、实时使用的日志数据给数据系统带来了新的挑战，因为它的数据量比 “真实 “的数据要大好几个数量级。</p><p>例如，搜索、推荐和广告往往需要计算颗粒化的点击率，这不仅会产生每一个用户点击的日志记录，还会产生每个页面上几十个未点击的项目的日志记录。</p><p>中国移动每天收集5-8TB的电话通话记录，Facebook每天则收集了近6TB的各种用户活动事件。</p><p>许多早期处理这类数据的系统都是依靠从生产服务器上实际收集日志文件进行分析。</p><p>近年来，一些专门的分布式日志聚合器已经发布，包括Facebook的Scribe[6]、Yahoo的Data Highway和Cloudera的Flume。</p><p>这些系统主要是为了收集日志数据，并将日志数据加载到数据仓库或Hadoop[8]中进行离线消费。</p><p>在LinkedIn（一家社交网站），我们发现除了传统的离线分析之外，我们还需要以不超过几秒的延迟支持上述大部分实时应用。</p><p>我们构建了一种新型的日志处理的消息传递系统，称为Kafka，它结合了传统日志聚合器和消息传递系统的优点。</p><p>一方面，Kafka具有分布式和可扩展性，并提供了高吞吐量。</p><p>另一方面，Kafka提供了类似于消息传递系统的API，允许应用程序实时消耗日志事件。</p><p>Kafka已经开源，并在LinkedIn的生产中成功使用了6个多月。</p><p>它极大地简化了我们的基础设施，因为我们可以利用一个单一的软件来在线和离线消费各种类型的日志数据。</p><p>本文的其余部分安排如下。</p><ul><li>在第2节中，我们重新审视了传统的消息传递系统和日志聚合器。</li><li>在第3节中，我们描述了Kafka的架构及其关键设计原则。</li><li>在第4节中，我们描述了我们在LinkedIn上部署的Kafka</li><li>在第5节中描述了Kafka的性能结果。</li><li>我们在第6节中讨论了未来的工作</li><li>在第6节中做了总结。</li></ul><h1 id="2-相关工作"><a href="#2-相关工作" class="headerlink" title="2. 相关工作"></a>2. 相关工作</h1><p>传统的企业消息系统已经存在了很长时间，通常在处理异步数据流的事件总线中起着至关重要的作用。</p><p>然而，有几个原因导致它们往往不能很好地适应日志处理。</p><p>首先，企业级系统提供的特性与日志处理该有的不匹配。那些系统往往侧重于提供丰富的交付保证。</p><p>例如，IBM Websphere MQ具有事务式支持，允许一个应用程序将消息以原子方式插入到多个队列中。</p><p>而JMS规范允许每个消息在消费后被确认消费，消费顺序可能是无序的。（没看懂，对JMS不了解，脑补了下，乱序消费并幂等的意思？）</p><p>这样的交付保证对于收集日志数据来说往往是矫枉过正的。偶尔丢失几个页面浏览事件当然不是世界末日。</p><p>那些不需要的功能往往会增加这些系统的API和底层实现的复杂性。</p><p>其次，相比较首要设计约束功能，许多系统并不是那样强烈地关注吞吐量。例如，JMS没有API允许生产者明确地将多个消息批量化为一个请求。这意味着每个消息都需要进行一次完整的TCP/IP往返，这对于我们领域的吞吐量要求是不可行的。</p><p>第三，那些系统在分布式支持方面比较弱。没有简单的方法可以在多台机器上对消息进行分区和存储。</p><p>最后，许多消息系统假设消息会被近似实时消费掉，未被消费的消息量总是相当小。</p><p>导致如果出现消息累积，它们的性能就会大大降低。比如当数据仓库等离线消耗者对消息系统做周期性的大负载消费，而不是连续消费数据时。</p><p>在过去几年里，已经建立了一些专门的日志聚合器。</p><p>比如Facebook使用了一个叫Scribe的系统，每个前端机器可以通过网络向一组Scribe机器发送日志数据。</p><p>每台Scribe机器聚合日志条目，并定期将其转储到HDFS或NFS设备上。</p><p>雅虎的数据高速公路项目也有类似的数据传递方式，一组机器聚合来自客户端的事件，按分钟保存为文件，然后将</p><p>其添加到HDFS。</p><p>Flume是Cloudera开发的一个比较新的日志聚合器。它支持可扩展的 “管道 “和 “数据下沉”，使流式日志数据的传</p><p>输非常灵活。它也有更多的集成分布式支持。</p><p>但是，这些系统大多是为离线消耗日志数据而构建的，往往会将实现细节（如 “按分钟保存的文件”）不必要地暴露给消费者。</p><p>此外，他们中的大多数都采用了 “推送 “模式，即Broker将数据转发给消费者。</p><p>在LinkedIn，我们发现 “拉动 “模式更适合我们的应用，因为每个消费者都能以自己能承受的最大速率检索到消</p><p>息，避免被推送的消息淹没在比自己能承受的速度更快的消息中。</p><p>拉动模式还可以让消费者很容易回传，我们在</p><p>3.2节末尾讨论了这个好处的细节。</p><p>最近，雅虎研究公司开发了一种新的分布式pub/sub系统，名为HedWig。HedWig具有高度的可扩展性和可</p><p>用性，并提供了强大的持久性保证。不过，它主要是用于存储资料库（data store）的提交日志。</p><h1 id="3-Kafka架构和设计原则"><a href="#3-Kafka架构和设计原则" class="headerlink" title="3. Kafka架构和设计原则"></a>3. Kafka架构和设计原则</h1><p>由于现有的各种消息系统的局限性，我们开发了一种新的基于消息传递的日志聚合器Kafka。</p><p>我们首先介绍一下Kafka中的基本概念。</p><p>一个主题定义一个特定类型的消息流。</p><p>一个生产者可以向一个主题发布消息。然后，发布的消息被存储在一组称为Broker的服务器上。</p><p>一个消费者可以从Broker那里订阅一个或多个主题，并通过从Broker那里提取数据来消费订阅的消息。</p><p>从概念上讲，消息传递的定义是比较简单的。同样的，我们试图使Kafka API也一样简单。为了证明这一点，我们</p><p>不展示具体的API，而是介绍一些示例代码来展示API的使用方法。</p><p>下面给出了生产者的示例代码。一个消息被定义为只包含一个字节的内容。用户可以选择自己喜欢的序列化方</p><p>法对消息进行编码。为了提高效率，生产者可以在一次发布请求中发送一组消息。</p><blockquote><p><strong>Sample producer code</strong>:</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">producer = <span class="keyword">new</span> Producer(...);</span><br><span class="line">message = <span class="keyword">new</span> Message(“test message str”.getBytes()); </span><br><span class="line">set = <span class="keyword">new</span> MessageSet(message); </span><br><span class="line">producer.send(“topic1”, set);</span><br></pre></td></tr></table></figure><p>要订阅一个主题，消费者首先要为该主题创建一个或多个消息流（理解为分区）。</p><p>发布到该主题的消息将被平均分配到这些子消息流（分区）中。</p><p>关于Kafka如何分配消息的细节将在后面的3.2节中描述。</p><p>每个消息流在持续产生的消息流上提供了一个迭代器接口。</p><p>消费者对消息流中的每个消息进行迭代，并处理消息的内容。</p><p>与传统的迭代器不同，消息流迭代器永远不会终止。</p><p>如果当前没有更多的消息要消费，迭代器就会阻塞，直到新的消息被发布到主题上。</p><p>我们既支持点对点的传递模式，即多个消费者共同消费一个主题中所有消息的单一副本，也支持多个消费者各自检</p><p>索一个主题的副本的发布/订阅模式。</p><blockquote><p> <strong>Sample consumer code</strong>:</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">streams[] = Consumer.createMessageStreams(“topic1”, <span class="number">1</span>) <span class="keyword">for</span> (message : streams[<span class="number">0</span>]) &#123;</span><br><span class="line"></span><br><span class="line">bytes = message.payload();</span><br><span class="line"> <span class="comment">// do something with the bytes</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="/images/Kafka论文/1.png" alt="image-20200428203312364" style="zoom:50%;"></p><p>Kafka的整体架构如图1所示。</p><p>由于Kafka是分布式的，所以一个Kafka集群通常由多个Broker组成。</p><p>为了平衡负载，一个主题被划分成多个分区，每个Broker存储一个或多个分区。</p><p>多个生产者和消费者可以同时发布和消费消息。</p><p>在第3.1节中，我们将描述Broker上的单个分区的布局，以及我们选择的一些设计选择，以使访问分区的效率更高。</p><p>在第3.2节中，我们将描述生产者和消费者在分布式设置中如何与多个Broker交互。</p><p>在第3.3节中，我们将讨论Kafka的交付保证（delivery guarantees）。</p><h2 id="3-1-单分区的性能"><a href="#3-1-单分区的性能" class="headerlink" title="3.1 单分区的性能"></a>3.1 单分区的性能</h2><p>我们在Kafka中做了一些设计的决策，让系统更有效率。</p><p><strong>1. 简单的存储方式</strong>：Kafka有一个非常简单的存储布局。</p><p>一个主题的每个分区对应一个逻辑日志。</p><p>在物理上，一个日志被实现为一组大小大致相同的段文件（例如，1GB）。</p><p>每当生产者向分区发布消息时，Broker只需将消息附加到最后一个段文件中。</p><p>为了更好的性能，我们只有在发布了一定数量的消息后，或者在发布了一定时间后，才会将段文件刷新到磁盘上。</p><p>一个消息只有在刷新后才会暴露在消费者面前。</p><p>与典型的消息传递系统不同，Kafka中存储的消息没有明确的消息ID。</p><p>相反，每条消息都是通过其在日志中的逻辑偏移来寻址。</p><p>这避免了维护用于辅助查询的索引结构的开销，这些索引结构将消息id映射到实际的消息位置。</p><p>注意，我们提到的消息id是递增的，但不是连续的。为了计算下一条消息的id，我们必须将当前消息的长度加到它的id上。</p><p>从现在开始，我们将交替使用消息id和偏移量。</p><p>消费者总是顺序消费来自特定分区的消息。</p><p>如果消费者确认某个特定的消息偏移，就意味着消费者已经接收到了该分区中该偏移之前的所有消息。</p><p>在实际的运行中，消费者向Broker发出异步拉取消息请求，以便有一个缓冲区的数据准备好供应用程序消费。</p><p>每个拉取消息请求都包含消费开始的消息的偏移量和可接受的字节数。</p><p>每个Broker在内存中保存一个排序的偏移量列表，包括每个段文件中第一个消息的偏移量。Broker<br>通过搜索偏移量列表来定位所请求的报文所在的段文件，并将数据发回给消费者。</p><p>当消费者收到一条消息后，它计算出下一条要消费的消息的偏移量，并在下一次拉取请求中使用它。</p><p>Kafka日志和内存中索引的布局如图2所示。每个框显示了一条消息的偏移量。</p><p><img src="/images/Kafka论文/2.png" alt="image-20200506192830629" style="zoom:50%;"></p><p><strong>2. 高效的传输</strong>: 我们在Kafka中传输数据的时候非常谨慎。</p><p>早前，我们已经表明，生产者可以在一次发送请求中提交一组消息。</p><p>虽然消费者API每次迭代一条消息，但在实际运行中，每一个消费者的拉动请求也会检索到多个消</p><p>息。一次传输通常是几百个K字节的大小。</p><p>我们做出的另一个非常规的选择是避免在Kafka层面缓存消息在内存中。</p><p>相反，我们依赖底层文件系统的页面缓存。</p><p>这样做的主要好处是避免了双重缓冲，消息就只会缓存在页面缓存中。</p><p>这样做还有一个额外的好处，那就是即使在代理进程重启的时候，也能保留热缓存（warm cache)。</p><p>由于Kafka根本不在进程中缓存消息，所以它在垃圾回收内存方面的开销非常小，这使得在基于VM</p><p>的语言中高效实现是可行的。</p><p>最后，由于生产者和消费者都是按顺序访问段文件，而消费者往往会比生产者晚一点，所以正常的</p><p>操作系统缓存启发式缓存是非常有效的（缓存直写和预读）。</p><p>我们发现，生产者和消费者的性能都与数据大小呈线性关系，最大的数据量可以达到很多T字节。（没看懂）</p><p>此外，我们还对消费者的网络访问进行了优化。</p><p>Kafka是一个多消费者系统，一条消息可能被不同的消费者应用多次消耗。</p><p>从本地文件向远程socket发送字节的典型方法包括以下步骤。</p><ol><li>从存储介质中读取数据到操作系统中的页面缓存</li><li>将页面缓存中的数据复制到应用缓冲区</li><li>将应用缓冲区复制到另一个内核缓冲区</li><li>将内核缓冲区发送到Socket。</li></ol><p>其中包括4个数据复制和2个系统调用。</p><p>在Linux和其他Unix操作系统上，存在一个sendfile API，可以直接将字节从文件通道传输到socket</p><p>通道。这通常可以避免步骤（2）和（3）中介绍的2个复制和1个系统调用。</p><p>Kafka利用sendfile API来有效地将日志段文件中的字节从代理服务器向消费者传递。</p><p><strong>3. 无状态的Broker</strong>: 与大多数其他消息系统不同，在Kafka中，每个消费者消费了多少消息的信</p><p>息不是由Broker维护，而是由消费者自己维护。这样的设计减少了很多的复杂性，也减少了Broker</p><p>的开销。</p><p>但是，这使得删除消息变得很棘手，因为Broker不知道是否所有的用户都消费了这个消息。</p><p>Kafka通过使用简单的基于时间的SLA保留策略解决了这个问题。</p><p>如果一条消息在代理中保留的时间超过一定的时间，通常是7天，则会自动删除。</p><p>这个方案在实际应用中效果不错。大部分消费者包括离线的消费者，都是按日、按小时或实时完成</p><p>消费。由于Kafka的性能不会随着数据量的增大而降低，所以这种长时间保留的方案是可行的。</p><p>这种设计有一个重要的副作用。</p><p>一个消费者可以故意倒退到一个旧的偏移量，重新消费数据。</p><p>这违反了队列的通用规定，但事实证明，这对很多消费者来说是一个必不可少的功能。</p><p>例如，当消费者中的应用逻辑出现错误时，应用可以在错误修复后回放某些消息。这对我们的数据仓库或Hadoop系统中的ETL数据加载特别重要。</p><p>再比如，被消费的数据可能只是周期性地被刷新到一个持久化存储（例如，全文索引器）。</p><p>如果消费者崩溃，未冲洗的数据就会丢失。在这种情况下，消费者可以检查未冲洗的消息的最小偏移量，并在重启时从该偏移量中重新消费。</p><p>我们注意到，相比于推送模型，在拉动模型中支持消费者重新消费要容易得多。</p><h2 id="3-2-分布式协调处理"><a href="#3-2-分布式协调处理" class="headerlink" title="3.2 分布式协调处理"></a>3.2 分布式协调处理</h2><p>现在我们来解释一下生产者和消费者在分布式环境中的执行方式。</p><p>每个生产者可以向一个随机的或由分区key和分区函数语义决定的分区发布消息。我们将重点讨论消</p><p>费者是如何与Broker互动的。</p><p>Kafka有消费者组的概念。</p><p>每个消费组由一个或多个消费者组成，共同消费一组被订阅的主题，也就是说，每条消息只传递给</p><p>消费组内的一个消费者。</p><p>不同的消费者组各自独立消费全套订阅的消息，不需要跨消费者组的协调机制。</p><p>同一组内的消费者可以在不同的进程或不同的机器上。</p><p>我们的目标是在不引入过多的协调开销的情况下，将存储在Broker中的消息平均分配给组中的所有</p><p>消费者。</p><p>我们的第一个决定是将一个主题内的分区作为最小的并行单元。</p><p>这意味着，在任何时候一个分区的所有消息都只被每个消费组中的一个消费者消费。</p><p>假设我们允许多个消费者同时消费一个分区，那么他们就必须协调谁消费什么消息，这就需要加锁和维护状态，会造成一定的额外开销。</p><p>相反，在我们的设计中，消费进程只需要在消费者重新平衡负载时进行协调，正常来说这种情况不经常发生。</p><p>为了使负载真正平衡，我们需要一个主题中的分区比每个消费组中的消费者多很多。</p><p>我们可以通过对一个主题进行更多的分区来达到这个目的。</p><p>我们做的第二个决定是不设立中心化的”主控 “节点，而是让消费者以去中心化的方式相互协调。</p><p>增加一个主节点会使系统变得复杂化，因为我们不得不进一步担心主节点故障。</p><p>为了方便协调，我们采用了一个高度可用的共识服务Zookeeper。</p><p>Zookeeper有一个非常简单的、类似于文件系统的API。</p><p>人们可以创建一个路径，设置一个路径的值，读取一个路径的值，删除一个路径的值，以及列出一个路径的子路径。</p><p>它还可以做一些更有趣的事情。</p><ul><li>可以在路径上注册一个watcher，当路径的子路径或路径的值发生变化时，可以得到通知</li><li>可以将路径创建为临时的（相对于持久性的），这意味着如果创建的客户端不在了，路径会被Zookeeper服务器自动删除</li><li>zookeeper将数据复制到多个服务器上，这使得数据的可靠性和可用性很高。</li></ul><p>Kafka使用Zookeeper完成以下任务。</p><ul><li><p>检测Broker和消费者的添加和删除</p></li><li><p>当上述事件发生时，在每个消费者中触发一个再平衡过程</p></li><li><p>维护消费关系，并跟踪每个分区的消费偏移情况。</p></li></ul><p>具体来说，当每个Broker或消费者启动时，它将其信息存储在Zookeeper中的Broker或消费者注册表中。</p><p>Broker注册表包含Broker的主机名和端口，以及存储在其上的主题和分区。</p><p>消费者注册表包括消费者所属的消费组，以及它所订阅的主题集合。</p><p>每个消费组都与Zookeeper中的一个所有权注册表和一个偏移注册表相关联。</p><p>所有权注册表对每个订阅的分区都有一个路径，路径值是当前从这个分区消费的消费者id（我们使用的术语是消费者拥有这个分区）。</p><p>偏移注册表为每个订阅的分区存储了该分区中最后一个被消费的消息的偏移量。</p><p>Broker注册表、消费者注册表和所有权注册表在 Zookeeper 中创建的路径都是临时的。</p><p>偏移注册表中创建的路径是持久的。</p><p>如果一个Broker服务器发生故障，其上的所有分区都会自动从Broker注册表中删除。</p><p>消费者的故障会导致其在消费者注册表中的记录和所有权注册表中的所有分区记录丢失。</p><p>每个消费者都会在Broker注册表和消费者注册表上注册一个Zookeeper的Watcher，每当Broker集合或消费者组</p><p>发生变化时，都会收到通知。</p><p><img src="/images/Kafka论文/3.png" alt="image-20200507194132517" style="zoom:50%;"></p><p>在消费者的初始启动过程中，或者当消费者通过Watcher收到关于Broker/消费者变更的通知时，消费者会启动一</p><p>个重新平衡过程，以确定它应该消费的新分区。</p><p>在算法1中描述了这个过程。</p><p>通过从Zookeeper读取Broker和消费者注册表，消费者首先计算每个订阅主题T的可用分区集合（PT）和订阅T的消费者集合（CT）。</p><p>对于消费者选择的每个分区，它在所有权注册表中写入自己作为该分区的新所有者。</p><p>最后，消费者开始一个线程从拥有的分区中拉出数据，偏移量从存储在偏移注册表中的记录值开始。</p><p>当消息从分区中拉出时，消费者会定期更新偏移注册表中的最新消耗的偏移量。</p><p>当一个消费组内有多个消费者时，每个消费者都会收到Broker或消费者变更的通知。</p><p>但是，通知到达每个消费者的时间上略有不同。</p><p>因此，有可能是一个消费者试图夺取仍由另一个消费者拥有的分区的所有权。</p><p>当这种情况发生时，第一个消费者只需释放其当前拥有的所有分区，等待一段时间，然后重新尝试重新平衡。</p><p>在实践中，重新平衡过程通常只需重试几次就会稳定下来。</p><p>当创建一个新的消费者组时，偏移注册表中没有可用的偏移量。</p><p>在这种情况下，消费者将使用我们在Broker上提供的API，从每个订阅分区上可用的最小或最大的偏移量开始（取</p><p>决于配置）。</p><h2 id="3-3-传递保证"><a href="#3-3-传递保证" class="headerlink" title="3.3 传递保证"></a>3.3 传递保证</h2><p>一般来说，Kafka只保证至少一次交付语义。</p><p>确切一次交付语义通常需要两阶段提交，对于我们的应用来说并不是必须的。</p><p>大多数情况下，一个消息会准确地传递给每个消费组一次。</p><p>但是，当一个消费组进程崩溃而没有干净关闭的情况下，新接管的消费进程可能会得到一些重复的消息，这些消息</p><p>在最后一次偏移成功提交给zookeeper之后。</p><p>如果一个应用程序关心重复的问题，那么它必须添加自己的去重复逻辑，要么使用我们返回给消费者的偏移量，要</p><p>么使用消息中的一些唯一密钥。这通常是一种比使用两阶段提交更经济的方法。</p><p>Kafka保证来自单个分区的消息按顺序传递给消费者。</p><p>然而，对于来自不同分区的消息的顺序，Kafka并不保证。</p><p>为了避免日志损坏，Kafka在日志中为每个消息存储一个CRC。</p><p>如果Broker上有任何I/O错误，Kafka会运行一个恢复过程来删除那些具有不一致CRC的消息。</p><p>在消息级别拥有CRC也允许我们在消息产生或消费后检查网络错误。</p><p>如果一个Broker宕机，那么存储在其上的任何未被消费的信息都将不可用。</p><p>如果一个Broker上的存储系统被永久损坏，任何未被消费的消息都会永远丢失。</p><p>在未来，我们计划在Kafka中添加复制功能，以便在多个Broker上冗余存储每一条消息。</p><h1 id="4-Kafka在LinkedIn的实践"><a href="#4-Kafka在LinkedIn的实践" class="headerlink" title="4. Kafka在LinkedIn的实践"></a>4. Kafka在LinkedIn的实践</h1><p>在本节中，我们将介绍我们如何在LinkedIn使用Kafka。</p><p>图3显示了我们部署的简化版本。</p><p>在每个运行面向用户服务的数据中心，我们都会部署一个Kafka集群。</p><p>前端服务会生成各种日志数据，并分批发布到本地的Kafka的Broker中。</p><p>我们依靠硬件负载均衡器将发布请求均匀地分配给Kafka的Broker。</p><p>Kafka的在线消费者在同一数据中心内的服务中运行。</p><p><img src="/Users/zhuyichen/Library/Application Support/typora-user-images/image-20200513201939870.png" alt="image-20200513201939870" style="zoom:50%;"></p><p>我们还在每个数据中心单独部署了一个Kafka集群，用于离线分析，该集群在地理位置上靠近我们的Hadoop集群</p><p>和其他数据仓库基础设施。</p><p>这个Kafka实例运行一组嵌入式消费者，实时从数据中心的Kafka实例中拉取数据。</p><p>然后，我们运行数据加载任务，将数据从这个Kafka的复制集群拉到Hadoop和我们的数据仓库中，在这里我们运</p><p>行各种报表作业和数据分析处理。</p><p>我们还使用这个Kafka集群进行原型开发，并有能力针对原始事件流运行简单的脚本进行实时查询。</p><p>无需过多的调整，整个管道的端到端延迟平均约为10秒，足以满足我们的要求。</p><p>目前，Kafka每天积累了数百G字节的数据和近10亿条消息。</p><p>随着我们完成对遗留系统的迁移，我们预计这个数字将大幅增长。</p><p>未来还会增加更多类型的消息。</p><p>当运营人员启动或停止Broker进行软件或硬件维护时，再平衡过程能够自动重定向消费。</p><p>我们的跟踪系统还包括一个审计系统，以验证整个管道中的数据没有丢失。</p><p>为了方便起见，每条消息都带有时间戳和服务器名称。</p><p>我们对每个生产者进行仪器化处理，使其定期生成一个监控事件，记录该生产者在固定时间窗口内为每个主题发布</p><p>的消息数量。</p><p>生产者将监控事件发布到Kafka的一个单独的主题中。</p><p>然后，消费者可以统计他们从一个给定的主题中收到的消息数量，并将这些计数与监测事件进行验证，以验证数据</p><p>的正确性。</p><p>加载到Hadoop集群中是通过实现一种特殊的Kafka输入格式来完成的，该格式允许MapReduce作业直接从Kafka</p><p>中读取数据。</p><p>MapReduce作业加载原始数据，然后将其分组和压缩，以便将来进行高效处理。</p><p>无状态的Broker和客户端存储消息偏移在这里再次发挥了作用，使得MapReduce任务管理（允许任务失败和重</p><p>启）以自然的方式处理数据负载，而不会在任务重启时重复或丢失消息。</p><p>只有在任务成功完成后，数据和偏移量才会存储在HDFS中。</p><p>我们选择使用Avro作为我们的序列化协议，因为它是高效的，并且支持模式演化。</p><p>对于每条消息，我们将其Avro模式的id和序列化的字节存储在有效payload中。</p><p>这个模式允许我们执行一个约定，以确保数据生产者和消费者之间的兼容性。</p><p>我们使用一个轻量级的模式注册服务来将模式id映射到实际的模式。</p><p>当消费者得到一个消息时，它在模式注册表中查找，以检索该模式，该模式被用来将字节解码成对象（这种查找只</p><p>需要对每个模式进行一次，因为值是不可更改的）。</p><h1 id="5-实验结果"><a href="#5-实验结果" class="headerlink" title="5. 实验结果"></a>5. 实验结果</h1><p>我们进行了一项实验性研究，将Kafka与Apache ActiveMQ v5.4（一种流行的JMS开源实现）和以性能著称的消息</p><p>系统RabbitMQ v2.4进行了比较。</p><p>我们使用了ActiveMQ的默认持久化消息存储KahaDB。</p><p>虽然这里没有介绍，但我们也测试了另一种AMQ消息存储，发现其性能与KahahaDB非常相似。</p><p>只要有可能，我们尽量在所有系统中使用可比性设置。</p><p>我们在2台Linux机器上进行了实验，每台机器都有8个2GHz核心，16GB内存，6个磁盘，带RAID 10。</p><p>这两台机器用1Gb网络链路连接。其中一台机器作为Broker，另一台机器作为生产者或消费者。</p><p><strong>Producer测试</strong>：</p><p>我们将所有系统中的Broker配置为异步刷新消息到其持久化磁盘中。</p><p>对于每个系统，我们运行了一个单一的生产者来发布总共1000万条消息，每条消息的大小为200字节。</p><p>我们将Kafka生产者配置为以1和50的大小分批发送消息。</p><p>ActiveMQ和RabbitMQ似乎没有一个简单的消息批处理方法，我们假设它使用的是1的批处理大小，结果如图4所示。</p><p>x轴代表的是随着时间的推移向Broker发送的数据量，单位为MB，y轴对应的是生产者吞吐量，单位为每秒的消息量。</p><p>平均而言，Kafka在批处理大小为1和50的情况下，Kafka可以以每秒5万条和40万条消息的速度分别发布消息。</p><p>这些数字比ActiveMQ高了好几个数量级，而且至少是比RabbitMQ高2倍。</p><p><img src="/images/Kafka论文/4.png" alt="image-20200514202746023" style="zoom:50%;"></p><p>Kafka的表现要好得多有几个原因。</p><p>首先，Kafka生产者目前不等待Broker的回执，以Broker能处理的速度发送消息。</p><p>这大大增加了发布者的吞吐量。</p><p>在批处理量为50个的情况下，单个Kafka生产者几乎打满了生产者和Broker之间的1Gb带宽。</p><p>这对于日志聚合的情况来说是一个有效的优化，因为数据必须异步发送，以避免在实时服务流量中引入任何延迟。</p><p>同时我们注意到，broker在没有回送ack的情况下，不能保证producer每一条发布的消息都能被broker实际接收到。</p><p>对于不同类型的日志数据，只要丢掉的消息数量相对较少，以持久化换取吞吐量是可取的。然而，我们确实计划在</p><p>未来解决更多关键数据的持久化问题。</p><p>其次，Kafka使用有更有效的存储格式。</p><p>正常来说，在Kafka中，每个消息的开销是9个字节，而在ActiveMQ中则是144个字节。</p><p>这意味着ActiveMQ比Kafka多用了70%的空间来存储同样的1000万条消息。</p><p>ActiveMQ的一个开销来自于JMS所要求的沉重的消息头。</p><p>另一个开销是维护各种索引结构的成本。</p><p>我们观察到，ActiveMQ中最繁忙的线程之一花了大部分时间访问B-Tree来维护消息元数据和状态。</p><p>最后，批处理通过摊销RPC开销，大大提高了吞吐量。在Kafka中，50条消息的批处理量几乎提高了一个数量级的</p><p>吞吐量。</p><p><strong>消费者测试</strong>：</p><p>在第二个实验中，我们测试了消费者的性能。</p><p>同样，对于所有系统，我们使用一个消费者来检索总共1000万条消息。</p><p>我们对所有系统进行了配置，使每个拉取请求预取的数据量大致相同–最多1000条消息或约200KB。</p><p>对于 ActiveMQ 和 RabbitMQ，我们将消费者确认模式设置为自动。</p><p>由于所有的消息都适合在内存中，所以所有的系统都是从底层文件系统的页面缓存或一些内存中的缓冲区中提供数</p><p>据。</p><p>结果如图5所示。</p><p><img src="/images/Kafka论文/5.png" alt="image-20200514203355691" style="zoom:50%;"></p><p>Kafka平均每秒消费22000条消息，是ActiveMQ和RabbitMQ的4倍多。</p><p>我们可以想到几个原因。</p><p>首先，由于Kafka有更有效的存储格式，所以消费者从Broker那里传输的字节数更少。</p><p>其次，ActiveMQ和RabbitMQ中的Broker都必须维护每一条消息的传递状态。</p><p>我们观察到ActiveMQ线程中的一个ActiveMQ线程在这个测试中忙于向磁盘写入KahaDB页面。</p><p>相比之下，Kafka代理上没有任何磁盘写入活动。</p><p>最后，通过使用sendfile API，Kafka降低了传输开销。</p><p>在这一节的最后，我们要指出，实验的目的并不是为了表明其他的消息传递系统不如Kafka。</p><p>毕竟，ActiveMQ和RabbitMQ都有比Kafka更多的功能。</p><p>主要是为了说明一个定制的系统可能带来的性能提升。</p><h1 id="6-总结与未来展望"><a href="#6-总结与未来展望" class="headerlink" title="6. 总结与未来展望"></a>6. 总结与未来展望</h1><p>我们提出了一个名为Kafka的新型系统，用于处理海量的日志数据流。</p><p>与普通消息传递系统一样，Kafka采用了一种基于拉取的消费模型，允许应用程序以自己的速度消费数据，并在需</p><p>要的时候随时倒带消费。</p><p>通过专注于日志处理应用，Kafka实现了比传统消息系统更高的吞吐量。</p><p>同时，它还提供了内置的分布式支持，并且可以进行扩展。我们已经在LinkedIn成功地将Kafka用于离线和在线应</p><p>用。</p><p>未来，我们有几个方向。</p><p>首先，我们计划在多个Broker之间添加内置的消息复制功能，即使在机器故障无法恢复的情况下，我们也可以提</p><p>供持久化和数据可用性保证。</p><p>我们希望同时支持异步和同步复制模型，以允许在生产者延迟和所提供的保证强度之间进行一些权衡。</p><p>一个应用可以根据自己对持久化、可用性和吞吐量的要求，选择合适的冗余级别。</p><p>其次，我们希望在Kafka中加入一些流处理能力。</p><p>在从Kafka中检索消息后，实时应用经常会执行类似的操作，例如基于窗口的计数，并将每条消息与二级存储中的</p><p>记录或与另一个流中的消息连接起来。</p><p>在最底层，在发布过程中，通过在join键上对消息进行语义上的分区来支持这种操作，这样，所有用特定键发送的</p><p>消息都会进入同一个分区，从而到达一个单一的消费进程。</p><p>这为在消费机集群中处理分布式流提供了基础。</p><p>在此基础上，我们觉得一个有用的信息流实用程序库，如不同的窗口化函数或连接技术将对这类应用有利。</p><h1 id="7-引用"><a href="#7-引用" class="headerlink" title="7. 引用"></a>7. 引用</h1><ol><li><a href="http://activemq.apache.org/" target="_blank" rel="noopener">http://activemq.apache.org/</a></li><li><a href="http://avro.apache.org/" target="_blank" rel="noopener">http://avro.apache.org/</a></li><li>Cloudera’s Flume, <a href="https://github.com/cloudera/flume" target="_blank" rel="noopener">https://github.com/cloudera/flume</a></li><li><a href="http://developer.yahoo.com/blogs/hadoop/posts/2010/06/ena" target="_blank" rel="noopener">http://developer.yahoo.com/blogs/hadoop/posts/2010/06/ena</a> bling_hadoop_batch_processi_1/</li><li>Efficient data transfer through zero copy: <a href="https://www.ibm.com/developerworks/linux/library/j-" target="_blank" rel="noopener">https://www.ibm.com/developerworks/linux/library/j-</a> zerocopy/</li><li>Facebook’s Scribe, <a href="http://www.facebook.com/note.php?note_id=32008268919" target="_blank" rel="noopener">http://www.facebook.com/note.php?note_id=32008268919</a></li><li>IBM Websphere MQ: <a href="http://www-" target="_blank" rel="noopener">http://www-</a> 01.ibm.com/software/integration/wmq/</li><li><a href="http://hadoop.apache.org/" target="_blank" rel="noopener">http://hadoop.apache.org/</a></li><li><a href="http://hadoop.apache.org/hdfs/" target="_blank" rel="noopener">http://hadoop.apache.org/hdfs/</a></li><li><a href="http://hadoop.apache.org/zookeeper/" target="_blank" rel="noopener">http://hadoop.apache.org/zookeeper/</a></li><li><a href="http://www.slideshare.net/cloudera/hw09-hadoop-based-" target="_blank" rel="noopener">http://www.slideshare.net/cloudera/hw09-hadoop-based-</a> data-mining-platform-for-the-telecom-industry</li><li><a href="http://www.slideshare.net/prasadc/hive-percona-2009" target="_blank" rel="noopener">http://www.slideshare.net/prasadc/hive-percona-2009</a></li><li><a href="https://issues.apache.org/jira/browse/ZOOKEEPER-775" target="_blank" rel="noopener">https://issues.apache.org/jira/browse/ZOOKEEPER-775</a></li><li>JAVA Message Service: <a href="http://download.oracle.com/javaee/1.3/jms/tutorial/1_3_1-" target="_blank" rel="noopener">http://download.oracle.com/javaee/1.3/jms/tutorial/1_3_1-</a> fcs/doc/jms_tutorialTOC.html.</li><li>Oracle Enterprise Messaging Service: <a href="http://www.oracle.com/technetwork/middleware/ias/index-" target="_blank" rel="noopener">http://www.oracle.com/technetwork/middleware/ias/index-</a> 093455.html</li><li><a href="http://www.rabbitmq.com/" target="_blank" rel="noopener">http://www.rabbitmq.com/</a></li><li>TIBCO Enterprise Message Service: <a href="http://www.tibco.com/products/soa/messaging/" target="_blank" rel="noopener">http://www.tibco.com/products/soa/messaging/</a></li><li>Kafka, <a href="http://sna-projects.com/kafka/" target="_blank" rel="noopener">http://sna-projects.com/kafka/</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;原文地址：&lt;a href=&quot;http://notes.stephenholiday.com/Kafka.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://notes.stephenholiday.com/Kafka.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;太长不看：&lt;/p&gt;
&lt;p&gt;相对于JMS等其他的消息系统，Kafka舍弃了很多功能，以达到性能上的提升。&lt;/p&gt;
&lt;p&gt;论文讲述了Kafka设计上的取舍，以及提升性能的很多点。&lt;/p&gt;
    
    </summary>
    
    
      <category term="论文翻译" scheme="https://blog.lovezhy.cc/categories/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/"/>
    
    
      <category term="Kafka" scheme="https://blog.lovezhy.cc/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>业务思考-点赞列表怎么做</title>
    <link href="https://blog.lovezhy.cc/2020/03/16/%E4%B8%9A%E5%8A%A1%E6%80%9D%E8%80%83-%E7%82%B9%E8%B5%9E%E5%88%97%E8%A1%A8%E6%80%8E%E4%B9%88%E5%81%9A/"/>
    <id>https://blog.lovezhy.cc/2020/03/16/%E4%B8%9A%E5%8A%A1%E6%80%9D%E8%80%83-%E7%82%B9%E8%B5%9E%E5%88%97%E8%A1%A8%E6%80%8E%E4%B9%88%E5%81%9A/</id>
    <published>2020-03-15T16:00:00.000Z</published>
    <updated>2020-03-17T15:34:22.000Z</updated>
    
    <content type="html"><![CDATA[<p>在小米有品的工作内容也算是和社交有点关系，会有类似微博的点赞，查看点赞列表的功能。<br>这个功能看起来简单，其实做起来一点都不容易。<br>为了避嫌，这里以微博为例，讲一讲自己的思考。<br>类似的，还有关注列表等。这里就简单思考点赞列表。</p><a id="more"></a><h1 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h1><p>微博上，我们可以给一个具体的微博点赞，然后个人中心页面可以查看自己点赞的内容的历史<br>所以基本功能概括起来如下：</p><ol><li>给微博点赞/取消点赞</li><li>查看是否给该微博点过赞</li><li>查看历史点赞记录</li></ol><p>在要应对的数据量比较大情况下，要完全实现上面这三个功能也不容易。尤其是这种很典型的具体冷热属性的数据。<br>所以会有一些产品妥协策略：</p><ol><li>时间久远的微博，默认返回未点过赞  //这种产品可能会比较同意</li><li>时间久远的微博，点赞记录中找不到  //这种一般不会同意的，放弃吧<br>为什么这么妥协会比较好做呢？下面再详细聊聊</li></ol><p>下面看看怎么实现</p><h1 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h1><p>这个是最简单的实现方式<br>其实还有更简单的，就是只有Mysql，但是这种一般都不会使用的，除非自己写写应用。</p><p>每个用户的点赞列表都存为一个ZSET<br><code>Key=weibo:like:${uid}</code><br><code>Value=${weiboId}，Score=${Time}</code></p><ol><li>点赞时加入到ZSET，取消点赞时从ZSET中删除</li><li>查询是否点过赞使用zscore</li><li>历史点赞记录用zrange</li></ol><h2 id="注意事项一"><a href="#注意事项一" class="headerlink" title="注意事项一"></a>注意事项一</h2><p>没问题吗？<br>是的，一般来说这么搞就行了，但是其实有个不小的瑕疵。<br>查询历史点赞记录用zrange。</p><p>想象如下的例子：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">request: &#123;</span><br><span class="line">page: 0,</span><br><span class="line">pageSize: 10</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>好，我们用<code>zrange(key, page, pageSize)</code>返回前十条</p><p>我看到自己的前十个点赞记录，卧槽太傻比了，全部取消点赞<br>ok，我们zrem() * 10次，把zset中前10个记录删除了。</p><p>再来请求下一页：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">request: &#123;</span><br><span class="line">page: 1,</span><br><span class="line">pageSize: 10</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>我们用<code>zrange(key, page, pageSize)</code>返回前十条</p><p>发现问题了吗？<br>第二次zrange的10条，其实是最原始数据的20-30条。<br>中间有一页的点赞记录因为我们zrem的原因，加载不出来。</p><p>这就是用zset做分页的普遍缺点。</p><p>怎么解呢？<br>有个简单的方法，我们用<code>rangeByScore</code>方法，其实参数最大值，是上一页的最小的一个<code>Score</code>。<br>这样，前端每次的请求其实是带上上一页的最小的那个时间戳<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">request: &#123;</span><br><span class="line">page: x,</span><br><span class="line">pageSize: 10,</span><br><span class="line">lastTime: 103232</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>这样就可以解决了。</p><h2 id="注意事项二"><a href="#注意事项二" class="headerlink" title="注意事项二"></a>注意事项二</h2><p>但是还有个问题：<br>我点赞了微博id=23。<br>然后这条微博被用户删除了。<br>那我从zset中拉到这个id，组装数据时会发现id=23查找不到。</p><p>这个时候其实有两种选择：</p><ol><li>告诉用户这个点赞内容被删除了，微博就是这么做的</li><li>返回空</li></ol><p>返回空其实又带来一个问题<br>如果我很不巧，第4页的点赞微博都是一个人的，她清空了微博<br>那请求和响应就会变成这样：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">request: &#123;</span><br><span class="line">page: 3,</span><br><span class="line">pageSize: 10,</span><br><span class="line">lastTime: 103232</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">response: &#123;</span><br><span class="line">[]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>后端返回了一个空数据。</p><p>如果这么定义的话，前端会以为已经请求空了，就会告诉用户已经没有数据了。</p><p>这个时候其实就出BUG了。</p><p>那这个怎么解呢？<br>很容易想到的就是：<br>response中带上total字段，前端判断后续有没有数据按照total来。<br>那其实和注意事项一又冲突了。不好。</p><p>还有个解法：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">response: &#123;</span><br><span class="line">[],</span><br><span class="line">hasNext: true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>用<code>hasNext</code>告诉前端有没有后续数据了<br><code>hasNext</code>怎么来呢？<br>我们从zset中range获取的时候，如果拉出来的个数小于pageSize，那么就是false。<br>如果等于pageSize，那么就是true。</p><h2 id="妥协策略"><a href="#妥协策略" class="headerlink" title="妥协策略"></a>妥协策略</h2><p>全存Redis，当然会有问题，数据量太大怎么办？<br>对于妥协策略1，我们定时的扫我们的Key（或者查询时，插入时异步操作），如果发现有些点赞记录太久远，就把Value删除。<br>这样我们的Redis负担就小点，<br>但是对不起，这样其实把妥协策略2也做了，是行不通的。</p><h1 id="类Redis数据库"><a href="#类Redis数据库" class="headerlink" title="类Redis数据库"></a>类Redis数据库</h1><p>但是又不想抛弃Redis，因为Redis实现起来确实简单啊。<br>那怎么办？<br>类Redis数据库来救场了。</p><p>类Redis说白了就是兼容Redis的指令，但是存储上，不全存内存，会存到磁盘上。<br>目前市面上比较流行的类Redis数据库有Pika，SSDB这种<br>具体笔者也没使用过，就不做评价，简单介绍下<br>小公司可以自己搭建着玩玩，但是大公司可能就没这个场景了，需要懂这个的运维来支持。</p><h2 id="Pika"><a href="#Pika" class="headerlink" title="Pika"></a>Pika</h2><h2 id="SSDB"><a href="#SSDB" class="headerlink" title="SSDB"></a>SSDB</h2><h1 id="Redis-Mysql"><a href="#Redis-Mysql" class="headerlink" title="Redis + Mysql"></a>Redis + Mysql</h1><p>这种比较少见其实，但是好歹这两数据库在公司都是标配。<br>主要是Redis存热数据，Mysql存冷数据。</p><p>写的时候双写<br>查询的时候先查Redis，Redis查不到再去查Mysql<br>分页查询的时候，查Redis，过期了就去Mysql捞一部分，然后存回Redis，设置个过期时间。<br>太久的就直接查Mysql，没必要存Redis了。</p><p>但是这里得考虑几个问题：</p><ol><li>这种行为数据，实时写数据库一般不会同意的，可以先写Redis，然后搞个消息队列慢慢写数据库</li><li>查是否给该文章点赞过，先查Redis，如果空了，再查Mysql。可能会出问题，有点隐患，不过也不用太担心，因为在Mysql中的一般就是冷数据库，问题不大。Redis存的容量大一点。</li><li>分页查询点赞历史，先查Redis，到底了去查Mysql，这里切换的衔接逻辑得好好想想。问题也不是很大。</li></ol><p>看起来很不错是不是，但是这种方案，最大的问题还是Mysql。<br>你想想这个表里的数据长啥样？<br>就几个字段：</p><ol><li>id：自增主键</li><li>uid：用户id</li><li>weiboId：微博id</li><li>createTime：点赞时间</li><li>del：是否删除了（这个看公司吧，有的只允许逻辑删除）</li></ol><p>这表数据太简单了，如果真到微博那种量级，增长速度会很快很快。<br>假设用户200w，每个人点赞2篇内容，那么一天增长400w条记录，一年就146000w，14亿。<br>这谁顶得住。</p><p>这种其实硬要解还是有点方法：</p><ol><li>压缩表：把字段weiboId，改成weiboIds，一行记录多存几个点赞记录。数据行数可以缩小几个量级，但是插入，查询和Redis衔接起来就比较复杂了。<strong>同时删除几乎不好做了。</strong></li><li>分库分表。其实我感觉分库分表意义不大。</li></ol><h2 id="妥协策略-1"><a href="#妥协策略-1" class="headerlink" title="妥协策略"></a>妥协策略</h2><p>来看看这种方案，如果产品妥协了，会不会简单点：<br>妥协策略1：查是否点过赞，Redis查不到，就默认未点赞，不用去查Mysql了。<br>妥协策略2：查完Redis，去查Mysql，可以支持。</p><p>其实再拓展下，如果产品妥协了策略1，那么写入的时候，只写Redis，然后再在某个时间点，把冷数据同步到Mysql就行。<br>这样就不用双写数据库了，同时同步的时候可以批量查入。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>所以综合来看，功能上，对热点数据的点赞/取消点赞/查询是否点赞比较好<br>如果你压缩数据行：对冷数据（Mysql中的数据），取消点赞，分页查询点赞记录比较复杂。<br>如果你不压缩：数据量太大</p><h1 id="Redis-Hbase"><a href="#Redis-Hbase" class="headerlink" title="Redis + Hbase"></a>Redis + Hbase</h1><p>Redis + Hbase算是比较终极的方案了。<br>其实笔者对Hbase也不是很了解。<br>了解了再说吧。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在小米有品的工作内容也算是和社交有点关系，会有类似微博的点赞，查看点赞列表的功能。&lt;br&gt;这个功能看起来简单，其实做起来一点都不容易。&lt;br&gt;为了避嫌，这里以微博为例，讲一讲自己的思考。&lt;br&gt;类似的，还有关注列表等。这里就简单思考点赞列表。&lt;/p&gt;
    
    </summary>
    
    
      <category term="业务思考" scheme="https://blog.lovezhy.cc/categories/%E4%B8%9A%E5%8A%A1%E6%80%9D%E8%80%83/"/>
    
    
      <category term="Redis" scheme="https://blog.lovezhy.cc/tags/Redis/"/>
    
      <category term="业务思考" scheme="https://blog.lovezhy.cc/tags/%E4%B8%9A%E5%8A%A1%E6%80%9D%E8%80%83/"/>
    
      <category term="Hbase" scheme="https://blog.lovezhy.cc/tags/Hbase/"/>
    
      <category term="Pika" scheme="https://blog.lovezhy.cc/tags/Pika/"/>
    
      <category term="分库分表" scheme="https://blog.lovezhy.cc/tags/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"/>
    
  </entry>
  
  <entry>
    <title>搞懂内存屏障-CPU的演进</title>
    <link href="https://blog.lovezhy.cc/2020/03/14/%E6%90%9E%E6%87%82%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C-CPU%E7%9A%84%E6%BC%94%E8%BF%9B/"/>
    <id>https://blog.lovezhy.cc/2020/03/14/%E6%90%9E%E6%87%82%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C-CPU%E7%9A%84%E6%BC%94%E8%BF%9B/</id>
    <published>2020-03-13T16:00:00.000Z</published>
    <updated>2020-03-14T14:55:28.795Z</updated>
    
    <content type="html"><![CDATA[<p>内存屏障是随着SMP系统的出现而出现的，也就意味着在单核的机器上，不需要任何的内存屏障。</p><p>所以要想理解内存屏障的意义，我们需要知道CPU从单核到多核，究竟修改了什么，需要我们引入内存屏障</p><a id="more"></a><h1 id="单核时代"><a href="#单核时代" class="headerlink" title="单核时代"></a>单核时代</h1><p>如果我们把CPU看做黑盒的话，简单的计算机中，除了CPU负责运算外，还需要存储系统进行存储。这个存储系统就是主存。<br><img src="/images/cpu演进/1.png" alt=""></p><p>但是问题来了，我们知道cpu的速度其实是很快很快的，但是主存的写入和读取的速度过慢，如果这么运行的话，会导致cpu的很多时间都浪费了。</p><p>如果在cpu和主存中间，加入了很多的cache系统，通常来说有L1，L2，L3等。<br><img src="/images/cpu演进/2.png" alt=""><br>cache的速度比主存快的多，这样会大大的提高性能。</p><p>在单核的系统中，当然是没问题的，因为只有一个CPU，所有的读取和写入都是它。<br>虽然一个值可能在主存和Cache中都有，但是都以Cache中的为准就行了。</p><h1 id="多核时代"><a href="#多核时代" class="headerlink" title="多核时代"></a>多核时代</h1><p>但是引入了SMP多核系统后，每个核心都有一个属于他自己的Cache。<br><img src="/images/cpu演进/3.png" alt=""></p><p>这就导致了一个问题。<br>我们知道Cache中的值其实是主存中的拷贝。<br>对一个值的修改先写到Cache中，再写到主存中，具体写入延迟不定。<br>对一个值的读取也是先从主存中读取到Cache中，CPU再从Cache中读取，什么时候失效也是不定。</p><p>多核的系统中，每个核心都有自己的Cache，并且是互相不可见的。<br>这就导致值的写入延迟和延迟失效都会导致数据不一致的问题。</p><p>怎么解决呢？<br>这个时候其实有个简单的方案：</p><ol><li>每次写入Cache时，锁总线，同步再写入主存</li><li>每次读取值时，锁总线，从主存中读。</li></ol><p>但是如果使用这种方案的话，那Cache基本就废了，毫无用处。</p><p>那怎么办呢？<br>那就让CPU的Cache“互相可见”吧。<br>于是MESI协议就诞生了。</p><h1 id="MESI协议"><a href="#MESI协议" class="headerlink" title="MESI协议"></a>MESI协议</h1><p>MESI协议，是一种缓存一致性协议，顾名思义，就是解决各个核心的Cache之间，对于同一个值的一致性问题。</p><p>首先我们要知道，Cache其实是分块的，类似于磁盘的分页，Cache的每一块叫一个CacheLine，对于Cache的基本操作都是以CacheLine为基本单位。</p><p>MESI协议定义每个CacheLine有4种状态：</p><ol><li>Modified：表示这个CacheLine对应的主存数据，只在当前核心中，并且已经被当前核心修改过，和主存中不一样。</li><li>Exclusive：该CacheLine对应的主存数据只在当前核心中，当前核心还未修改该CacheLine。</li><li>Shared：该CacheLine对应的主存数据，也会在别的核心中，但是大家都不能修改，相当于只读。</li><li>Invalid：协议未使用</li></ol><p>同时定义了CPU之间可以互发的六种消息：</p><ol><li>Read：由某个cpu发出给其他的cpu和主存，包含要读的主存地址</li><li>Read Response：由主存或者其他的cpu发出的对于Read的响应，收到响应后把CacheLine放入自己的核心缓存中</li><li>Invalidate：请求中包含需要失效的数据地址，当收到Invalidate请求后，核心必须要删除这部分数据地址</li><li>Invalidate Ack：当核心删除Invalidate请求的数据地址后，发送Ack给来源的CPU</li><li>WriteBack：当CacheLine为Modify状态时，核心将该数据写回到主存时发出</li></ol><p>说到这里你可以明白了MESI大致的作用：<br>当某个核心想要修改某个CacheLine的数据时，由于该CacheLine可能也在其他的核心中，所以必须要发消息给其他的核心，先移除对应的CacheLine。<br>同时，如果其他的核心有对应的CacheLine，必须先从自己的Cache中移除。以免自己读到已经被修改过的数据。</p><p>具体的操作流程有点复杂，估计读者也没耐心读完，这里就略过了。<br>想要详细了解的可以阅读本文的参考文章。</p><h1 id="StoreBuffer和InvalidaQueue"><a href="#StoreBuffer和InvalidaQueue" class="headerlink" title="StoreBuffer和InvalidaQueue"></a>StoreBuffer和InvalidaQueue</h1><p>有了MESI协议，Cache还是派的上用场，但是每次写入都得通知其他的核心，同时接收到其他核心的写入，还得把自己的那部分CacheLine失效。<br>必然会拖慢很多的性能。</p><p>比如说，当Core0想要修改a的值，但是发现a并不在CacheLine中，或者在CacheLine中，是Shared状态，这个时候他并不能直接修改a的值，他需要发消息给其他的Core， Invalidate这部分CacheLine，等所有的Core返回Ack的时候，他才能修改。<br>这部分时间cpu属于Stall状态。<br>那怎么办呢？<br>于是在写入Cache前，加入了一个Store Buffer。<br><img src="/images/cpu演进/4.png" alt=""></p><p>当需要写入一个值的时候，如果这个值的CacheLine并不在当前核心，或者该CacheLine并不是Modified或者Exclusive状态，先写入StoreBuffer，等其他的CPU的Ack到来时候，再择机把StoreBuffer中的值写入Cache。<br>同时，由于对该核心而言，一个值可能已经被修改了，但是并不在Cache中，而是在StoreBuffer中，所以读取的时候，以StoreBuffer的为准。</p><p>除了写入一个值时，需要进行等待，当收到Invalidate请求时，CPU也得放下手中的活，把CacheLine删除发送Ack才能继续。<br>这部分时间能不能缩减呢？<br>我们引入InvalidateQueue。<br><img src="/images/cpu演进/5.png" alt=""><br>当接收到其他的Invalidate请求时，我们将请求放在InvalidateQueue中，并立马返回Ack。<br>再择机把InvalidateQueue中标志到的需要失效的CacheLine移除。</p><h1 id="StoreBuffer导致的问题"><a href="#StoreBuffer导致的问题" class="headerlink" title="StoreBuffer导致的问题"></a>StoreBuffer导致的问题</h1><p>我们首先看一段代码：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    a=<span class="number">1</span>;  <span class="comment">//S1</span></span><br><span class="line">    b=<span class="number">1</span>;  <span class="comment">//S2</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (b == <span class="number">0</span>) <span class="keyword">continue</span>;  <span class="comment">//L1</span></span><br><span class="line">    <span class="keyword">assert</span>(a == <span class="number">1</span>);           <span class="comment">//L2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>如果CPU0执行foo函数，CPU1执行bar函数。<br>同时a的值所在的CacheLine并不在CPU0中，b的值所在的CacheLine在CPU0中，并且是Exlusive状态。</p><ol><li>CPU0执行S1，发现a不在CacheLine中，发送Read Validate消息给主存和CPU1。同时把a=1的值放入StoreBuffer。</li><li>CPU0执行S2，b值所在的CacheLine在CPU0中，并且是Exlusive状态，于是直接修改为1，放入CPU缓存。</li><li>这个时候CPU1启动运行bar函数，发现b不在CacheLine中，于是广播Read，获取b的值</li><li>CPU0得到这个Read b的消息，把b的值发送回去</li><li>CPU1得到b的值为1，L1通过</li><li>CPU1执行L2，a在CacheLine中并且是0，assert fail</li><li>CPU1得到第1步的Read Validate消息，把a所在的CacheLine移除。</li></ol><p>步骤有点复杂，需要耐心阅读。<br>核心就是第1步的Read Validate消息，CPU1延迟到第7步才收到。</p><p>那怎么避免这种情况呢？<br>我们能不能让StoreBuffer退化到没有之前的流程？<br>也就是把第一步中的操作中，写入StoreBuffer后，不允许执行后续的操作，直到收到Validate Ack消息。<br>于是我们引入sfence()函数，遇到这个函数时，必须等到所有的Validate Ack，并且把StoreBuffer全部Flush到Cache，清空StoreBuffer。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    a=<span class="number">1</span>;  <span class="comment">//S1</span></span><br><span class="line">    sfence();</span><br><span class="line">    b=<span class="number">1</span>;  <span class="comment">//S2</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (b == <span class="number">0</span>) <span class="keyword">continue</span>;  <span class="comment">//L1</span></span><br><span class="line">    <span class="keyword">assert</span>(a == <span class="number">1</span>);           <span class="comment">//L2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h1 id="InvalidateQueue导致的问题"><a href="#InvalidateQueue导致的问题" class="headerlink" title="InvalidateQueue导致的问题"></a>InvalidateQueue导致的问题</h1><p>还是看这段代码：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    a=<span class="number">1</span>;  <span class="comment">//S1</span></span><br><span class="line">    sfence();</span><br><span class="line">    b=<span class="number">1</span>;  <span class="comment">//S2</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (b == <span class="number">0</span>) <span class="keyword">continue</span>;  <span class="comment">//L1</span></span><br><span class="line">    <span class="keyword">assert</span>(a == <span class="number">1</span>);           <span class="comment">//L2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>InvalidateQueue导致的就是，将CacheLine的移除时机变得不可确定。即使这个指示需要移除该CacheLine的Invalidate消息已经在InvalidateQueue中了，CPU还是会可能会从自己的Cache中读到旧的值。</p><p>比如例子中：<br>Core0执行foo函数，此时a在Core1中。<br>Core0发送Read Invalidate消息，Core1返回a的值，同时将Invalidate消息放入InvalidateQueue。<br>Core0将a=1推送到Cache中。<br>Core0执行b=1，放入缓存中。<br>Core1发送Read b的消息，Core0返回b=1；<br>L1执行成功，Core1获取a的值，由于移除该CacheLine的Invalidate消息还在InvalidateQueue中，所以发现a的值在Cache中，并且为0。<br>于是assert fail。</p><p>于是我们引入lfence()函数，该函数强制刷新InvalidateQueue。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    a=<span class="number">1</span>;  <span class="comment">//S1</span></span><br><span class="line">    sfence();</span><br><span class="line">    b=<span class="number">1</span>;  <span class="comment">//S2</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (b == <span class="number">0</span>) <span class="keyword">continue</span>;  <span class="comment">//L1</span></span><br><span class="line">    lfence();</span><br><span class="line">    <span class="keyword">assert</span>(a == <span class="number">1</span>);           <span class="comment">//L2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>前文提到的sfence()和lfence()，便是内存屏障。<br>一个是写屏障，也就是同步刷新StoreBuffer<br>一个是读屏障，也就是同步刷新InvalidateQueue。<br>也有mfence()，既刷新StoreBuffer，也刷新InvalidateQueue。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://zhuanlan.zhihu.com/p/48157076" target="_blank" rel="noopener">高并发编程–多处理器编程中的一致性问题(上)</a><br><a href="https://zhuanlan.zhihu.com/p/55767485" target="_blank" rel="noopener">为什么需要内存屏障</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;内存屏障是随着SMP系统的出现而出现的，也就意味着在单核的机器上，不需要任何的内存屏障。&lt;/p&gt;
&lt;p&gt;所以要想理解内存屏障的意义，我们需要知道CPU从单核到多核，究竟修改了什么，需要我们引入内存屏障&lt;/p&gt;
    
    </summary>
    
    
      <category term="计算机基础" scheme="https://blog.lovezhy.cc/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"/>
    
    
      <category term="内存屏障" scheme="https://blog.lovezhy.cc/tags/%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C/"/>
    
  </entry>
  
  <entry>
    <title>搞懂内存屏障-指令与JMM</title>
    <link href="https://blog.lovezhy.cc/2020/03/14/%E6%90%9E%E6%87%82%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C-%E6%8C%87%E4%BB%A4%E4%B8%8EJMM/"/>
    <id>https://blog.lovezhy.cc/2020/03/14/%E6%90%9E%E6%87%82%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C-%E6%8C%87%E4%BB%A4%E4%B8%8EJMM/</id>
    <published>2020-03-13T16:00:00.000Z</published>
    <updated>2020-03-14T14:55:25.770Z</updated>
    
    <content type="html"><![CDATA[<p>前面讲了CPU的演进，提出了StoreBuffer和InvalidateQueue的设计，并且讲解了这两个设计会带来的问题。<br>解决这两个问题就是引入内存屏障：强制刷新StoreBuffer和InvalidateQueue。</p><p>这里详细讲讲x86机器上的内存屏障指令与其他隐式的含有内存屏障的指令。<br>然后再聊一聊JMM与内存屏障的对应关系。</p><a id="more"></a><h1 id="x86与内存屏障"><a href="#x86与内存屏障" class="headerlink" title="x86与内存屏障"></a>x86与内存屏障</h1><p>前面提到的StoreBuffer和InvalidateQueue并不是所有的CPU都会去实现。<br>其中x86的机器上，遵循的内存一致性协议叫TSO协议。<br>在这个协议中，有个叫WriteBuffer的东西，就是对应StoreBuffer。<br>但是并没有InvalidateQueue的存在。</p><h1 id="内存屏障指令集"><a href="#内存屏障指令集" class="headerlink" title="内存屏障指令集"></a>内存屏障指令集</h1><p>上文中，提到了三个内存屏障的指令：</p><ol><li>lfence()：读屏障</li><li>sfence()：写屏障</li><li>mfence()：读写屏障</li></ol><p>那么在代码中是怎么定义的呢：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> barrier() __asm__ __volatile__(<span class="meta-string">""</span>: : :<span class="meta-string">"memory"</span>) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> mb() alternative(<span class="meta-string">"lock; addl $0,0(%%esp)"</span>, <span class="meta-string">"mfence"</span>, X86_FEATURE_XMM2) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> rmb() alternative(<span class="meta-string">"lock; addl $0,0(%%esp)"</span>, <span class="meta-string">"lfence"</span>, X86_FEATURE_XMM2)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> wmb() alternative(<span class="meta-string">"lock; addl $0,0(%%esp)"</span>, <span class="meta-string">"sfence"</span>, X86_FEATURE_XMM)   </span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> CONFIG_SMP </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_mb() mb() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_rmb() rmb() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_wmb() wmb() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_read_barrier_depends() read_barrier_depends() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> set_mb(var, value) do &#123; (void) xchg(&amp;var, value); &#125; while (0) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span> </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_mb() barrier() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_rmb() barrier() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_wmb() barrier() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_read_barrier_depends() do &#123; &#125; while(0) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> set_mb(var, value) do &#123; var = value; barrier(); &#125; while (0) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure></p><p>首先来看barrirer()的定义，这个是禁止编译器进行重排序的。<br>具体的解释可以参考笔者的另外一个文章：<a href="https://blog.lovezhy.cc/2020/03/08/volatile%E5%92%8C%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C/">volatile和内存屏障</a></p><p>然后我们看CONFIG_SMP，如果定义了这个，说明该机器上不止一个Core，否则就是单核心的机器。<br>在单核心的机器上，所有的CPU的内存屏障指令都是空指令，只有禁止编译器重排序的作用。<br>这个也好理解，就不多做解释了。</p><p>而在多核心的机器上，分别定义了:</p><ol><li>smp_mb()：读写屏障</li><li>smp_rmb()：读屏障</li><li>smp_wmb()：写屏障</li></ol><p>同时我们看具体的实现，也就是用到了我们上面提到了lfence，sfence，mfence。</p><p>但是我们再仔细看看这句话：<br><code>#define rmb() alternative(&quot;lock; addl $0,0(%%esp)&quot;, &quot;lfence&quot;, X86_FEATURE_XMM2)</code></p><p>如果CPU没有lfence指令，那么就用<code>lock; addl $0,0(%%esp)</code>代替。<br>为什么？难道<code>lock; addl $0,0(%%esp)</code>也能有内存屏障的语义吗？</p><p>是的！<br>除了fence指令，还有很多的其他的指令也隐藏了内存屏障的语义。<br>下面笔者来总结一下：</p><h2 id="常见的三种"><a href="#常见的三种" class="headerlink" title="常见的三种"></a>常见的三种</h2><p>x86/64系统架构提供了三种多核的内存屏障指令：(1) sfence; (2) lfence; (3) mfence</p><ol><li>sfence：在sfence指令前的写操作当必须在sfence指令后的写操作前完成。</li><li>lfence：在lfence指令前的读操作当必须在lfence指令后的读操作前完成。</li><li>mfence：在mfence指令前的读写操作当必须在mfence指令后的读写操作前完成。</li></ol><p>其实总结起来就是读屏障，写屏障，读写屏障。</p><p>上述的是显式的会起到内存屏障作用的指令，但是还有许多指令带有异常的内存屏障的作用。</p><h2 id="MMIO写屏障"><a href="#MMIO写屏障" class="headerlink" title="MMIO写屏障"></a>MMIO写屏障</h2><p>Linux 内核有一个专门用于 MMIO 写的屏障：<br><code>mmiowb()</code><br>笔者也不熟悉这个的作用，后续再补上</p><h2 id="隐藏的内存屏障"><a href="#隐藏的内存屏障" class="headerlink" title="隐藏的内存屏障"></a>隐藏的内存屏障</h2><p>Linux 内核中一些锁或者调度函数暗含了内存屏障。</p><p>锁函数：</p><ul><li>spin locks</li><li>R/W spin locks</li><li>mutexes</li><li>semaphores</li><li>R/W semaphores</li></ul><p>中断禁止函数：<br>启动或禁止终端的函数的作用仅仅是作为编译器屏障，所以要使用内存或者 I/O 屏障 的场合，必须用别的函数。</p><p>SLEEP和WAKE-UP以及其它调度函数：<br>使用 SLEEP 和 WAKE-UP 函数时要改变 task 的状态标志，这需要使用合适的内存屏 障保证修改的顺序。</p><h1 id="JMM"><a href="#JMM" class="headerlink" title="JMM"></a>JMM</h1><p>在JMM中，定义了4中内存可见性语义：</p><ol><li>LoadLoad</li><li>LoadStore</li><li>StoreStore</li><li>StoreLoad</li></ol><p>但是这些指令对应到x86的机器上，并不是都需要实现的。<br>因为x86的核心问题是有StoreBuffer，一个值被Core0写入了StoreBuffer，另外一个Core可能读不到最新的值，除非Flush StoreBuffer。所以StoreLoad语义需要内存屏障来维持。</p><p>例如以下的例子：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    x=<span class="number">1</span>;  <span class="comment">//S1</span></span><br><span class="line">    r1=y;  <span class="comment">//S2</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    y=<span class="number">1</span>;  <span class="comment">//L1</span></span><br><span class="line">    r2=x;<span class="comment">//L2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>在这个例子中，如果没有内存屏障，Core0执行foo，Core1执行bar，则r1和r2可能出现同时为0的情况。</p><p>再具体的这个文章讲的很好：<a href="https://zhuanlan.zhihu.com/p/81555436" target="_blank" rel="noopener">为什么在 x86 架构下只有 StoreLoad 屏障是有效指令？</a></p><h2 id="更具体的例子"><a href="#更具体的例子" class="headerlink" title="更具体的例子"></a>更具体的例子</h2><p>下面我们看看代码，经过JIT编译后的指令<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">int</span> a = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">int</span> b = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10000</span>; i++) &#123;</span><br><span class="line">        add();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++) &#123;</span><br><span class="line">        a++;</span><br><span class="line">        b += <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>如果a没有被volatile修饰：<br><img src="/images/搞定内存屏障-指令与JMM/1.png" alt="image-20200314152942448"><br>可以看到a和b的操作分别对应：<br><code>inc %r9d</code><br><code>add $0x2, %r9d</code><br>中间没有任何内存屏障的指令</p><p>如果我们加上volatile修饰呢？<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">volatile</span> <span class="keyword">int</span> a = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">volatile</span> <span class="keyword">int</span> b = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10000</span>; i++) &#123;</span><br><span class="line">        add();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++) &#123;</span><br><span class="line">        a++;</span><br><span class="line">        b += <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><img src="/images/搞定内存屏障-指令与JMM/2.png" alt="image-20200314153303884"><br>可以很明显的看到两个<code>lock</code>指令。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前面讲了CPU的演进，提出了StoreBuffer和InvalidateQueue的设计，并且讲解了这两个设计会带来的问题。&lt;br&gt;解决这两个问题就是引入内存屏障：强制刷新StoreBuffer和InvalidateQueue。&lt;/p&gt;
&lt;p&gt;这里详细讲讲x86机器上的内存屏障指令与其他隐式的含有内存屏障的指令。&lt;br&gt;然后再聊一聊JMM与内存屏障的对应关系。&lt;/p&gt;
    
    </summary>
    
    
      <category term="计算机基础" scheme="https://blog.lovezhy.cc/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"/>
    
    
      <category term="内存屏障" scheme="https://blog.lovezhy.cc/tags/%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C/"/>
    
  </entry>
  
  <entry>
    <title>搞懂内存屏障-CPU重排序</title>
    <link href="https://blog.lovezhy.cc/2020/03/09/%E6%90%9E%E6%87%82%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C-CPU%E9%87%8D%E6%8E%92%E5%BA%8F/"/>
    <id>https://blog.lovezhy.cc/2020/03/09/%E6%90%9E%E6%87%82%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C-CPU%E9%87%8D%E6%8E%92%E5%BA%8F/</id>
    <published>2020-03-08T16:00:00.000Z</published>
    <updated>2020-03-14T14:55:31.926Z</updated>
    
    <content type="html"><![CDATA[<p>我决定写一个系列，从头到尾讲一讲我理解的内存屏障的起源。<br>要想真正理解内存屏障，其实要讲很多的东西。</p><p>第一节，先来讲讲CPU的执行与重排序。</p><a id="more"></a><h1 id="CPU的执行"><a href="#CPU的执行" class="headerlink" title="CPU的执行"></a>CPU的执行</h1><h2 id="流水线"><a href="#流水线" class="headerlink" title="流水线"></a>流水线</h2><p>当然我对CPU几乎没系统的学过，都是从网上看看博客学来的。</p><p>CPU执行一条指令需要4个步骤（当然网上可能有其他说法，比如三个步骤或者五个步骤，不过没关系，不影响下面我们的结论）：</p><ol><li>取址：从内存中取出指令</li><li>译码：翻译指令，生成响应的控制信号</li><li>执行：使用CPU的逻辑处理单元计算</li><li>回写：把结果写回到寄存器或者内存</li></ol><p>假设我们有三条指令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mov $0x0, %esi</span><br><span class="line">mov $0x0, %edi</span><br><span class="line">and $0xf, %ebx</span><br></pre></td></tr></table></figure></p><p>我们把这四个步骤都合并成一个组合逻辑去运行的话<br>架构图如下：<br><img src="/images/CPU重排序/1.png" alt=""></p><p>那么我们需要的时间其实就是串行的，如下图：<br><img src="/images/CPU重排序/2.png" alt=""></p><p>但是这样，太慢了。<br>于是CPU流水线技术就诞生了（大约在Intel 386里开始出现）。</p><p>原理大概是把一个组合逻辑，拆分成多个小的组合逻辑：<br><img src="/images/CPU重排序/3.png" alt=""><br>这样，第一个指令进行组合逻辑B的时候，第二个指令就可以进行组合逻辑A了。<br>我们的时间消耗可以大大减少：<br><img src="/images/CPU重排序/4.png" alt=""></p><h2 id="冒险"><a href="#冒险" class="headerlink" title="冒险"></a>冒险</h2><p>上面的例子中，流水线可以非常完美。因为我们的三个指令所需的数据都互不依赖。<br>但是如果指令是这样的：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Mov $0x0, %esi</span><br><span class="line">Mov $0x0, %edi</span><br><span class="line">Add %esi, %edi</span><br></pre></td></tr></table></figure></p><p>第三个指令，是把第一个指令和第二个指令的结果进行相加<br>如果我们仍采用上述的流水线去运行，就会出问题：<br><img src="/images/CPU重排序/5.png" alt=""><br>CPU在执行Add指令时，依赖第二步中%edi的值。<br>但是指令3执行到第二个组合逻辑时，第二个指令还没写回到寄存器。<br>这样下去，指令3的Add用到的%edi，其实就不是0。<br>和预期的结果不符合。</p><p>这个就叫冒险<br>其中冒险分为数据冒险和控制冒险，数据冒险就是我们上面提到的。<br>而控制冒险和数据冒险类似，不过一般涉及到跳转指令。</p><p>如：<br><img src="/images/CPU重排序/6.png" alt=""><br>我们在执行JE的时候，依赖上一步的CMP的结果，导致正常的流水线执行就会有问题。</p><h2 id="Bubble"><a href="#Bubble" class="headerlink" title="Bubble"></a>Bubble</h2><p>那怎么解决呢？<br>就是插入Nop指令。</p><p><img src="/images/CPU重排序/7.png" alt=""><br>如上图所示，我们在第二个指令和第三个指令中间加入一个Nop指令，空转一个流水线。</p><p>当然我们不需要编译器每次都进行加入Nop，CPU会自己加入。<br>这个就叫Bubble，而执行Bubble叫Stall。<br><img src="/images/CPU重排序/8.png" alt=""></p><p>对于分支预测而言，CPU除了Bubble，还可能会随机选择一个分支先去执行，等CMP的结果出来，如果预测错了，就把执行结果丢弃掉：<br><img src="/images/CPU重排序/9.png" alt=""><br>分支预测失败当然是比较消耗性能的，Google的报告上指出了一次错误的分支预测的耗时：<br><img src="/images/CPU重排序/10.png" alt=""></p><p><img src="/images/CPU重排序/11.png" alt=""></p><h1 id="重排序"><a href="#重排序" class="headerlink" title="重排序"></a>重排序</h1><p>除了Bubble和分支预测的解决方案，还有一种解决方案，就是CPU的重排序。</p><p>对于下面的指令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ADD AX, BX;   </span><br><span class="line">INC AX;         </span><br><span class="line">MOV CX, DX;</span><br></pre></td></tr></table></figure></p><p>ADD和INC操作都用到了AX，必然会导致Stall。<br>但是我们发现MOV指令和ADD和INC都没有关系，<br>那么我们能不能调换顺序：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ADD AX, BX;  </span><br><span class="line">MOV CX, DX; </span><br><span class="line">INC AX;</span><br></pre></td></tr></table></figure></p><p>在执行时使用这种次序呢？<br>毕竟这种次序，就不会产生Stall，性能必然会提升。</p><p>这种就是CPU的重排序。</p><h1 id="锅是谁的？"><a href="#锅是谁的？" class="headerlink" title="锅是谁的？"></a>锅是谁的？</h1><p>在x86的机器上，CPU会进行大量的指令重排序。<br>但是CPU重排序也不会想重排就重排的，而是需要遵守一定的规范，不然就会影响软件的正常运行。</p><p>比如说下面这段经典的代码：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> x = <span class="number">0</span>, y = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> a = <span class="number">0</span>, b = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">far</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    a=<span class="number">1</span>;</span><br><span class="line">    x=b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    b=<span class="number">1</span>;</span><br><span class="line">    y=a;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>如果我们启动两个线程分别去执行far和bar函数。<br>正常的情况下，要么x=1，要么y=1，要么x=y=1;<br>但是也可能是x=y=0;</p><p>怎么解释的呢？很多人是这么解释的，这里我找了一个博客的解释：</p><blockquote><p>这是处理器乱序执行的结果：<br>线程t1内部的两行代码之间不存在数据依赖<br>因此，可以将x = b乱序到a = 1前；<br>同时，线程t2中的y = a早于线程t1中的a = 1执行。<br>一个可能的执行序列如下：<br>t1: x = b<br>t2: b = 1<br>t2: y = a<br>t1: a = 1</p></blockquote><p>看起来非常的有道理，CPU乱序执行害死人。<br>但是事实确实如此吗？<br>这个锅真的是CPU重排序执行导致的吗？</p><h1 id="真的能观测到CPU的重排序吗"><a href="#真的能观测到CPU的重排序吗" class="headerlink" title="真的能观测到CPU的重排序吗"></a>真的能观测到CPU的重排序吗</h1><p>我对CPU不熟悉，这里我就举几个网上的答案反驳吧。</p><h2 id="反驳一"><a href="#反驳一" class="headerlink" title="反驳一"></a>反驳一</h2><p><a href="https://stackoverflow.com/questions/50307693/does-an-x86-cpu-reorder-instructions" target="_blank" rel="noopener">Does an x86 CPU reorder instructions?</a><br>这个是英文回答，内容有点多，我从里面摘抄几个：</p><blockquote><p>Yes, all modern x86 chips from Intel and AMD aggressively reorder instructions across a window which is around 200 instructions deep on recent CPUs from both manufacturers</p></blockquote><p>肯定了x86的CPU会执行很多的指令重排序</p><blockquote><p>That should answer the titular question, but then your second question is about memory barriers. It contains, however, an incorrect assumption that instruction reordering necessarily causes (and is the only cause of) visible memory reordering</p></blockquote><p>这个其实超纲了，他提到了内存可见性的重排序。<br>否定了CPU的指令执行重排序一定会导致内存可见性问题。</p><blockquote><p>At the same time, x86 defines quite a strict memory model, which bans most possible reorderings<br>So actually most memory re-orderings are not allowed</p></blockquote><p>重点来了，x86定义了一个严格的内存模型，这个内存模型禁止了大多数可能的重排序<br>后续的文章中，我会提到这个内存模型。</p><blockquote><p>So it is possible to define an ISA that doesn’t allow any re-ordering at all, but under the covers do re-ordering but carefully check that it isn’t observed</p></blockquote><p>注意看这个词，<strong>observed</strong>。<br>是的，CPU确实会做指令的重排序，但是如果出现了重排序可以被observe的情况，就是BUG。<br>这里我们假定CPU不会出BUG。</p><h2 id="反驳二"><a href="#反驳二" class="headerlink" title="反驳二"></a>反驳二</h2><p><a href="https://www.zhihu.com/question/53761499" target="_blank" rel="noopener">https://www.zhihu.com/question/53761499</a><br>有人问：</p><blockquote><p>如何辨识代码是否被CPU的乱序执行优化了？</p></blockquote><p>一个是<code>中央处理器 (CPU) 话题的优秀回答者</code>的回答：</p><blockquote><p>看不到，也无法控制，ROB存在的目的就是让上层程序员看到的执行结果回归顺序。有一些memory model带来的重排序是可以被上层检测到的，比如x86的TSO模型可以通过精心设计的load store序列检测到访存的乱序。</p></blockquote><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>总而言之，我们记得一个词就够了：<code>observed</code>。<br>CPU确实会进行重排序，但是这种重排序是无法被我们观测到和控制的。<br>如果CPU没有BUG的话（基本上没听过CPU出现BUG），那么程序出现与预期不一致的行为，和CPU的重排序没半点关系。</p><p>插一句，什么内存屏障之类的，和CPU的重排序也没有关系。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://uestc-dpz.github.io/blog/2016/11/17/Reordering.html" target="_blank" rel="noopener">指令重排序</a><br><a href="https://www.zhihu.com/question/53761499" target="_blank" rel="noopener">如何辨识代码是否被CPU的乱序执行优化了</a><br><a href="https://www.cs.utexas.edu/~lin/cs380p/Free_Lunch.pdf" target="_blank" rel="noopener">https://www.cs.utexas.edu/~lin/cs380p/Free_Lunch.pdf</a><br><a href="https://monkeysayhi.github.io/2017/12/28/%E4%B8%80%E6%96%87%E8%A7%A3%E5%86%B3%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C/" target="_blank" rel="noopener">https://monkeysayhi.github.io/2017/12/28/%E4%B8%80%E6%96%87%E8%A7%A3%E5%86%B3%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C/</a><br><a href="https://stackoverflow.com/questions/50307693/does-an-x86-cpu-reorder-instructions" target="_blank" rel="noopener">https://stackoverflow.com/questions/50307693/does-an-x86-cpu-reorder-instructions</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我决定写一个系列，从头到尾讲一讲我理解的内存屏障的起源。&lt;br&gt;要想真正理解内存屏障，其实要讲很多的东西。&lt;/p&gt;
&lt;p&gt;第一节，先来讲讲CPU的执行与重排序。&lt;/p&gt;
    
    </summary>
    
    
      <category term="计算机基础" scheme="https://blog.lovezhy.cc/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"/>
    
    
      <category term="内存屏障" scheme="https://blog.lovezhy.cc/tags/%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C/"/>
    
      <category term="CPU重排序" scheme="https://blog.lovezhy.cc/tags/CPU%E9%87%8D%E6%8E%92%E5%BA%8F/"/>
    
  </entry>
  
  <entry>
    <title>volatile和内存屏障</title>
    <link href="https://blog.lovezhy.cc/2020/03/08/volatile%E5%92%8C%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C/"/>
    <id>https://blog.lovezhy.cc/2020/03/08/volatile%E5%92%8C%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C/</id>
    <published>2020-03-07T16:00:00.000Z</published>
    <updated>2020-03-14T15:04:57.467Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>事实上，我很多次以为我懂了volatile的原理，最终都是错误的。<br>关于重排序，CPU，缓存一致性，内存可见性的话题，其实非常复杂。</p><p>这篇文章较为混乱，较为详细的可以看笔者的一个系列：</p><p><a href="https://blog.lovezhy.cc/2020/03/09/%E6%90%9E%E6%87%82%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C-CPU%E9%87%8D%E6%8E%92%E5%BA%8F/">搞懂内存屏障-CPU重排序</a></p><p><a href="https://blog.lovezhy.cc/2020/03/14/%E6%90%9E%E6%87%82%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C-CPU%E7%9A%84%E6%BC%94%E8%BF%9B/">搞懂内存屏障-CPU的演进</a></p><p><a href="https://blog.lovezhy.cc/2020/03/14/%E6%90%9E%E6%87%82%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C-%E6%8C%87%E4%BB%A4%E4%B8%8EJMM/">搞懂内存屏障-指令与JMM</a><br><a id="more"></a></p><p>很多文章提到的关于volatile的例子：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> data[<span class="number">5</span>] = &#123; <span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span> &#125;;</span><br><span class="line">bool is_ready = <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">init_data</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span>( <span class="keyword">int</span> i=<span class="number">0</span>; i &lt; <span class="number">5</span>; ++i )</span><br><span class="line">    data[i] = i;</span><br><span class="line">  is_ready = <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">sum_data</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span>( !is_ready )</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">for</span>( <span class="keyword">int</span> i=<span class="number">0</span>; i &lt;<span class="number">5</span>; ++i )</span><br><span class="line">    sum += data[i];</span><br><span class="line">  printf( <span class="string">"%d"</span>, sum );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><blockquote><p>如果我们启动两个线程，线程1执行init_data()，另外一个线程不断执行sum_data()<br>正常的结果应该是0+1+2+3+4，但是由于重排序和内存可见性的问题，得到的结果是不一定的。</p></blockquote><p>其实我们很多人没有思考过一个问题：</p><blockquote><p>在这个例子中，是因为内存可见性的问题造成的，还是重排序的问题造成的？还是两个一起造成的</p></blockquote><p>太长不看：</p><ol><li>CPU对指令进行重排序的条件非常苛刻，在这个例子中，完全不存在CPU会将指令重排序的问题。这个代码运行出现的问题，完全是内存可见性的问题。</li><li>其实关于Volatile的所有问题都是内存可见性的问题，只不过看起来像是CPU重排序了。</li><li>内存屏障指令分编译器级别和CPU级别，内存屏障和CPU重排序没半点关系。</li><li>CPU的厂家使用的协议和CPU具体实现不尽相同，JVM定义的4种内存屏障指令，在x86的机器上，其实只有一种有用，其他的都是空指令。</li><li>JMM定义的”CPU缓存，主存“只是一种抽象，真正的CPU缓存实现，CPU之间在一定程度上是<strong>互相可见</strong>的。</li></ol><h1 id="我的思考"><a href="#我的思考" class="headerlink" title="我的思考"></a>我的思考</h1><p>上面的例子有点复杂，我们再举个简单的例子：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    a=<span class="number">1</span>;  <span class="comment">//S1</span></span><br><span class="line">    b=<span class="number">1</span>;  <span class="comment">//S2</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (b == <span class="number">0</span>) <span class="keyword">continue</span>;  <span class="comment">//L1</span></span><br><span class="line">    <span class="keyword">assert</span>(a == <span class="number">1</span>);           <span class="comment">//L2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>执行的流程和上面的例子一样，我们把步骤拆成了4个，分别为S1，S2，L1，L2。</p><h2 id="正常流程"><a href="#正常流程" class="headerlink" title="正常流程"></a>正常流程</h2><p>正常流程应该是：<br><code>S1 &gt; S2 &gt; L1 &gt; L2</code><br>也就是说，在执行L2的时候，a=1已经执行过了，所以这个断言是正确的。</p><h2 id="内存可见性导致的问题"><a href="#内存可见性导致的问题" class="headerlink" title="内存可见性导致的问题"></a>内存可见性导致的问题</h2><p>在JMM模型中，每个CPU都有自己的缓存，写入时，先写自己的缓存，然后再同步到主存中。<br>在这个例子中，如果还是<code>S1 &gt; S2 &gt; L1 &gt; L2</code>的执行顺序<br>但是S1执行结束后，a其实存在于三个地方，这三个地方的可能值为：</p><ol><li>foo线程所在的CPU缓存中，这个地方a=1</li><li>bar线程所在的CPU缓存中，这个地方a=0或者a=1</li><li>主存中，这个地方a=0或者a=1</li></ol><p>同样的S2执行结束后，b也存在于三个地方。</p><p>如果在bar线程中，b的值为1，但是a的值还是0，那么断言还是失败的。</p><p>这个时候有人会告诉你使用volatile<br>被volatile修饰的变量，每次写入时，会实时同步到主存中，每次读取时，实时从主存中读取<br>这个就会导致S1和S2执行完之后，L1和L2步骤的a和b的值都是最新的。<br>没毛病，说得通对吧。</p><h2 id="重排序导致的问题"><a href="#重排序导致的问题" class="headerlink" title="重排序导致的问题"></a>重排序导致的问题</h2><p>CPU在执行中会对指令进行重排序<br>比如S1和S2这两个操作，在CPU看来没有任何数据依赖顺序，所以它可以乱序执行<br>这下执行顺序可能就变成<code>S2 &gt; L1 &gt; L2 &gt; S1</code>。<br>也会导致断言失败。<br>这个时候Volatile也会保证执行的时候不会导致重排序。<br>也没毛病。</p><h2 id="内存屏障"><a href="#内存屏障" class="headerlink" title="内存屏障"></a>内存屏障</h2><p>Volatile的具体是怎么实现的呢？<br>实现就是插入内存屏障。<br>内存屏障是什么东西？<br>简单的说：保证内存屏障前的读写指令必须在屏障后的读写指令之前执行，通知被Volatile修饰的值，每次读取都从主存中读取，每次写入都同步写入主存（锁总线）。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>从这个例子中看到，其实重排序和内存可见性的问题都会导致程序产生和我们预期不一致的行为，<br>而Volatile恰好能解决这两个问题。</p><h1 id="内存屏障底层指令"><a href="#内存屏障底层指令" class="headerlink" title="内存屏障底层指令"></a>内存屏障底层指令</h1><p>其实正常来说，一般的Java开发者能理解到上面的层次就行了。<br>但是我还想理解的更多，比如这个重排序其实是CPU级别的，我们的Volatile关键词，肯定会映射成汇编指令，那么是哪些汇编指令呢？</p><p>我们先来了解一下<code>barrier()</code>函数。</p><h2 id="编译器重排序"><a href="#编译器重排序" class="headerlink" title="编译器重排序"></a>编译器重排序</h2><p>对于指令重排序，我一直以为只有CPU才会进行重排序，其实编译器也会对我们的指令进行重排序。<br>举个例子：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> x, y, r;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    x = r;</span><br><span class="line">    y = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>如果我们直接编译源文件：<code>g++ -S test.cpp</code><br>会得到这样的汇编文件：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">movl    r(%rip), %eax</span><br><span class="line">movl    %eax, x(%rip)</span><br><span class="line">movl    $<span class="number">1</span>, y(%rip)</span><br></pre></td></tr></table></figure></p><p>可以看到，这个结果并没有进行重排序</p><p>但是如果我们指定优化级别：<code>g++ -O2 –S test.cpp</code><br>得到的汇编指令如下：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">movl    r(%rip), %eax</span><br><span class="line">movl    $<span class="number">1</span>, y(%rip)</span><br><span class="line">movl    %eax, x(%rip)</span><br></pre></td></tr></table></figure></p><p>看，两个指令的顺序反了。<br>这也就是编译器的重排序。</p><p>那么怎么避免呢？<br>这个时候<code>barrier()</code>函数就派上用场了。</p><p>我们修改我们的代码：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> x, y, r;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">x = r;</span><br><span class="line">barrier();</span><br><span class="line">    y = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>这个时候我们再进行编译，会发现顺序并没有颠倒。</p><h2 id="内存屏障-1"><a href="#内存屏障-1" class="headerlink" title="内存屏障"></a>内存屏障</h2><p>我们从内核的代码中找出：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> barrier() __asm__ __volatile__(<span class="meta-string">""</span>: : :<span class="meta-string">"memory"</span>) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> mb() alternative(<span class="meta-string">"lock; addl $0,0(%%esp)"</span>, <span class="meta-string">"mfence"</span>, X86_FEATURE_XMM2) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> rmb() alternative(<span class="meta-string">"lock; addl $0,0(%%esp)"</span>, <span class="meta-string">"lfence"</span>, X86_FEATURE_XMM2)</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> CONFIG_SMP </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_mb() mb() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_rmb() rmb() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_wmb() wmb() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_read_barrier_depends() read_barrier_depends() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> set_mb(var, value) do &#123; (void) xchg(&amp;var, value); &#125; while (0) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span> </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_mb() barrier() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_rmb() barrier() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_wmb() barrier() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_read_barrier_depends() do &#123; &#125; while(0) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> set_mb(var, value) do &#123; var = value; barrier(); &#125; while (0) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure></p><p>别急，我们慢慢来看<br>内存屏障指令，大致有3个</p><ol><li><code>smp_mb</code></li><li><code>smp_rmb</code></li><li><code>smp_wmb</code></li></ol><p>但是看这个<code>#ifdef CONFGIG_SMP</code><br>SMP就是表示多核的意思。</p><blockquote><p>内存屏障指令，在单核和多核的系统中的实现定义是不一样的</p></blockquote><p>我们可以看到，如果计算机是单核的，那么其实所有的内存屏障指令都是编译器级别的，实际的实现都是<code>barrier()</code>函数，在CPU级别都是空操作。</p><h2 id="我的疑惑"><a href="#我的疑惑" class="headerlink" title="我的疑惑"></a>我的疑惑</h2><p>其实不对啊，既然CPU会进行重排序，那为什么单核中并没有使用任何CPU的指令避免重排序呢？</p><p>我们再回到那个例子：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    a=<span class="number">1</span>;  <span class="comment">//S1</span></span><br><span class="line">    b=<span class="number">1</span>;  <span class="comment">//S2</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (b == <span class="number">0</span>) <span class="keyword">continue</span>;  <span class="comment">//L1</span></span><br><span class="line">    <span class="keyword">assert</span>(a == <span class="number">1</span>);           <span class="comment">//L2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>假设这个程序是单核中执行的，也就是没有多核中的可见性的问题，但是CPU重排序的问题依然存在。<br>如果CPU进行重排序：<br><code>S2 &gt; L2 &gt; L2 &gt; S1</code><br>那不是仍然会出问题吗？</p><p>黑人问号？</p><p>带着这个问题，我继续开始了我的资料搜寻。</p><h1 id="内存一致性"><a href="#内存一致性" class="headerlink" title="内存一致性"></a>内存一致性</h1><blockquote><p>主要内容来自<a href="https://zhuanlan.zhihu.com/p/48157076" target="_blank" rel="noopener">高并发编程–多处理器编程中的一致性问题(上)</a><br>很多东西这个文章解释的很好，建议先读一读，有的我就直接略讲了</p></blockquote><p>我产生上述疑惑的前提其实就是默认CPU会对指令进行重排序。<br>很多书中对Volatile也提到了这一点，问题源头都是CPU会对指令重排序。<br>这个时候我们可能会觉得CPU厂家不给力，把这个锅丢给了开发者去解决。</p><p>其实不是的。</p><blockquote><p>那么为了保证不会出现这种超出预期的行为，我们就需要一种规则来约束这种行为不能出现。这个任务就是memory consistency需要保证的（这里指的是强一致性模型：SC/TSO， XC的memory consistency并不能保证这点）</p></blockquote><p>CPU的理论中，其实有一系列协议约束CPU的执行不能出现上述行为。<br>也就是memory consistency，内存一致性。或者也叫<code>Memory Model</code>。<br>中文资料关于这个话题确实很少被提到，这个知乎问答提到了哪儿可以去学习。<br><a href="https://www.zhihu.com/question/23572082" target="_blank" rel="noopener">如何系统的学习 Memory Model?</a><br>其实这个话题也分理论与工业实现，就跟操作系统一样。</p><p>笔者了解的也不多，这里就简单提一下。<br>关于内存一致性的问题，其实和分布式的精髓略相似，有强弱之分，不同的CPU架构上实现的强弱程度不同。</p><h2 id="Sequential-Consistency"><a href="#Sequential-Consistency" class="headerlink" title="Sequential Consistency"></a>Sequential Consistency</h2><p>在理论上，不得不提一个人，Lamport，就是Paxos理论的那个教授。<br>他提出了<code>Sequential Consistency</code>，就是顺序一致性，硬件层面的一致性。</p><p>在解释SC的理论之前，还得了解<code>Program Order</code>和<code>Memory Order</code></p><blockquote><p>Program Order: 就是我们写的代码的顺序，这个是静态的也是每个CPU core各自拥有的。<br>Memory Order: 就是代码执行的顺序，这个是全局的，每个CPU core对共享内存的执行都会出现在Memory order中。<br>用&lt;p 表示Program order的先于顺序，&lt;m表示Memory order的先于顺序。</p></blockquote><p>SC的形式化定义如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">If L(a) &lt;p L(b) ⇒ L(a) &lt;m L(b) /* Load→Load */</span><br><span class="line">If L(a) &lt;p S(b) ⇒ L(a) &lt;m S(b) /* Load→Store */</span><br><span class="line">If S(a) &lt;p S(b) ⇒ S(a) &lt;m S(b) /* Store→Store */</span><br><span class="line">If S(a) &lt;p L(b) ⇒ S(a) &lt;m L(b) /* Store→Load */</span><br></pre></td></tr></table></figure></p><p>在SC的理论中，这4种关系不允许被Reorder。<br>好了，根据这个理论，我们再看一看上面的代码：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    a=<span class="number">1</span>;  <span class="comment">//S1</span></span><br><span class="line">    b=<span class="number">1</span>;  <span class="comment">//S2</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (b == <span class="number">0</span>) <span class="keyword">continue</span>;  <span class="comment">//L1</span></span><br><span class="line">    <span class="keyword">assert</span>(a == <span class="number">1</span>);           <span class="comment">//L2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>在foo函数中，a的Store在程序顺序中是大于b的Store的，所以a=1的MemoryOrder是必须要大于b=1的MemoryOrder的。</p><p>也就说，如果CPU实现了SC协议，那么其实<code>S2 -&gt; S1</code>这个重排序是不允许的。</p><h2 id="Total-Store-Order"><a href="#Total-Store-Order" class="headerlink" title="Total Store Order"></a>Total Store Order</h2><p>当然理论归理论，实现不一定按照理论来。<br>前面提到了SC的理论，在SC理论的指导下，一切都是按照顺序来的，对CPU重排序的条件非常苛刻。</p><p>SC的问题：</p><blockquote><p>SC严格定义了对于共享内存的load和store操作，loadload，storestore，loadstore，storeload四种执行顺序是不允许reorder的。当下CPU的执行速度已经甩DRAM（memory）好几个量级，如果每次store，load操作都从DRAM读取会拖慢CPU的执行速度，在这个极度压榨硬件性能的时代，是不能接受这种行为的。因此在x86的架构实现中引入了TSO。</p></blockquote><p>简单说，就是CPU厂家觉得SC太严格，不利于性能提升，所以几乎没人用SC，而X86而言，他自己定义了一个叫Total Store Order的内存模型。</p><p>在讲TSO之前，在提一嘴前面提到的，内存一致性的协议有强弱之分，就像分布式协议中的强一致性，最终一致性一样。<br>SC显然是强一致性，但是TSO的一致性就略微弱与SC。</p><p>具体体现在哪儿呢：</p><blockquote><p>TSO在CPU与memory之间引入了write buffer。CPU写入的时候先写入write buffer然后就返回了，这样就将cpu与memory之间的差距隐藏了。</p></blockquote><p>引入了write buffer后，这里其实就是一个内存可见性的隐藏问题，在write buffer中的值，到memory中其实需要一段时间的，这个时间是不定的。</p><p>所以还是会导致一些其他的问题出现：</p><p>比如我们看这个例子：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    x=<span class="number">1</span>;  <span class="comment">//S1</span></span><br><span class="line">    r1=y;  <span class="comment">//L1</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    y=<span class="number">1</span>;  <span class="comment">//S2</span></span><br><span class="line">    r2=x;<span class="comment">//L2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><blockquote><p>还是上面这个例子，S1将x=1放到了core C1的write buffer中，S2将y=1放到了C2的write buffer中，那么在执行L1,L2的时候，r1与r2这时候从memory读到是0。这个是违背了SC的，但是这样的设计确实带来了性能的提升。</p></blockquote><p>怎么解决这个问题呢？</p><p>可能你想到了，就是我们使用某种指令，让CPU去同步Flush这个write buffer中的值。<br>这个指令就是我们提到的内存屏障。</p><p>在详细介绍内存屏障的指令前，我们在TSO模型下，看看我们之前举的例子，到底是什么原因导致的：<br>还是前面的例子：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    a=<span class="number">1</span>;  <span class="comment">//S1</span></span><br><span class="line">    b=<span class="number">1</span>;  <span class="comment">//S2</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (b == <span class="number">0</span>) <span class="keyword">continue</span>;  <span class="comment">//L1</span></span><br><span class="line">    <span class="keyword">assert</span>(a == <span class="number">1</span>);           <span class="comment">//L2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>在TOS的引入了write buffer后，我们再来看看上面的例子还会出现问题吗？<br>如果a=1，b=1先后被写入write buffer，并没有写入memory。但是如果把write buffer中的值flush到内存，b=1这个可见性的时间 &gt;= a=1的可见性。<br>所以如果bar中，读到b=1了，那么a肯定也已经读到等于1了。<br>就不会出现上面的问题。</p><p>这个时候，我们可以解答我的疑惑了<br>为什么单核的情况下，仅仅需要禁止编译器的重排序就行了？<br>答案就是在TSO模型下，在上面的例子中，CPU不会进行指令的重排序。</p><h2 id="内存屏障指令"><a href="#内存屏障指令" class="headerlink" title="内存屏障指令"></a>内存屏障指令</h2><p>让我们再回到这个代码：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> barrier() __asm__ __volatile__(<span class="meta-string">""</span>: : :<span class="meta-string">"memory"</span>) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> mb() alternative(<span class="meta-string">"lock; addl $0,0(%%esp)"</span>, <span class="meta-string">"mfence"</span>, X86_FEATURE_XMM2) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> rmb() alternative(<span class="meta-string">"lock; addl $0,0(%%esp)"</span>, <span class="meta-string">"lfence"</span>, X86_FEATURE_XMM2)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> wmb() alternative(<span class="meta-string">"lock; addl $0,0(%%esp)"</span>, <span class="meta-string">"sfence"</span>, X86_FEATURE_XMM)   </span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> CONFIG_SMP </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_mb() mb() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_rmb() rmb() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_wmb() wmb() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_read_barrier_depends() read_barrier_depends() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> set_mb(var, value) do &#123; (void) xchg(&amp;var, value); &#125; while (0) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span> </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_mb() barrier() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_rmb() barrier() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_wmb() barrier() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_read_barrier_depends() do &#123; &#125; while(0) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> set_mb(var, value) do &#123; var = value; barrier(); &#125; while (0) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure></p><h3 id="常见的三种"><a href="#常见的三种" class="headerlink" title="常见的三种"></a>常见的三种</h3><p>x86/64系统架构提供了三种多核的内存屏障指令：(1) sfence; (2) lfence; (3) mfence</p><ol><li>sfence：在sfence指令前的写操作当必须在sfence指令后的写操作前完成。</li><li>lfence：在lfence指令前的读操作当必须在lfence指令后的读操作前完成。</li><li>mfence：在mfence指令前的读写操作当必须在mfence指令后的读写操作前完成。</li></ol><p>其实总结起来就是读屏障，写屏障，读写屏障。</p><p>上述的是显式的会起到内存屏障作用的指令，但是还有许多指令带有异常的内存屏障的作用。</p><h3 id="MMIO写屏障"><a href="#MMIO写屏障" class="headerlink" title="MMIO写屏障"></a>MMIO写屏障</h3><p>Linux 内核有一个专门用于 MMIO 写的屏障：<br><code>mmiowb()</code><br>笔者也不熟悉这个的作用，后续再补上</p><h3 id="隐藏的内存屏障"><a href="#隐藏的内存屏障" class="headerlink" title="隐藏的内存屏障"></a>隐藏的内存屏障</h3><p>Linux 内核中一些锁或者调度函数暗含了内存屏障。</p><p>锁函数：</p><ul><li>spin locks</li><li>R/W spin locks</li><li>mutexes</li><li>semaphores</li><li>R/W semaphores</li></ul><p>中断禁止函数：<br>启动或禁止终端的函数的作用仅仅是作为编译器屏障，所以要使用内存或者 I/O 屏障 的场合，必须用别的函数。</p><p>SLEEP和WAKE-UP以及其它调度函数：<br>使用 SLEEP 和 WAKE-UP 函数时要改变 task 的状态标志，这需要使用合适的内存屏 障保证修改的顺序。</p><h1 id="MESI缓存一致性"><a href="#MESI缓存一致性" class="headerlink" title="MESI缓存一致性"></a>MESI缓存一致性</h1><p>写不动了，缓存一致性的内容还是大家自己百度吧<br>其实简单点可以这么理解：</p><ol><li>JMM中的主存其实在实现上，包含了CPU的缓存</li><li>JMM中的CPU的缓存在x86机器上可以理解为write buffer。</li></ol><h1 id="JMM"><a href="#JMM" class="headerlink" title="JMM"></a>JMM</h1><p>写到这儿，基本把开头的一些结论说清楚了，但是还有一个：<br>JVM定义的4种内存屏障指令，在x86的机器上，其实只有一种有用，其他的都是空指令。</p><p>我们先来看JMM中的定义，根据Store和Load的操作，JMM分成了4中：</p><ol><li>LoadLoad</li><li>LoadStore</li><li>StoreStore</li><li>StoreLoad</li></ol><p>这4中都是为了禁止重排序的<br>这里的Load就是从主存中获取值，Store就是把值同步写入主存。</p><p>按照读屏障，写屏障，读写屏障划分的话，和fence的对应关系如下：</p><ol><li>LoadLoad -&gt; lfence</li><li>LoadStore -&gt; mfence</li><li>StoreStore -&gt; sfence</li><li>StoreLoad -&gt; mfence</li></ol><p>当然了解这些还是不够的，我们还需要JMM对应了哪种CPU模型。<br>在x86中，我们除了内存，还了解到有write buffer的存在。<br>然而事实上，CPU的实现中，还有一个东西的存在叫<code>invalidate queue</code></p><p>具体的演进与作用可以参照这篇文章：<br><a href="https://zhuanlan.zhihu.com/p/66085562" target="_blank" rel="noopener">内存屏障Memory Barrier: a Hardware View</a></p><p>StoreBuffer就是对应WriteBuffer<br>而Invalidate queue在x86的CPU上是不存在的。</p><p>再回到我们提到的例子：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    x=<span class="number">1</span>;  <span class="comment">//S1</span></span><br><span class="line">    r1=y;  <span class="comment">//S2</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    y=<span class="number">1</span>;  <span class="comment">//L1</span></span><br><span class="line">    r2=x;<span class="comment">//L2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>在这个例子中，我们需要哪一种屏障呢？<br>就是StoreLoad屏障<br>按照TSO的协议解释，也就是我们读取y的值的之前，必须flush writebuffer。<br>这样，r1和r2就不会出现同时等于0的情况。</p><p>再具体的这个文章讲的很好：<a href="https://zhuanlan.zhihu.com/p/81555436" target="_blank" rel="noopener">为什么在 x86 架构下只有 StoreLoad 屏障是有效指令？</a></p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://mortoray.com/2010/11/18/cpu-reordering-what-is-actually-being-reordered/" target="_blank" rel="noopener">cpu-reordering-what-is-actually-being-reordered</a><br><a href="http://lday.me/2017/11/04/0016_what_is_memory_barriers/" target="_blank" rel="noopener">什么是内存屏障(Memory Barriers)</a><br><a href="https://www.linuxidc.com/Linux/2011-10/44623.htm" target="_blank" rel="noopener">Linux内核中的内存屏障</a><br><a href="https://quant67.com/post/linux/memory-barriers/memory-barriers.html#sec-2-6" target="_blank" rel="noopener">内存屏障</a><br><a href="https://zhuanlan.zhihu.com/p/33626920" target="_blank" rel="noopener">为什么我们需要内存屏障？</a><br><a href="https://blog.csdn.net/muxiqingyang/article/details/6615199" target="_blank" rel="noopener">《大话处理器》Cache一致性协议之MESI</a><br><a href="https://paulcavallaro.com/blog/x86-tso-a-programmers-model-for-x86-multiprocessors/" target="_blank" rel="noopener">x86 TSO: A Programmer’s Model for x86 Multiprocessors</a><br><a href="https://stackoverflow.com/questions/51292687/if-i-dont-use-fences-how-long-could-it-take-a-core-to-see-another-cores-write" target="_blank" rel="noopener">If I don’t use fences, how long could it take a core to see another core’s writes?</a><br><a href="https://blog.csdn.net/automan12138/article/details/104682093" target="_blank" rel="noopener">深入理解内存屏障</a><br><a href="https://www.cnblogs.com/aquester/p/10328479.html" target="_blank" rel="noopener">C和C++中的volatile、内存屏障和CPU缓存一致性协议MESI</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzUzMDk3NjM3Mg==&amp;mid=2247483755&amp;idx=1&amp;sn=50f80e73f46fab04d8a799e8731432c6&amp;chksm=fa48da70cd3f5366d9658277cccd9e36fca540276f580822d41aef7d8af4dda480fc85e3bde4&amp;token=1910810820&amp;lang=zh_CN#rd" target="_blank" rel="noopener">从 Java 内存模型看内部细节</a><br><a href="https://www.zhihu.com/question/296949412/answer/864851230" target="_blank" rel="noopener">既然CPU有缓存一致性协议（MESI），为什么JMM还需要volatile关键字？</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;事实上，我很多次以为我懂了volatile的原理，最终都是错误的。&lt;br&gt;关于重排序，CPU，缓存一致性，内存可见性的话题，其实非常复杂。&lt;/p&gt;
&lt;p&gt;这篇文章较为混乱，较为详细的可以看笔者的一个系列：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.lovezhy.cc/2020/03/09/%E6%90%9E%E6%87%82%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C-CPU%E9%87%8D%E6%8E%92%E5%BA%8F/&quot;&gt;搞懂内存屏障-CPU重排序&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.lovezhy.cc/2020/03/14/%E6%90%9E%E6%87%82%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C-CPU%E7%9A%84%E6%BC%94%E8%BF%9B/&quot;&gt;搞懂内存屏障-CPU的演进&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.lovezhy.cc/2020/03/14/%E6%90%9E%E6%87%82%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C-%E6%8C%87%E4%BB%A4%E4%B8%8EJMM/&quot;&gt;搞懂内存屏障-指令与JMM&lt;/a&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="计算机基础" scheme="https://blog.lovezhy.cc/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"/>
    
    
      <category term="内存屏障" scheme="https://blog.lovezhy.cc/tags/%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C/"/>
    
      <category term="volatile" scheme="https://blog.lovezhy.cc/tags/volatile/"/>
    
  </entry>
  
  <entry>
    <title>Kafka指南-分区副本详解</title>
    <link href="https://blog.lovezhy.cc/2020/03/03/Kafka%E6%8C%87%E5%8D%97-%E5%88%86%E5%8C%BA%E5%89%AF%E6%9C%AC/"/>
    <id>https://blog.lovezhy.cc/2020/03/03/Kafka%E6%8C%87%E5%8D%97-%E5%88%86%E5%8C%BA%E5%89%AF%E6%9C%AC/</id>
    <published>2020-03-02T16:00:00.000Z</published>
    <updated>2020-03-03T14:40:27.865Z</updated>
    
    <content type="html"><![CDATA[<p>分区副本是Kafka中重要的概念。<br>下面我们来详细谈一谈副本相关的概念。</p><a id="more"></a><h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><p>Kafka中，每个Topic，可能有多个分区，同时为了提高每个分区的可用性，每个分区会有多个冗余备份，这个备份就叫副本（Replica），Kafka集群会将一个分区的不同副本分配在不同的Broker上，这样即使一个Broker系统宕机，也不会影响该分区的可用性。</p><p>这也是分布式系统中常见的高可用实现方式。</p><p>但是Kafka中的关于副本，还有几个比较重要的概念。</p><h2 id="Leader副本，Follower副本"><a href="#Leader副本，Follower副本" class="headerlink" title="Leader副本，Follower副本"></a>Leader副本，Follower副本</h2><p>Leader副本，Follower副本：<br>虽然有多个副本，但是只会有一个Leader副本接收客户端的读写操作，其他的副本都叫Follower副本，Follower副本只做一件事，就是同步Leader副本的日志。</p><h2 id="AR（Assigned-Replica）"><a href="#AR（Assigned-Replica）" class="headerlink" title="AR（Assigned Replica）"></a>AR（Assigned Replica）</h2><p>AR（Assigned Replica）：<br>就是某分区所有副本的统称，包括Leader副本和Follower副本。</p><h2 id="优先副本（Preferred-Replica）"><a href="#优先副本（Preferred-Replica）" class="headerlink" title="优先副本（Preferred Replica）"></a>优先副本（Preferred Replica）</h2><p>优先副本（Preferred Replica)，也叫Preferred Leader：<br>Leader副本也不是随意选出的，前面提到过Leader副本是接收客户端的读写请求的，所有的Leader副本都集中在一个Broker上，那设立多个Broker进行负载均衡的意义就没有了。<br>所有控制器会选出每个分区的优先副本是那个，然后使用一些手段让优先副本变成Leader副本。</p><p>注意：不是每个Partition的优先副本都等于Leader副本，如果中途进行了Leader副本切换，Broker重启等事件，Leader副本就会变化，这种情况，有脚本可以手动操作。</p><h2 id="ISR（In-Sync-Replica"><a href="#ISR（In-Sync-Replica" class="headerlink" title="ISR（In-Sync Replica)"></a>ISR（In-Sync Replica)</h2><p>ISR（In-Sync Replica):<br>前面提到，所有的Follower副本，只做一件事，就是同步Leader副本的日志。<br>但是每个副本的同步进度有快有慢，我们将与Leader副本保持一定同步的Follower副本，包括Leader副本自己，叫In-Sync Replica。</p><p>那么你可能要问了，这个“保持一定同步”的标准是什么？<br>落后日志小于X条？</p><p>猜的没错，确实，在Kafka的0.9版本之前，有个参数叫<code>replica.lag.max.messages</code>，默认值是4000。如果一个Follower副本落后Leader副本4000条消息，那么就会被移出ISR集合。</p><p>你可能会注意到，这个是在0.9版本之前，那么在之后被改掉了，为什么呢？<br>因为这个参数很难设置。<br>如果业务系统的流量一直比较平稳也就算了，但是正常的业务流量难免有波动，高的时候可能QPS就超过了这个参数，很容易就触发，低的时候每秒就1条消息，那得4000s才能发现，那也没啥意义。<br>所以这个参数，很难设置。</p><p>从Kafka的0.9版本开始，Broker端有个参数叫<code>replica.lag.time.max.ms</code>，默认值是10000，Broker会启动一个参数定时的检查每个Follower副本上次和Leader副本日志完全一致的时间（注：并不完全等于上次通信时间），如果距离现在已经过去了10000ms，那么就会把这个Follower副本从ISR集合中移除。</p><h1 id="分区Leader"><a href="#分区Leader" class="headerlink" title="分区Leader"></a>分区Leader</h1><h2 id="Leader副本的产生"><a href="#Leader副本的产生" class="headerlink" title="Leader副本的产生"></a>Leader副本的产生</h2><p>一般来说，当我们创建一个Topic，进行分区的时候，Kafka控制器会决定分区分在哪些Broker上，同时也会决定那个副本是Leader副本，并且把这个信息写入ZK。同时通过Http请求通知其他的Broker。</p><h2 id="Leader副本的重新选取"><a href="#Leader副本的重新选取" class="headerlink" title="Leader副本的重新选取"></a>Leader副本的重新选取</h2><p>我们知道，每个Broker启动的时候，都会在ZK的目录下注册一个临时节点。<br>Kafka控制器对这个目录注册监听事件，当发生Broker断开，或者Broker新增的时候，就会触发一些响应的逻辑。</p><p>返回到我们的Leader副本，什么情况下Leader副本会不可用呢？通常来说就是Leader副本所在的Broker整个挂掉了。<br>Kafka控制器感应到这个事件后，就会重新指定一个副本为Leader副本。<br>到底指定哪一个呢？这里面有大文章。<br>我们慢慢来说。</p><p>在Raft中，重新选举一个Leader的条件就是谁的日志最新，谁就可以当Leader。<br>这样可以避免消息丢失。<br>在Kafka中类似，但是没有Raft中那么严格，Broker会从ISR集合中<strong>随机</strong>选取一个。<br>是的，随机选举一个当Leader。<br>我们知道，ISR集合中的副本，可不一定与Leader副本的日志完全一致的。<br><img src="/images/Kafka指南-分区/选举.png" alt=""><br>如上图所示，Leader副本如果挂掉，Follower1和2都属于ISR集合的话，虽然Follower1的日志比Follower2更新，但是Follower2也可以被选举为Leader。<br>当Follower2被选举为Leader后，Follower1的2003和2004的日志，都要被<strong>删除</strong>。</p><h2 id="分区的可用性，AP还是CP"><a href="#分区的可用性，AP还是CP" class="headerlink" title="分区的可用性，AP还是CP"></a>分区的可用性，AP还是CP</h2><p>分布式系统，有个著名的理论就是CAP理论，这里有个A就是可用性。<br>那么Kafka作为一个分布式的系统，其实也是遵循这个理论的。<br>那么你会问了，Kafka是个AP系统还是个CP系统。</p><p>说到这里，不得不提一个共识性算法，叫Raft，Raft协议其实是为了构建一个CP系统，它的A属性，是保证不能挂掉一半以上的节点。<br>而共识性算法中，有个微软的协议叫PacificA，kafka其实和这个系统相近。</p><p>不兜圈子了，直接明说，Kafka系统到底是AP还是CP其实是可以配置的。<br>在Raft中，一个数据的提交，Leader节点必须要接收到一半以上（包括自己）的节点的成功响应，才能告诉客户端，说你这条消息，提交成功，我们保证，肯定不会丢失了。</p><p>把这个概念移到Kafka中，我们的Producer的发送的数据，Leader副本自己Append后，要同步给多少节点才能响应成功呢？<br>这个是个参数，可以配置。<br><code>acks</code>：指明分区中必须要有多少个副本收到这条消息，Broker才能响应成功。</p><ol><li><code>acks=1</code>。这也是默认值，生产者发送消息后，只要分区的Leader成功写入，就会收到成功的响应。显然，这种是不能保证数据不被丢失的。万一写完，Leader副本就挂了，Follower副本还没来得及同步。</li><li><code>acks=0</code>：这个比等于1还夸张，完全随缘的，不关心服务端。一般不这么设置。</li><li><code>acks=-1,acks=all</code>：这个参数，要保证所有的ISR副本都写入成功，才可以返回成功。结合前面我们提到的ISR的概念，会发现，单独设置这个参数其实没啥用，因为ISR集合中副本的个数你根本不知道。所以这个选项，还需要我们设置出ISR集合中，至少有几个副本：<code>min.insync.replicas</code>。</li></ol><p>如果我们需要我们的Kafka是像Raft一样的CP系统，那么我们需要配置：</p><ol><li><code>acks=all</code></li><li><code>min.insync.replicas=${f/2 + 1}</code></li><li><code>unclean.leader.election.enable=false</code><br>显然这种，性能肯定不咋地，可用性也会大大折扣。</li></ol><p>如果我们需要我们的Kafka系统是AP系统，那么我们需要把</p><ol><li><code>min.insync.replicas=1</code></li><li><code>unclean.leader.election.enable=true</code><br>这样我们可以容忍最多（f-1）个副本失效。<br>但是会丢失数据。</li></ol><p>默认值：当然大部分人肯定没关心过这两个参数，其实从参数的设计来看，Kafka其实偏向于一个AP系统，<code>acks</code>的默认值为1，<code>min.insync.replicas</code>的默认值也是1，<code>unclean.leader.election.enable</code>的默认值是false。<br>这么配置的话，如果ISR集合中，某一时间只有Leader副本，同时恰好宕机了，那么整个分区就不可用了。</p><h1 id="ISR更新"><a href="#ISR更新" class="headerlink" title="ISR更新"></a>ISR更新</h1><p>对于ISR流程的更新，笔者也画了一些示意图，当然其实流程大家心里应该也清楚了。</p><h2 id="流程一"><a href="#流程一" class="headerlink" title="流程一"></a>流程一</h2><p><img src="/images/Kafka指南-分区/副本上下线1.png" alt=""><br>如上图所示，我们有3个Broker。<br>对于Topic=Hello而言，我们假设他有10个Partition，其中每个Partition有3个副本。<br>图中所示的是Partition5的副本分布情况。</p><blockquote><p>Leader副本，也就是Replica-0，在Broker-0节点上。</p><p>这个时候，ISR集合有[0,1,2]。</p></blockquote><p>在Kafka控制器和Zookeeper中都记录了该信息。<br>对于ZK而言，在<code>/state/Hello/5</code>节点中记录了该信息。<br>并且<code>/Isr_notification/</code>节点下，没有子节点。<br>图中没有标明的一点是：KafkaController监听了<code>/Isr_notification/</code>节点。</p><h2 id="流程二"><a href="#流程二" class="headerlink" title="流程二"></a>流程二</h2><p><img src="/images/Kafka指南-分区/副本上下线2.png" alt=""></p><p>渐渐的，副本2同步日志出现了落后，被Leader副本检测到了，下面Leader副本需要更新ISR集合。</p><h2 id="流程三"><a href="#流程三" class="headerlink" title="流程三"></a>流程三</h2><p><img src="/images/Kafka指南-分区/副本上下线3.png" alt=""></p><p>Leader副本所在的Broker0，会连接ZK，做两个操作：</p><ol><li>修改<code>/state/Hello/5/</code>的值，把ISR集合中的2移除</li><li>在<code>/Isr_notification/</code>下新增一个节点，表示Hello的Partition的ISR集合发生了变化</li></ol><h2 id="流程四"><a href="#流程四" class="headerlink" title="流程四"></a>流程四</h2><p><img src="/images/Kafka指南-分区/副本上下线4.png" alt=""><br>ZK会通知Kafka控制器</p><h2 id="流程五"><a href="#流程五" class="headerlink" title="流程五"></a>流程五</h2><p><img src="/images/Kafka指南-分区/副本上下线5.png" alt=""><br>Kafka控制器会做两个操作：</p><ol><li>更新自己的元数据，将副本2从ISR集合中删除</li><li>通知其他所有的Broker，更新其元数据。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;分区副本是Kafka中重要的概念。&lt;br&gt;下面我们来详细谈一谈副本相关的概念。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kafka指南" scheme="https://blog.lovezhy.cc/categories/Kafka%E6%8C%87%E5%8D%97/"/>
    
    
      <category term="Kafka" scheme="https://blog.lovezhy.cc/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka指南-模块与职能划分</title>
    <link href="https://blog.lovezhy.cc/2020/02/29/Kafka%E6%8C%87%E5%8D%97-%E6%A8%A1%E5%9D%97%E4%B8%8E%E8%81%8C%E8%83%BD%E5%88%92%E5%88%86/"/>
    <id>https://blog.lovezhy.cc/2020/02/29/Kafka%E6%8C%87%E5%8D%97-%E6%A8%A1%E5%9D%97%E4%B8%8E%E8%81%8C%E8%83%BD%E5%88%92%E5%88%86/</id>
    <published>2020-02-28T16:00:00.000Z</published>
    <updated>2020-02-29T14:27:06.411Z</updated>
    
    <content type="html"><![CDATA[<p>Kafka的是个复杂的系统，除了基本的Producer，Consumer，Broker外，为了实现完备的功能，Kafka中有许多重要的模块，本文梳理一下这些模块的划分，与他们负责的功能。</p><a id="more"></a><h1 id="运行组件"><a href="#运行组件" class="headerlink" title="运行组件"></a>运行组件</h1><p>基本上来说，正常的一个运行Kafka的业务，都需要4个组件：</p><ol><li>Broker。也就是Kafka服务器。</li><li>Producer。也就是消息的生产者，负责把消息传入Broker。</li><li>Consumer。消息的消费者，负责从Broker拉取消息。</li><li>Zookeeper。Broker的运行需要Zookeeper保存一些元数据。</li></ol><p>这四大组件的关系如下图所示：<br><img src="../images/Kafka-模块划分/组件.png" alt=""></p><p>流程也不用我多介绍了。<br>这里要提的一点就是，<strong>Consumer端不再感知Zookeeper了</strong><br>这个其实是演进出来的，之前的Offset保存的方式导致了Consumer端必须要感知ZK的地址。<br>但是使用了新的Offset提交方式后，Consumer没有必要感知Zookeeper了，所以在新版本的启动参数中仅仅需要使用<code>--bootstrap-server</code>指定任意一个Broker地址就行了。</p><p>当然这个问题我也去搜集了一下答案：<br><a href="https://segmentfault.com/q/1010000015795614" target="_blank" rel="noopener">新版kafka消费者、生产者配置为何使用bootstrap-servers而不是zookeeper服务器地址？</a></p><p>答案中提到了一个Kafka的提案，就是要取代Zookeeper。也是值得看一看的。</p><h1 id="控制器"><a href="#控制器" class="headerlink" title="控制器"></a>控制器</h1><p>控制器，也叫Kafka Controller。<br>我们知道Kafka集群中，会有多个Broker，这些Broker并不是对等的关系，和Raft协议一样，其中一个Broker会被选举为Leader，也就是控制器，KafkaController。</p><p>为什么需要一个Leader呢？这个在我看来其实有两个原因。</p><ol><li>Zookeeper的性能有限。</li><li>避免复杂的逻辑。</li></ol><p>在早期的Kafka版本中，其实没有控制器这个概念，所有的Broker都是对等的，很多复杂的逻辑难以解决，以及对ZK会造成很大的负载，笔者列举几个：</p><ol><li>分区的ISR集合变更。每个分区的ISR集合，属于元数据，需要保存到每个Broker上的。分区的Leader副本所在的Broker会首先感知到该分区的ISR变更，它会把这个事件发布上ZK上，然后其他的Broker会监听到这个事件，更新自己的元数据。</li><li>Leader副本出现问题。当一个分区的Leader副本出现问题时，需要重新选举出新的Leader副本，这个事件也是通过注册ZK的监听器实现的。</li><li>Topic的分区分配，分区迁移，优先副本的选举：这是为了负载均衡的分布在不同的Broker上，如果没有Leader，随机的让这些决策由任意一个Broker去完成，会比较复杂。</li></ol><p>所有加入KafkaController后，这个被选为Leader的Broker需要做很多事：</p><ol><li>注册ZK的监听器，事件触发后，将信息传递给其他的Broker。</li><li>对集群的配置进行决策和任务发放</li></ol><p>再具体一点：</p><ol><li>分区Leader副本出现故障，选举出新的Leader副本</li><li>ISR集合变更，通知给其他的Broker</li><li>Topic的新增，删除，分区分配，分区迁移，副本管理</li><li>监听其他的Broker的变化，新增，删除等。</li></ol><h1 id="消费者协调器，组协调器"><a href="#消费者协调器，组协调器" class="headerlink" title="消费者协调器，组协调器"></a>消费者协调器，组协调器</h1><p>消费者协调器（ConsumerCoordinator），组协调器（GroupCoordinator）是为了解决旧版本的消费者再均衡问题而诞生的。</p><p>首先让我们思考一下消费组需要解决的问题。<br>通常来说，一个Topic会有多个分区，而每个分区，都会指派给一个Consumer会消费。<br><img src="../images/Kafka-模块划分/分区分配.png" alt=""><br>如上图所示，这个Topic共有4个partition，有3个Consumer。<br>Consumer0分配了P0和P1给它，Consumer1和Consumer2分别分配了P2和P3。</p><p>这样很美好，但是美好的事情总是不稳定。<br>如果Consumer0挂了呢？<br>那么我们需要把P0和P1分配给Consumer1和Consumer2。<br>如果多了一个Consumer加入，我们需要把P0分配给它。</p><p>这些就是消费者再均衡问题。<br>怎么解决这个问题呢？<br>旧版的Kafka中同样使用了很多的ZK的监听器去完成，很复杂。<br>问题有2：</p><ol><li>ZK负载较大。</li><li>ZK本身的脑裂问题，会导致各个消费者拿到的消费组的状态不一致，产生问题。</li></ol><p>解决这个问题的关键和Kafka的控制器的思路一致，我们需要引入Leader来完成重分配。<br>于是有了组协调器</p><h2 id="组协调器（GroupCoordinator）"><a href="#组协调器（GroupCoordinator）" class="headerlink" title="组协调器（GroupCoordinator）"></a>组协调器（GroupCoordinator）</h2><blockquote><p>组协调器：Kafka将全部的消费组分成了多个子集，每个消费组的子集在服务端对应一个GroupCoordinator对其进行管理</p></blockquote><p>组协调器是在服务端的，由某一个Broker担任。<br>有了组协调器后，某消费组中的所有消费者定时的向其发送心跳包，这样组协调器就能感知该消费组的消费者的个数变更，从而触发分区重分配。</p><p>好像解决重分配的问题，只要有了组协调器就行了？<br>是的，确实是的。</p><p>那么消费者协调器是干什么用的？<br>别急，等我慢慢道来。</p><h2 id="消费者协调器"><a href="#消费者协调器" class="headerlink" title="消费者协调器"></a>消费者协调器</h2><p>说到这个其实不能不提一个概念，<strong>分区分配规则</strong>。<br>X个分区，Y个消费者，怎么分配分区给消费者呢？<br>当然我们可以轮询着来，但是作为一个完备的框架，这一层分配策略是需要抽象出来的，甚至可以由用户自定义的。</p><p>Kafka提供了消费者参数<code>partition.assignment.strategy</code>来进行配置，可选值如下：</p><ol><li>RangeAssignor：按照消费者总数和分区总数进行整除运算来获得一个跨度，然后将分区按照跨度进行平均分配，也是默认的分配策略。</li><li>RoundRobinAssignor：轮询分配</li><li>StickyAssignor：前面两种分配方式，都没有考虑分区和Consumer的状态，消费情况，以及之前的分配情况，这种分配结合前面两种状态来决定分配方式。</li></ol><p>当然也可以进行自定义分配方式，需要我们在Consumer代码里进行编写。</p><p>所以问题来了，为什么配置是在Consumer端？<br>你可能想到了，<strong>灵活配置！</strong>。</p><p>写到这儿，消费者协调器的存在就可以理解了，真正的分配其实并不是组协调器进行的，而是组协调器会在所有的Consumer中指定一个Leader，这个Leader就叫消费者协调器，真正的分配结果由这个Consumer来执行，消费者协调器把分配结果告诉组协调器，组协调器再通知给所有的消费者结果。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Kafka的是个复杂的系统，除了基本的Producer，Consumer，Broker外，为了实现完备的功能，Kafka中有许多重要的模块，本文梳理一下这些模块的划分，与他们负责的功能。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kafka指南" scheme="https://blog.lovezhy.cc/categories/Kafka%E6%8C%87%E5%8D%97/"/>
    
    
      <category term="Kafka" scheme="https://blog.lovezhy.cc/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka指南-源码导入Idea</title>
    <link href="https://blog.lovezhy.cc/2020/02/23/Kafka%E6%8C%87%E5%8D%97-%E6%BA%90%E7%A0%81%E5%AF%BC%E5%85%A5Idea/"/>
    <id>https://blog.lovezhy.cc/2020/02/23/Kafka%E6%8C%87%E5%8D%97-%E6%BA%90%E7%A0%81%E5%AF%BC%E5%85%A5Idea/</id>
    <published>2020-02-22T16:00:00.000Z</published>
    <updated>2020-02-29T14:26:36.194Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>虽然网上教程很多，但是我依然要写系列<br>因为我踩到的坑有的是网上没有遇到过的</p><a id="more"></a><h2 id="详细步骤"><a href="#详细步骤" class="headerlink" title="详细步骤"></a>详细步骤</h2><h3 id="克隆源码"><a href="#克隆源码" class="headerlink" title="克隆源码"></a>克隆源码</h3><p><code>git clone https://github.com/apache/kafka.git</code></p><p><strong>这个时候切记不能先用idea直接打开项目！</strong><br><strong>这个时候切记不能先用idea直接打开项目！</strong><br><strong>这个时候切记不能先用idea直接打开项目！</strong></p><h3 id="打包环境"><a href="#打包环境" class="headerlink" title="打包环境"></a>打包环境</h3><p>kafka自带了一些Gradle的Task，可以生成出导入Eclipse或者Idea配置。<br>在Kafka目录下执行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./gradlew jar</span><br><span class="line">./gradlew idea</span><br></pre></td></tr></table></figure><p>这个时候目录下会出现一个文件叫<code>kafka.ipr</code><br>在finder中双击这个文件，idea会自动打开并导入项目。<br><strong>注：也就是这个时候才会打开Idea</strong></p><h3 id="配置Gradle"><a href="#配置Gradle" class="headerlink" title="配置Gradle"></a>配置Gradle</h3><p>一般Idea打开会，右下角会弹出一个框，大致意思是：</p><blockquote><p>我们检测出这个是Gradle项目，需要导入Gradle的配置吗？</p></blockquote><p>这个时候，点击确认就行。</p><p>如果打开Idea啥也没发生，那么就需要我们自己打开文件<code>build.gradle</code><br>然后进行刷新之类的操作，具体我也忘了怎么操作的。</p><h3 id="修改配置"><a href="#修改配置" class="headerlink" title="修改配置"></a>修改配置</h3><p>一些配置的修改是比较重要的</p><ol><li>文件build.gradle<br>第一处修改：<br>找到<code>tasks.withType(ScalaCompile) {</code>这一行<br>修改<code>scalaCompileOptions.additionalParameters</code>的配置<figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">    scalaCompileOptions.additionalParameters = [</span><br><span class="line">      <span class="string">"-nowarn"</span>,  <span class="comment">//新增</span></span><br><span class="line">      <span class="string">"-deprecation"</span>,</span><br><span class="line">      <span class="string">"-unchecked"</span>,</span><br><span class="line">      <span class="string">"-encoding"</span>, <span class="string">"utf8"</span>,</span><br><span class="line">      <span class="string">"-Xlog-reflective-calls"</span>,</span><br><span class="line">      <span class="string">"-feature"</span>,</span><br><span class="line">      <span class="string">"-language:postfixOps"</span>,</span><br><span class="line">      <span class="string">"-language:implicitConversions"</span>,</span><br><span class="line">      <span class="string">"-language:existentials"</span>,</span><br><span class="line"><span class="comment">//      "-Xlint:constant",  //注释</span></span><br><span class="line"><span class="comment">//      "-Xlint:delayedinit-select",</span></span><br><span class="line"><span class="comment">//      "-Xlint:doc-detached",</span></span><br><span class="line"><span class="comment">//      "-Xlint:missing-interpolator",</span></span><br><span class="line"><span class="comment">//      "-Xlint:nullary-override",</span></span><br><span class="line"><span class="comment">//      "-Xlint:nullary-unit",</span></span><br><span class="line"><span class="comment">//      "-Xlint:option-implicit",</span></span><br><span class="line"><span class="comment">//      "-Xlint:package-object-classes",</span></span><br><span class="line"><span class="comment">//      "-Xlint:poly-implicit-overload",</span></span><br><span class="line"><span class="comment">//      "-Xlint:private-shadow",</span></span><br><span class="line"><span class="comment">//      "-Xlint:stars-align",</span></span><br><span class="line"><span class="comment">//      "-Xlint:type-parameter-shadow",</span></span><br><span class="line"><span class="comment">//      "-Xlint:unused"</span></span><br><span class="line">    ]</span><br></pre></td></tr></table></figure></li></ol><p>第二处修改：<br>还有<code>tasks.withType(JavaCompile) {</code>这一行<br>修改为<br><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">  tasks.withType(JavaCompile) &#123;</span><br><span class="line">    <span class="keyword">options</span>.encoding = <span class="string">'UTF-8'</span></span><br><span class="line"><span class="comment">//    options.compilerArgs &lt;&lt; "-Xlint:all"</span></span><br><span class="line">    <span class="comment">// temporary exclusions until all the warnings are fixed</span></span><br><span class="line"><span class="comment">//    options.compilerArgs &lt;&lt; "-Xlint:-rawtypes"</span></span><br><span class="line"><span class="comment">//    options.compilerArgs &lt;&lt; "-Xlint:-serial"</span></span><br><span class="line"><span class="comment">//    options.compilerArgs &lt;&lt; "-Xlint:-try"</span></span><br><span class="line"><span class="comment">//    options.compilerArgs &lt;&lt; "-Werror"</span></span><br><span class="line">    <span class="comment">// --release is the recommended way to select the target release, but it's only supported in Java 9 so we also</span></span><br><span class="line">    <span class="comment">// set --source and --target via `sourceCompatibility` and `targetCompatibility`. If/when Gradle supports `--release`</span></span><br><span class="line">    <span class="comment">// natively (https://github.com/gradle/gradle/issues/2510), we should switch to that.</span></span><br><span class="line">    <span class="keyword">if</span> (JavaVersion.current().isJava9Compatible())</span><br><span class="line">      <span class="keyword">options</span>.compilerArgs &lt;&lt; <span class="string">"--release"</span> &lt;&lt; minJavaVersion</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p><p><strong>上面两个修改主要是为了Idea启动时编译，会把一堆warn当做Error报出来，Gradle不给启动</strong></p><p>第三处修改：<br>找到<code>project(&#39;:core&#39;) {</code>这一行<br>下面会有一堆<br><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">dependencies</span> &#123;</span><br><span class="line">  <span class="keyword">compile</span> <span class="keyword">project</span>(<span class="string">':clients'</span>)</span><br><span class="line">  <span class="keyword">compile</span> libs.jacksonDatabind</span><br><span class="line">  <span class="keyword">compile</span> libs.jacksonModuleScala</span><br><span class="line">~~~</span><br></pre></td></tr></table></figure></p><p>这种配置<br>在<code>compileOnly libs.log4j</code>这一行的下面，加上<br><code>compile libs.slf4jlog4j</code></p><p><strong>这个修改主要是终端启动Kafka的时候日志打印不出来的问题</strong></p><blockquote><p>很多的网上的答案都是让自己把两个依赖加进去，但是我发现其实Kafka配置了两个依赖，但是却没有Compile，所以不需要自己加进去，只要加上这行配置就行</p></blockquote><ol><li>配置log4j文件<br>第一步：把config目录下的log4j.properties文件复制到core/src/main/resources目录下<br>需要创建rescources目录<br>如图所示：<br><img src="/images/Kafka源码导入Idea/log4j1.png" alt=""></li></ol><p><strong>并不是很多网上说的复制到/scala目录下</strong></p><p>第二步：修改log4j.properties文件<br>主要是把很多的<code>${kafka.logs.dir}</code>这种变量去掉，换成自己电脑上的绝对路径</p><h2 id="启动配置"><a href="#启动配置" class="headerlink" title="启动配置"></a>启动配置</h2><p>下面就是启动配置了，这个网上都有，我就直接复制一下</p><p><strong>首先得自己启动一个Zookeeper进程</strong></p><h3 id="Broker"><a href="#Broker" class="headerlink" title="Broker"></a>Broker</h3><p><img src="/images/Kafka源码导入Idea/Kafka.png" alt=""></p><h3 id="Consumer"><a href="#Consumer" class="headerlink" title="Consumer"></a>Consumer</h3><p><strong>Program arguments可根据自己的情况修改</strong><br><img src="/images/Kafka源码导入Idea/consumer.png" alt=""></p><h3 id="produer"><a href="#produer" class="headerlink" title="produer"></a>produer</h3><p><strong>Program arguments可根据自己的情况修改</strong><br><img src="/images/Kafka源码导入Idea/producer.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;虽然网上教程很多，但是我依然要写系列&lt;br&gt;因为我踩到的坑有的是网上没有遇到过的&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kafka指南" scheme="https://blog.lovezhy.cc/categories/Kafka%E6%8C%87%E5%8D%97/"/>
    
    
      <category term="Kafka" scheme="https://blog.lovezhy.cc/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka指南-时间轮实现</title>
    <link href="https://blog.lovezhy.cc/2020/01/11/Kafka%E6%8C%87%E5%8D%97-%E6%97%B6%E9%97%B4%E8%BD%AE%E5%AE%9E%E7%8E%B0/"/>
    <id>https://blog.lovezhy.cc/2020/01/11/Kafka%E6%8C%87%E5%8D%97-%E6%97%B6%E9%97%B4%E8%BD%AE%E5%AE%9E%E7%8E%B0/</id>
    <published>2020-01-10T16:00:00.000Z</published>
    <updated>2020-02-29T14:26:48.032Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Kafka延迟任务的实现</p><a id="more"></a><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>延迟任务的实现，一般是利用有序队列，按照执行时间的顺序排列，然后有个线程不断的去取第一个元素，如果到了需要执行的时间，就去执行。</p><p>伪代码：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Delay</span> </span>&#123;</span><br><span class="line">    Queue&lt;Comparable&gt; taskQueue;</span><br><span class="line">    </span><br><span class="line">    <span class="function">func <span class="title">add</span><span class="params">(Comparable task)</span> </span>&#123;</span><br><span class="line">        taskQueue.add(task);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function">func <span class="title">pollAndRun</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">                var task = taskQueue.peek();</span><br><span class="line">                <span class="keyword">if</span> (task.expireTime &lt;= System.currentTime) &#123;</span><br><span class="line">                    run(taskQueue.poll());</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    Thread.sleep(task.expireTime - System.currentTime);</span><br><span class="line">                &#125;</span><br><span class="line">        &#125; </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><strong>注意：这里的伪代码不完善，在add方法中，一般来说在某种情况下要interrupt执行pollAndRun的线程。</strong></p><p>目前聚焦的主要问题是Queue是怎么个实现法。<br>在Java中有优先权队列可以进行排序，底层是基于最小堆做的，插入和删除的时间复杂度是O(logn)</p><p>当然正常情况下，这种实现可以了，Java中的标准实现也是这样。</p><p>但是呢，Kafka中有大量的<strong>低延迟</strong>的任务，如果都用最小堆去做，难免性能不太好<br>所以Kafka中实现了时间轮的算法，将插入和删除的时间复杂度降低到了O(1)。</p><p>下面细讲下实现：</p><h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><p>源码路径在：<code>package kafka.utils.timer</code>下。</p><h3 id="TimerTask"><a href="#TimerTask" class="headerlink" title="TimerTask"></a>TimerTask</h3><p>Task是队列中的执行元素</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">trait TimerTask extends Runnable &#123;</span><br><span class="line">    val delayMs: Long </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>实现了Runnable接口，delayMs是指的需要被执行的时间戳，不是相对时间</p><h3 id="TimerTaskList"><a href="#TimerTaskList" class="headerlink" title="TimerTaskList"></a>TimerTaskList</h3><p>看名字就知道是存储Task的集合类</p><p>但是其实它的定义并没有我开始想的那么简单</p><p>TimerTask在TimerTaskList内部的存储形式是双向链表</p><p>所以TimerTask其实被TimerTaskEntry的类包装了一层，增加了Prev和Next指针。</p><p><img src="/images/Kafka时间轮/TimerTaskList.png"></p><p>但是注意哦，这里虽然TimerTask实现了Comparable接口，但是TimerTaskList内部其实就是个简单的双向列表，并不会根据TimerTask的expireTime进行排序。</p><p>恰恰相反，TimerTaskList也实现了Comparable接口。</p><p>在TimerTaskList内部，有一个变量</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[<span class="keyword">this</span>] val expiration = <span class="keyword">new</span> AtomicLong(-<span class="number">1L</span>)</span><br></pre></td></tr></table></figure><p>从名字中看出其实是存放的是到期时间，TimerTask有过期时间我们可以理解，那么为什么TimerTaskList也有个过期时间？</p><p>这个过期时间是怎么定的，有什么用？</p><h3 id="TimingWheel"><a href="#TimingWheel" class="headerlink" title="TimingWheel"></a>TimingWheel</h3><p>来了，时间轮最主要的数据结构来了。</p><p><img src="/images/Kafka时间轮/TimerWheel.png"></p><p>首先，看图中，模仿了一个钟表的运行图。<br>每tick一下，就把当前指针指向下一个格子。<br>其中每个格子对应着一个TimerTaskList</p><p>格子在Kafka中叫bucket<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val buckets = Array.tabulate[TimerTaskList](wheelSize) &#123; _ =&gt; <span class="keyword">new</span> TimerTaskList(taskCounter) &#125;</span><br></pre></td></tr></table></figure></p><p>每一格代表的时间叫TickMs，整个表最长的跨度叫Interval。</p><p>如果TickMs=5，Bucket=4，就表示这个时间轮有4个格子，总共能执行20ms内的延迟任务，同时TickMs也就是该时间轮保证的延迟任务的延迟执行的单位。</p><p>什么意思呢？就是说如果一个任务是2ms后执行，一个是4ms后执行，但是整个时间轮的TickMs是5ms，那么这两个任务在时间轮看来其实是没区别，是同时执行。</p><p>所以时间轮的TickMs最小，时间就越精确。</p><p>如果延迟时间超过了该时间轮的Interval怎么办？</p><p>比如执行50ms后才运行的任务，则需要建立跨度更大的时间轮。</p><p>而Kafka中会自动建立跨度更大的时间轮，叫overflowWheel，<strong>更大的时间轮的TickMs是下一层的Interval</strong>。</p><p>看到这里，其实可以解答TimerTaskList中的expiration有什么用了。</p><p>这里的expiration其实就是整个TimerTaskList的过期时间，是TickMs的整数倍</p><p>与在TimerTaskList中每个Task的具体延迟时间关系是</p><p><code>TimerTaskList.expiration &lt;= Task.expiration &lt;= TimerTaskList.expiration + TickMs</code></p><p>在Kafka中，默认的时间轮配置TickMs=1，Bucket=20，也就是20MS内的延迟任务。</p><h2 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h2><p>讲完了数据结构，下面需要讲怎么运行了。<br>TimingWheel的运行，交给了Timer来操作。<br>Timer有两个方法<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//往时间轮中加入任务</span></span><br><span class="line"><span class="function">def <span class="title">add</span><span class="params">(timerTask: TimerTask)</span></span>&#123;&#125;</span><br><span class="line"><span class="comment">//驱动时间轮向前Tick</span></span><br><span class="line"><span class="function">def <span class="title">advanceClock</span><span class="params">(timeoutMs: Long)</span></span>&#123;&#125;</span><br></pre></td></tr></table></figure></p><h3 id="菜鸡的猜想方案"><a href="#菜鸡的猜想方案" class="headerlink" title="菜鸡的猜想方案"></a>菜鸡的猜想方案</h3><p>让我们暂时脱离源码，猜猜时间轮怎么运行的。</p><p><img src="/images/Kafka时间轮/tick.png" alt=""></p><p>正常来说，我们把任务分到具体的Bucket中，每隔一个TickMs，将当前的指针向下运行一格。</p><p>找到这一格中的TimerTaskList，将里面的任务全部拿出来run一遍。</p><p>伪代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">List&lt;TimerTaskList&gt; buckets;</span><br><span class="line"><span class="keyword">int</span> nextBucket;</span><br><span class="line"><span class="function">func <span class="title">tick</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  var timerTaskList = buckets.get(nextBucket % buckets.length)</span><br><span class="line">  <span class="keyword">if</span> (timerTaskList.expiration &lt;= System.currentTime) &#123;</span><br><span class="line">    timerTaskList.timerTaskEntrys.foreach(entry -&gt; entry.run()));</span><br><span class="line">    timerTaskList.timerTaskEntrys.foreach(TimerTaskList::remove);</span><br><span class="line">    nextBucket++;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在add元素的时候，先需要判断当前的时间轮是否能承载延迟时间，如果不能，则建立overflowWheel，加到overflowWheel中。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">List&lt;TimerTaskList&gt; buckets;</span><br><span class="line"><span class="function">func <span class="title">add</span><span class="params">(taskEntry)</span> </span>&#123;</span><br><span class="line">  var targetBucketId = (taskEntry.expiration - System.time) / tickMs + nextBucket;</span><br><span class="line">  var timerTaskList = buckets.get(targetBucketId % buckets.length)</span><br><span class="line">  timerTaskList.add(taskEntry);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>看起来非常完美，但是问题来了，这个tick函数，怎么个运行策略呢？</p><p>如果要要跑的非常精确的话，必须要有个线程去单独驱动是肯定的，线程里还得这么跑</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//1</span></span><br><span class="line"><span class="function">func <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">    timer.tick()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//2</span></span><br><span class="line"><span class="function">func <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">    timer.tick()</span><br><span class="line">    sleep(timer.tickms)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>有方案1和方案2两种，第二种肯定是有问题的，如果出现了FullGC的情况，那么整个时间轮就不准了。</p><p>只能选择第一种方案，那么第一种肯定是不行的，这样CPU就是100%了，即使时间轮中没有任何任务，很多时间都是无用功，太浪费CPU了。</p><p>其实这里还有个很严重的问题，我们没有考虑overflowWheel。</p><p>正常情况下，在overflowWheel中的任务，如果已经到了下一层TimingWheel的interval范围内，是需要手动放到下一层的。</p><p>如果是这种实现的话，对于overflowWheel的处理会更加的复杂。</p><h3 id="Kafka中的实现"><a href="#Kafka中的实现" class="headerlink" title="Kafka中的实现"></a>Kafka中的实现</h3><p>菜鸡的猜想方案是不行的，面试都是直接挂的节奏。</p><p>所以这种思路是不成立的，那么我们能不能换个思路呢？</p><p>我们沿用最基本的最小堆来实现延迟任务的思路，建立一个优先权队列</p><p>但是队列中的元素不再是TimerTask了，而是TimerTaskList，相比较最原始的方案，队列中的元素少了一个数量级。</p><p>这样，每次单独的线程进行Tick的时候，选出最早需要执行的TimerTaskList，如果还没到执行时间，就可以进行Sleep，而不是占满CPU。</p><p>所以在TimingWheel中增加一个数据结构</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">var queue = <span class="keyword">new</span> PriorityQueue&lt;TimerTaskList&gt;()</span><br></pre></td></tr></table></figure><p>每次进行add时，除了把TaskEntry添加到TimerTaskEntry中，还将TimerTaskList添加到queue中。</p><p>这样线程的驱动函数就是这么写：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">func <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">    var timerTaskList = timer.queue.poll();</span><br><span class="line">    <span class="keyword">if</span> (timerTaskList.expiration &lt; System.time) &#123;</span><br><span class="line">      sleep(System.time - timerTaskList.expiration);</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>虽然也使用了插入是O(logn)的最小堆结构，但是堆中元素不再是全量的Task了，而是TaskList，所以时间复杂度其实类似于O(1)了。</p><p>那么对于overflowWheel里面的Task怎么处理呢？</p><p>很简单，和第一层的timingWheel一样，将overFlowWheel中的TimerTaskList也加到queue中</p><p>但是从Queue取出的时候，就不是立即执行了，而是再走一遍add程序</p><p>下面是源码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">//类似于源代码中nextBuckets的作用，这里是绝对时间，startMs是时间轮的开始的绝对时间，这里计算成tickMs的整数倍</span><br><span class="line">private[this] var currentTime = startMs - (startMs % tickMs)</span><br><span class="line"></span><br><span class="line">//向时间轮中加入任务</span><br><span class="line">def add(timerTaskEntry: TimerTaskEntry): Boolean = &#123;</span><br><span class="line">   val expiration = timerTaskEntry.expirationMs</span><br><span class="line">   if (timerTaskEntry.cancelled) &#123;</span><br><span class="line">     //如果任务已经取消，添加失败，可以直接实行</span><br><span class="line">     false</span><br><span class="line">   &#125; else if (expiration &lt; currentTime + tickMs) &#123;</span><br><span class="line">     //如果已经到执行时间，那么也是可以直接执行</span><br><span class="line">     false</span><br><span class="line">   &#125; else if (expiration &lt; currentTime + interval) &#123;</span><br><span class="line">           //这里其实还挺难理解的，如果我们按照钟表的概念，指针每隔一段时间去转动一下，就很难理解下面的代码</span><br><span class="line">           //这里其实就是每隔tickMs，指针不转，整个表顺时针转tickMs圈</span><br><span class="line">     val virtualId = expiration / tickMs</span><br><span class="line">     val bucket = buckets((virtualId % wheelSize.toLong).toInt)</span><br><span class="line">     bucket.add(timerTaskEntry)</span><br><span class="line"></span><br><span class="line">     if (bucket.setExpiration(virtualId * tickMs)) &#123;</span><br><span class="line">       //如果Bucket的失效时间设置成功，就把这个TimerTaskList加入到queue中</span><br><span class="line">       queue.offer(bucket)</span><br><span class="line">     &#125;</span><br><span class="line">     true</span><br><span class="line">   &#125; else &#123;</span><br><span class="line">     //放不下，建立overflowWheel，overflowWheel和当前timingWheel公用一个queue</span><br><span class="line">     if (overflowWheel == null) addOverflowWheel()</span><br><span class="line">     overflowWheel.add(timerTaskEntry)</span><br><span class="line">   &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>timingWheel的advanceClock代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def advanceClock(timeMs: Long): Unit = &#123;</span><br><span class="line">  if (timeMs &gt;= currentTime + tickMs) &#123;</span><br><span class="line">    currentTime = timeMs - (timeMs % tickMs)</span><br><span class="line">    if (overflowWheel != null) overflowWheel.advanceClock(currentTime)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>主要就是调整下currentTime，其实currentTime在有了queue之后，就没有其他作用了，主要就是在add方法中拦住即将过期或者已经过期的任务</p><p>下面是伪代码中的run方法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">def advanceClock(timeoutMs: Long): Boolean = &#123;</span><br><span class="line">   var bucket = delayQueue.poll(timeoutMs, TimeUnit.MILLISECONDS)</span><br><span class="line">   if (bucket != null) &#123;</span><br><span class="line">     writeLock.lock()</span><br><span class="line">     try &#123;</span><br><span class="line">       while (bucket != null) &#123;</span><br><span class="line">         timingWheel.advanceClock(bucket.getExpiration())</span><br><span class="line">         //这里不能把bucket中的任务全部执行，因为可能是overFlowWheel中的TimerTaskList，还没到执行时间，直接再走一遍add程序</span><br><span class="line">         bucket.flush(reinsert)</span><br><span class="line">         bucket = delayQueue.poll()</span><br><span class="line">       &#125;</span><br><span class="line">     &#125; finally &#123;</span><br><span class="line">       writeLock.unlock()</span><br><span class="line">     &#125;</span><br><span class="line">     true</span><br><span class="line">   &#125; else &#123;</span><br><span class="line">     false</span><br><span class="line">   &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>注意一下这里的delayQueue，其中poll方法返回的是过期的任务，并不是集合中第一个元素。</p><p>也就是说，即使queue中元素，但是没有元素要过期，返回的也是null。</p><p>当时作者在哪儿晕了半天。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;Kafka延迟任务的实现&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kafka指南" scheme="https://blog.lovezhy.cc/categories/Kafka%E6%8C%87%E5%8D%97/"/>
    
    
      <category term="kafka" scheme="https://blog.lovezhy.cc/tags/kafka/"/>
    
      <category term="TimeWheel" scheme="https://blog.lovezhy.cc/tags/TimeWheel/"/>
    
      <category term="时间轮" scheme="https://blog.lovezhy.cc/tags/%E6%97%B6%E9%97%B4%E8%BD%AE/"/>
    
  </entry>
  
  <entry>
    <title>HotSpot原理指南-分层编译</title>
    <link href="https://blog.lovezhy.cc/2020/01/04/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-%E5%88%86%E5%B1%82%E7%BC%96%E8%AF%91/"/>
    <id>https://blog.lovezhy.cc/2020/01/04/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-%E5%88%86%E5%B1%82%E7%BC%96%E8%AF%91/</id>
    <published>2020-01-03T16:00:00.000Z</published>
    <updated>2020-02-29T14:36:30.467Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>HotSpot的初衷是将运行环境分为Client和Server，并且为他们定制了不同的JIT策略以及不同的JIT编译器（C1和C2）。</p><p>设计出ClientMode的年代，个人PC的性能还比较低，无论是CPU资源还是内存资源都比较稀少且价格较高，所以C1节约资源的快速编译是很有必要的。</p><p>随着时代的发展，个人计算机的配置在慢慢升级，同时价格也在慢慢降低，在这种环境下，ClientMode并不是那么适用了，所以HotSpot也就慢慢放弃了ClientMode，在个人计算机上默认采用Server模式。</p><a id="more"></a><h2 id="Oracle的想法"><a href="#Oracle的想法" class="headerlink" title="Oracle的想法"></a>Oracle的想法</h2><p>所有的场景都默认使用Server模式自然是没有什么问题的，但是Oracle并不甘心（作者脑补的），主要不甘心在两个方面：</p><ul><li>默认使用Server模式，那么相当于放弃了开发了很久的C1编译器</li><li>由于Server模式JIT编译策略问题，会导致应用的Warm-Up时间较长</li></ul><p>那么有没有什么方法可以结合C1和C2呢？</p><p>比如用C1解决Warm-Up时间过长的问题。</p><h2 id="分层编译"><a href="#分层编译" class="headerlink" title="分层编译"></a>分层编译</h2><p>前面提到过，Oracle想用C1解决Server模式中Warm-Up时间过长的问题，于是引入了分层编译的概念。</p><p>如下图所示：</p><p><img src="/images/HotSpot原理指南-分层编译/c1c2.png" alt=""></p><p>解释阶段主要是为了收集运行时Profile，Profile收集的越多，对JIT编译出的代码性能帮助越大。</p><p>先看上半部分图，如果我们采用传统的ServerMode运行，在一段时间X内，只能收集300份Profile，然后将这些Profile丢给C2去进行编译。</p><p>我们可以减少解释模式的运行时间，尽快用C1把字节码编译成机器码，用机器码去收集Profile。这就如下半部分图所示：</p><p>收集了100份Profile后，运行C1编译后的代码，在一段时间内，可以收集到更多的Profile。</p><p>上面是限制了收集Profile的时间是一定的，如果我们反过来，<strong>收集Profile的样本数是一定的</strong>：</p><ul><li>传统的Server模式，可能需要花费更多的时间进行收集到指定次数的样本</li><li>先利用C1进行代码编译，提升方法的运行速度，相对可以花费更少的时间进行收集</li></ul><p>如上的思想就是引入C1解决传统的ServerMode热身时间较少的问题，也就是分层编译：先采用C1进行编译，再采用C2进行编译。</p><p>具体的时间对比如下两张图所示：只使用C2 VS 分层编译</p><p><img src="/images/HotSpot原理指南-分层编译/only-c2.png" alt=""><br><img src="/images/HotSpot原理指南-分层编译/tier.png" alt=""></p><h2 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h2><p>分层编译在JDK7中就引入了，但是默认是不开启的</p><p>如果运行环境还是JDK7，可以使用<code>-XX:+TieredCompilation</code>开启</p><p>在JDK8中，分层编译就默认开启了，如果要关闭它，可以使用<code>-XX:-TieredCompilation</code>关闭</p><h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><p>正常的话，只要理解到上面就够了，分层大概分为两层，先是C1，然后是C2。</p><p>但是事实上，我们如果查看以Tier开头的HotSpot参数的话，会发现其包含的参数很多很多</p><p><img src="/images/HotSpot原理指南-分层编译/参数.png" alt=""></p><p>笔者第一次搜索出来时，实在是吃了一惊。<br>经过研究，其实发现分层编译，并不是分了两层，而是足足分了<strong>4</strong>层。</p><ul><li>第0层：解释阶段</li><li>第1-3层：C1编译<ul><li>第1层：C1编译出的<strong>不收集任何Profile</strong>的机器码</li><li>第2层：C1编译出的<strong>仅仅收集方法调用计数</strong>的机器码</li><li>第3层：C1编译出的<strong>收集全部Profile</strong>的机器码</li></ul></li><li>第4层：C2编译</li></ul><p>可以看到，在C1编译的阶段，还拆分成了三个小的阶段。<br>同时，对于这三个小的阶段，需要理解的是，<strong>运行上并不是递进关系</strong>，也就是说并不是先运行第1层，再运行第2层，再运行第3层。具体怎么运行，其实和很多因素有关。<br>我们先看看有哪些经典的分层流程：</p><p><img src="/images/HotSpot原理指南-分层编译/4个阶段.png" alt=""><br>如上图所示。</p><ul><li>流程1：正常的方法的编译流程，先是解释执行，然后直接跳到第3阶段，也就是C1编译出的收集全部Profile的机器码。然后再跳到第4层，也就是C2编译。深色的框表示是编译的终止阶段。</li><li>流程2：但是，如果第3层的等待队列太长，可能就先提交到第2层进行编译，等待一段时间后，再提交给第3层</li><li>流程3：如果该方法比较简单，是个Trivial方法，比如Getter方法，这种方法去收集Profile其实没有什么Profile，给C2去进行编译纯属于浪费资源，所以提交给第3层后，直接给第1层，然后终止。</li><li>流程4：同样也是Trivial方法，如果在解释阶段就发现其比较简单，也可以直接提交给第1层编译</li></ul><p>以上是一些经典的流程，还有一些流程，比如从解释阶段可以直接提交给C2等。</p><p>所以，虽说是分层编译，但是具体的编译流程是不确定的，这个各个编译器的状态以及方法的属性有关。</p><h2 id="C1和C2编译线程数"><a href="#C1和C2编译线程数" class="headerlink" title="C1和C2编译线程数"></a>C1和C2编译线程数</h2><p>各个编译的状态，最简单的就是负责编译的线程数<br>HotSpot分配给C1和C2编译器的线程数，和<strong>指定的启动参数</strong>以及<strong>机器的核心数</strong>有关。</p><p>启动参数：影响线程数的参数有CICompilerCount和CICompilerCountPerCPU两个，默认值如下，一般不会去改这些<br><img src="/images/HotSpot原理指南-分层编译/启动参数.png" alt=""></p><p>有了参数之后，具体的分配代码如下：<br><img src="/images/HotSpot原理指南-分层编译/启动参数2.png" alt=""></p><p>简单聊聊分配策略：</p><ul><li>C1+C2的总的线程数：log2(log2(CoreNum)) * 3 / 2</li><li>C1 / C2 = 1 / 2</li><li>C1和C2至少有一个线程</li></ul><p>下面表格简单显示了一些常见情况</p><table><thead><tr><th>CPU Core</th><th>C1</th><th>C2</th></tr></thead><tbody><tr><td>4</td><td>1</td><td>2</td></tr><tr><td>8</td><td>1</td><td>3</td></tr><tr><td>16</td><td>4</td><td>8</td></tr><tr><td>32</td><td>5</td><td>10</td></tr><tr><td>64</td><td>6</td><td>12</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;HotSpot的初衷是将运行环境分为Client和Server，并且为他们定制了不同的JIT策略以及不同的JIT编译器（C1和C2）。&lt;/p&gt;
&lt;p&gt;设计出ClientMode的年代，个人PC的性能还比较低，无论是CPU资源还是内存资源都比较稀少且价格较高，所以C1节约资源的快速编译是很有必要的。&lt;/p&gt;
&lt;p&gt;随着时代的发展，个人计算机的配置在慢慢升级，同时价格也在慢慢降低，在这种环境下，ClientMode并不是那么适用了，所以HotSpot也就慢慢放弃了ClientMode，在个人计算机上默认采用Server模式。&lt;/p&gt;
    
    </summary>
    
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/categories/HotSpot/"/>
    
    
      <category term="Java" scheme="https://blog.lovezhy.cc/tags/Java/"/>
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/tags/HotSpot/"/>
    
      <category term="JIT" scheme="https://blog.lovezhy.cc/tags/JIT/"/>
    
      <category term="JVM" scheme="https://blog.lovezhy.cc/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>HotSpot原理指南-JIT触发条件</title>
    <link href="https://blog.lovezhy.cc/2019/12/14/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-JIT%E8%A7%A6%E5%8F%91%E6%9D%A1%E4%BB%B6/"/>
    <id>https://blog.lovezhy.cc/2019/12/14/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-JIT%E8%A7%A6%E5%8F%91%E6%9D%A1%E4%BB%B6/</id>
    <published>2019-12-13T16:00:00.000Z</published>
    <updated>2020-02-29T14:36:09.667Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>通过前面我们知道，对于每个方法，HotSpot都维护两个计数器</p><ul><li>Invocation Counter：方法被调用次数，每被调用一次都会+1</li><li>BackEdge Counter：专业的说法就是字节码在执行时的回跳次数。通俗点说就是，在For或者While循环中，每执行一次，都会+1。</li></ul><p>并且我们知道对于一个方法，JIT有两种不同的编译方式</p><ul><li>完整的原方法编译，就是把原本的方法逻辑进行编译。入参和运行结果和解释运行都是一致的。</li><li>OSR编译，OSR后的方法入参以及运行流程和原方法有较大差异。</li></ul><p>很自然得我们就会想到，其实计数器和编译方式之间是有对应关系的。</p><ul><li>Invocation Counter -&gt; 完整的原方法编译</li><li>BackEdge Counter  -&gt; OSR编译</li></ul><p>当对应的方法计数器达到一定的次数，就会触发响应的编译</p><a id="more"></a><h2 id="编译流程图"><a href="#编译流程图" class="headerlink" title="编译流程图"></a>编译流程图</h2><p>完整的编译流程如下：</p><p><img src="/images/HotSpot原理指南-JIT触发条件/编译流程.png" alt=""></p><p><strong>注：该图引自R大的JVM分享PPT，如有侵权，请联系我删除</strong></p><p>图中的流程非常的清晰，这里提几个小点：</p><ul><li><p>问：对于同一方法，是否两种编译方式都可能会执行？</p><p>答：是的，而且两种代码可能同时被运行，但是正常情况下，只要运行的够久，都会运行完整的原方法编译后的代码。</p></li><li><p>问：具体哪种编译方式先触发？</p><p>答：其实无法确定，看哪个计数器先达到阈值</p></li></ul><h2 id="触发阈值"><a href="#触发阈值" class="headerlink" title="触发阈值"></a>触发阈值</h2><p>可能你还想更直观的了解下两个计数器的触发阈值到底是多少。</p><p>在HotSpot源码中，有这样两个参数：</p><ul><li><blockquote><p>intx CompileThreshold = 10000</p><p>globals.hpp &gt; ”number of interpreted method invocations before (re-)compiling” </p></blockquote></li><li><blockquote><p>intx BackEdgeThreshold = 100000</p><p>globals.hpp &gt; “Interpreter Back edge threshold at which an OSR compilation is invoked”</p></blockquote></li></ul><p>数值可能根据不同的发行版本略有不同，上面的数值是JDK7版本中的。</p><p>那么你可能以为</p><ul><li>当Invocation Counter &gt; Compile Threshold时，就会触发原来方法的JIT</li><li>当BackEdge Counter &gt; BackEdge Threshold时，就会触发方法的OSR编译</li></ul><p>但是事实并不是如此。</p><p>问题出在哪儿呢？难道官方的定义还会有错吗？</p><p>是的，问题出在BackEdgeThreshold上，虽然HotSpot中确实定义了该参数，描述中似乎也证实了该参数的作用，但是这个参数并没有实际使用过。</p><p>对于BackEdgeThreshold的计算，是另外一套公示。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (ProfileInterpreter) &#123;</span><br><span class="line">  InterpreterBackwardBranchLimit = </span><br><span class="line">                 (CompileThreshold * (OnStackReplacePercentage - InterpreterProfilePercentage)) / <span class="number">100</span>;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  InterpreterBackwardBranchLimit = </span><br><span class="line">                ((CompileThreshold * OnStackReplacePercentage) / <span class="number">100</span>) &lt;&lt; number_of_noncount_bits;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>首先解释下<code>ProfileInterpreter</code>参数，这个参数也是在HotSpot中定义的，之前在文章<code>HotSpot原理指南-C1和C2介绍</code>中也讲解过，就是是否在运行时收集方法的Profile信息，这个字段在Server模式默认是开启的。</p><p>所以大部分情况下，除非你的计算机比较老，都会根据第一个公示进行计算</p><p><code>(CompileThreshold * (OnStackReplacePercentage - InterpreterProfilePercentage)) / 100</code></p><p>其中<strong>OnStackReplacePercentage</strong>默认值是140，<strong>InterpreterProfilePercentage</strong>默认值是33。</p><p>由此我们可以计算出真实的BackEdge Invocation阈值大概是10700左右。</p><h2 id="衰减"><a href="#衰减" class="headerlink" title="衰减"></a>衰减</h2><p>假如方法计数器不会根据时间进行衰减的话，那么只要服务器运行的时间足够长，再罕见被调用的函数，也会触发到阈值，然后被JIT编译。</p><p>这显然是不合理的，因为我们知道JIT后的机器码数据，还是会保存在内存中的，这样相当于一段逻辑在内存中又保存了字节码，又保存了一份机器码，十分的浪费内存。</p><p>所以对于Invocation Counter而言，经过一段时间，个数就会进行减少。</p><p>具体的减少逻辑，读者有兴趣的可以自己去探索。</p><p>但是注意：对于BackEdge Counter，是不会作衰减的。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;通过前面我们知道，对于每个方法，HotSpot都维护两个计数器&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Invocation Counter：方法被调用次数，每被调用一次都会+1&lt;/li&gt;
&lt;li&gt;BackEdge Counter：专业的说法就是字节码在执行时的回跳次数。通俗点说就是，在For或者While循环中，每执行一次，都会+1。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;并且我们知道对于一个方法，JIT有两种不同的编译方式&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;完整的原方法编译，就是把原本的方法逻辑进行编译。入参和运行结果和解释运行都是一致的。&lt;/li&gt;
&lt;li&gt;OSR编译，OSR后的方法入参以及运行流程和原方法有较大差异。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;很自然得我们就会想到，其实计数器和编译方式之间是有对应关系的。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Invocation Counter -&amp;gt; 完整的原方法编译&lt;/li&gt;
&lt;li&gt;BackEdge Counter  -&amp;gt; OSR编译&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当对应的方法计数器达到一定的次数，就会触发响应的编译&lt;/p&gt;
    
    </summary>
    
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/categories/HotSpot/"/>
    
    
      <category term="Java" scheme="https://blog.lovezhy.cc/tags/Java/"/>
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/tags/HotSpot/"/>
    
      <category term="JIT" scheme="https://blog.lovezhy.cc/tags/JIT/"/>
    
  </entry>
  
  <entry>
    <title>HotSpot原理指南-OSR是什么</title>
    <link href="https://blog.lovezhy.cc/2019/11/30/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-OSR%E6%98%AF%E4%BB%80%E4%B9%88/"/>
    <id>https://blog.lovezhy.cc/2019/11/30/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-OSR%E6%98%AF%E4%BB%80%E4%B9%88/</id>
    <published>2019-11-29T16:00:00.000Z</published>
    <updated>2020-02-29T14:36:16.869Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>前面我们讲解了C1和C2的基本知识，但是我们还未触及一个核心的策略，就是<strong>什么时候触发即使编译</strong>，也就是<strong>when</strong>的问题。</p><p>对于when的问题，相信大家多多少少都大概知道，每个方法都会有一个调用次数的计数器，当这个计数器的次数到达一定的次数时，就会被认为是热点方法，继而触发JIT编译。</p><p>但是本文要科普另外一种触发条件，和方法计数器类似。</p><a id="more"></a><h2 id="方法计数器的问题"><a href="#方法计数器的问题" class="headerlink" title="方法计数器的问题"></a>方法计数器的问题</h2><p>大部分人看来，维护一个方法被调用次数计数器当然是一个很完美的方案</p><p>但是有一类方法，即使在我们认知范围内，属于热点方法，但是却无法享受到这个计数器的好处。</p><p>如下代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OSRExample</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">200000</span>; i++) &#123;</span><br><span class="line">            <span class="comment">//do a lot of things</span></span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(sum);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在Main函数中，有一个循环，在循环中并没有调用某个方法，而是一直在线性执行一些逻辑。</p><p>假如我们把循环中的逻辑看做一个函数，这个函数肯定是热点函数，需要进行JIT编译的，但是在这种场景下，并不是一个函数，也就是无法进行JIT。</p><p>如果JIT无法处理这种情况，将是非常可惜的。</p><h2 id="Hot-Loop优化"><a href="#Hot-Loop优化" class="headerlink" title="Hot Loop优化"></a>Hot Loop优化</h2><p>但是如果我们构造一个上面的代码的情况，并且使用计数器给每次循环的执行时间进行计时。</p><p>会发现下面这张时间和次数的图</p><p><img src="/images/HotSpot原理指南-OSR是什么/hotLoop耗时.png" alt=""></p><p>从图中我们可以看出，大概在150次的时候，整个Loop的耗时突发的大大降低。</p><p>说明在HotSpot的JIT中，是可以处理这种情况的。</p><p>那么HotSpot究竟是怎么做的呢？</p><p>前面我们提到过，如果在Loop中调用的是方法，将不会存在上述的问题，但是实际的情况并不是调用的方法。</p><p>那么，我们能不能，把它包装成一个函数呢？</p><p>举个例子，原方法如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OSRExample</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">20000</span>; i++) &#123;</span><br><span class="line">            sum += i;</span><br><span class="line">          sum *= sum;</span><br><span class="line">          sum |= sum;</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(sum);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们把它改成如下的方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OSRExample</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">20000</span>; i++) &#123;</span><br><span class="line">sum = doLoop(sum);</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(sum);</span><br><span class="line">    &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">doLoop</span><span class="params">(<span class="keyword">int</span> sum)</span> </span>&#123;</span><br><span class="line">      sum += i;</span><br><span class="line">      sum *= sum;</span><br><span class="line">      sum |= sum;</span><br><span class="line">      <span class="keyword">return</span> sum;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样可以不可以呢？</p><p>当然是可以的。</p><p>但是！这是作者的猜测，HotSpot真实的情况并不是这样。</p><p>事实上，这种割裂整个main方法，动态把一部分代码进行修改的操作似乎消耗太大了，性价比并不高。</p><p>HotSpot并不会把Loop的内容动态生成一个函数，然后对该函数进行JIT。</p><p>而是对包含这个Loop的<strong>整个方法进行了JIT</strong>。</p><p>什么？对整个方法进行JIT？</p><p>要知道，这个方法在运行中啊，可能再也不会运行第二次，对整个方法进行JIT有什么意义呢？</p><p>稍安勿躁，虽然对整个方法进行了JIT，但是JIT后的代码和原来的函数其实还是有区别的。</p><p>如果我们需要将运行到一半的函数，从一个源代码替换到另外一个源代码，遇到的问题是什么呢？</p><p>首先，这个方法的循环执行到一半，这个i的具体数值肯定不是0了，是一个不可预测的值。</p><p>同时这个sum的值，肯定也是一个不好预测的值。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">20000</span>; i++) &#123;</span><br><span class="line">sum = doLoop(sum);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果要进行替换，需要把替换时的i和sum的值记录下来，那么替换后的源代码大概就长这样</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">public static void main#jit(int i, int sum) &#123;</span><br><span class="line"><span class="keyword">for</span> (; i &lt; <span class="number">20000</span>; i++) &#123;</span><br><span class="line">        sum += i;</span><br><span class="line">      sum *= sum;</span><br><span class="line">      sum |= sum;</span><br><span class="line">    &#125;</span><br><span class="line">    System.out.println(sum);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>没错！把运行中动态的值作为参数传给JIT后的函数，就是HotSpot的JIT对于这种HotLoop的优化。</p><h2 id="OSR"><a href="#OSR" class="headerlink" title="OSR"></a>OSR</h2><p>OSR的全称是On-Stack-Replacement。也就是栈上替换。</p><p>从上一节我们了解的可以知道，对于main函数，JIT进行编译的时候，直接把运行中的main函数源代码进行了替换，替换成了修改后的main函数。那么之前的main函数栈帧其实就完全失效了，被替换成了新的函数的栈帧。</p><p>这种JIT编译的方式就叫OSR编译。</p><p>这种栈上替换的方式其实并不是HotSpot独有的，很多其他的语言中也有这样的优化，如V8。</p><h2 id="后续问题"><a href="#后续问题" class="headerlink" title="后续问题"></a>后续问题</h2><p>OSR能够解决HotLoop的优化问题，但是其实在HotSpot中还是有几个值得深究的点。</p><ol><li><p>如果这个main函数方法非常大，Loop只是很小的一部分，那么把整个函数进行JIT编译的性价比就值得商榷了。核心问题其实是，为什么必须要编译整个方法呢？</p><p>这个问题R大也给了我们解释，详细看文章</p><p><a href="https://github.com/AdoptOpenJDK/jitwatch/wiki/Understanding-the-On-Stack-Replacement-(OSR)-optimisation-in-the-HotSpot-C1-compiler" target="_blank" rel="noopener">https://github.com/AdoptOpenJDK/jitwatch/wiki/Understanding-the-On-Stack-Replacement-(OSR)-optimisation-in-the-HotSpot-C1-compiler</a></p></li><li><p>OSR其实并不是完美的解决方案，在某些场景下它会生成非常丑陋的代码，如果有多个Loop或者Loop进行嵌套的方法。</p><p>HotSpot在一篇文章中进行了解释，有兴趣可以看文章</p><p><a href="https://www.h2o.ai/blog/what-the-heck-is-osr-and-why-is-it-bad-or-good/" target="_blank" rel="noopener">What ths heck is osr and why is it bad or good?</a></p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;前面我们讲解了C1和C2的基本知识，但是我们还未触及一个核心的策略，就是&lt;strong&gt;什么时候触发即使编译&lt;/strong&gt;，也就是&lt;strong&gt;when&lt;/strong&gt;的问题。&lt;/p&gt;
&lt;p&gt;对于when的问题，相信大家多多少少都大概知道，每个方法都会有一个调用次数的计数器，当这个计数器的次数到达一定的次数时，就会被认为是热点方法，继而触发JIT编译。&lt;/p&gt;
&lt;p&gt;但是本文要科普另外一种触发条件，和方法计数器类似。&lt;/p&gt;
    
    </summary>
    
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/categories/HotSpot/"/>
    
    
      <category term="Java" scheme="https://blog.lovezhy.cc/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>银行报考指北</title>
    <link href="https://blog.lovezhy.cc/2019/11/30/%E9%93%B6%E8%A1%8C%E6%8A%A5%E8%80%83%E6%8C%87%E5%8C%97/"/>
    <id>https://blog.lovezhy.cc/2019/11/30/%E9%93%B6%E8%A1%8C%E6%8A%A5%E8%80%83%E6%8C%87%E5%8C%97/</id>
    <published>2019-11-29T16:00:00.000Z</published>
    <updated>2020-02-29T14:44:02.280Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>看到标题，你可能会疑问，为什么我会去报考银行，我不是在互联网公司上班吗？难道是想逃离互联网回家养老去了？</p><a id="more"></a><p>当然，这个是个多因一果的事情。我确实报考了银行，并且顺利拿到了Offer。但是我并不是想逃离互联网，而是一次尝试，很大程度上只是去看看，顺便敷衍一下我妈。</p><p>当我说到敷衍我妈时，其实我比较伤心的，因为我妈一直觉得做技术太苦了，天天加班，不仅压力大，而且到了35岁会面临辞退的危险，所以希望我回家安安稳稳的过日子。</p><p>讲道理，我也有这种疑虑，但是目前并没有回家养老的意思，所以还是会继续留在南京上班。</p><p>扯了一堆，这次报考流程也算是踩了一次坑，这里记录下来，留给后人参考。</p><h2 id="报名"><a href="#报名" class="headerlink" title="报名"></a>报名</h2><p>一般我不会关注银行的招聘的，但是消息是我妈发给我的</p><p><a href="http://www.yinhangzhaopin.com/yzrcb/2019/0929/85386.html" target="_blank" rel="noopener">http://www.yinhangzhaopin.com/yzrcb/2019/0929/85386.html</a></p><p>后来我才发现原来有个网站专门就是收集各种银行招聘的信息。</p><p>报名在51Job上报名，上去填写一些资料就行了。</p><p>然后它会审核你的资料，算是一个初审，初审过了之后，会再发一封邮件给你告诉你初审过了，可以去缴费了。</p><p><img src="/images/银行报考指北/资料审核通过.png" alt=""></p><p>但是这个缴费网站，要到一定时间才会开通。</p><p>等到开通之后，登录到这个网站，付报名费，大概100块左右，然后选择考场。</p><p>这个考场并不是你报哪儿就必须去哪儿考试的。</p><p>比如我在南京，但是我报的是扬州的农商行，并不是一定要去扬州考试。他在每个城市都会有考点的。</p><p>在南京有4个考点，我记得有林业大学考点，金陵科技学院考点，还有两个记不得了。</p><p>我报的是金陵科技学院的考点。</p><p>好消息就是它考试是在周末考，这样如果是上学或者是上班的话，就不用请假了。</p><p>交完费之后，它还会给你一封邮件，让你准备笔试。</p><p><img src="/images/银行报考指北/笔试通知.png" alt=""></p><h2 id="考试"><a href="#考试" class="headerlink" title="考试"></a>考试</h2><p>周末那一天考试是从9：00到11：30。时间还是挺长的。</p><p>准考证需要提前打印好，然后考试带自己身份证就行了。也可以带一支笔，因为题目可能有数学题。</p><p>写到这个章节，你可能最想知道的是考试考什么题目。</p><p>题目其实是分岗位的，通用岗的我不是很清楚，我报的是科技岗，而且可能各个银行之间又不太一样。</p><p>首先题量很大。题型主要分为：</p><ul><li>找病句</li><li>句子排序</li><li>数学题。比如一排数字，让你找规律那种，那种题基本看一会儿看不出来就过吧</li><li>图形题。和公务员那种差不多，给三个奇怪的组合图形，然后让你选下一个和他们属性一致的图形是什么，这个看一会儿看不出来也过吧</li><li><p>材料题。给一些数据的图标，然后给4个选择题，让你从图标中找答案。还挺难找的。题量少。</p></li><li><p>英语题，缺词填空那种。大概有20道</p></li><li>计算机专业的题目。设计网络，操作系统，Java等。大概有80题。</li><li>考验智商的。比如给你个矩阵，会随机出现几个图形，5秒后消失，然后让你点击刚才出现的图形的位置。</li></ul><p>总而言之，有几点值得关注</p><ul><li>题量大。如果每道题都细做肯定来不及的，有点数学题不会就直接瞎选的。</li><li>不需要专业知识。我考之前有人和我说要很多经济学知识的，其实发现并不需要。</li></ul><p>我当时高估了自己，再加上其实去的意愿不高，做了一个半小时就赶紧溜了去上班了。</p><p>大概百分之60的题目，我都是瞎选的。</p><h2 id="面试"><a href="#面试" class="headerlink" title="面试"></a>面试</h2><p>其实我笔试考完觉得自己肯定挂了，但是过了两天打电话告诉我过了。</p><p>过了就过了吧，大概就是通知我去面试了。</p><p>让我周六去扬州交材料，周日面试。</p><p>我正好有朋友在扬州，所以就打算去顺便找他玩一下。</p><p>交材料的话，需要毕业证的复印件。身份证的正反面复印件，学信网的电子备案表的打印件。</p><p>周六去交了材料，顺便问了我的成绩。</p><p>傍晚的时候发短信通知我明天中午去面试。</p><p>我中午到的时候，发现大家都是穿正装来的，就我穿的花里胡哨的。心想大概率是凉了。</p><p>哈哈，所以这里提醒大家最好穿正装去面试，没有正装也穿个黑色的衣服去。</p><p>然后就是签到。</p><p>到了时间又让我们做了一个半小时的题目，题目大概和笔试的差不多，不知道这个是什么套路。</p><p>这个题目并不包括计算机的题目，我估计通用的和科技岗的都一样。</p><p>做完题目，需要把手机交上去，然后排队去面试。</p><p>流程是这样的，一个一个进去面试，当一个人进去时，后面一个人去等候区，等候区就一个人，有张桌子，上面有张纸，记着三个题目，有人给你计时4分钟，你看完题目想想怎么回答。</p><p>然后前一个出来时，你进去，然后对面三个面试官，面试官不会多对你说什么，你就把三个问题的答案说一遍就行。每个题目计时2分钟，说完也没有其他的问题，你就可以直接走了。</p><p>具体的题目其实和计算机的关系不大，属于需要总结概括的题目，需要的话可能私聊我。</p><p>面完就直接回去了，也没管什么。</p><h2 id="体检"><a href="#体检" class="headerlink" title="体检"></a>体检</h2><p>其实我面完之后感觉自己肯定差不多挂了，下面应该没后续流程了。</p><p>然后过了两天，大概是周二的时候，银行打电话告诉我过了面试。</p><p>下面的流程是体检，而且就在明天，银行的人问我能不能去。</p><p>我一想这也太突然了，我今天就得再去扬州，这也不太可能啊，所以我直接拒绝了。</p><p>以为这个机会就没了，但是她告诉我明天不去，那就等下一批的通知吧。</p><p>感情原来体检还是分批来的，我说好的。</p><p>其实我比较奇怪的地方是为什么直接去体检了，而不是先谈工资待遇啥的，这是明摆着面试通过了大家就肯定先去吗？</p><p>然后我问了在银行工作的同学，似乎他们都是这样的，都不知道具体的待遇什么的，都是上了一个月的班才知道具体的工资是多少。</p><p>这就有点坑了。</p><p>我回去也和我爸妈商量了下，我说我其实不太想回去。我爸妈也表示明白。</p><p>然后下一次打电话来的时候，我就直接拒绝了。</p><p>我以为银行的人会问问为什么，结果她直接说好的。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这次的银行面试经历就是如上了，我顺利的度过了笔试和面试，中间决定不去了。</p><p>整体上的体验一般般，流程拉的太长了，而且面试和体检都是在固定的地方，所以导致体验不会太好。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;看到标题，你可能会疑问，为什么我会去报考银行，我不是在互联网公司上班吗？难道是想逃离互联网回家养老去了？&lt;/p&gt;
    
    </summary>
    
    
      <category term="我的生活" scheme="https://blog.lovezhy.cc/categories/%E6%88%91%E7%9A%84%E7%94%9F%E6%B4%BB/"/>
    
    
      <category term="生活" scheme="https://blog.lovezhy.cc/tags/%E7%94%9F%E6%B4%BB/"/>
    
  </entry>
  
  <entry>
    <title>HotSpot原理指南-内联</title>
    <link href="https://blog.lovezhy.cc/2019/11/28/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-%E5%86%85%E8%81%94/"/>
    <id>https://blog.lovezhy.cc/2019/11/28/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-%E5%86%85%E8%81%94/</id>
    <published>2019-11-27T16:00:00.000Z</published>
    <updated>2020-02-29T14:36:23.516Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>内联是编程语言编译器中常规的优化操作，几乎所有的语言在编译时或者在执行时都会有内联操作。</p><p>内联的本质是把几个方法合并成一个方法</p><p>从一方面讲，内联减少了函数调用的栈帧创建和销毁的时间消耗</p><p>从另一方面讲，内联为很多其他的优化方法提供了更多的可能，比如逃逸分析，无用代码消除，虚函数优化等，这也是内联被叫做<strong>优化之母</strong>（The Mother Of All Optimization）的原因。</p><a id="more"></a><h2 id="HotSpot-JIT"><a href="#HotSpot-JIT" class="headerlink" title="HotSpot-JIT"></a>HotSpot-JIT</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>对于HotSpot的JIT而言，内联是一个渐进的过程，这个渐进表现在两方面</p><ul><li>C1和C2两个JIT编译器的内联策略不同，C2可能更加激进一些</li><li>内联策略和很多因素有关<ul><li>内联发起函数大小，被内联函数大小</li><li>被内联函数的调用次数</li><li>内联深度</li><li>中间表示的NodeCount</li><li>函数方法签名</li></ul></li></ul><h3 id="初步体验"><a href="#初步体验" class="headerlink" title="初步体验"></a>初步体验</h3><p>先看一段代码，初步的了解下HotSpot的内联，以下代码的执行参数<code>-XX:CompileCommand=exclude,Inline.main</code></p><p>这个参数的意义是禁止<code>main</code>函数内联<code>inline</code>方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Inline</span> </span>&#123;</span><br><span class="line">  </span><br><span class="line"><span class="keyword">static</span> Random random = <span class="keyword">new</span> Random();</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span> ; i &lt; <span class="number">1000000</span>; i++) &#123;</span><br><span class="line">            inline();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">inline</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> add(random.nextInt(), </span><br><span class="line">               random.nextInt());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> a, <span class="keyword">int</span> b)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> a + b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="/images/HotSpot原理指南-内联/inline.png" alt="inline"></p><p>上图中展示了经过C2编译后，整个<code>inline</code>函数的内联状态</p><p>可以看到不仅仅内联了<code>random.nextInt()</code>方法，还将<code>nextInt</code>方法中的<code>next</code>方法等等好几个再下层的方法也内联了进来</p><h3 id="HotSpot参数"><a href="#HotSpot参数" class="headerlink" title="HotSpot参数"></a>HotSpot参数</h3><p><code>java -XX:+PrintFlagsFinal | grep &quot;Inlin&quot;</code></p><p><img src="/images/HotSpot原理指南-内联/内联参数.png" alt="内联参数"></p><p>可以看到HotSpot可以控制内联的参数很多很多，从侧面也表示HotSpot的内联策略是非常复杂的。</p><p>笔者也无法精通所有的内联策略，所以只挑选出比较重要的几个参数来讲解。</p><p>主要讲解如下几个参数</p><table><thead><tr><th>参数</th><th>默认值</th></tr></thead><tbody><tr><td>MaxTrivialSize</td><td>6</td></tr><tr><td>MaxInlineSize</td><td>35</td></tr><tr><td>FreqInlineSize</td><td>350</td></tr><tr><td>MinInliningThreshold</td><td>250</td></tr><tr><td>InlineSmallCode</td><td>1000(No-Tier)  2000(Tier)</td></tr><tr><td>MaxInlineLevel</td><td>9</td></tr><tr><td>MaxRecursiveInlineLevel</td><td>1</td></tr></tbody></table><h2 id="内联策略"><a href="#内联策略" class="headerlink" title="内联策略"></a>内联策略</h2><h3 id="MaxTrivialSize"><a href="#MaxTrivialSize" class="headerlink" title="MaxTrivialSize"></a>MaxTrivialSize</h3><p>对于Trivial方法，在HotSpot中有着严格的定义</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">bool</span> SimpleThresholdPolicy::is_trivial(Method* method) &#123;</span><br><span class="line">  <span class="keyword">if</span> (method-&gt;is_accessor() ||</span><br><span class="line">      method-&gt;is_constant_getter()) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (method-&gt;has_loops() || method-&gt;code_size() &gt;= <span class="number">15</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  MethodData* mdo = method-&gt;method_data();</span><br><span class="line">  <span class="keyword">if</span> (mdo != <span class="literal">NULL</span> &amp;&amp; !mdo-&gt;would_profile() &amp;&amp;</span><br><span class="line">      (method-&gt;code_size() &lt; <span class="number">5</span>  || (mdo-&gt;num_blocks() &lt; <span class="number">4</span>))) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从上面的代码可以看出，常见的Getter方法，肯定是trivial方法</p><p>而函数中有循环，或者函数大小超过15bytes，则不是trivial方法</p><p>对于trivial方法，如果它的函数字节码小于<strong>MaxTrivialSize</strong>，那么即使它在调用方至今一次也没有被执行过，HotSpot也会将它内联进来。</p><p>这是对于C1而言，对于C2而言，则不会进行内联，而是会生成<code>UnCommon Trap</code></p><h3 id="MaxInlineSize"><a href="#MaxInlineSize" class="headerlink" title="MaxInlineSize"></a>MaxInlineSize</h3><p>我们了解了MaxTrivialSize，那么对于MaxInlineSize则很容易理解。</p><p>对于调用方至少执行过一次的方法，如果它的大小小于MaxInlineSize，那么就会考虑将它内联进去</p><h3 id="FreqInlineSize和MinInliningThreshold"><a href="#FreqInlineSize和MinInliningThreshold" class="headerlink" title="FreqInlineSize和MinInliningThreshold"></a>FreqInlineSize和MinInliningThreshold</h3><p>了解了以上两个参数后，你可能会问，如果被调用的函数既不符合Trivial方法，大小也大于MaxInlineSize，但是这个方法非常的Hot，就没有机会被内联了吗</p><p>并不是，FreqInlineSize和MinInliningThreshold这两个参数就是为这种方法设置的。</p><p>当一个方法既不是Trivial方法，而且大于MaxInlineSize，如果他的调用次数大于MinInliningThreshold，也就是250次，且它的大小小于FreqInlineSize，那么它也会被内联</p><h3 id="InlineSmallCode"><a href="#InlineSmallCode" class="headerlink" title="InlineSmallCode"></a>InlineSmallCode</h3><p>我们知道，调用方进行方法内联的时候，函数本身的大小会越来越大。</p><p>这时候你又会问了，那调用方内联可以无限内联吗，内联后的大小肯定会有限制的吧。</p><p>对的！InlineSmallCode就是限制的大小</p><p>如果是非分层编译的环境，阈值是1000bytes</p><p>如果是分层编译的环境，那么阈值是2000bytes</p><h3 id="MaxInlineLevel"><a href="#MaxInlineLevel" class="headerlink" title="MaxInlineLevel"></a>MaxInlineLevel</h3><p>对于一个函数进行其他函数的内联，除了内联后的大小限制，内联的深度也是有限制的。</p><p>在HotSpot中，默认的内联最大深度是MaxInlineLevel控制，也就是9层。</p><p>为什么要限制内联的最大深度呢？</p><p>在stackoverflow上有个我认为比较中肯的答案</p><p><a href="https://stackoverflow.com/questions/32503669/why-does-the-jvm-have-a-maximum-inline-depth" target="_blank" rel="noopener">Why does the JVM have a maximum inline depth?</a></p><blockquote><p>Not exactly, but I guess the basic reason is to keep things simple. Unlimited inlining depth would increase complexity, the compilation time and memory usage might be less predictable (that is OK for AOT compilers, but not for JIT). Also mind that compiled code should keep track of the whole inlining tree at run-time (to be able to unwind and deoptimize). Though I think the default value of 9 is outdated. It has not been changed for ages, but nowadays, with much more resources available, with streams and lamdas in mind, there is definitely a place for improvement</p></blockquote><p>总结一下答案：</p><ul><li>为了保持内联的简单性。无限制的内联会增加复杂度。</li><li>内联后的编译代码，需要记录整个内联树。</li><li>编译时间和内存消耗会变得不可预测。</li></ul><p>当然，作者也认为默认值9已经很久没有改动了，随着计算机资源变得不再那么昂贵，完全可以适当调大这个值。</p><h3 id="MaxRecursiveInlineLevel"><a href="#MaxRecursiveInlineLevel" class="headerlink" title="MaxRecursiveInlineLevel"></a>MaxRecursiveInlineLevel</h3><p>对于递归的方法，它内联自己最多只能内联MaxRecursiveInlineLevel层，也就是1次。</p><h2 id="查看内联结果"><a href="#查看内联结果" class="headerlink" title="查看内联结果"></a>查看内联结果</h2><p>如果想要知道我们的代码在编译时，内联了哪些方法，那么可以加上参数</p><p><code>java -XX:+UnlockDiagnosticVMOptions -XX:+PrintInlining</code></p><p>对于上面的inline.java的结果输出如下</p><p><img src="/images/HotSpot原理指南-内联/内联输出结果.png" alt="内联输出结果"></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;内联是编程语言编译器中常规的优化操作，几乎所有的语言在编译时或者在执行时都会有内联操作。&lt;/p&gt;
&lt;p&gt;内联的本质是把几个方法合并成一个方法&lt;/p&gt;
&lt;p&gt;从一方面讲，内联减少了函数调用的栈帧创建和销毁的时间消耗&lt;/p&gt;
&lt;p&gt;从另一方面讲，内联为很多其他的优化方法提供了更多的可能，比如逃逸分析，无用代码消除，虚函数优化等，这也是内联被叫做&lt;strong&gt;优化之母&lt;/strong&gt;（The Mother Of All Optimization）的原因。&lt;/p&gt;
    
    </summary>
    
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/categories/HotSpot/"/>
    
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/tags/HotSpot/"/>
    
      <category term="JVM" scheme="https://blog.lovezhy.cc/tags/JVM/"/>
    
      <category term="内联" scheme="https://blog.lovezhy.cc/tags/%E5%86%85%E8%81%94/"/>
    
  </entry>
  
  <entry>
    <title>HotSpot原理指南-C1和C2编译流程</title>
    <link href="https://blog.lovezhy.cc/2019/11/27/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-C1%E5%92%8CC2%E7%BC%96%E8%AF%91%E6%B5%81%E7%A8%8B/"/>
    <id>https://blog.lovezhy.cc/2019/11/27/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-C1%E5%92%8CC2%E7%BC%96%E8%AF%91%E6%B5%81%E7%A8%8B/</id>
    <published>2019-11-26T16:00:00.000Z</published>
    <updated>2020-02-29T14:36:21.235Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>前文讲述了C1和C2的功能定位，以及引出了Client和Server模式的区别。</p><p>这回抛开功能和定位的角度，简单看看从设计与实现角度的区别。</p><a id="more"></a><h2 id="前导知识"><a href="#前导知识" class="headerlink" title="前导知识"></a>前导知识</h2><p>要讲解设计与实现角度的区别，需要了解很多的编译原理知识。</p><p>😄编译原理是科班必学的一门课，当时作者上的迷迷糊糊的，觉得没什么用，也没怎么听。</p><p>现在看到C1和C2的东西，真的是一筹莫展。</p><p>相信很多科班和非科班的人也是。</p><p>不过大家不用担心，作者水平有限，更是不会瞎写自己根本不会的东西，所以涉及到编译原理的东西讲的都很简单。</p><h3 id="IR"><a href="#IR" class="headerlink" title="IR"></a>IR</h3><p>IR，中文中间表示，全称是intermediate representation。</p><p>其实它和中间语言的定义类似，但是中间语言的定义更加狭义，只规定必须是某种语言，而中间表示则扩宽了范围，可以是树类型或者是图类型的表示。</p><p>在维基百科上，中间语言的定义是</p><blockquote><p><strong>中间语言</strong>（英语：Intermediate language），在计算机科学中，是指一种应用于抽象机器（abstract machine）的编程语言，它设计的目的，是用来帮助我们分析计算机程序。这个术语源自于编译器，在编译器将源代码编译为目的码的过程中，会先将源代码转换为一个或多个的中间表述，以方便编译器进行最佳化，并产生出目的机器的机器语言</p></blockquote><p>其实更简单的定义，我觉得就是源代码的另一种表达形式。</p><p>比如Java代码，会被编译成字节码，字节码也是一种IR，是Java代码的中间表示。</p><p>IR在编译原理中的作用个人理解其实起到两种：</p><ul><li>统一后端语言。比如JRuby，Scala，Kotlin等，他们的解释器其实都是JVM。但是他们的源代码都是不一样的。倘若对于每种语言的处理都是不一样的，那其实JVM的实现就没什么意义了，所以将所有语言的源代码都编译成同一种IR，然后JVM不用关心源语言是什么，只要符合该IR定义的都可以执行。</li><li>方便优化。很多的优化技术，其实人眼可以简单看出的，很难归一化到程序去理解。但是通过一些IR的表示，使用特定的规则，就可以进行优化。就行我们在拼魔方时的公式一样。那为什么有这么多种IR呢，很大一个程度的区别就是他们在解决一些特定优化时各有优势。比如SSA在进行复制传播时就很方便。</li></ul><h3 id="寄存器分配"><a href="#寄存器分配" class="headerlink" title="寄存器分配"></a>寄存器分配</h3><p>一个解释器执行的程序和以机器码执行的程序的一个很大的区别就是对于系统寄存器的使用。</p><p>比如对于下面的函数</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> i, <span class="keyword">int</span> j)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> k = i + j;</span><br><span class="line">    k += <span class="number">2</span>;</span><br><span class="line">    k *= <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">return</span> i + j;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果是以解释的形式而言，则需要把k存在内存的变量中，然后再进行运算，每一步的运算都要把k的值写回到内存中。</p><p>但是如果是C++的话，完全可以给k分配一个寄存器，把k放到寄存器中，然后直接对寄存器中的值进行运算就行。</p><p>所以，如果能够很好的利用系统现有的寄存器，那么程序执行的性能将提升一个档次。</p><p>对于寄存器的分配算法，有很多论文可以参考，作者水平有限，还没能学会一种。</p><p>读者有兴趣可以自己去搜索相关论文进行了解。</p><h2 id="C1流程"><a href="#C1流程" class="headerlink" title="C1流程"></a>C1流程</h2><p><img src="/images/HotSpot原理指南-C1和C2流程/C1流程.png" alt=""></p><p>C1的流程较为简单，如上图所示。</p><p>首先，字节码会经过转换，变成HIR，也就是High Level的IR，高级中间表示。</p><p>在HIR中，会进行一些优化，比如</p><ul><li>GVN优化</li><li>基本块优化</li><li>null检查消除</li><li>…</li></ul><p>经过HIR优化之后，转换成LIR，也就是Low-Level的IR，低级中间表示。</p><p>这个阶段的IR其实已经很接近机器码了</p><p>在LIR时，进行</p><ul><li>寄存器分配。这里的寄存器分配算法是线性扫描，时间消耗短，但是分配效果有限</li><li>窥孔优化</li></ul><p>在LIR的优化过后，就是机器码的生成。</p><p>对于C1的更详细的流程，笔者也从网上找到了当时作者的一个PPT，有兴趣的可以自行下载</p><p><a href="http://compilers.cs.uni-saarland.de/ssasem/talks/Christian.Wimmer.pdf" target="_blank" rel="noopener">http://compilers.cs.uni-saarland.de/ssasem/talks/Christian.Wimmer.pdf</a></p><p>同时，如果有人对线性扫描寄存器分配算法有兴趣，也可以参照论文</p><p><a href="http://web.cs.ucla.edu/~palsberg/course/cs132/linearscan.pdf" target="_blank" rel="noopener">http://web.cs.ucla.edu/~palsberg/course/cs132/linearscan.pdf</a></p><h2 id="C2流程"><a href="#C2流程" class="headerlink" title="C2流程"></a>C2流程</h2><p>通过前面我们已经知道C2相对于C1编译过程，更加的耗时，这个耗时可以体现在两方面</p><ul><li>比C1有更多的优化</li><li>同一种优化使用的算法不同，C2的结果更好</li></ul><p>对于C2而言，它的IR只有一种，叫<code>Sea Of Nodes</code></p><p>就笔者了解到的知识来看，这个IR非常的牛逼，在V8引擎中，也是使用的这种IR。</p><p>不过这种IR的资料似乎非常少，笔者也仅仅是搜到了论文，没什么更深层次的讲解。</p><p>如果有人想要了解Sea Of Nodes的原理，那么大家可以从网上搜集资料来看。</p><p><strong>比C1拥有更多的优化</strong></p><p>相比较于C1，C2几乎会做所有的经典优化。如下图所示</p><p><img src="/images/HotSpot原理指南-C1和C2流程/C2优化.png" alt=""></p><p><strong>同一种优化使用不同的算法</strong></p><p>这个体现在寄存器分配算法上，我们知道对于C1而言，使用的较为简单的线性扫描的分配算法，执行较快。</p><p>而C2使用了叫图染色的算法，消耗的时间更久，但是产生的解法比线性扫描更优。</p><p>对于图染色算法，在经典的编译原理书中都有解答。</p><p>笔者这里就不赘述了（其实是笔者也没看懂）</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;前文讲述了C1和C2的功能定位，以及引出了Client和Server模式的区别。&lt;/p&gt;
&lt;p&gt;这回抛开功能和定位的角度，简单看看从设计与实现角度的区别。&lt;/p&gt;
    
    </summary>
    
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/categories/HotSpot/"/>
    
    
      <category term="Java" scheme="https://blog.lovezhy.cc/tags/Java/"/>
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/tags/HotSpot/"/>
    
      <category term="JVM" scheme="https://blog.lovezhy.cc/tags/JVM/"/>
    
      <category term="C1和C2" scheme="https://blog.lovezhy.cc/tags/C1%E5%92%8CC2/"/>
    
  </entry>
  
  <entry>
    <title>HotSpot原理指南-C1和C2介绍</title>
    <link href="https://blog.lovezhy.cc/2019/11/24/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-C1%E5%92%8CC2%E4%BB%8B%E7%BB%8D/"/>
    <id>https://blog.lovezhy.cc/2019/11/24/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-C1%E5%92%8CC2%E4%BB%8B%E7%BB%8D/</id>
    <published>2019-11-23T16:00:00.000Z</published>
    <updated>2020-02-29T14:36:19.131Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>HotSpot是一款Java虚拟机的实现，除了基本的解释功能以外，该虚拟机还拥有将字节码编译成机器码的并执行的能力，我们知道，直接执行机器码肯定比解释更快。</p><p>HotSpot最初会通过解释的方式执行程序，当它发现某个方法运行得特别频繁时，就会将这些热点（Hot Spot）代码进行编译，编译成平台相关的机器码。这个过程也叫做JIT（Just In Time），与之相对的是AOT（Ahead Of Time），比较典型的是C和C++语言。</p><p>HotSpot进行JIT编译的编译器有两个，分别叫做<strong>C1</strong>和<strong>C2</strong>，或者也可以叫做<strong>Client Compiler</strong>和<strong>Server Compiler</strong>。这两种编译器编译策略不同，运用在不同的场景，下面会详细的说明。</p><a id="more"></a><h2 id="JIT编译"><a href="#JIT编译" class="headerlink" title="JIT编译"></a>JIT编译</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Add</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">200</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">long</span> start = System.nanoTime();</span><br><span class="line">            add();</span><br><span class="line">            <span class="keyword">long</span> end = System.nanoTime();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">add</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1000</span>; i++) &#123;</span><br><span class="line">            sum += i;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> sum;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面这段代码，我们有一个<code>add</code>方法，如果我们对改方法进行时间统计，我们会得到下面的曲线。</p><p>X轴是次数，Y轴是时间的log2。</p><p><img src="/images/HotSpot原理指南-C1和C2/add.png" alt=""></p><p>从这个曲线我们可以看出，在第大概100次的时间，时间消耗会下滑，也就是性能提升了一个档次。</p><p>由此我们可以猜到，前100次的add方法是由解释执行的，在100次后，执行的是由JIT编译器编译过的机器码。所以性能会有较大的提升。</p><h2 id="Profile"><a href="#Profile" class="headerlink" title="Profile"></a>Profile</h2><p>在详细讲述C1和C2之前，我们还有一个内容需要科普，就是方法的Profile信息。</p><p>除了最基本的用于判定某个方法是否是HotSpot的方法调用次数（Invocation Counter）信息外，对于某个方法，还有一些信息是会在运行时进行收集的。</p><p>比如我们看下面这段代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">record</span><span class="params">(List&lt;String&gt; list)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (list != <span class="keyword">null</span>) &#123;</span><br><span class="line">list.add(<span class="string">"大骚包卢布"</span>);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    log.warn(<span class="string">"我不是大骚包"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>record</code>函数的功能很简单，入参是一个List，如果List不为空，那么就把<code>大骚包卢布</code>这个字符串传递进去。不然的话就打出一个warn级别的日志<code>我不是大骚包</code>。</p><p>那么在调用这个方法的时候，HotSpot还会记录哪些信息呢</p><ul><li>List的真实类。因为List在Java中是一个接口，具体的传入可能是ArrayList或者LinkedList或者其他的。HotSpot需要记录具体的类为了以后的优化。</li><li>Log的真实类，理由和List一样。</li><li>进入if的次数，以及进入else的次数，更通俗的说是条件选择的实际情况。</li></ul><p>有人可能会问统计这些Profile有什么用。</p><p>举个最简单的例子，如果我们需要对<code>list.add</code>做内联，那么我们到底内联那个实现呢，这个就需要我们收集list的真实实现是什么。</p><h2 id="C1和C2"><a href="#C1和C2" class="headerlink" title="C1和C2"></a>C1和C2</h2><table><thead><tr><th></th><th>C1</th><th>C2</th></tr></thead><tbody><tr><td>编译时间</td><td>快</td><td>慢（x4）</td></tr><tr><td>执行时间</td><td>慢</td><td>快（30%）</td></tr><tr><td>输出代码</td><td>多</td><td>少</td></tr></tbody></table><p>上表是C1和C2在编译时间，执行时间，输出代码的区别</p><ul><li>编译时间：同样一段代码，C1需要时间比C2短，也就是需求的CPU资源较少</li><li>执行时间：C1编译时间短，通常意味着优化不如C2，所以C2编译出的机器码执行效率较高</li><li>输出代码：C1编译时间短，最终也就导致输出的机器码占用的内存要比C2多的</li></ul><p>总结：同一段代码，C1消耗的CPU资源较少，但是输出的代码质量不如C2。但是毋庸置疑的事，无论是C1还是C2输出的机器码，执行效率肯定都比解释快的。</p><p>C1又称<strong>Client Compiler</strong>，C2又称<strong>Server Compiler</strong>，不是没有历史渊源的。</p><p>或许我们都听过java在启动的时候可以执行是<code>client</code>模式还是<code>server</code>模式。</p><p>当我们使用client模式时，一般运行的是应用程序，比如java swing，awt之类的图形软件，对于这些桌面软件，作为使用者而言，并不希望哪个桌面应用占用大量的CPU，所以非常适合C1的场景</p><ul><li>编译速度快</li><li>占用CPU资源少</li></ul><p>而对于Server模式而言，一般是公司的服务器上跑的稳定的服务应用，服务器的资源一般较为丰富，同时一个应用并不会像桌面应用一样频繁的开关，一般都要跑几周或者几个月甚至几年。这种应用，当然速度越快越好。所以非常适合C2的场景</p><ul><li>编译消耗更多的CPU资源</li><li>代码质量更高，也就是性能更好</li></ul><h2 id="C1和C2和Profile"><a href="#C1和C2和Profile" class="headerlink" title="C1和C2和Profile"></a>C1和C2和Profile</h2><p>前面提到过的Profile信息，你可能会疑惑这个和C1和C2有什么联系。</p><p>其实我们需要先明白一个概念，就是收集那些Profile不仅仅会占用程序以外的更多的内容，而且会占用很多的CPU消耗。同样一段代码，插入了收集Profile逻辑和没有插入收集Profile逻辑，执行性能是不同的。</p><p>结合我们提到的C1和C2的使用场景的区别，可以得出这样的结论，这个收集Profile的消耗，对于桌面应用而言，是非常<strong>不合适</strong>的。</p><p>但是C2则需要这些Profile去做更好的性能优化。</p><p>所以对于Client模式的应用而言，解释器不会去收集程序的Profile信息，而Server模式在解释器阶段，则会进行Profile的收集，这也就导致了Client模式的起步性能是比Server模式的起步性能要好很多。</p><h2 id="启动模式"><a href="#启动模式" class="headerlink" title="启动模式"></a>启动模式</h2><p>在JDK1.6之前，指定是<code>client</code>还是<code>server</code>模式，我们在java程序启动时直接加参数就行了</p><p><code>java -client Hello</code></p><p><strong>但是</strong></p><p>注意我这个但是</p><p>其实自从JDK6的某个版本开始，你已经控制不了这个参数了</p><p><a href="https://docs.oracle.com/javase/7/docs/technotes/guides/vm/server-class.html" target="_blank" rel="noopener">https://docs.oracle.com/javase/7/docs/technotes/guides/vm/server-class.html</a></p><p>从这个网站可以看到，默认如果你是64位的机器并且至少有2G内存和2核心的CPU，默认都是Server模式了。</p><p><code>-client</code>这个参数会被忽略</p><p>但是也并不是没有办法指定client模式</p><p>不仅仅要在启动参数中加上<code>-client</code></p><p>还需要去修改文件<code>jre/lib/jvm.cfg</code></p><p>比如我的文件中默认是这个状态</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">-server KNOWN</span><br><span class="line">-client IGNORE</span><br><span class="line">-hotspot ERROR</span><br><span class="line">-classic WARN</span><br><span class="line">-native ERROR</span><br><span class="line">-green ERROR</span><br></pre></td></tr></table></figure><p>注意到我的<code>-client</code>后面跟的是<code>IGNORE</code>，所以我指定<code>-client</code>模式其实是不生效的</p><p>我需要改成<code>-client KNOWN</code>才行。</p><p>当然Oracle选择忽略<code>-client</code>模式也不是没有道理的</p><ul><li>Java的桌面应用已经很少了，Swing基本已经死了</li><li>现在大家的笔记本的CPU和内容资源都很充足</li></ul><p>所以全部使用<code>server</code>模式也没问题。</p><h2 id="后续"><a href="#后续" class="headerlink" title="后续"></a>后续</h2><p>当然C1和C2的故事并没有这么简单</p><p>同时JIT编译的策略也不是非C1就是C2，在JDK7中引入了分层编译，结合了C1和C2的优点。</p><p>这些会在后面的文章讲述。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;HotSpot是一款Java虚拟机的实现，除了基本的解释功能以外，该虚拟机还拥有将字节码编译成机器码的并执行的能力，我们知道，直接执行机器码肯定比解释更快。&lt;/p&gt;
&lt;p&gt;HotSpot最初会通过解释的方式执行程序，当它发现某个方法运行得特别频繁时，就会将这些热点（Hot Spot）代码进行编译，编译成平台相关的机器码。这个过程也叫做JIT（Just In Time），与之相对的是AOT（Ahead Of Time），比较典型的是C和C++语言。&lt;/p&gt;
&lt;p&gt;HotSpot进行JIT编译的编译器有两个，分别叫做&lt;strong&gt;C1&lt;/strong&gt;和&lt;strong&gt;C2&lt;/strong&gt;，或者也可以叫做&lt;strong&gt;Client Compiler&lt;/strong&gt;和&lt;strong&gt;Server Compiler&lt;/strong&gt;。这两种编译器编译策略不同，运用在不同的场景，下面会详细的说明。&lt;/p&gt;
    
    </summary>
    
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/categories/HotSpot/"/>
    
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/tags/HotSpot/"/>
    
  </entry>
  
  <entry>
    <title>给RedisTemplate插入Cat打点</title>
    <link href="https://blog.lovezhy.cc/2019/11/08/%E7%BB%99RedisTemplate%E6%8F%92%E5%85%A5Cat%E6%89%93%E7%82%B9/"/>
    <id>https://blog.lovezhy.cc/2019/11/08/%E7%BB%99RedisTemplate%E6%8F%92%E5%85%A5Cat%E6%89%93%E7%82%B9/</id>
    <published>2019-11-07T16:00:00.000Z</published>
    <updated>2020-03-14T14:57:53.851Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Cat是美团开源的一套监控系统，功能非常强大<br>一般对方法进行打点，它会自动生成每个方法的耗时，同时也会记录全链路的每个调用方法的耗时</p><p>对于查系统的性能瓶颈和稳定性有非常大的帮助</p><a id="more"></a><p>基本用法<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Transaction tranx = Cat.newTransaction(<span class="string">"Cache"</span>, <span class="string">"get"</span>);</span><br><span class="line">tranx.addData(<span class="string">"key"</span>, <span class="string">"name"</span>);</span><br><span class="line"><span class="comment">//do something</span></span><br><span class="line">tranx.setStatus(<span class="string">"0"</span>);</span><br><span class="line">tranx.complete();</span><br></pre></td></tr></table></figure></p><p>上面的方法就是对中间的代码执行进行耗时打点，这里假设的是我们对Redis的get方法进行打点</p><ul><li>第一句：new一个Transaction出来，Type是Cache，也就是Transaction属于Cache，然后具体的方法是get</li><li>第二句：addData，在执行过程中进行关键日志的记录，我们这里记录了get的key是name，方面查询长耗时的方法，增加一些提示性的参数</li><li>第三句：执行具体的方法</li><li>第四句：执行成功，设置status=0，0表示成功的意思，当然也有失败的方法，可以把具体的Exception传递进去</li><li>第五句：标记Transaction完成</li></ul><h2 id="框架集成"><a href="#框架集成" class="headerlink" title="框架集成"></a>框架集成</h2><p>Cat只是提供了一些工具，并没有直接提供方法与常见的方法集成，让我们在业务代码的每个方法都手动编码上面这些流程肯定不现实，可以借助于很多的方法进行隐式的插入逻辑。</p><h3 id="与Dubbo集成"><a href="#与Dubbo集成" class="headerlink" title="与Dubbo集成"></a>与Dubbo集成</h3><p>Dubbo提供了Filter机制，可以声明一个Filter进行对Dubbo服务方法的打点</p><p><a href="https://github.com/dianping/cat/tree/master/integration/dubbo" target="_blank" rel="noopener">Dubbo</a></p><p>在Cat的官方仓库中收集了此集成方式，可以直接使用</p><h2 id="与Mybatis集成"><a href="#与Mybatis集成" class="headerlink" title="与Mybatis集成"></a>与Mybatis集成</h2><p>和Dubbo一个，Mybatis也提供了Filter插件</p><p><a href="https://github.com/dianping/cat/tree/master/integration/mybatis" target="_blank" rel="noopener">Mybatis</a></p><p>在Cat的官方仓库中收集了此集成方式，可以直接使用</p><p>上面两种插件几乎是最常用的两个了，但是Redis的需求也比较强烈</p><h2 id="Redis打点"><a href="#Redis打点" class="headerlink" title="Redis打点"></a>Redis打点</h2><p>Cat的官方仓库并没有提供Redis的打点插件，借着Filter的简单的逻辑，我准备找找现有框架的逻辑插入方法</p><p>在正常的SpringBoot应用中，默认的Redis使用类是RedisTemplate，如果具体到某个操作，在内部声明了多个具体的类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedisTemplate</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt;    </span>&#123;</span><br><span class="line">  <span class="comment">// cache singleton objects (where possible)</span></span><br><span class="line">    <span class="keyword">private</span> <span class="meta">@Nullable</span> ValueOperations&lt;K, V&gt; valueOps;</span><br><span class="line">    <span class="keyword">private</span> <span class="meta">@Nullable</span> ListOperations&lt;K, V&gt; listOps;</span><br><span class="line">    <span class="keyword">private</span> <span class="meta">@Nullable</span> SetOperations&lt;K, V&gt; setOps;</span><br><span class="line">    <span class="keyword">private</span> <span class="meta">@Nullable</span> ZSetOperations&lt;K, V&gt; zSetOps;</span><br><span class="line">    <span class="keyword">private</span> <span class="meta">@Nullable</span> GeoOperations&lt;K, V&gt; geoOps;</span><br><span class="line">    <span class="keyword">private</span> <span class="meta">@Nullable</span> HyperLogLogOperations&lt;K, V&gt; hllOps;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>比如当我们调用</p><p><code>redisTemplate.opsForSet().members(cacheName)</code>时，</p><p>调用的是</p><p><code>DefaultSetOperations.members(K key)</code>方法</p><p>所以我们只要对上面提到的具体操作的类的一些方法进行打点就行</p><p>但是很可惜，RedisTemplate并没有提供</p><h2 id="方案一"><a href="#方案一" class="headerlink" title="方案一"></a>方案一</h2><p>直接使用SpringAop对具体的类进行代理</p><p>这当时是我觉得最简单的方法，但是很遗憾</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DefaultSetOperations</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">AbstractOperations</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; <span class="keyword">implements</span> <span class="title">SetOperations</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; </span>&#123;&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DefaultValueOperations</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">AbstractOperations</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; <span class="keyword">implements</span> <span class="title">ValueOperations</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; </span>&#123;&#125;</span><br></pre></td></tr></table></figure><p>这些具体实现类都不是public的，对这些方法进行切面处理是处理不了的</p><h2 id="方案二"><a href="#方案二" class="headerlink" title="方案二"></a>方案二</h2><p>最简单的方法被否决了，于是只能找一些其他的方法</p><p>当时看到Java的Agent可以在类被加载时进行一些修改，于是产生了写一个javaagent的方法</p><p>目标效果</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">get</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> execute(<span class="keyword">new</span> ValueDeserializingRedisCallback(key) &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">protected</span> <span class="keyword">byte</span>[] inRedis(<span class="keyword">byte</span>[] rawKey, RedisConnection connection) &#123;</span><br><span class="line">            <span class="keyword">return</span> connection.get(rawKey);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;, <span class="keyword">true</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">=&gt;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">get</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">    Transaction tranx = Cat.newTransaction(<span class="string">"Cache"</span>, <span class="string">"get"</span>); </span><br><span class="line">    tranx.addData(<span class="string">"key"</span>, key);</span><br><span class="line">    V res = execute(<span class="keyword">new</span> ValueDeserializingRedisCallback(key) &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">protected</span> <span class="keyword">byte</span>[] inRedis(<span class="keyword">byte</span>[] rawKey, RedisConnection connection) &#123;</span><br><span class="line">            <span class="keyword">return</span> connection.get(rawKey);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;, <span class="keyword">true</span>);</span><br><span class="line">    </span><br><span class="line">    tranx.setStatus(<span class="string">"0"</span>);</span><br><span class="line">    tranx.complete();</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>但是为了得到失败的效果，同时防止Cat方法抛出异常影响正常逻辑，需要多加几个try catch</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">get</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">    Transaction tranx = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      tranx = Cat.newTransaction(<span class="string">"Cache"</span>, <span class="string">"get"</span>);</span><br><span class="line">      tranx.addData(<span class="string">"key"</span>, key);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable e) &#123;&#125;</span><br><span class="line">    </span><br><span class="line">    V res = <span class="keyword">null</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        V res = execute(<span class="keyword">new</span> ValueDeserializingRedisCallback(key) &#123;</span><br><span class="line"></span><br><span class="line">              <span class="meta">@Override</span></span><br><span class="line">              <span class="keyword">protected</span> <span class="keyword">byte</span>[] inRedis(<span class="keyword">byte</span>[] rawKey, RedisConnection connection) &#123;</span><br><span class="line">                  <span class="keyword">return</span> connection.get(rawKey);</span><br><span class="line">              &#125;</span><br><span class="line">          &#125;, <span class="keyword">true</span>);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">       <span class="keyword">try</span> &#123;</span><br><span class="line">         <span class="keyword">if</span> (tranx != <span class="keyword">null</span>) &#123;</span><br><span class="line">           tranx.setStatus(e);</span><br><span class="line">           tranx.complete();</span><br><span class="line">         &#125;</span><br><span class="line">       &#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">         </span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">throw</span> e;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (tranx != <span class="keyword">null</span>) &#123;</span><br><span class="line">        tranx.setStatus(<span class="string">"0"</span>);</span><br><span class="line">        tranx.complete();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span>(Throwable e) &#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到，代码非常长，但是不用担心性能，经过编译优化之后很多其实都被优化掉了</p><h2 id="java-lang-instrument包"><a href="#java-lang-instrument包" class="headerlink" title="java.lang.instrument包"></a>java.lang.instrument包</h2><blockquote><p>Provides services that allow Java programming language agents to instrument programs running on the JVM. The mechanism for instrumentation is modification of the byte-codes of methods.<br>Package Specification</p></blockquote><p>Oracle的官网上对这个包的定义如上，简单的说就是给与我们能力动态的修改Java类的字节码<br>一般可以用来监控，织入类似于AOP的逻辑</p><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p>当时选择了javaassit进行字节码的织入，但是javaassit有一个很大的局限就是不能使用本地变量</p><p>比如<code>Transaction tranx</code>这个我们在声明出来之后，在下面的代码就获取不到这个变量了</p><p>但是整个方法不会触及多线程的场景，所以想到的方案就是放在一个ThreadLocal中</p><p>先构造出一个ThreadLocal的类进行封装</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedisCatLog</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> ThreadLocal&lt;RedisCatLog&gt; THREAD_LOCAL_CAT_LOG = <span class="keyword">new</span> ThreadLocal&lt;&gt;();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">startLog</span><span class="params">(String action, Object data)</span> </span>&#123;</span><br><span class="line">        THREAD_LOCAL_CAT_LOG.remove();</span><br><span class="line">        RedisCatLog redisCatLog = <span class="keyword">new</span> RedisCatLog(action);</span><br><span class="line">        redisCatLog.before(String.valueOf(data));</span><br><span class="line">        THREAD_LOCAL_CAT_LOG.set(redisCatLog);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">endLog</span><span class="params">(<span class="keyword">boolean</span> success)</span> </span>&#123;</span><br><span class="line">        RedisCatLog redisCatLog = THREAD_LOCAL_CAT_LOG.get();</span><br><span class="line">        <span class="keyword">if</span> (Objects.nonNull(redisCatLog)) &#123;</span><br><span class="line">            redisCatLog.after(success);</span><br><span class="line">            THREAD_LOCAL_CAT_LOG.remove();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String action;</span><br><span class="line">    <span class="keyword">private</span> Transaction tranx;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">RedisCatLog</span><span class="params">(String action)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.action = action;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">before</span><span class="params">(String data)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.tranx = Cat.newTransaction(<span class="string">"Cache."</span>, <span class="keyword">this</span>.action);</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>.tranx <span class="keyword">instanceof</span> NullMessage) &#123;</span><br><span class="line">            log.error(<span class="string">"is null message"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">this</span>.tranx.addData(<span class="string">"key"</span>, data);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">after</span><span class="params">(<span class="keyword">boolean</span> success)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (!success) &#123;</span><br><span class="line">            <span class="keyword">this</span>.tranx.setStatus(<span class="string">"failed"</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">this</span>.tranx.setStatus(<span class="string">"0"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">this</span>.tranx.complete();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样，有了这个类之后，我们的织入代码就比较简单了</p><ul><li>给现有方法的开始加入RedisCatLog.startLog()</li><li>给方法的结尾加上RedisCatLog.endLog()</li><li>给原有的完整代码加上try catch</li></ul><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">public V get(Object key) &#123;</span><br><span class="line">    try &#123;RedisCatLog.startLog("get", key);&#125; catch(Throwable e) &#123;&#125;</span><br><span class="line">  </span><br><span class="line">    try &#123;</span><br><span class="line">        V res = execute(new ValueDeserializingRedisCallback(key) &#123;</span><br><span class="line">              @Override</span><br><span class="line">              protected byte[] inRedis(byte[] rawKey, RedisConnection connection) &#123;</span><br><span class="line">                  return connection.get(rawKey);</span><br><span class="line">              &#125;</span><br><span class="line">          &#125;, true);</span><br><span class="line">    &#125; catch(Throwable e) &#123;</span><br><span class="line">        try &#123;RedisCatLog.endLog(false);&#125; catch(Throwable e) &#123;&#125;</span><br><span class="line">        throw e;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    try &#123;RedisCatLog.endLog(true);&#125; catch(Throwable e) &#123;&#125;</span><br><span class="line">    return res;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>整体来看是不是简单的了很多</p><p>下面就是具体的javaassit代码编写了</p><p>在编写时参考了文档，并没有系统的学习javaassit</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">String methodName = methods[i].getName();</span><br><span class="line">CtClass etype = ClassPool.getDefault().get(<span class="string">"java.lang.Throwable"</span>);</span><br><span class="line">methods[i].addCatch(<span class="string">"&#123; RedisCatLog.endLog(false); throw $e; &#125;"</span>, etype);</span><br><span class="line">methods[i].insertBefore(before(classMethodNameInfo.getType() + <span class="string">"-"</span> + methodName));</span><br><span class="line">methods[i].insertAfter(after());</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">before</span><span class="params">(String action)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> String.format(<span class="string">"try &#123; RedisCatLog.startLog(\"%s\", $1); &#125; catch (Throwable e) &#123;&#125;"</span>, action);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">after</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="string">"try&#123; RedisCatLog.endLog(true);&#125; catch (Throwable e) &#123;&#125;"</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>大概的整体逻辑如下</p><p>项目我传到了Github上，<a href="https://github.com/zhyzhyzhy/CatRedisLogAspect" target="_blank" rel="noopener">https://github.com/zhyzhyzhy/CatRedisLogAspect</a></p><p>大家可以参考文档进行使用</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;Cat是美团开源的一套监控系统，功能非常强大&lt;br&gt;一般对方法进行打点，它会自动生成每个方法的耗时，同时也会记录全链路的每个调用方法的耗时&lt;/p&gt;
&lt;p&gt;对于查系统的性能瓶颈和稳定性有非常大的帮助&lt;/p&gt;
    
    </summary>
    
    
      <category term="Spring和SpringBoot" scheme="https://blog.lovezhy.cc/categories/Spring%E5%92%8CSpringBoot/"/>
    
    
      <category term="Spring" scheme="https://blog.lovezhy.cc/tags/Spring/"/>
    
      <category term="Cat" scheme="https://blog.lovezhy.cc/tags/Cat/"/>
    
  </entry>
  
  <entry>
    <title>Raft实现指北</title>
    <link href="https://blog.lovezhy.cc/2019/09/05/Raft%E5%AE%9E%E7%8E%B0%E6%8C%87%E5%8C%97/"/>
    <id>https://blog.lovezhy.cc/2019/09/05/Raft%E5%AE%9E%E7%8E%B0%E6%8C%87%E5%8C%97/</id>
    <published>2019-09-04T16:00:00.000Z</published>
    <updated>2020-02-29T14:53:02.382Z</updated>
    
    <content type="html"><![CDATA[<p>Raft实现指北<br><a id="more"></a></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>自己陆陆续续花了一些时间完成了一个Raft的库，目前基本的流程都完成了，下面要继续做的话，就是要进行一些优化的逻辑了。<br><a href="https://github.com/zhyzhyzhy/Rub-Raft" target="_blank" rel="noopener">Rub-Raft</a><br>取名叫Rub，就是卢布的意思，纪念雯姐今年去世的花枝鼠[2016-2019]。<br>卢布是我见过最乖的鼠，很聪明，她喜欢睡在吊床上，不会像其他的鼠去啃吊床的线。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>一个很好的博文<br><a href="https://lichuang.github.io/post/20180921-raft/" target="_blank" rel="noopener">https://lichuang.github.io/post/20180921-raft/</a>  </p><p>《CONSENSUS: BRIDGING THEORY AND PRACTICE》论文<br><a href="https://ramcloud.stanford.edu/~ongaro/thesis.pdf" target="_blank" rel="noopener">https://ramcloud.stanford.edu/~ongaro/thesis.pdf</a>  </p><p>动画讲解<br><a href="https://raft.github.io/" target="_blank" rel="noopener">https://raft.github.io/</a></p><h2 id="整体流程"><a href="#整体流程" class="headerlink" title="整体流程"></a>整体流程</h2><p>集群的整体状态一般分为三种</p><ul><li>选举</li><li>日志添加<ul><li>正常添加</li><li>非正常添加</li><li>新节点获取日志</li></ul></li><li>新增节点</li></ul><p>我可能不太会对所有流程做详细的阐述，只是一些简单的问答和心得。</p><p>整个RPC的方法其实只要4个就可以完成Raft，前两个和选举有关，后两个和日志有关</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">VoteResponse <span class="title">requestPreVote</span><span class="params">(VoteRequest voteRequest)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function">VoteResponse <span class="title">requestVote</span><span class="params">(VoteRequest voteRequest)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function">ReplicatedLogResponse <span class="title">requestAppendLog</span><span class="params">(ReplicatedLogRequest replicatedLogRequest)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function">InstallSnapshotResponse <span class="title">requestInstallSnapShot</span><span class="params">(InstallSnapshotRequest installSnapShotRequest)</span></span>;</span><br></pre></td></tr></table></figure><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><h3 id="需要节点的自动注册和发现吗"><a href="#需要节点的自动注册和发现吗" class="headerlink" title="需要节点的自动注册和发现吗"></a>需要节点的自动注册和发现吗</h3><p>一开始我还是RPC的实现思路，以为需要一个自动的节点注册和发现机制<br>当然其实并不需要，集群启动的时候，只要我们把初始的节点信息写死在启动Config文件中就好  </p><p>那么可不可以有呢，我理解是不可以的，因为选举的时候，节点需要知道当前节点的个数，来判断自己得到的选票是不是已经有集群节点的一半了。<br>如果你还搞个节点自动注册，那么到底集群有几个节点呢？</p><h2 id="节点的RPC连接"><a href="#节点的RPC连接" class="headerlink" title="节点的RPC连接"></a>节点的RPC连接</h2><p>讲道理其实RPC连接并不是什么大问题，但是我们不能先入为主的当做DUBBO这种RPC框架去实现我们的RPC框架。<br>这个问题的根源是：正常的RPC模型并不是互相问答的模式<br>都是C/S模型<br>一个节点一般会开一个Server，让其他的节点来连接，并提出请求，这个Server并不会主动向其他的Node发送消息。 </p><p>这个时候会想到，我们每个节点都当做是一个Server，然后对每个其他的Node，开对应的Client连接。我就是这么实现的，这样的情况其实对于两个节点而言，互相的连接通过了两个不同的Channel来实现。</p><p>后来发现其实这样还有问题。<br>问题是在无法重新连接的情况<br>假设这样的情形，3Node互相连接，过程中Node1断开，其他两个Node互相连接，过一阵子，Node1又启动，开启自己的RpcServer，并顺利连接到其他两个Node的RpcServer<br>而其他两个Node并不会主动的去连接Node1的RpcServer</p><p>这个就需要一种机制，当其他的节点连接上自己的RpcServer的时候，获得感知，然后自己也去连接对方的RpcServer</p><p>那么这个感知机制，放在哪里去做呢。<br>放在Rpc层面吗？我感觉侵入性很大，一方面作为一个Rpc并不需要这种机制，需要的话，也是一个抽象度很高的东西，类似于连接上的回调之类。</p><p>我这里另外开了一个RPC方法，叫<code>requestConnect</code>，当每个节点RPCClient或者RPCServer启动的时候，都会向其他的节点发送<code>requestConnect</code>请求，其他节点接收到这个请求，会检查自己与发送请求的节点的链路是否已经失效，如果失效，则请求重新连接。</p><p>这样完成的很好，但是就是RPC请求的次数会有点多。</p><h2 id="RPC请求的异步与同步"><a href="#RPC请求的异步与同步" class="headerlink" title="RPC请求的异步与同步"></a>RPC请求的异步与同步</h2><p>这个问题不是很复杂，但是我们如果自己实现RPC的话，要注意的一点就是不能不支持异步的方式。<br>我的RPC的实现中，支持3种请求方式</p><ul><li>SYNC 同步请求</li><li>ASYNC 异步请求</li><li>ONE_WAY 不需要返回的请求</li></ul><p>不过异步请求说白了就是RPC框架帮你封装好了SYNC的Future的方式</p><p>上面提到了Raft的需要的5种方法，那些需要异步呢</p><ul><li>requestConnect =&gt; ONE_WAY</li><li>requestPreVote =&gt; ASYCN</li><li>requestVote =&gt; ASYNC</li><li>requestAppendLog =&gt; SYNC</li><li>requestInstallSnapShot =&gt; SYNC</li></ul><h2 id="选举"><a href="#选举" class="headerlink" title="选举"></a>选举</h2><h3 id="节点启动顺序"><a href="#节点启动顺序" class="headerlink" title="节点启动顺序"></a>节点启动顺序</h3><p>节点启动的顺序要注意什么吗？<br>还是不需要，选举要得到一般的选票才能成为Leader，即使有一个节点最后启动，此时集群中已经选举出一个Leader了，最后启动的那个节点收到AppendLog的消息，就会自动变成Follower。</p><h3 id="节点初始化"><a href="#节点初始化" class="headerlink" title="节点初始化"></a>节点初始化</h3><p>节点初始化要做的事不多，就是设置自己的状态为<code>Follower</code><br>然后启动一个选举超时的定时器</p><h3 id="选举超时时间"><a href="#选举超时时间" class="headerlink" title="选举超时时间"></a>选举超时时间</h3><p>节点刚启动的状态是<code>Follower</code>，并且启动一个超时定时器，当时间到了的时候开始进行选举<br>那么这个超时的时间是多少呢？论文中给出的范围是150 - 300ms[章节3.4]  </p><h3 id="超时期间收到Request"><a href="#超时期间收到Request" class="headerlink" title="超时期间收到Request"></a>超时期间收到Request</h3><p>我们知道当选举超时之后，节点把自己的状态设为<code>pre_candidate</code>，并且发送消息给其他节点进行选举。<br>如果超时期间收到消息呢<br>论文中写，<code>A server remains in follower state as long as it receives valid RPCs from a leader or candidate.</code></p><p>很明晰，超时期间收到其他节点的Request，那么就不会进入选举流程，依然是一个Follower。</p><h3 id="超时方法什么时候调用"><a href="#超时方法什么时候调用" class="headerlink" title="超时方法什么时候调用"></a>超时方法什么时候调用</h3><p>在接收到PreVote，Vote，AppendLog的RPC请求接收到之后都要开始调用  </p><h3 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h3><p>要加锁吗，当然是要的<br>上一个我们提到<br>节点超时，开始发起选举RPC之前，启动超时，如果到超时结束，还没有选举出一个Leader，那么就把自己的term加一再次发起选举</p><p>这个过程中有两个事件需要一些条件的同步</p><ul><li>超时线程：没有收到Leader的信息和其他节点的选举信息，就执行，也就是心跳有更新</li><li>接收vote线程：收到Leader和其他节点的信息，还在超时未完成状态，就更新心跳信息</li></ul><p>如果分为两个方法的话，最简单的就是给整个方法都加锁<br>但是这样锁的粒度太大了，能不能把条件抽象出来呢</p><p>我想的是对Node的状态进行cas的修改<br>超时线程，首先判断心跳有没有更新，如果有更新就不进行选举，如果没有更新，就加锁的对NodeStatus进行CAS更新，从Follower更新到Pre_Candidate<br>接收Vote线程，首先对NodeStatus进行CAS的更新，从Follower更新到Follower，然后更新心跳时间<br>我们分析两个线程的流程<br>超时线程</p><ul><li>1.判断心跳有没有更新</li><li>2.NodeStatus从Follower更新到Pre_Candidate</li></ul><p>接收Vote线程</p><ul><li>3.首先对NodeStatus进行CAS的更新，从Follower更新到Follower</li><li>4.更新心跳时间</li></ul><p>如果不加锁，流程从3 - 1 - 2 - 4就出问题了</p><p>这个思路很麻烦</p><p>我们再换个思路</p><p>超时线程进行vote的时候，需要对term进行+1<br>接收Vote线程，如果成功接收其他节点的信息维持Follower的话，那么对面的term肯定比自己大的，那么也就是需要对Term进行加1</p><p>所以我们对Term进行cas操作，谁成功了谁进行操作</p><h3 id="PreVote"><a href="#PreVote" class="headerlink" title="PreVote"></a>PreVote</h3><p>其实论文中并没有很直观的提到PreVote的阶段<br>需要PreVote的原因也不复杂，可以百度一下。</p><h3 id="VoteFor可以进行修改吗"><a href="#VoteFor可以进行修改吗" class="headerlink" title="VoteFor可以进行修改吗"></a>VoteFor可以进行修改吗</h3><p><code>Vote</code>阶段<br>假设这样一种场景：<br>我们有节点1 2 3<br>2最后启动<br>1，3同时超时，且3的请求先到2<br>3，term = 1，2投票给他，1拒绝，于是3变成leader<br>1，term=1，2拒绝了他，3也拒绝了他</p><p>这个时候Term2其实已经有Leader了，是3，那么1也要变成Follower<br>这个时候1收到HeartBeat就要把自己变成Follower<br>那么这里的1的Term=1的votedfor其实已经设置为自己了<br>所以VotedFor还是可以进行修改的  </p><h3 id="Leader发现更高任期的Server"><a href="#Leader发现更高任期的Server" class="headerlink" title="Leader发现更高任期的Server"></a>Leader发现更高任期的Server</h3><p>这种情况也是会发现的，就是Leader进行了STW的GC，然后其他的节点进行了超时选举，选出了Leader。<br>这种时候，原来的Leader的GC结束，进行进行AppendLogRequest，就会发现更高任期的Server<br>这种情况直接自己变成Follower就行</p><h3 id="日志比较的原则"><a href="#日志比较的原则" class="headerlink" title="日志比较的原则"></a>日志比较的原则</h3><p><a href="https://zhuanlan.zhihu.com/p/32052223" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/32052223</a><br>日志比较的原则是，如果本地的最后一条log entry的term更大，则term大的更新，如果term一样大，则Log Index更大的更新</p><h3 id="选举模型"><a href="#选举模型" class="headerlink" title="选举模型"></a>选举模型</h3><p>5个节点中，如果有两个节点同意，那么就可以成为Leader<br>但是反过来说，如果3个节点拒绝了，那么就不能成为Leader</p><p>第一个条件我们可以使用Latch<br>第二个条件我们还是可以使用Latch</p><p>那么怎么组合这两个Latch呢<br>答案就是<br>所以总而言之，不能用Latch<br>只能加锁唤醒了</p><p>我这里自己实现了一个类专门用来进行选举的计数。</p><h2 id="日志复制"><a href="#日志复制" class="headerlink" title="日志复制"></a>日志复制</h2><h3 id="Peer状态管理"><a href="#Peer状态管理" class="headerlink" title="Peer状态管理"></a>Peer状态管理</h3><p>这个也是我实现的时候遇到的比较棘手的问题<br>一开始也没有什么好的解决思路</p><p>因为每个节点的任务执行的状态在同一个时刻肯定是不一致的，有可能这个快一点，那个慢一点</p><p>也有可能就是有的是正常发送心跳，有的则是刚刚重启需要进行日志的同步  </p><p>但是有一个很明确的点就是每个Follower节点都是不同的状态管理</p><p>同时我们再关注下Leader向Follower节点发送心跳或者AppendLogRequest的频率，会发现每次只能有一个请求过去，当这个请求没有返回或者未超时失败时，是不能够发送下一个Rpc的。</p><p><img src="/images/raft/peer.png" alt=""></p><p>综合以上两点，我的设计就是为每个PeerNode分配一个任务队列，每个PeerNode都有一个单独的线程去拿队列的第一个任务，然后同步的执行。</p><p>当Leader需要进行发送心跳或者AppendLogRequest或者其他的请求时，直接Append一个Task到PeerNode的任务队列就行。</p><h3 id="除了AppendLog还要做什么"><a href="#除了AppendLog还要做什么" class="headerlink" title="除了AppendLog还要做什么"></a>除了AppendLog还要做什么</h3><p>这个也是一个误区，因为心跳的RpcRequest就是一个空的AppendLogRequest<br>我开始的实现中，会判断如果需要Append的Log为空，那么就重置一下选举定时器，然后就直接返回了。  </p><p>这个其实是错误的，我们对每一个AppendLogRequest都要进行日志的比对，把还没有Commit的日志，如果需要，给删了或者覆盖了。  </p><p>这么说可能不太明白，假设这样一种场景。<br>一共三个节点，Node1是Leader，三个节点的日志都是1，2，3，一致的。<br><img src="/images/raft/log.png" alt="">  </p><p>然后发生了网络分区，Leader被隔绝了，但是Node1并不知道，同时客户端的请求也过来了，虽然日志无法commit，但是还是Append到了Node1中。  </p><p>如果网络分区结束，Node2变成了Leader，Node2给Node1发送心跳的时候，这时候就需要根据Log的index和Leader的commitIndex，把4和5删掉。<br>这个BUG我也是找了很久，当初图省事简单也没考虑到这些。  </p><h3 id="ReplicatedLogResponse的变更"><a href="#ReplicatedLogResponse的变更" class="headerlink" title="ReplicatedLogResponse的变更"></a>ReplicatedLogResponse的变更</h3><p>如果是节点Down了之后重启，Leader发现nextIndex对不上的时候，会一步一步的退一个NextIndex把日志发送过去，但是每次都发送后续的全量的Log，开销会很大，所以这里可能可以加一个优化，就是在ReplicatedLogResponse加上自己的lastCommitIndex，让Leader可以一次定位到matchIndex。</p><h2 id="成员变更"><a href="#成员变更" class="headerlink" title="成员变更"></a>成员变更</h2><p>论文中讲了，如果3台节点中突然加了两台，可能出现两个Leader，一个通过新配置，一个通过旧配置。</p><p>所以一般的实现是一次只增加一个节点，这个增加的行为其实是人为控制的。</p><p>这个地方的实现也有一些坑点存在。</p><p>比如论文中写新配置是通过日志的形式进行Append进去的，那么这个日志的格式是啥样的呢。<br>一开始我们定义成了增加节点和删除节点的形式，比如<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ClusterChangeLog</span> </span>&#123;</span><br><span class="line">Type type; <span class="comment">//表示是增加节点还是删除节点</span></span><br><span class="line">NodeId nodeId; <span class="comment">//需要增加的节点Id或者删除的节点Id</span></span><br><span class="line">EndPoint endPoint; <span class="comment">//需要增加的节点Id或者删除的节点Id的IP和端口地址</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>像这种形式的日志进行Append，但是其实是不行的。</p><p>我们需要的Log要包含新的集群的所有的节点信息，是否是删除还是增加，删除还是增加的节点信息由节点的日志模块自己去解析。<br>所以正确的形式应该是这样<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ClusterChangeLog</span> </span>&#123;</span><br><span class="line">List&lt;NodeConfig&gt; nodeConfigs;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>为什么说第一种的形式是行不通的或者说实现起来有BUG呢？<br>主要的问题还是在要新增的那个节点上，</p><ul><li>首先新增的节点会有个像Leader获取日志的情况，在获取日志的时候，新增的节点还不属于集群，也就是说，在日志中并没有体现，除了Leader节点，其他的follower节点并不知道该节点的存在。也就是说，我们在开启新增的节点的时候，是不能够将现有的集群的配置写给他启动的，不然就自动连接到其他的节点上去了。</li><li>第二种情况就是，如果我们把当前的集群配置写给新增的那个节点，然后启动它，再把新的集群配置写给Leader，在Leader还没发送时，Leader挂了，那么这个新增的节点咋办呢，能办也能办，但是搞起来会很复杂</li></ul><p>所以我们需要在启动新的节点时，不给它写当前的集群的配置，然后把新增的集群信息写给Leader，Leader也不会立即写日志，而是会进行日志的同步，</p><ul><li>如果日志同步的过程中，Leader挂了，那么没关系，因为新的配置还没写日志，挂了就人为的再写给新的Leader就行，不会影响当前的集群</li><li>日志同步结束之后，把日志进行Append，然后发送给所有的节点，包括新增的节点，那么即使这中间Leader挂了，因为集群更改日志是只要Append就生效的，按照日志最新的才能当前Leader的原则，新的Leader出现之后，会把更改日志再同步到其他的节点，包括新增的节点。</li></ul><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>好的，代码写完了，那么你怎么测试你的代码的正确性呢。<br>这个是我当初头疼的一点，没什么办法进行测试，我到底有没有写对。</p><p>首先这是个分布式的应用，我们除了模拟分布式的环境，还要模拟网络的各种情况，这些肯定不是我们真实模拟硬件和网络情况的，所以肯定要侵入代码的。<br>但是这种需要侵入代码的方法，没有一个方法论在里面的话很容易写乱。</p><p>这里我参考了MIT6.824的课程代码<br><a href="https://github.com/chaozh/MIT-6.824/blob/master/src/raft/test_test.go" target="_blank" rel="noopener">MIT-6.824/blob/master/src/raft/test_tes</a> </p><p>这里模拟了诸多情况</p><ul><li>Leader断网</li><li>Leader断网又恢复</li><li>集群整体掉线恢复</li><li>网络分区</li></ul><p>等诸多情况</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Raft实现指北&lt;br&gt;
    
    </summary>
    
    
      <category term="分布式" scheme="https://blog.lovezhy.cc/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="raft" scheme="https://blog.lovezhy.cc/tags/raft/"/>
    
  </entry>
  
  <entry>
    <title>HotSpot原理指南-基本知识</title>
    <link href="https://blog.lovezhy.cc/2019/07/26/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/"/>
    <id>https://blog.lovezhy.cc/2019/07/26/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/</id>
    <published>2019-07-25T16:00:00.000Z</published>
    <updated>2020-02-29T14:36:27.956Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>作为写了好几年Java的人，自然想去深入了解一下JVM的构造，它的具体实现。</p><p>Clone了代码，运行了起来，看了《HotSpot实战》和《揭秘Java虚拟机-JVM设计原理与实现》，但是能力一般，水平有限，对JVM还是知之甚少，发现继续研究下去将是一种苦修，要做好看很久代码都毫无进展的准备。但是本人志不在此，还是想去研究分布式与数据库，精力有限，只有暂且放弃JVM的深入研究。</p><p>如此直接放弃还是有点可惜，虽然目前学到的不成体系，但是还是想写一篇Blog记录一下。</p><p>所以此博客是上文提到的两本书的摘要+自己的一些学习理解，内容会很散，同时为了省力，摘要部分不特别标出。</p><a id="more"></a><h2 id="源码目录"><a href="#源码目录" class="headerlink" title="源码目录"></a>源码目录</h2><p>HotSpot源码目录较多，有几个是比较重要的</p><ul><li>/c1 =&gt; 客户端解释器</li><li>/classfile =&gt; Class文件解析</li><li>/gc =&gt; gc相关</li><li>/interpreter =&gt; C++解释器和模板解释器都在里面</li><li>/oops =&gt; Java的类模型，也就是OOP-KLASS模型</li><li>/opto =&gt; c2解释器，也就是服务端解释器</li><li>/prims =&gt; 供外部程序访问JVM的通道，比如JNI，Perf，JMX等</li><li>/runtime =&gt; 运行时模块，包括frame，thread，VMOptions等</li><li>/shark =&gt; 基于LLVM实现的JIT编译器</li></ul><h2 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h2><p>JMM开头的方法，和Memory没关系，指的是Management的意思</p><h2 id="命令行选项"><a href="#命令行选项" class="headerlink" title="命令行选项"></a>命令行选项</h2><p>JRockit JVM中命令行选项分为三种</p><ul><li>系统属性，-D开头</li><li>标准选项，-X,-Xms其实我觉得全拼是-X:memory-start?</li><li>非标准选项,-XX</li></ul><h2 id="Class文件解析"><a href="#Class文件解析" class="headerlink" title="Class文件解析"></a>Class文件解析</h2><p>Class文件的解析的代码都在/classfile目录下</p><p><img src="/images/JVM杂记/class文件格式.jpg" alt=""></p><p>HotSpot构建了一个叫systemDictionary的字典，结构是<code>[class name,class loader] -&gt; class</code>，用来存储系统中已经加载的类，从这个Map中我们可以看到一些类加载器的条件，双亲委派的概念。</p><p>在classFileParser.cpp中，宏定义了Class文件开头的MagicWord和Java_Version的对应关系<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> JAVA_CLASSFILE_MAGIC              0xCAFEBABE</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> JAVA_MIN_SUPPORTED_VERSION        45</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> JAVA_MAX_SUPPORTED_VERSION        53</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> JAVA_MAX_SUPPORTED_MINOR_VERSION  0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> JAVA_1_5_VERSION                  49</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> JAVA_6_VERSION                    50</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> JAVA_7_VERSION                    51</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> JAVA_8_VERSION                    52</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> JAVA_9_VERSION                    53</span></span><br></pre></td></tr></table></figure></p><p>文件解析后，各个Class文件是独立的，而各个类之间的联系其实是通过符号引用来串联在一起，JVM在进行符号引用的解析之后，就可以进行类型的相互引用和方法调用</p><p>JVM的链接分为三个部分：</p><ul><li>验证：对方法进行一系列的检查，方法的访问控制，参数和静态类型检查等</li><li>准备：为类静态变量分配内存空间，但是不会初始化值</li><li>解析：将常量池中的4类符号引用转换为直接引用(用常量池项表示的字符串 -&gt; 实际内存地址)<ul><li>类</li><li>接口</li><li>字段</li><li>类方法和接口方法</li></ul></li></ul><p>链接完之后就是进行初始化，也就是调用static {}方法</p><p>对于方法的链接，运用的是链接解析器，LinkResolver对方法进行解析和查找<br>对一个方法进行解析时，需要对instanceKlass中的method表进行查找，找到目标方法后转换成MethodHandle类型句柄返回<br>对方法的权限检查（public，private这种）是在找到之后进行</p><h2 id="runtime模块与Shutdown-Hook"><a href="#runtime模块与Shutdown-Hook" class="headerlink" title="runtime模块与Shutdown Hook"></a>runtime模块与Shutdown Hook</h2><p>runtime模块主要定义HotSpot运行时数据</p><p><code>frame.hpp</code>定义了栈帧的结构，包括Java栈帧，C栈帧。</p><p><code>destroy_vm</code>的退出流程中，会运行JVM层的关闭钩子函数。<br>这里的关闭钩子函数就是提到的<code>Runtime.getRuntime().addShutdownHook();</code><br>书中提到的File.deleteOnExit方法，也是调用的这个，但是获取方式看起来不太一样<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sun.misc.SharedSecrets.getJavaLangAccess()</span><br><span class="line">            .registerShutdownHook(<span class="number">2</span> <span class="comment">/* Shutdown hook invocation order */</span>,</span><br><span class="line">                <span class="keyword">true</span> <span class="comment">/* register even if shutdown in progress */</span>,</span><br><span class="line">                <span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                       runHooks();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br></pre></td></tr></table></figure></p><p>而且参数也是不止一个，看起来还可以指定顺序<br>但是不管咋样，最后两种方式其实都是调用的<code>Shutdown.add</code>方法<br>Runtime中的调用<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Shutdown.add(<span class="number">1</span> <span class="comment">/* shutdown hook invocation order */</span>,</span><br><span class="line">               <span class="keyword">false</span> <span class="comment">/* not registered if shutdown in progress */</span>,</span><br><span class="line">               <span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">                   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                       runHooks();</span><br><span class="line">                   &#125;</span><br><span class="line">               &#125;</span><br><span class="line">           );</span><br></pre></td></tr></table></figure></p><p>看Order的参数来说的话，其实Runtime的优先级更高，而File.deleteOnExit的优先级第二。</p><h2 id="synchronized实现"><a href="#synchronized实现" class="headerlink" title="synchronized实现"></a>synchronized实现</h2><p>synchronized方法或者代码块，会生成两个特殊的字节码  </p><ul><li>monitorenter  </li><li>monitorexit<br>对于解释器而言，具体的执行逻辑在<br><code>intercepter/bytecodeIntercepter.cpp 1803行 JDK9</code><br>也就是<code>CASE(_monitorenter)</code>中<br>具体的实现分为偏向锁，轻量级锁，重量级锁<br>最后会调用<code>InterpreterRuntime::monitorenter</code>方法，这个方法定义在<code>interpreter/interpreterRuntime.cpp</code>中<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">IRT_ENTRY_NO_ASYNC(<span class="keyword">void</span>, InterpreterRuntime::monitorenter(JavaThread* thread, BasicObjectLock* elem))</span><br><span class="line">...</span><br><span class="line">  <span class="keyword">if</span> (PrintBiasedLockingStatistics) &#123;</span><br><span class="line">    Atomic::inc(BiasedLocking::slow_path_entry_count_addr());</span><br><span class="line">  &#125;</span><br><span class="line">  Handle h_obj(thread, elem-&gt;obj());</span><br><span class="line">  assert(Universe::heap()-&gt;is_in_reserved_or_null(h_obj()),</span><br><span class="line">         <span class="string">"must be NULL or an object"</span>);</span><br><span class="line">  <span class="keyword">if</span> (UseBiasedLocking) &#123;</span><br><span class="line">    <span class="comment">// Retry fast entry if bias is revoked to avoid unnecessary inflation</span></span><br><span class="line">    ObjectSynchronizer::fast_enter(h_obj, elem-&gt;lock(), <span class="literal">true</span>, CHECK);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    ObjectSynchronizer::slow_enter(h_obj, elem-&gt;lock(), CHECK);</span><br><span class="line">  &#125;</span><br><span class="line"> ...</span><br></pre></td></tr></table></figure></li></ul><p>仔细看会使用到<code>ObjectSynchronizer</code>的两个方法，如果使用了偏向锁，那么就是<code>fast_enter</code>，如果不允许偏向锁，那么就是<code>slow_enter</code></p><p>在<code>slow_enter</code>的最后，如果还是不行，就会进入锁膨胀的状态，也就是重量级锁</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ObjectSynchronizer::inflate(THREAD,</span><br><span class="line">                            obj(),</span><br><span class="line">                            inflate_cause_monitor_enter)-&gt;enter(THREAD);</span><br></pre></td></tr></table></figure><p>这个时候就要用到<code>ObjectMonitor</code>类中的方法，最后还会涉及到<code>ObjectWaiter</code>类，这个类就是设计了一个链表，类似于<code>ReententLock</code>中的等待链表。</p><p>最后还是很好奇最终的互斥锁到底是怎么实现的，代码在<code>runtime/mutex.cpp</code>中，仔细看了一下，并没有使用到c语言中的Mutex库，最终还是依赖于CAS实现的。</p><p>其实说到底，最后所有的锁都是基于CAS + 链表。</p><p>这里有一个概念上的观念，就是<a href="https://stackoverflow.com/questions/1898374/does-the-jvm-create-a-mutex-for-every-object-in-order-to-implement-the-synchron" target="_blank" rel="noopener">https://stackoverflow.com/questions/1898374/does-the-jvm-create-a-mutex-for-every-object-in-order-to-implement-the-synchron</a>该问题中提到的</p><blockquote><p>Ask: Using only CAS instructions, how do you get the OS scheduler to put a thread to sleep? </p><p>Answer: you don’t. You only use CAS to acquire / release the lock in the uninflated / uncontended case. If contention is detected, the locking/unlocking code would then do the relevant thread scheduling syscalls … or whatever.</p></blockquote><p>如果你查看ReentrentLock的最后将等待的线程放入等待链表中，对线程调用的是<code>LockSupport.park()</code>方法，这是一个native方法，要去源码中找实现，在<code>hotspot/src/os/linux/vm/os_linux.cpp</code>中，可以看到这里为了让线程能够进入os的调度，也就是放弃CPU资源，还是需要进行<code>pthread_cond_wait</code>的调用的。最后对线程的唤醒，还是需要进行notify的。</p><p>在synchronized的底层实现中，最后也是进行park，调用的是<code>os::PlatformEvent::park</code>方法，使用的类是</p><p><code>class ParkEvent : public os::PlatformEvent</code></p><p>所以，(CAS+链表+pthread_mutex)才是真正的实现机制。</p><p>而如果是多线程争用的情况，其实最终的目的还是要保证原子释放CPU资源。</p><p>说了一堆，其实核心在锁的实现上，基本都放弃了直接使用pthread_mutex的方法，而是运用<strong>CAS的方式进行自旋</strong>，而pthread_mutex的使用仅仅是为了将线程进行操作系统的重新调度。</p><p>参考文章：</p><ul><li><a href="https://github.com/farmerjohngit/myblog/issues/15" target="_blank" rel="noopener">https://github.com/farmerjohngit/myblog/issues/15</a></li><li><a href="https://www.jianshu.com/p/c5058b6fe8e5" target="_blank" rel="noopener">https://www.jianshu.com/p/c5058b6fe8e5</a></li></ul><p>偏向锁<br>这个名词看名字不是那么容易理解，在JRockit中描述为延迟解锁</p><p><img src="/images/JVM杂记/锁转换.png" alt=""></p><blockquote><p>在上图中，有三种锁类型，其中胖锁和瘦锁在之前中介绍过，这里新增了延迟锁，用来解释 锁在大部分情况下都只作用于线程局部场景下的情况。<br>正如之前介绍过的，对象首先是未加锁状态的，然后线程 T1 执行 monitorenter 指令，使 之进入延迟加锁状态。但如果线程 T1 在该对象上执行了 monitorexit 指令，这时系统会假装 已经解锁了，但实际上仍是锁定状态，锁对象的锁字中仍记录着线程 T1 的线程 ID。在此之后， 线程 T1 如果再执行加锁操作，就不用再执行相关操作了。<br>如果另一个线程 T2 试图获取同一个锁，则之前所做“该锁绝大部分被线 T1 程使用”的假 设不再成立，会受到性能惩罚，将锁字中的线程 ID 由线程 T1 的 ID 替换为线程 T2 的。如果这 种情况经常出现，那么可能会禁用该对象作为延迟锁，并将该对象作为普通的瘦锁使用。假设这 是线程 T2 第一次在该对象上调用 monitorenter 指令，则程序会进入瘦锁控制流程。在上图中， 被禁用于延迟解锁的对象用星号(*)做了标记。此时，当线程 T3 试图在某个已被禁用于延迟解 锁的对象上加锁，如果该对象还未被锁定，则此时仍会使用瘦锁。<br>使用瘦锁时，如果竞争激烈，或者在锁对象上调用了 wait 方法或 notify 方法，则瘦锁会 膨胀为胖锁，需要等待队列来处理。从图中可以看到，处于延迟解锁状态的对象直接调用 wait 方法或 notify 方法的话，也会膨胀为胖锁</p></blockquote><p>单例模式的双重校验锁的实现其实是有问题的，加了volatile能解决问题，但是会带来略微的性能问题</p><h2 id="内存-OOP"><a href="#内存-OOP" class="headerlink" title="内存 OOP"></a>内存 OOP</h2><p>虚拟机中内存空间按照内存的用途，可以划分为<strong>堆和非堆</strong></p><ul><li>堆：用于对象的分配空间</li><li>非堆：包括方法区和Code Cache</li></ul><p>Perf Data区域，有perfMemory模块管理<br>为了支持虚拟机性能监控，在虚拟机中开辟了一块共享内存，专门存储一些性能指标<br>虚拟机使用共享内存方式向外部进程提供了一种通信手段，允许外部监控进程attach至虚拟机进程，从共享内存中读取这些perf Data</p><p>oop-klass模型<br>这个感觉是比较重要的点了<br>还是一个老生长谈的问题，why的问题<br>运用C++的基础模型去实现有没有问题呢？<br>其实我感觉是没有问题的，但是相对于C++的模型，Java这种方式，其实主要是更省内存。<br>同一个类的所有对象维护同一个VTable，其次就是和C++的多态方式不同，Java是模型每一个函数都是可以被子类覆盖的，而C++的只有是虚函数才能，换句话说，Java里面每个函数都是虚函数。<br>虚函数暴增的情况下，显然这种方式更加的省内存。<br>//fixMe</p><blockquote><p>而且我感觉还和Java的类加载机制有关，因为Java的符号引用转换为直接引用的解析过程，是可以再运行中才进行的，如果父类的方法被动态改变了，函数的地址肯定也需要进行相应的改变，而现有子类的对于这个方法的指向，只要改变一次Klass就行。</p></blockquote><p>在该模型中，Java的method也作为一种OOP存在</p><p><img src="/images/JVM杂记/markword.jpg" alt=""></p><p>实例对象的创建 分为快速分配和慢速分配  </p><ul><li>快速分配就是必须是该类已经被加载和正确解析 因为类的解析，就是符号引用变直接引用的过程不一定就是ClassLoader的时候进行，HotSpot是类第一次被使用的时候解析<br>快速分配就是可以在TLAB，就是线程缓存中分配，而不必先分配到Eden区，如果开启了TLAB选项</li><li>慢速分配就是需要先解析，然后在Eden区分配</li></ul><p>对象在内存中的布局，也就是OOP对象，可以分为连续的两部分，也就是MarkWord对象头和实例数据部分<br>而在Klass模型中，存储着对象的每个变量在实例数据部分的偏移量和长度</p><p>Klass中，有一个和Java类对应的mirror成员</p><p>JVM为每个线程分配一个PC寄存器，在真实机器中，往往提供一个PC寄存器专门用来保存程序运行的指令在内存中的位置，在HotSpot的实现中，为每个线程分配了一个字长的存储空间，以实现类似硬件级的PC寄存器<br>如果当前执行方法不是本地方法，那么PC寄存器就保存的是JVM正在执行的字节码指令的地址，如果是本地方法，那么PC寄存器的值是未定义的，因为本地方法的执行依赖硬件PC寄存器，其值是由操作系统维护</p><p>Java虚拟机栈的作用：存储方法执行中的局部变量，中间演算结果以及方法返回结果</p><p>JVM允许Java虚拟机栈被实现为固定大小和动态收缩</p><ul><li><p>固定大小，顾名思义，如果超过，抛出StackOverflowError异常</p></li><li><p>动态扩展：OOM异常</p></li></ul><p>虚拟机规范对方法区实现的位置并没有明确要求，在HotSpot中，位于永久代中。<br>HotSpot会收集方法区，主要是常量池的收集和类的卸载<br>在HotSpot内部，Java方法也是由一个内部对象表示的，对象的类型是methodOop，是Java方法在JVM内部的表示方式<br>methodOop内部有指向所在类的运行时常量池的指针<br>methodOop内部有个_constMethod指针，类型是constMethodOop，用来存储和定位方法中的只读数据，如字节码，方法引用，方法名，方法签名，异常表等信息</p><p>Perf Data区域，有perfMemory模块管理<br>为了支持虚拟机性能监控，在虚拟机中开辟了一块共享内存，专门存储一些性能指标<br>虚拟机使用共享内存方式向外部进程提供了一种通信手段，允许外部监控进程attach至虚拟机进程，从共享内存中读取这些perf Data</p><p>Java类的生命周期的第一个阶段，加载，就是为了在JVM内部创建一个与Java类结构对等的数据对象</p><p>如果想要破坏双亲委派的机制，自定义类加载器加载核心类库，还是会被拒绝，因为在defineClass方法中，会提供保护，对类名为Java开头的类，直接抛出异常</p><p>同样的，类型转换需要两个类都是同一个类加载器加载的，不然会报错，上次那个Dubbo的问题就这样，报错是两个一样的类，无法进行cast</p><h2 id="GC"><a href="#GC" class="headerlink" title="GC"></a>GC</h2><p>GC的几个策略</p><ul><li>GC工作线程：串行还是并行</li><li>GC工作线程和应用线程：并发执行还是暂停应用</li><li>基本收集算法：压缩，非压缩还是拷贝</li></ul><p>吞吐量：应用程序运行时间/(应用程序运行时间 + 垃圾收集时间)</p><p>HotSpot每个线程在Eden区都有自己的一小块区域，用于TLAB分配<br>通常情况下，系统中有大量连续的内存块可以用来进行分配的话，碰撞指针算法进行分配，效率很高。思路就是记录上一次分配对象的位置，当有新对象要分配的时候，只需要一次移动位置就可以完成内存的分配<br>在TLAB中进行分配，也就是碰撞指针(bump-the-pointer)分配，效率很高</p><p>不然就需要全局锁进行在Eden区分配</p><p>还有另外一种优化，叫栈上分配</p><p>栈上分配需要对方法的对象进行逃逸分析<br>如果局部变量的作用域仅限于方法内部，则JVM直接在栈帧内分配对象，避免在堆中分配<br>但是这里引用R大的话</p><blockquote><p>嗯但是Oracle/Sun的HotSpot VM从来没在产品里实现过栈上分配，而只实现过它的一种特殊形式——标量替换（scalar replacement）。这俩是不一样的喔。栈上分配还是要分配完整的对象结构，只不过是在栈帧里而不在GC堆里分配；标量替换则不分配完整的对象，直接把对象的字段打散看作方法的局部变量，也就是说标量替换后就没有对象头了，也不需要把该对象的字段打包为一个整体。<br><a href="https://book.douban.com/people/RednaxelaFX/annotation/25847620/" target="_blank" rel="noopener">https://book.douban.com/people/RednaxelaFX/annotation/25847620/</a></p></blockquote><p>有个类叫GCCause，里面定义了一些枚举，就是引起GC的一些情况<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum</span> Cause &#123;</span><br><span class="line"><span class="comment">/* public */</span></span><br><span class="line">_java_lang_system_gc,</span><br><span class="line">_full_gc_alot,</span><br><span class="line">_scavenge_alot,</span><br><span class="line">_allocation_profiler,</span><br><span class="line">_jvmti_force_gc,</span><br><span class="line">_gc_locker,</span><br><span class="line">_heap_inspection,</span><br><span class="line">_heap_dump,</span><br><span class="line">_wb_young_gc,</span><br><span class="line">_wb_conc_mark,</span><br><span class="line">_wb_full_gc,</span><br><span class="line">_update_allocation_context_stats_inc,</span><br><span class="line">_update_allocation_context_stats_full,</span><br><span class="line"></span><br><span class="line"><span class="comment">/* implementation independent, but reserved for GC use */</span></span><br><span class="line">_no_gc,</span><br><span class="line">_no_cause_specified,</span><br><span class="line">_allocation_failure,</span><br><span class="line"></span><br><span class="line"><span class="comment">/* implementation specific */</span></span><br><span class="line"></span><br><span class="line">_tenured_generation_full,</span><br><span class="line">_metadata_GC_threshold,</span><br><span class="line">_metadata_GC_clear_soft_refs,</span><br><span class="line"></span><br><span class="line">_cms_generation_full,</span><br><span class="line">_cms_initial_mark,</span><br><span class="line">_cms_final_remark,</span><br><span class="line">_cms_concurrent_mark,</span><br><span class="line"></span><br><span class="line">_old_generation_expanded_on_last_scavenge,</span><br><span class="line">_old_generation_too_full_to_scavenge,</span><br><span class="line">_adaptive_size_policy,</span><br><span class="line"></span><br><span class="line">_g1_inc_collection_pause,</span><br><span class="line">_g1_humongous_allocation,</span><br><span class="line"></span><br><span class="line">_dcmd_gc_run,</span><br><span class="line"></span><br><span class="line">_last_gc_cause</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><p>收集算法</p><ul><li>标记-清除 Mark-Sweep</li><li>复制算法 Copying</li><li>标记-压缩算法 Mark-Compact</li></ul><p>堆的类型</p><p>不同的收集器可能对应着不同类型的堆</p><p><code>CollectedHeap &lt;- ParallelScavengeHeap</code></p><p><code>CollectedHeap &lt;- SharedHeap &lt;- G1CollectedHeap</code></p><p>CMS的创新之处在于把标记分为两个阶段，初始标记和并发标记</p><p>但是引入了新的缺点，就是并发收集失败的问题，在并发标记时，内存使用过度，只有STW，采取线性标记和收集</p><p>而且只能由于并发清除的问题，只能进行标记-清除，将产生内存碎片，而新生代由于其特殊性，将产生更多的内存碎片，所以CMS在新生代并不适用，只运用在老年代</p><p>安全点</p><blockquote><p>由于JVM系统运行期间的复杂性，不可能做到随时暂停，因此引入了安全点（safepoint）：程序只有在运行到安全点的时候，才准暂停下来。HotSpot采取主动中断的方式，让执行线程在运行时轮询是否需要暂停的标识，若需要则中断挂起。</p></blockquote><p>//fixme<br>其实我觉得这里说的不对，应该不是不可能做到随时暂停，而是随时暂停的消耗太大了，因为后面也写到是主动中断的方式，如果在每个字节码后面都插入check是否需要中断的代码，则消耗确实是太大了<br>参考文章：<a href="https://www.jianshu.com/p/c79c5e02ebe6" target="_blank" rel="noopener">https://www.jianshu.com/p/c79c5e02ebe6</a></p><p>G1收集器<br>G1重新定义了堆空间，打破了原有的分代模型，将堆划分为一个个区域<br>在进行收集的时候，不必在全堆的范围内进行，好吃就是带来了停顿时间的可预测<br>G1会通过一个合理的计算模型，计算出每个region的收集成本并量化</p><p>分代模型的写屏障<br>这个是比较重要的一个，一开始是比较难理解的<br><img src="/images/JVM杂记/写屏障.png" alt=""><br>我们从正常的新生代的GC开始说，从图中看到，如果只从GCRoot出发，其实是扫描不到F的，如果扫描不到，说明F是需要被清除的<br>但是其实F被老年代的E所引用，也就是说他不能被清除<br>这就是说，GCRoot需要包含新生代中的被老年代引用的对象。<br>但是如果要实现这个功能，可能要扫描所有的老年代对象了，如果每次进行新生代的GC时都扫描老年代，那么分代GC的意义就不是那么明显了<br>所以这里用了一个写屏障，底层使用的是卡表的概念进行标记。<br>简单的说就是每当有老年代对象引用新生代对象时，就把老年代对象所在的位置标记一下，然后进行新生代GC时，把老年代标记了的位置进行扫描进行，而不用全部扫描<br><a href="https://juejin.im/post/5c39920b6fb9a049e82bbf94" target="_blank" rel="noopener">https://juejin.im/post/5c39920b6fb9a049e82bbf94</a></p><p>压缩指针<br>指针的大小一般是平台的决定的，但是在64位的机器上，但是还是可以进行一些优化，优化的基础是内存的申请是一下子一大片连续的内存<br>举个例子就是在64位机器上，如果我们要申请的一块内存小于4G，那么完全可以只用32位就可以进行指针的保存</p><p>JRockit里面提到了一种伪优化<br>就是对象池，有人认为，保留一个存活对象池来重新使用已创建的对象可以提升垃圾回收的性能</p><blockquote><p>但实际上，对象池不仅增加了应用程序的复杂度，还很容易出错。对于现代垃圾收集器来说，使用 java.lang. ref.Reference 系列类实现缓存，或者直接将无用对象的引用置为 null 就好了，不用多操心。<br>此外，长期持有无用的对象其实是个大麻烦，分代式垃圾回收器可以很好地处理临时对象，但如果这些临时对象被人为保存下来，无法被回收掉的话，最终就会被提升到老年代，并将其挤满。</p></blockquote><h2 id="栈帧"><a href="#栈帧" class="headerlink" title="栈帧"></a>栈帧</h2><p>如果函数要返回整数或者指针的话，寄存器%eax可以用来返回值<br>寄存器eax，edx，ecx被划分为调用者保存<br>而寄存器ebx，esi，edi寄存器划分为被调用者保存<br>栈是以帧为单位保存当前线程的运行状态<br>当线程执行一个方法时，它会跟踪当前常量池<br>栈帧存储了方法的局部变量表，操作数栈，动态链接和方法返回地址</p><p><img src="/images/JVM杂记/栈帧结构.png" alt=""><br><img src="/images/JVM杂记/解释器帧.png" alt=""></p><p>局部变量表</p><ul><li>局部变量表被组织为一个字长为单位，从0开始计数的数组</li><li>存储时以slot为单位，一个slot一般为32位，short，byte，char在存入表中要先转换为int</li><li>一般会存储的类型除了基本类型和引用，还有returnAddress类型，它指向了一个字节码指令的地址</li><li>参数值到参数变量列表的传递依赖于局部变量表</li><li>第0位索引的slot默认是用于传递方法所属对象实例的引用</li></ul><p>局部变量表的描述</p><ul><li>start_pc，length：描述局部变量的作用域</li><li>name_index：描述局部变量名的常量池索引，对应Class文件中的Name</li><li>descriptor_index:描述局部变量类型的常量池索引，对应Class文件中的Signature</li><li>index：描述局部变量在当前栈帧的局部变量索引</li></ul><p>局部变量表的大小在编译期就可以确定，在Code属性中明确了大小</p><p>操作数栈</p><ul><li>操作数栈的深度由Code属性max_stacks在编译期确定</li><li>和局部变量表不同的是，操作数栈不是通过索引来访问的，而是通过入栈和出栈来访问</li><li>还有一个比较重要的点，就是操作数栈和下一个栈帧的参数列表是可以复用的，不然我们在HSDB调试操作数栈的时候看起来会比较迷惑</li></ul><p>异常表<br>为了处理Java方法中的异常情况，帧数据区还必须保存一个对此方法异常表的引用，当异常抛出时，JVM给catch块中的代码<br>如果没发现，方法立即终止，然后JVM用帧区数据的信息回复发起调用的方法的帧，然后再发起调用方法的上下文重新抛出同样的异常</p><p>Hotspot解释器执行引擎在执行字节码时，实际上是执行一段已经被编译成本地机器直接运行的指令<br>在JVM启动期间，解释器模块就会将每个字节码转换成与之等价的机器指令，放在Code Cache中<br>所以HotSpot充分利用了计算机的资源，包括寄存器</p><h2 id="JavaCalls"><a href="#JavaCalls" class="headerlink" title="JavaCalls"></a>JavaCalls</h2><p>JavaCalls，说白了就是JVM调用Java方法</p><p>然后CallStub，是一个函数指针，在调用Java程序的Main函数时，需要使用这个函数指针</p><p>但是CallStub指向的函数是一个entry_point，是一个例程</p><p>当然这里其实是有歧义的例程在JVM的概念就是提前用机器码写好的函数，而entry_point虽然也是例程，然后它主要突出entry这个词，主要是在方法调用切换时进行调用的例程</p><p>再说回CallStub，它指向的例程，就是为所有Java程序的唯一一个Main方法构造他的前一个栈帧</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;&#125;</span><br></pre></td></tr></table></figure><p>最直接的就是参数args，在栈中需要使用CallStub指向的例程构建好，然后CallStub的函数指针的函数中，还需要传入一个entry_point，这个就是在进行Java函数调用的时候，需要进行寄存器的保存等之类的操作，而这些操作由不同的entry_point来操作。</p><p>//fix me</p><p>个人理解就是在各种invoke的字节码指令中，会频繁的调用这些不同的entry_point。</p><h2 id="常量池"><a href="#常量池" class="headerlink" title="常量池"></a>常量池</h2><p>其实JVM中常量池有两种不同的概念<br>第一种是Class文件的常量池<br>虚拟机在创建一个类或者接口时候，按照Class文件的定义创建相应的常量池，也就是Class文件中的constant_pool表。<br>第二种是方法区中的常量池，虚拟机在对类进行解析和连接之后，将在内存中为该类生成一套运行时常量池，常量池在运行时动态分配<br>第三种是代码中我们提到的常量池，也就是String常量池，JVM中创建了一个String的Table</p><p>参考<a href="https://blog.csdn.net/zm13007310400/article/details/77534349" target="_blank" rel="noopener">https://blog.csdn.net/zm13007310400/article/details/77534349</a></p><p>那么为什么要有常量池呢<br>Answer：</p><blockquote><p>常量池的出现，解决了JVM定位字段和方法的问题，它在不破坏指令集的简洁性的前提下，仅仅通过少量字节就能定位到目标。<br>更详细的说，以字符串数据aVeryLongFunctionName为例，如果在编译时每次都要重新避免这个字符串的话，那么字节码就谈不上压缩了</p></blockquote><p>但是每次字段或者方法的访问都需要解析常量池项的话，将不可避免的造成性能下降<br>对于类文件的运行时常量池，JVM内还会有它的高速缓冲ConstantPoolCache</p><h2 id="解释器"><a href="#解释器" class="headerlink" title="解释器"></a>解释器</h2><p>HotSpot的解释器分为了两种<br>一种是CPP解释器，也就是最原始的解释器，类似于Case，Case这种形式，文件是intercepter/bytecodeIntercepter.cpp<br>一种是模板解释器，现在默认是这样，这种是在JVM启动时对每一个字节码都进行了当前平台的机器码转换，具体的是维护了一个平台相关TemplateTable，可以在cpu/x86/vm中的templateTable_XX.cpp中找到，相对于CPP解释器，其实这也是一种解释的方法，虽然第一种最终执行的也是C++编译成的机器码，但是模板解释器相对于CPP解释器，机器码是手动写的，可以进行一些优化，比如TOS，还有就是对于取出下一个执行进行运行，也可以直接插入到当前字节码的机器码中</p><p>对于模板解释器的取指令的操作，其实在写在每一个字节码指令的最后。<br>HotSpot在为每一个字节码指令生成其机器逻辑指令时，会同时为该字节码指令生成其取址逻辑</p><p>PC计数器，在x86平台上就是esi寄存器，所以在JVM中并不是完全不使用CPU的寄存器</p><p>面向栈式的指令，可以省去很多的操作数，所以一定程度上也减少了代码体积<br>这话其实不对，因为相对于寄存器式的指令，寄存器式的一个指令就能完成的事，其实栈式需要多个指令</p><p>栈帧重叠<br>就是前面提到的上一个方法的操作数栈可以直接成为下一个方法的参数表</p><p>栈上替换 OSR<br>个人理解就是在一个方法里遇到了Loop非常久的情况，对方法进行了JIT编译，但是由于这个Loop非常长，JIT编译完还未结束，所以为了将当前方法替换到新的栈帧，使用栈上替换<br>具体的解释在R大这儿<br><a href="https://www.zhihu.com/question/45910849" target="_blank" rel="noopener">OSR（On-Stack Replacement）是怎样的机制？</a><br>JRockit没有实现OSR，因为太复杂了</p><p>JIT编译器<br>为什么不直接全部aot编译一下，而是选择了解释+JIT的方式<br>R大这里也回答了[<a href="https://www.zhihu.com/question/37389356)(https://www.zhihu.com/question/37389356" target="_blank" rel="noopener">https://www.zhihu.com/question/37389356)(https://www.zhihu.com/question/37389356</a>)<br>我总结一下</p><ul><li>时间开销，aot的启动时间肯定很慢</li><li>空间开销，字节码到机器码会代码膨胀</li><li>编译时机，一些profile的收集对编译有很大的影响<blockquote><p>JIT是一个充满希望的方向，因为它可以搜集到程序在AOT编译时得不到的runtime数据，在优化时，有更多的上下文可以依靠，理论上应该有更好的优化特性</p></blockquote></li></ul><p>在JRockit中，讲了aot其实在90年代就已经出现了，但是这种方式虽然快了很多，但是抛弃了很多Java的动态特性，提到了一个很重要的场景，就是在JSP的应用中，我们知道JSP其实就是b被编译成class文件，做的事也仅仅是疯狂的sout，如果aot一下，效率不会提高太多，但是代码体积会提高很多</p><p>其实aot与全部JIT编译并不是一个概念，一个好的办法是，给JIT的编译加上不同层级的编译，一开始可能是优化不高的，后面收集到profile后再进行深层次的profile</p><p>判断热方法</p><ul><li>counter，但是会降低效率</li><li>基于软件的线程采样，周期性的获取活动线程的上下文</li></ul><p>JVM字节码的表现力其实比Java语言强，所以需要对字节码进行校验，防止一些恶意的技巧</p><h2 id="TOS"><a href="#TOS" class="headerlink" title="TOS"></a>TOS</h2><p>TosState的取值范围为0-8，共计9种</p><ul><li>byte，bool</li><li>char</li><li>short</li><li>int</li><li>long</li><li>float</li><li>double</li><li>object</li><li>void</li></ul><p>最后一种其实就是空，参见R大的笔记，HotSpot实战中写的是tos类型，我还去百度了tos类型是啥类型😓 </p><h2 id="VM选项"><a href="#VM选项" class="headerlink" title="VM选项"></a>VM选项</h2><table><thead><tr><th>配置</th><th>解释</th><th>备注</th></tr></thead><tbody><tr><td>-XX:UseG1GC</td><td>配置G1收集器</td><td></td></tr><tr><td>-Xint</td><td>配置虚拟机以纯解释方式运行</td><td></td></tr><tr><td>-XX:+MaxFDLimit</td><td>最大文件描述符数量</td><td></td></tr><tr><td>-XX:DisableExplicitGC</td><td>Parallel Scanvenge收集器的配置，屏蔽System.gc()</td></tr></tbody></table><h2 id="Tools"><a href="#Tools" class="headerlink" title="Tools"></a>Tools</h2><p>实际的性能分析可以查看《HotSpot实战》的5.3小节，讲的很详细</p><ul><li>HSDB：可以用来看JVM的运行时数据，查看线程栈，对象的数据</li><li>jps：查看Java进程信息</li><li>jinfo：</li><li>jmap：</li><li>jhat：</li><li>jstat：</li><li>jstack：</li></ul><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://book.douban.com/people/RednaxelaFX/annotation/25847620/?start=0" target="_blank" rel="noopener">RednaxelaFX对《HotSpot实战》的笔记</a><br><a href="https://book.douban.com/subject/25847620/" target="_blank" rel="noopener">HotSpot实战</a><br><a href="https://book.douban.com/subject/30394745/" target="_blank" rel="noopener">JRockit权威指南：深入理解JVM</a><br><a href="https://book.douban.com/subject/27086821/" target="_blank" rel="noopener">https://book.douban.com/subject/27086821/</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;作为写了好几年Java的人，自然想去深入了解一下JVM的构造，它的具体实现。&lt;/p&gt;
&lt;p&gt;Clone了代码，运行了起来，看了《HotSpot实战》和《揭秘Java虚拟机-JVM设计原理与实现》，但是能力一般，水平有限，对JVM还是知之甚少，发现继续研究下去将是一种苦修，要做好看很久代码都毫无进展的准备。但是本人志不在此，还是想去研究分布式与数据库，精力有限，只有暂且放弃JVM的深入研究。&lt;/p&gt;
&lt;p&gt;如此直接放弃还是有点可惜，虽然目前学到的不成体系，但是还是想写一篇Blog记录一下。&lt;/p&gt;
&lt;p&gt;所以此博客是上文提到的两本书的摘要+自己的一些学习理解，内容会很散，同时为了省力，摘要部分不特别标出。&lt;/p&gt;
    
    </summary>
    
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/categories/HotSpot/"/>
    
    
      <category term="JVM" scheme="https://blog.lovezhy.cc/tags/JVM/"/>
    
  </entry>
  
</feed>
