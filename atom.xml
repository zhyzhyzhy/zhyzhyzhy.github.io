<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>LoveZhy</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://blog.lovezhy.cc/"/>
  <updated>2020-03-09T14:30:36.248Z</updated>
  <id>https://blog.lovezhy.cc/</id>
  
  <author>
    <name>zhy</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>搞懂内存屏障-CPU重排序</title>
    <link href="https://blog.lovezhy.cc/2020/03/09/%E6%90%9E%E6%87%82%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C-CPU%E9%87%8D%E6%8E%92%E5%BA%8F/"/>
    <id>https://blog.lovezhy.cc/2020/03/09/%E6%90%9E%E6%87%82%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C-CPU%E9%87%8D%E6%8E%92%E5%BA%8F/</id>
    <published>2020-03-08T16:00:00.000Z</published>
    <updated>2020-03-09T14:30:36.248Z</updated>
    
    <content type="html"><![CDATA[<p>我决定写一个系列，从头到尾讲一讲我理解的内存屏障的起源。<br>要想真正理解内存屏障，其实要讲很多的东西。</p><p>第一节，先来讲讲CPU的执行与重排序。</p><a id="more"></a><h1 id="CPU的执行"><a href="#CPU的执行" class="headerlink" title="CPU的执行"></a>CPU的执行</h1><h2 id="流水线"><a href="#流水线" class="headerlink" title="流水线"></a>流水线</h2><p>当然我对CPU几乎没系统的学过，都是从网上看看博客学来的。</p><p>CPU执行一条指令需要4个步骤（当然网上可能有其他说法，比如三个步骤或者五个步骤，不过没关系，不影响下面我们的结论）：</p><ol><li>取址：从内存中取出指令</li><li>译码：翻译指令，生成响应的控制信号</li><li>执行：使用CPU的逻辑处理单元计算</li><li>回写：把结果写回到寄存器或者内存</li></ol><p>假设我们有三条指令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mov $0x0, %esi</span><br><span class="line">mov $0x0, %edi</span><br><span class="line">and $0xf, %ebx</span><br></pre></td></tr></table></figure></p><p>我们把这四个步骤都合并成一个组合逻辑去运行的话<br>架构图如下：<br><img src="/images/CPU重排序/1.png" alt=""></p><p>那么我们需要的时间其实就是串行的，如下图：<br><img src="/images/CPU重排序/2.png" alt=""></p><p>但是这样，太慢了。<br>于是CPU流水线技术就诞生了（大约在Intel 386里开始出现）。</p><p>原理大概是把一个组合逻辑，拆分成多个小的组合逻辑：<br><img src="/images/CPU重排序/3.png" alt=""><br>这样，第一个指令进行组合逻辑B的时候，第二个指令就可以进行组合逻辑A了。<br>我们的时间消耗可以大大减少：<br><img src="/images/CPU重排序/4.png" alt=""></p><h2 id="冒险"><a href="#冒险" class="headerlink" title="冒险"></a>冒险</h2><p>上面的例子中，流水线可以非常完美。因为我们的三个指令所需的数据都互不依赖。<br>但是如果指令是这样的：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Mov $0x0, %esi</span><br><span class="line">Mov $0x0, %edi</span><br><span class="line">Add %esi, %edi</span><br></pre></td></tr></table></figure></p><p>第三个指令，是把第一个指令和第二个指令的结果进行相加<br>如果我们仍采用上述的流水线去运行，就会出问题：<br><img src="/images/CPU重排序/5.png" alt=""><br>CPU在执行Add指令时，依赖第二步中%edi的值。<br>但是指令3执行到第二个组合逻辑时，第二个指令还没写回到寄存器。<br>这样下去，指令3的Add用到的%edi，其实就不是0。<br>和预期的结果不符合。</p><p>这个就叫冒险<br>其中冒险分为数据冒险和控制冒险，数据冒险就是我们上面提到的。<br>而控制冒险和数据冒险类似，不过一般涉及到跳转指令。</p><p>如：<br><img src="/images/CPU重排序/6.png" alt=""><br>我们在执行JE的时候，依赖上一步的CMP的结果，导致正常的流水线执行就会有问题。</p><h2 id="Bubble"><a href="#Bubble" class="headerlink" title="Bubble"></a>Bubble</h2><p>那怎么解决呢？<br>就是插入Nop指令。</p><p><img src="/images/CPU重排序/7.png" alt=""><br>如上图所示，我们在第二个指令和第三个指令中间加入一个Nop指令，空转一个流水线。</p><p>当然我们不需要编译器每次都进行加入Nop，CPU会自己加入。<br>这个就叫Bubble，而执行Bubble叫Stall。<br><img src="/images/CPU重排序/8.png" alt=""></p><p>对于分支预测而言，CPU除了Bubble，还可能会随机选择一个分支先去执行，等CMP的结果出来，如果预测错了，就把执行结果丢弃掉：<br><img src="/images/CPU重排序/9.png" alt=""><br>分支预测失败当然是比较消耗性能的，Google的报告上指出了一次错误的分支预测的耗时：<br><img src="/images/CPU重排序/10.png" alt=""></p><p><img src="/images/CPU重排序/11.png" alt=""></p><h1 id="重排序"><a href="#重排序" class="headerlink" title="重排序"></a>重排序</h1><p>除了Bubble和分支预测的解决方案，还有一种解决方案，就是CPU的重排序。</p><p>对于下面的指令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ADD AX, BX;   </span><br><span class="line">INC AX;         </span><br><span class="line">MOV CX, DX;</span><br></pre></td></tr></table></figure></p><p>ADD和INC操作都用到了AX，必然会导致Stall。<br>但是我们发现MOV指令和ADD和INC都没有关系，<br>那么我们能不能调换顺序：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ADD AX, BX;  </span><br><span class="line">MOV CX, DX; </span><br><span class="line">INC AX;</span><br></pre></td></tr></table></figure></p><p>在执行时使用这种次序呢？<br>毕竟这种次序，就不会产生Stall，性能必然会提升。</p><p>这种就是CPU的重排序。</p><h1 id="锅是谁的？"><a href="#锅是谁的？" class="headerlink" title="锅是谁的？"></a>锅是谁的？</h1><p>在x86的机器上，CPU会进行大量的指令重排序。<br>但是CPU重排序也不会想重排就重排的，而是需要遵守一定的规范，不然就会影响软件的正常运行。</p><p>比如说下面这段经典的代码：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> x = <span class="number">0</span>, y = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> a = <span class="number">0</span>, b = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">far</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    a=<span class="number">1</span>;</span><br><span class="line">    x=b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    b=<span class="number">1</span>;</span><br><span class="line">    y=a;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>如果我们启动两个线程分别去执行far和bar函数。<br>正常的情况下，要么x=1，要么y=1，要么x=y=1;<br>但是也可能是x=y=0;</p><p>怎么解释的呢？很多人是这么解释的，这里我找了一个博客的解释：</p><blockquote><p>这是处理器乱序执行的结果：<br>线程t1内部的两行代码之间不存在数据依赖<br>因此，可以将x = b乱序到a = 1前；<br>同时，线程t2中的y = a早于线程t1中的a = 1执行。<br>一个可能的执行序列如下：<br>t1: x = b<br>t2: b = 1<br>t2: y = a<br>t1: a = 1</p></blockquote><p>看起来非常的有道理，CPU乱序执行害死人。<br>但是事实确实如此吗？<br>这个锅真的是CPU重排序执行导致的吗？</p><h1 id="真的能观测到CPU的重排序吗"><a href="#真的能观测到CPU的重排序吗" class="headerlink" title="真的能观测到CPU的重排序吗"></a>真的能观测到CPU的重排序吗</h1><p>我对CPU不熟悉，这里我就举几个网上的答案反驳吧。</p><h2 id="反驳一"><a href="#反驳一" class="headerlink" title="反驳一"></a>反驳一</h2><p><a href="https://stackoverflow.com/questions/50307693/does-an-x86-cpu-reorder-instructions" target="_blank" rel="noopener">Does an x86 CPU reorder instructions?</a><br>这个是英文回答，内容有点多，我从里面摘抄几个：</p><blockquote><p>Yes, all modern x86 chips from Intel and AMD aggressively reorder instructions across a window which is around 200 instructions deep on recent CPUs from both manufacturers</p></blockquote><p>肯定了x86的CPU会执行很多的指令重排序</p><blockquote><p>That should answer the titular question, but then your second question is about memory barriers. It contains, however, an incorrect assumption that instruction reordering necessarily causes (and is the only cause of) visible memory reordering</p></blockquote><p>这个其实超纲了，他提到了内存可见性的重排序。<br>否定了CPU的指令执行重排序一定会导致内存可见性问题。</p><blockquote><p>At the same time, x86 defines quite a strict memory model, which bans most possible reorderings<br>So actually most memory re-orderings are not allowed</p></blockquote><p>重点来了，x86定义了一个严格的内存模型，这个内存模型禁止了大多数可能的重排序<br>后续的文章中，我会提到这个内存模型。</p><blockquote><p>So it is possible to define an ISA that doesn’t allow any re-ordering at all, but under the covers do re-ordering but carefully check that it isn’t observed</p></blockquote><p>注意看这个词，<strong>observed</strong>。<br>是的，CPU确实会做指令的重排序，但是如果出现了重排序可以被observe的情况，就是BUG。<br>这里我们假定CPU不会出BUG。</p><h2 id="反驳二"><a href="#反驳二" class="headerlink" title="反驳二"></a>反驳二</h2><p><a href="https://www.zhihu.com/question/53761499" target="_blank" rel="noopener">https://www.zhihu.com/question/53761499</a><br>有人问：</p><blockquote><p>如何辨识代码是否被CPU的乱序执行优化了？</p></blockquote><p>一个是<code>中央处理器 (CPU) 话题的优秀回答者</code>的回答：</p><blockquote><p>看不到，也无法控制，ROB存在的目的就是让上层程序员看到的执行结果回归顺序。有一些memory model带来的重排序是可以被上层检测到的，比如x86的TSO模型可以通过精心设计的load store序列检测到访存的乱序。</p></blockquote><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>总而言之，我们记得一个词就够了：<code>observed</code>。<br>CPU确实会进行重排序，但是这种重排序是无法被我们观测到和控制的。<br>如果CPU没有BUG的话（基本上没听过CPU出现BUG），那么程序出现与预期不一致的行为，和CPU的重排序没半点关系。</p><p>插一句，什么内存屏障之类的，和CPU的重排序也没有关系。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://uestc-dpz.github.io/blog/2016/11/17/Reordering.html" target="_blank" rel="noopener">指令重排序</a><br><a href="https://www.zhihu.com/question/53761499" target="_blank" rel="noopener">如何辨识代码是否被CPU的乱序执行优化了</a><br><a href="https://www.cs.utexas.edu/~lin/cs380p/Free_Lunch.pdf" target="_blank" rel="noopener">https://www.cs.utexas.edu/~lin/cs380p/Free_Lunch.pdf</a><br><a href="https://monkeysayhi.github.io/2017/12/28/%E4%B8%80%E6%96%87%E8%A7%A3%E5%86%B3%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C/" target="_blank" rel="noopener">https://monkeysayhi.github.io/2017/12/28/%E4%B8%80%E6%96%87%E8%A7%A3%E5%86%B3%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C/</a><br><a href="https://stackoverflow.com/questions/50307693/does-an-x86-cpu-reorder-instructions" target="_blank" rel="noopener">https://stackoverflow.com/questions/50307693/does-an-x86-cpu-reorder-instructions</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我决定写一个系列，从头到尾讲一讲我理解的内存屏障的起源。&lt;br&gt;要想真正理解内存屏障，其实要讲很多的东西。&lt;/p&gt;
&lt;p&gt;第一节，先来讲讲CPU的执行与重排序。&lt;/p&gt;
    
    </summary>
    
    
      <category term="刨根究底" scheme="https://blog.lovezhy.cc/categories/%E5%88%A8%E6%A0%B9%E7%A9%B6%E5%BA%95/"/>
    
    
      <category term="内存屏障" scheme="https://blog.lovezhy.cc/tags/%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C/"/>
    
      <category term="CPU重排序" scheme="https://blog.lovezhy.cc/tags/CPU%E9%87%8D%E6%8E%92%E5%BA%8F/"/>
    
  </entry>
  
  <entry>
    <title>volatile和内存屏障</title>
    <link href="https://blog.lovezhy.cc/2020/03/08/volatile%E5%92%8C%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C/"/>
    <id>https://blog.lovezhy.cc/2020/03/08/volatile%E5%92%8C%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C/</id>
    <published>2020-03-07T16:00:00.000Z</published>
    <updated>2020-03-09T08:42:32.046Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>事实上，我很多次以为我懂了volatile的原理，最终都是错误的。<br>关于重排序，CPU，缓存一致性，内存可见性的话题，其实非常复杂。</p><a id="more"></a><p>很多文章提到的关于volatile的例子：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> data[<span class="number">5</span>] = &#123; <span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span> &#125;;</span><br><span class="line">bool is_ready = <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">init_data</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span>( <span class="keyword">int</span> i=<span class="number">0</span>; i &lt; <span class="number">5</span>; ++i )</span><br><span class="line">    data[i] = i;</span><br><span class="line">  is_ready = <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">sum_data</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span>( !is_ready )</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">for</span>( <span class="keyword">int</span> i=<span class="number">0</span>; i &lt;<span class="number">5</span>; ++i )</span><br><span class="line">    sum += data[i];</span><br><span class="line">  printf( <span class="string">"%d"</span>, sum );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><blockquote><p>如果我们启动两个线程，线程1执行init_data()，另外一个线程不断执行sum_data()<br>正常的结果应该是0+1+2+3+4，但是由于重排序和内存可见性的问题，得到的结果是不一定的。</p></blockquote><p>其实我们很多人没有思考过一个问题：</p><blockquote><p>在这个例子中，是因为内存可见性的问题造成的，还是重排序的问题造成的？还是两个一起造成的</p></blockquote><p>太长不看：</p><ol><li>CPU对指令进行重排序的条件非常苛刻，在这个例子中，完全不存在CPU会将指令重排序的问题。这个代码运行出现的问题，完全是内存可见性的问题。</li><li>其实关于Volatile的所有问题都是内存可见性的问题，只不过看起来像是CPU重排序了。</li><li>内存屏障指令分编译器级别和CPU级别，内存屏障和CPU重排序没半点关系。</li><li>CPU的厂家使用的协议和CPU具体实现不尽相同，JVM定义的4种内存屏障指令，在x86的机器上，其实只有一种有用，其他的都是空指令。</li><li>JMM定义的”CPU缓存，主存“只是一种抽象，真正的CPU缓存实现，CPU之间在一定程度上是<strong>互相可见</strong>的。</li></ol><h1 id="我的思考"><a href="#我的思考" class="headerlink" title="我的思考"></a>我的思考</h1><p>上面的例子有点复杂，我们再举个简单的例子：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    a=<span class="number">1</span>;  <span class="comment">//S1</span></span><br><span class="line">    b=<span class="number">1</span>;  <span class="comment">//S2</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (b == <span class="number">0</span>) <span class="keyword">continue</span>;  <span class="comment">//L1</span></span><br><span class="line">    <span class="keyword">assert</span>(a == <span class="number">1</span>);           <span class="comment">//L2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>执行的流程和上面的例子一样，我们把步骤拆成了4个，分别为S1，S2，L1，L2。</p><h2 id="正常流程"><a href="#正常流程" class="headerlink" title="正常流程"></a>正常流程</h2><p>正常流程应该是：<br><code>S1 &gt; S2 &gt; L1 &gt; L2</code><br>也就是说，在执行L2的时候，a=1已经执行过了，所以这个断言是正确的。</p><h2 id="内存可见性导致的问题"><a href="#内存可见性导致的问题" class="headerlink" title="内存可见性导致的问题"></a>内存可见性导致的问题</h2><p>在JMM模型中，每个CPU都有自己的缓存，写入时，先写自己的缓存，然后再同步到主存中。<br>在这个例子中，如果还是<code>S1 &gt; S2 &gt; L1 &gt; L2</code>的执行顺序<br>但是S1执行结束后，a其实存在于三个地方，这三个地方的可能值为：</p><ol><li>foo线程所在的CPU缓存中，这个地方a=1</li><li>bar线程所在的CPU缓存中，这个地方a=0或者a=1</li><li>主存中，这个地方a=0或者a=1</li></ol><p>同样的S2执行结束后，b也存在于三个地方。</p><p>如果在bar线程中，b的值为1，但是a的值还是0，那么断言还是失败的。</p><p>这个时候有人会告诉你使用volatile<br>被volatile修饰的变量，每次写入时，会实时同步到主存中，每次读取时，实时从主存中读取<br>这个就会导致S1和S2执行完之后，L1和L2步骤的a和b的值都是最新的。<br>没毛病，说得通对吧。</p><h2 id="重排序导致的问题"><a href="#重排序导致的问题" class="headerlink" title="重排序导致的问题"></a>重排序导致的问题</h2><p>CPU在执行中会对指令进行重排序<br>比如S1和S2这两个操作，在CPU看来没有任何数据依赖顺序，所以它可以乱序执行<br>这下执行顺序可能就变成<code>S2 &gt; L1 &gt; L2 &gt; S1</code>。<br>也会导致断言失败。<br>这个时候Volatile也会保证执行的时候不会导致重排序。<br>也没毛病。</p><h2 id="内存屏障"><a href="#内存屏障" class="headerlink" title="内存屏障"></a>内存屏障</h2><p>Volatile的具体是怎么实现的呢？<br>实现就是插入内存屏障。<br>内存屏障是什么东西？<br>简单的说：保证内存屏障前的读写指令必须在屏障后的读写指令之前执行，通知被Volatile修饰的值，每次读取都从主存中读取，每次写入都同步写入主存（锁总线）。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>从这个例子中看到，其实重排序和内存可见性的问题都会导致程序产生和我们预期不一致的行为，<br>而Volatile恰好能解决这两个问题。</p><h1 id="内存屏障底层指令"><a href="#内存屏障底层指令" class="headerlink" title="内存屏障底层指令"></a>内存屏障底层指令</h1><p>其实正常来说，一般的Java开发者能理解到上面的层次就行了。<br>但是我还想理解的更多，比如这个重排序其实是CPU级别的，我们的Volatile关键词，肯定会映射成汇编指令，那么是哪些汇编指令呢？</p><p>我们先来了解一下<code>barrier()</code>函数。</p><h2 id="编译器重排序"><a href="#编译器重排序" class="headerlink" title="编译器重排序"></a>编译器重排序</h2><p>对于指令重排序，我一直以为只有CPU才会进行重排序，其实编译器也会对我们的指令进行重排序。<br>举个例子：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> x, y, r;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    x = r;</span><br><span class="line">    y = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>如果我们直接编译源文件：<code>g++ -S test.cpp</code><br>会得到这样的汇编文件：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">movl    r(%rip), %eax</span><br><span class="line">movl    %eax, x(%rip)</span><br><span class="line">movl    $<span class="number">1</span>, y(%rip)</span><br></pre></td></tr></table></figure></p><p>可以看到，这个结果并没有进行重排序</p><p>但是如果我们指定优化级别：<code>g++ -O2 –S test.cpp</code><br>得到的汇编指令如下：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">movl    r(%rip), %eax</span><br><span class="line">movl    $<span class="number">1</span>, y(%rip)</span><br><span class="line">movl    %eax, x(%rip)</span><br></pre></td></tr></table></figure></p><p>看，两个指令的顺序反了。<br>这也就是编译器的重排序。</p><p>那么怎么避免呢？<br>这个时候<code>barrier()</code>函数就派上用场了。</p><p>我们修改我们的代码：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> x, y, r;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">x = r;</span><br><span class="line">barrier();</span><br><span class="line">    y = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>这个时候我们再进行编译，会发现顺序并没有颠倒。</p><h2 id="内存屏障-1"><a href="#内存屏障-1" class="headerlink" title="内存屏障"></a>内存屏障</h2><p>我们从内核的代码中找出：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> barrier() __asm__ __volatile__(<span class="meta-string">""</span>: : :<span class="meta-string">"memory"</span>) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> mb() alternative(<span class="meta-string">"lock; addl $0,0(%%esp)"</span>, <span class="meta-string">"mfence"</span>, X86_FEATURE_XMM2) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> rmb() alternative(<span class="meta-string">"lock; addl $0,0(%%esp)"</span>, <span class="meta-string">"lfence"</span>, X86_FEATURE_XMM2)</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> CONFIG_SMP </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_mb() mb() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_rmb() rmb() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_wmb() wmb() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_read_barrier_depends() read_barrier_depends() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> set_mb(var, value) do &#123; (void) xchg(&amp;var, value); &#125; while (0) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span> </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_mb() barrier() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_rmb() barrier() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_wmb() barrier() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_read_barrier_depends() do &#123; &#125; while(0) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> set_mb(var, value) do &#123; var = value; barrier(); &#125; while (0) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure></p><p>别急，我们慢慢来看<br>内存屏障指令，大致有3个</p><ol><li><code>smp_mb</code></li><li><code>smp_rmb</code></li><li><code>smp_wmb</code></li></ol><p>但是看这个<code>#ifdef CONFGIG_SMP</code><br>SMP就是表示多核的意思。</p><blockquote><p>内存屏障指令，在单核和多核的系统中的实现定义是不一样的</p></blockquote><p>我们可以看到，如果计算机是单核的，那么其实所有的内存屏障指令都是编译器级别的，实际的实现都是<code>barrier()</code>函数，在CPU级别都是空操作。</p><h2 id="我的疑惑"><a href="#我的疑惑" class="headerlink" title="我的疑惑"></a>我的疑惑</h2><p>其实不对啊，既然CPU会进行重排序，那为什么单核中并没有使用任何CPU的指令避免重排序呢？</p><p>我们再回到那个例子：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    a=<span class="number">1</span>;  <span class="comment">//S1</span></span><br><span class="line">    b=<span class="number">1</span>;  <span class="comment">//S2</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (b == <span class="number">0</span>) <span class="keyword">continue</span>;  <span class="comment">//L1</span></span><br><span class="line">    <span class="keyword">assert</span>(a == <span class="number">1</span>);           <span class="comment">//L2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>假设这个程序是单核中执行的，也就是没有多核中的可见性的问题，但是CPU重排序的问题依然存在。<br>如果CPU进行重排序：<br><code>S2 &gt; L2 &gt; L2 &gt; S1</code><br>那不是仍然会出问题吗？</p><p>黑人问号？</p><p>带着这个问题，我继续开始了我的资料搜寻。</p><h1 id="内存一致性"><a href="#内存一致性" class="headerlink" title="内存一致性"></a>内存一致性</h1><blockquote><p>主要内容来自<a href="https://zhuanlan.zhihu.com/p/48157076" target="_blank" rel="noopener">高并发编程–多处理器编程中的一致性问题(上)</a><br>很多东西这个文章解释的很好，建议先读一读，有的我就直接略讲了</p></blockquote><p>我产生上述疑惑的前提其实就是默认CPU会对指令进行重排序。<br>很多书中对Volatile也提到了这一点，问题源头都是CPU会对指令重排序。<br>这个时候我们可能会觉得CPU厂家不给力，把这个锅丢给了开发者去解决。</p><p>其实不是的。</p><blockquote><p>那么为了保证不会出现这种超出预期的行为，我们就需要一种规则来约束这种行为不能出现。这个任务就是memory consistency需要保证的（这里指的是强一致性模型：SC/TSO， XC的memory consistency并不能保证这点）</p></blockquote><p>CPU的理论中，其实有一系列协议约束CPU的执行不能出现上述行为。<br>也就是memory consistency，内存一致性。或者也叫<code>Memory Model</code>。<br>中文资料关于这个话题确实很少被提到，这个知乎问答提到了哪儿可以去学习。<br><a href="https://www.zhihu.com/question/23572082" target="_blank" rel="noopener">如何系统的学习 Memory Model?</a><br>其实这个话题也分理论与工业实现，就跟操作系统一样。</p><p>笔者了解的也不多，这里就简单提一下。<br>关于内存一致性的问题，其实和分布式的精髓略相似，有强弱之分，不同的CPU架构上实现的强弱程度不同。</p><h2 id="Sequential-Consistency"><a href="#Sequential-Consistency" class="headerlink" title="Sequential Consistency"></a>Sequential Consistency</h2><p>在理论上，不得不提一个人，Lamport，就是Paxos理论的那个教授。<br>他提出了<code>Sequential Consistency</code>，就是顺序一致性，硬件层面的一致性。</p><p>在解释SC的理论之前，还得了解<code>Program Order</code>和<code>Memory Order</code></p><blockquote><p>Program Order: 就是我们写的代码的顺序，这个是静态的也是每个CPU core各自拥有的。<br>Memory Order: 就是代码执行的顺序，这个是全局的，每个CPU core对共享内存的执行都会出现在Memory order中。<br>用&lt;p 表示Program order的先于顺序，&lt;m表示Memory order的先于顺序。</p></blockquote><p>SC的形式化定义如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">If L(a) &lt;p L(b) ⇒ L(a) &lt;m L(b) /* Load→Load */</span><br><span class="line">If L(a) &lt;p S(b) ⇒ L(a) &lt;m S(b) /* Load→Store */</span><br><span class="line">If S(a) &lt;p S(b) ⇒ S(a) &lt;m S(b) /* Store→Store */</span><br><span class="line">If S(a) &lt;p L(b) ⇒ S(a) &lt;m L(b) /* Store→Load */</span><br></pre></td></tr></table></figure></p><p>在SC的理论中，这4种关系不允许被Reorder。<br>好了，根据这个理论，我们再看一看上面的代码：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    a=<span class="number">1</span>;  <span class="comment">//S1</span></span><br><span class="line">    b=<span class="number">1</span>;  <span class="comment">//S2</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (b == <span class="number">0</span>) <span class="keyword">continue</span>;  <span class="comment">//L1</span></span><br><span class="line">    <span class="keyword">assert</span>(a == <span class="number">1</span>);           <span class="comment">//L2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>在foo函数中，a的Store在程序顺序中是大于b的Store的，所以a=1的MemoryOrder是必须要大于b=1的MemoryOrder的。</p><p>也就说，如果CPU实现了SC协议，那么其实<code>S2 -&gt; S1</code>这个重排序是不允许的。</p><h2 id="Total-Store-Order"><a href="#Total-Store-Order" class="headerlink" title="Total Store Order"></a>Total Store Order</h2><p>当然理论归理论，实现不一定按照理论来。<br>前面提到了SC的理论，在SC理论的指导下，一切都是按照顺序来的，对CPU重排序的条件非常苛刻。</p><p>SC的问题：</p><blockquote><p>SC严格定义了对于共享内存的load和store操作，loadload，storestore，loadstore，storeload四种执行顺序是不允许reorder的。当下CPU的执行速度已经甩DRAM（memory）好几个量级，如果每次store，load操作都从DRAM读取会拖慢CPU的执行速度，在这个极度压榨硬件性能的时代，是不能接受这种行为的。因此在x86的架构实现中引入了TSO。</p></blockquote><p>简单说，就是CPU厂家觉得SC太严格，不利于性能提升，所以几乎没人用SC，而X86而言，他自己定义了一个叫Total Store Order的内存模型。</p><p>在讲TSO之前，在提一嘴前面提到的，内存一致性的协议有强弱之分，就像分布式协议中的强一致性，最终一致性一样。<br>SC显然是强一致性，但是TSO的一致性就略微弱与SC。</p><p>具体体现在哪儿呢：</p><blockquote><p>TSO在CPU与memory之间引入了write buffer。CPU写入的时候先写入write buffer然后就返回了，这样就将cpu与memory之间的差距隐藏了。</p></blockquote><p>引入了write buffer后，这里其实就是一个内存可见性的隐藏问题，在write buffer中的值，到memory中其实需要一段时间的，这个时间是不定的。</p><p>所以还是会导致一些其他的问题出现：</p><p>比如我们看这个例子：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    x=<span class="number">1</span>;  <span class="comment">//S1</span></span><br><span class="line">    r1=y;  <span class="comment">//L1</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    y=<span class="number">1</span>;  <span class="comment">//S2</span></span><br><span class="line">    r2=x;<span class="comment">//L2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><blockquote><p>还是上面这个例子，S1将x=1放到了core C1的write buffer中，S2将y=1放到了C2的write buffer中，那么在执行L1,L2的时候，r1与r2这时候从memory读到是0。这个是违背了SC的，但是这样的设计确实带来了性能的提升。</p></blockquote><p>怎么解决这个问题呢？</p><p>可能你想到了，就是我们使用某种指令，让CPU去同步Flush这个write buffer中的值。<br>这个指令就是我们提到的内存屏障。</p><p>在详细介绍内存屏障的指令前，我们在TSO模型下，看看我们之前举的例子，到底是什么原因导致的：<br>还是前面的例子：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    a=<span class="number">1</span>;  <span class="comment">//S1</span></span><br><span class="line">    b=<span class="number">1</span>;  <span class="comment">//S2</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (b == <span class="number">0</span>) <span class="keyword">continue</span>;  <span class="comment">//L1</span></span><br><span class="line">    <span class="keyword">assert</span>(a == <span class="number">1</span>);           <span class="comment">//L2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>在TOS的引入了write buffer后，我们再来看看上面的例子还会出现问题吗？<br>如果a=1，b=1先后被写入write buffer，并没有写入memory。但是如果把write buffer中的值flush到内存，b=1这个可见性的时间 &gt;= a=1的可见性。<br>所以如果bar中，读到b=1了，那么a肯定也已经读到等于1了。<br>就不会出现上面的问题。</p><p>这个时候，我们可以解答我的疑惑了<br>为什么单核的情况下，仅仅需要禁止编译器的重排序就行了？<br>答案就是在TSO模型下，在上面的例子中，CPU不会进行指令的重排序。</p><h2 id="内存屏障指令"><a href="#内存屏障指令" class="headerlink" title="内存屏障指令"></a>内存屏障指令</h2><p>让我们再回到这个代码：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> barrier() __asm__ __volatile__(<span class="meta-string">""</span>: : :<span class="meta-string">"memory"</span>) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> mb() alternative(<span class="meta-string">"lock; addl $0,0(%%esp)"</span>, <span class="meta-string">"mfence"</span>, X86_FEATURE_XMM2) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> rmb() alternative(<span class="meta-string">"lock; addl $0,0(%%esp)"</span>, <span class="meta-string">"lfence"</span>, X86_FEATURE_XMM2)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> wmb() alternative(<span class="meta-string">"lock; addl $0,0(%%esp)"</span>, <span class="meta-string">"sfence"</span>, X86_FEATURE_XMM)   </span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> CONFIG_SMP </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_mb() mb() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_rmb() rmb() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_wmb() wmb() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_read_barrier_depends() read_barrier_depends() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> set_mb(var, value) do &#123; (void) xchg(&amp;var, value); &#125; while (0) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span> </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_mb() barrier() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_rmb() barrier() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_wmb() barrier() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_read_barrier_depends() do &#123; &#125; while(0) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> set_mb(var, value) do &#123; var = value; barrier(); &#125; while (0) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure></p><h3 id="常见的三种"><a href="#常见的三种" class="headerlink" title="常见的三种"></a>常见的三种</h3><p>x86/64系统架构提供了三种多核的内存屏障指令：(1) sfence; (2) lfence; (3) mfence</p><ol><li>sfence：在sfence指令前的写操作当必须在sfence指令后的写操作前完成。</li><li>lfence：在lfence指令前的读操作当必须在lfence指令后的读操作前完成。</li><li>mfence：在mfence指令前的读写操作当必须在mfence指令后的读写操作前完成。</li></ol><p>其实总结起来就是读屏障，写屏障，读写屏障。</p><p>上述的是显式的会起到内存屏障作用的指令，但是还有许多指令带有异常的内存屏障的作用。</p><h3 id="MMIO写屏障"><a href="#MMIO写屏障" class="headerlink" title="MMIO写屏障"></a>MMIO写屏障</h3><p>Linux 内核有一个专门用于 MMIO 写的屏障：<br><code>mmiowb()</code><br>笔者也不熟悉这个的作用，后续再补上</p><h3 id="隐藏的内存屏障"><a href="#隐藏的内存屏障" class="headerlink" title="隐藏的内存屏障"></a>隐藏的内存屏障</h3><p>Linux 内核中一些锁或者调度函数暗含了内存屏障。</p><p>锁函数：</p><ul><li>spin locks</li><li>R/W spin locks</li><li>mutexes</li><li>semaphores</li><li>R/W semaphores</li></ul><p>中断禁止函数：<br>启动或禁止终端的函数的作用仅仅是作为编译器屏障，所以要使用内存或者 I/O 屏障 的场合，必须用别的函数。</p><p>SLEEP和WAKE-UP以及其它调度函数：<br>使用 SLEEP 和 WAKE-UP 函数时要改变 task 的状态标志，这需要使用合适的内存屏 障保证修改的顺序。</p><h1 id="MESI缓存一致性"><a href="#MESI缓存一致性" class="headerlink" title="MESI缓存一致性"></a>MESI缓存一致性</h1><p>写不动了，缓存一致性的内容还是大家自己百度吧<br>其实简单点可以这么理解：</p><ol><li>JMM中的主存其实在实现上，包含了CPU的缓存</li><li>JMM中的CPU的缓存在x86机器上可以理解为write buffer。</li></ol><h1 id="JMM"><a href="#JMM" class="headerlink" title="JMM"></a>JMM</h1><p>写到这儿，基本把开头的一些结论说清楚了，但是还有一个：<br>JVM定义的4种内存屏障指令，在x86的机器上，其实只有一种有用，其他的都是空指令。</p><p>我们先来看JMM中的定义，根据Store和Load的操作，JMM分成了4中：</p><ol><li>LoadLoad</li><li>LoadStore</li><li>StoreStore</li><li>StoreLoad</li></ol><p>这4中都是为了禁止重排序的<br>这里的Load就是从主存中获取值，Store就是把值同步写入主存。</p><p>按照读屏障，写屏障，读写屏障划分的话，和fence的对应关系如下：</p><ol><li>LoadLoad -&gt; lfence</li><li>LoadStore -&gt; mfence</li><li>StoreStore -&gt; sfence</li><li>StoreLoad -&gt; mfence</li></ol><p>当然了解这些还是不够的，我们还需要JMM对应了哪种CPU模型。<br>在x86中，我们除了内存，还了解到有write buffer的存在。<br>然而事实上，CPU的实现中，还有一个东西的存在叫<code>invalidate queue</code></p><p>具体的演进与作用可以参照这篇文章：<br><a href="https://zhuanlan.zhihu.com/p/66085562" target="_blank" rel="noopener">内存屏障Memory Barrier: a Hardware View</a></p><p>StoreBuffer就是对应WriteBuffer<br>而Invalidate queue在x86的CPU上是不存在的。</p><p>再回到我们提到的例子：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    x=<span class="number">1</span>;  <span class="comment">//S1</span></span><br><span class="line">    r1=y;  <span class="comment">//S2</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    y=<span class="number">1</span>;  <span class="comment">//L1</span></span><br><span class="line">    r2=x;<span class="comment">//L2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>在这个例子中，我们需要哪一种屏障呢？<br>就是StoreLoad屏障<br>按照TSO的协议解释，也就是我们读取y的值的之前，必须flush writebuffer。<br>这样，r1和r2就不会出现同时等于0的情况。</p><p>再具体的这个文章讲的很好：<a href="https://zhuanlan.zhihu.com/p/81555436" target="_blank" rel="noopener">为什么在 x86 架构下只有 StoreLoad 屏障是有效指令？</a></p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://mortoray.com/2010/11/18/cpu-reordering-what-is-actually-being-reordered/" target="_blank" rel="noopener">cpu-reordering-what-is-actually-being-reordered</a><br><a href="http://lday.me/2017/11/04/0016_what_is_memory_barriers/" target="_blank" rel="noopener">什么是内存屏障(Memory Barriers)</a><br><a href="https://www.linuxidc.com/Linux/2011-10/44623.htm" target="_blank" rel="noopener">Linux内核中的内存屏障</a><br><a href="https://quant67.com/post/linux/memory-barriers/memory-barriers.html#sec-2-6" target="_blank" rel="noopener">内存屏障</a><br><a href="https://zhuanlan.zhihu.com/p/33626920" target="_blank" rel="noopener">为什么我们需要内存屏障？</a><br><a href="https://blog.csdn.net/muxiqingyang/article/details/6615199" target="_blank" rel="noopener">《大话处理器》Cache一致性协议之MESI</a><br><a href="https://paulcavallaro.com/blog/x86-tso-a-programmers-model-for-x86-multiprocessors/" target="_blank" rel="noopener">x86 TSO: A Programmer’s Model for x86 Multiprocessors</a><br><a href="https://stackoverflow.com/questions/51292687/if-i-dont-use-fences-how-long-could-it-take-a-core-to-see-another-cores-write" target="_blank" rel="noopener">If I don’t use fences, how long could it take a core to see another core’s writes?</a><br><a href="https://blog.csdn.net/automan12138/article/details/104682093" target="_blank" rel="noopener">深入理解内存屏障</a><br><a href="https://www.cnblogs.com/aquester/p/10328479.html" target="_blank" rel="noopener">C和C++中的volatile、内存屏障和CPU缓存一致性协议MESI</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzUzMDk3NjM3Mg==&amp;mid=2247483755&amp;idx=1&amp;sn=50f80e73f46fab04d8a799e8731432c6&amp;chksm=fa48da70cd3f5366d9658277cccd9e36fca540276f580822d41aef7d8af4dda480fc85e3bde4&amp;token=1910810820&amp;lang=zh_CN#rd" target="_blank" rel="noopener">从 Java 内存模型看内部细节</a><br><a href="https://www.zhihu.com/question/296949412/answer/864851230" target="_blank" rel="noopener">既然CPU有缓存一致性协议（MESI），为什么JMM还需要volatile关键字？</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;事实上，我很多次以为我懂了volatile的原理，最终都是错误的。&lt;br&gt;关于重排序，CPU，缓存一致性，内存可见性的话题，其实非常复杂。&lt;/p&gt;
    
    </summary>
    
    
      <category term="计算机基础" scheme="https://blog.lovezhy.cc/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"/>
    
    
      <category term="内存屏障" scheme="https://blog.lovezhy.cc/tags/%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C/"/>
    
      <category term="volatile" scheme="https://blog.lovezhy.cc/tags/volatile/"/>
    
  </entry>
  
  <entry>
    <title>Kafka指南-分区副本详解</title>
    <link href="https://blog.lovezhy.cc/2020/03/03/Kafka%E6%8C%87%E5%8D%97-%E5%88%86%E5%8C%BA%E5%89%AF%E6%9C%AC/"/>
    <id>https://blog.lovezhy.cc/2020/03/03/Kafka%E6%8C%87%E5%8D%97-%E5%88%86%E5%8C%BA%E5%89%AF%E6%9C%AC/</id>
    <published>2020-03-02T16:00:00.000Z</published>
    <updated>2020-03-03T14:40:27.865Z</updated>
    
    <content type="html"><![CDATA[<p>分区副本是Kafka中重要的概念。<br>下面我们来详细谈一谈副本相关的概念。</p><a id="more"></a><h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><p>Kafka中，每个Topic，可能有多个分区，同时为了提高每个分区的可用性，每个分区会有多个冗余备份，这个备份就叫副本（Replica），Kafka集群会将一个分区的不同副本分配在不同的Broker上，这样即使一个Broker系统宕机，也不会影响该分区的可用性。</p><p>这也是分布式系统中常见的高可用实现方式。</p><p>但是Kafka中的关于副本，还有几个比较重要的概念。</p><h2 id="Leader副本，Follower副本"><a href="#Leader副本，Follower副本" class="headerlink" title="Leader副本，Follower副本"></a>Leader副本，Follower副本</h2><p>Leader副本，Follower副本：<br>虽然有多个副本，但是只会有一个Leader副本接收客户端的读写操作，其他的副本都叫Follower副本，Follower副本只做一件事，就是同步Leader副本的日志。</p><h2 id="AR（Assigned-Replica）"><a href="#AR（Assigned-Replica）" class="headerlink" title="AR（Assigned Replica）"></a>AR（Assigned Replica）</h2><p>AR（Assigned Replica）：<br>就是某分区所有副本的统称，包括Leader副本和Follower副本。</p><h2 id="优先副本（Preferred-Replica）"><a href="#优先副本（Preferred-Replica）" class="headerlink" title="优先副本（Preferred Replica）"></a>优先副本（Preferred Replica）</h2><p>优先副本（Preferred Replica)，也叫Preferred Leader：<br>Leader副本也不是随意选出的，前面提到过Leader副本是接收客户端的读写请求的，所有的Leader副本都集中在一个Broker上，那设立多个Broker进行负载均衡的意义就没有了。<br>所有控制器会选出每个分区的优先副本是那个，然后使用一些手段让优先副本变成Leader副本。</p><p>注意：不是每个Partition的优先副本都等于Leader副本，如果中途进行了Leader副本切换，Broker重启等事件，Leader副本就会变化，这种情况，有脚本可以手动操作。</p><h2 id="ISR（In-Sync-Replica"><a href="#ISR（In-Sync-Replica" class="headerlink" title="ISR（In-Sync Replica)"></a>ISR（In-Sync Replica)</h2><p>ISR（In-Sync Replica):<br>前面提到，所有的Follower副本，只做一件事，就是同步Leader副本的日志。<br>但是每个副本的同步进度有快有慢，我们将与Leader副本保持一定同步的Follower副本，包括Leader副本自己，叫In-Sync Replica。</p><p>那么你可能要问了，这个“保持一定同步”的标准是什么？<br>落后日志小于X条？</p><p>猜的没错，确实，在Kafka的0.9版本之前，有个参数叫<code>replica.lag.max.messages</code>，默认值是4000。如果一个Follower副本落后Leader副本4000条消息，那么就会被移出ISR集合。</p><p>你可能会注意到，这个是在0.9版本之前，那么在之后被改掉了，为什么呢？<br>因为这个参数很难设置。<br>如果业务系统的流量一直比较平稳也就算了，但是正常的业务流量难免有波动，高的时候可能QPS就超过了这个参数，很容易就触发，低的时候每秒就1条消息，那得4000s才能发现，那也没啥意义。<br>所以这个参数，很难设置。</p><p>从Kafka的0.9版本开始，Broker端有个参数叫<code>replica.lag.time.max.ms</code>，默认值是10000，Broker会启动一个参数定时的检查每个Follower副本上次和Leader副本日志完全一致的时间（注：并不完全等于上次通信时间），如果距离现在已经过去了10000ms，那么就会把这个Follower副本从ISR集合中移除。</p><h1 id="分区Leader"><a href="#分区Leader" class="headerlink" title="分区Leader"></a>分区Leader</h1><h2 id="Leader副本的产生"><a href="#Leader副本的产生" class="headerlink" title="Leader副本的产生"></a>Leader副本的产生</h2><p>一般来说，当我们创建一个Topic，进行分区的时候，Kafka控制器会决定分区分在哪些Broker上，同时也会决定那个副本是Leader副本，并且把这个信息写入ZK。同时通过Http请求通知其他的Broker。</p><h2 id="Leader副本的重新选取"><a href="#Leader副本的重新选取" class="headerlink" title="Leader副本的重新选取"></a>Leader副本的重新选取</h2><p>我们知道，每个Broker启动的时候，都会在ZK的目录下注册一个临时节点。<br>Kafka控制器对这个目录注册监听事件，当发生Broker断开，或者Broker新增的时候，就会触发一些响应的逻辑。</p><p>返回到我们的Leader副本，什么情况下Leader副本会不可用呢？通常来说就是Leader副本所在的Broker整个挂掉了。<br>Kafka控制器感应到这个事件后，就会重新指定一个副本为Leader副本。<br>到底指定哪一个呢？这里面有大文章。<br>我们慢慢来说。</p><p>在Raft中，重新选举一个Leader的条件就是谁的日志最新，谁就可以当Leader。<br>这样可以避免消息丢失。<br>在Kafka中类似，但是没有Raft中那么严格，Broker会从ISR集合中<strong>随机</strong>选取一个。<br>是的，随机选举一个当Leader。<br>我们知道，ISR集合中的副本，可不一定与Leader副本的日志完全一致的。<br><img src="/images/Kafka指南-分区/选举.png" alt=""><br>如上图所示，Leader副本如果挂掉，Follower1和2都属于ISR集合的话，虽然Follower1的日志比Follower2更新，但是Follower2也可以被选举为Leader。<br>当Follower2被选举为Leader后，Follower1的2003和2004的日志，都要被<strong>删除</strong>。</p><h2 id="分区的可用性，AP还是CP"><a href="#分区的可用性，AP还是CP" class="headerlink" title="分区的可用性，AP还是CP"></a>分区的可用性，AP还是CP</h2><p>分布式系统，有个著名的理论就是CAP理论，这里有个A就是可用性。<br>那么Kafka作为一个分布式的系统，其实也是遵循这个理论的。<br>那么你会问了，Kafka是个AP系统还是个CP系统。</p><p>说到这里，不得不提一个共识性算法，叫Raft，Raft协议其实是为了构建一个CP系统，它的A属性，是保证不能挂掉一半以上的节点。<br>而共识性算法中，有个微软的协议叫PacificA，kafka其实和这个系统相近。</p><p>不兜圈子了，直接明说，Kafka系统到底是AP还是CP其实是可以配置的。<br>在Raft中，一个数据的提交，Leader节点必须要接收到一半以上（包括自己）的节点的成功响应，才能告诉客户端，说你这条消息，提交成功，我们保证，肯定不会丢失了。</p><p>把这个概念移到Kafka中，我们的Producer的发送的数据，Leader副本自己Append后，要同步给多少节点才能响应成功呢？<br>这个是个参数，可以配置。<br><code>acks</code>：指明分区中必须要有多少个副本收到这条消息，Broker才能响应成功。</p><ol><li><code>acks=1</code>。这也是默认值，生产者发送消息后，只要分区的Leader成功写入，就会收到成功的响应。显然，这种是不能保证数据不被丢失的。万一写完，Leader副本就挂了，Follower副本还没来得及同步。</li><li><code>acks=0</code>：这个比等于1还夸张，完全随缘的，不关心服务端。一般不这么设置。</li><li><code>acks=-1,acks=all</code>：这个参数，要保证所有的ISR副本都写入成功，才可以返回成功。结合前面我们提到的ISR的概念，会发现，单独设置这个参数其实没啥用，因为ISR集合中副本的个数你根本不知道。所以这个选项，还需要我们设置出ISR集合中，至少有几个副本：<code>min.insync.replicas</code>。</li></ol><p>如果我们需要我们的Kafka是像Raft一样的CP系统，那么我们需要配置：</p><ol><li><code>acks=all</code></li><li><code>min.insync.replicas=${f/2 + 1}</code></li><li><code>unclean.leader.election.enable=false</code><br>显然这种，性能肯定不咋地，可用性也会大大折扣。</li></ol><p>如果我们需要我们的Kafka系统是AP系统，那么我们需要把</p><ol><li><code>min.insync.replicas=1</code></li><li><code>unclean.leader.election.enable=true</code><br>这样我们可以容忍最多（f-1）个副本失效。<br>但是会丢失数据。</li></ol><p>默认值：当然大部分人肯定没关心过这两个参数，其实从参数的设计来看，Kafka其实偏向于一个AP系统，<code>acks</code>的默认值为1，<code>min.insync.replicas</code>的默认值也是1，<code>unclean.leader.election.enable</code>的默认值是false。<br>这么配置的话，如果ISR集合中，某一时间只有Leader副本，同时恰好宕机了，那么整个分区就不可用了。</p><h1 id="ISR更新"><a href="#ISR更新" class="headerlink" title="ISR更新"></a>ISR更新</h1><p>对于ISR流程的更新，笔者也画了一些示意图，当然其实流程大家心里应该也清楚了。</p><h2 id="流程一"><a href="#流程一" class="headerlink" title="流程一"></a>流程一</h2><p><img src="/images/Kafka指南-分区/副本上下线1.png" alt=""><br>如上图所示，我们有3个Broker。<br>对于Topic=Hello而言，我们假设他有10个Partition，其中每个Partition有3个副本。<br>图中所示的是Partition5的副本分布情况。</p><blockquote><p>Leader副本，也就是Replica-0，在Broker-0节点上。</p><p>这个时候，ISR集合有[0,1,2]。</p></blockquote><p>在Kafka控制器和Zookeeper中都记录了该信息。<br>对于ZK而言，在<code>/state/Hello/5</code>节点中记录了该信息。<br>并且<code>/Isr_notification/</code>节点下，没有子节点。<br>图中没有标明的一点是：KafkaController监听了<code>/Isr_notification/</code>节点。</p><h2 id="流程二"><a href="#流程二" class="headerlink" title="流程二"></a>流程二</h2><p><img src="/images/Kafka指南-分区/副本上下线2.png" alt=""></p><p>渐渐的，副本2同步日志出现了落后，被Leader副本检测到了，下面Leader副本需要更新ISR集合。</p><h2 id="流程三"><a href="#流程三" class="headerlink" title="流程三"></a>流程三</h2><p><img src="/images/Kafka指南-分区/副本上下线3.png" alt=""></p><p>Leader副本所在的Broker0，会连接ZK，做两个操作：</p><ol><li>修改<code>/state/Hello/5/</code>的值，把ISR集合中的2移除</li><li>在<code>/Isr_notification/</code>下新增一个节点，表示Hello的Partition的ISR集合发生了变化</li></ol><h2 id="流程四"><a href="#流程四" class="headerlink" title="流程四"></a>流程四</h2><p><img src="/images/Kafka指南-分区/副本上下线4.png" alt=""><br>ZK会通知Kafka控制器</p><h2 id="流程五"><a href="#流程五" class="headerlink" title="流程五"></a>流程五</h2><p><img src="/images/Kafka指南-分区/副本上下线5.png" alt=""><br>Kafka控制器会做两个操作：</p><ol><li>更新自己的元数据，将副本2从ISR集合中删除</li><li>通知其他所有的Broker，更新其元数据。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;分区副本是Kafka中重要的概念。&lt;br&gt;下面我们来详细谈一谈副本相关的概念。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kafka指南" scheme="https://blog.lovezhy.cc/categories/Kafka%E6%8C%87%E5%8D%97/"/>
    
    
      <category term="Kafka" scheme="https://blog.lovezhy.cc/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka指南-模块与职能划分</title>
    <link href="https://blog.lovezhy.cc/2020/02/29/Kafka%E6%8C%87%E5%8D%97-%E6%A8%A1%E5%9D%97%E4%B8%8E%E8%81%8C%E8%83%BD%E5%88%92%E5%88%86/"/>
    <id>https://blog.lovezhy.cc/2020/02/29/Kafka%E6%8C%87%E5%8D%97-%E6%A8%A1%E5%9D%97%E4%B8%8E%E8%81%8C%E8%83%BD%E5%88%92%E5%88%86/</id>
    <published>2020-02-28T16:00:00.000Z</published>
    <updated>2020-02-29T14:27:06.411Z</updated>
    
    <content type="html"><![CDATA[<p>Kafka的是个复杂的系统，除了基本的Producer，Consumer，Broker外，为了实现完备的功能，Kafka中有许多重要的模块，本文梳理一下这些模块的划分，与他们负责的功能。</p><a id="more"></a><h1 id="运行组件"><a href="#运行组件" class="headerlink" title="运行组件"></a>运行组件</h1><p>基本上来说，正常的一个运行Kafka的业务，都需要4个组件：</p><ol><li>Broker。也就是Kafka服务器。</li><li>Producer。也就是消息的生产者，负责把消息传入Broker。</li><li>Consumer。消息的消费者，负责从Broker拉取消息。</li><li>Zookeeper。Broker的运行需要Zookeeper保存一些元数据。</li></ol><p>这四大组件的关系如下图所示：<br><img src="../images/Kafka-模块划分/组件.png" alt=""></p><p>流程也不用我多介绍了。<br>这里要提的一点就是，<strong>Consumer端不再感知Zookeeper了</strong><br>这个其实是演进出来的，之前的Offset保存的方式导致了Consumer端必须要感知ZK的地址。<br>但是使用了新的Offset提交方式后，Consumer没有必要感知Zookeeper了，所以在新版本的启动参数中仅仅需要使用<code>--bootstrap-server</code>指定任意一个Broker地址就行了。</p><p>当然这个问题我也去搜集了一下答案：<br><a href="https://segmentfault.com/q/1010000015795614" target="_blank" rel="noopener">新版kafka消费者、生产者配置为何使用bootstrap-servers而不是zookeeper服务器地址？</a></p><p>答案中提到了一个Kafka的提案，就是要取代Zookeeper。也是值得看一看的。</p><h1 id="控制器"><a href="#控制器" class="headerlink" title="控制器"></a>控制器</h1><p>控制器，也叫Kafka Controller。<br>我们知道Kafka集群中，会有多个Broker，这些Broker并不是对等的关系，和Raft协议一样，其中一个Broker会被选举为Leader，也就是控制器，KafkaController。</p><p>为什么需要一个Leader呢？这个在我看来其实有两个原因。</p><ol><li>Zookeeper的性能有限。</li><li>避免复杂的逻辑。</li></ol><p>在早期的Kafka版本中，其实没有控制器这个概念，所有的Broker都是对等的，很多复杂的逻辑难以解决，以及对ZK会造成很大的负载，笔者列举几个：</p><ol><li>分区的ISR集合变更。每个分区的ISR集合，属于元数据，需要保存到每个Broker上的。分区的Leader副本所在的Broker会首先感知到该分区的ISR变更，它会把这个事件发布上ZK上，然后其他的Broker会监听到这个事件，更新自己的元数据。</li><li>Leader副本出现问题。当一个分区的Leader副本出现问题时，需要重新选举出新的Leader副本，这个事件也是通过注册ZK的监听器实现的。</li><li>Topic的分区分配，分区迁移，优先副本的选举：这是为了负载均衡的分布在不同的Broker上，如果没有Leader，随机的让这些决策由任意一个Broker去完成，会比较复杂。</li></ol><p>所有加入KafkaController后，这个被选为Leader的Broker需要做很多事：</p><ol><li>注册ZK的监听器，事件触发后，将信息传递给其他的Broker。</li><li>对集群的配置进行决策和任务发放</li></ol><p>再具体一点：</p><ol><li>分区Leader副本出现故障，选举出新的Leader副本</li><li>ISR集合变更，通知给其他的Broker</li><li>Topic的新增，删除，分区分配，分区迁移，副本管理</li><li>监听其他的Broker的变化，新增，删除等。</li></ol><h1 id="消费者协调器，组协调器"><a href="#消费者协调器，组协调器" class="headerlink" title="消费者协调器，组协调器"></a>消费者协调器，组协调器</h1><p>消费者协调器（ConsumerCoordinator），组协调器（GroupCoordinator）是为了解决旧版本的消费者再均衡问题而诞生的。</p><p>首先让我们思考一下消费组需要解决的问题。<br>通常来说，一个Topic会有多个分区，而每个分区，都会指派给一个Consumer会消费。<br><img src="../images/Kafka-模块划分/分区分配.png" alt=""><br>如上图所示，这个Topic共有4个partition，有3个Consumer。<br>Consumer0分配了P0和P1给它，Consumer1和Consumer2分别分配了P2和P3。</p><p>这样很美好，但是美好的事情总是不稳定。<br>如果Consumer0挂了呢？<br>那么我们需要把P0和P1分配给Consumer1和Consumer2。<br>如果多了一个Consumer加入，我们需要把P0分配给它。</p><p>这些就是消费者再均衡问题。<br>怎么解决这个问题呢？<br>旧版的Kafka中同样使用了很多的ZK的监听器去完成，很复杂。<br>问题有2：</p><ol><li>ZK负载较大。</li><li>ZK本身的脑裂问题，会导致各个消费者拿到的消费组的状态不一致，产生问题。</li></ol><p>解决这个问题的关键和Kafka的控制器的思路一致，我们需要引入Leader来完成重分配。<br>于是有了组协调器</p><h2 id="组协调器（GroupCoordinator）"><a href="#组协调器（GroupCoordinator）" class="headerlink" title="组协调器（GroupCoordinator）"></a>组协调器（GroupCoordinator）</h2><blockquote><p>组协调器：Kafka将全部的消费组分成了多个子集，每个消费组的子集在服务端对应一个GroupCoordinator对其进行管理</p></blockquote><p>组协调器是在服务端的，由某一个Broker担任。<br>有了组协调器后，某消费组中的所有消费者定时的向其发送心跳包，这样组协调器就能感知该消费组的消费者的个数变更，从而触发分区重分配。</p><p>好像解决重分配的问题，只要有了组协调器就行了？<br>是的，确实是的。</p><p>那么消费者协调器是干什么用的？<br>别急，等我慢慢道来。</p><h2 id="消费者协调器"><a href="#消费者协调器" class="headerlink" title="消费者协调器"></a>消费者协调器</h2><p>说到这个其实不能不提一个概念，<strong>分区分配规则</strong>。<br>X个分区，Y个消费者，怎么分配分区给消费者呢？<br>当然我们可以轮询着来，但是作为一个完备的框架，这一层分配策略是需要抽象出来的，甚至可以由用户自定义的。</p><p>Kafka提供了消费者参数<code>partition.assignment.strategy</code>来进行配置，可选值如下：</p><ol><li>RangeAssignor：按照消费者总数和分区总数进行整除运算来获得一个跨度，然后将分区按照跨度进行平均分配，也是默认的分配策略。</li><li>RoundRobinAssignor：轮询分配</li><li>StickyAssignor：前面两种分配方式，都没有考虑分区和Consumer的状态，消费情况，以及之前的分配情况，这种分配结合前面两种状态来决定分配方式。</li></ol><p>当然也可以进行自定义分配方式，需要我们在Consumer代码里进行编写。</p><p>所以问题来了，为什么配置是在Consumer端？<br>你可能想到了，<strong>灵活配置！</strong>。</p><p>写到这儿，消费者协调器的存在就可以理解了，真正的分配其实并不是组协调器进行的，而是组协调器会在所有的Consumer中指定一个Leader，这个Leader就叫消费者协调器，真正的分配结果由这个Consumer来执行，消费者协调器把分配结果告诉组协调器，组协调器再通知给所有的消费者结果。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Kafka的是个复杂的系统，除了基本的Producer，Consumer，Broker外，为了实现完备的功能，Kafka中有许多重要的模块，本文梳理一下这些模块的划分，与他们负责的功能。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kafka指南" scheme="https://blog.lovezhy.cc/categories/Kafka%E6%8C%87%E5%8D%97/"/>
    
    
      <category term="Kafka" scheme="https://blog.lovezhy.cc/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka指南-源码导入Idea</title>
    <link href="https://blog.lovezhy.cc/2020/02/23/Kafka%E6%8C%87%E5%8D%97-%E6%BA%90%E7%A0%81%E5%AF%BC%E5%85%A5Idea/"/>
    <id>https://blog.lovezhy.cc/2020/02/23/Kafka%E6%8C%87%E5%8D%97-%E6%BA%90%E7%A0%81%E5%AF%BC%E5%85%A5Idea/</id>
    <published>2020-02-22T16:00:00.000Z</published>
    <updated>2020-02-29T14:26:36.194Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>虽然网上教程很多，但是我依然要写系列<br>因为我踩到的坑有的是网上没有遇到过的</p><a id="more"></a><h2 id="详细步骤"><a href="#详细步骤" class="headerlink" title="详细步骤"></a>详细步骤</h2><h3 id="克隆源码"><a href="#克隆源码" class="headerlink" title="克隆源码"></a>克隆源码</h3><p><code>git clone https://github.com/apache/kafka.git</code></p><p><strong>这个时候切记不能先用idea直接打开项目！</strong><br><strong>这个时候切记不能先用idea直接打开项目！</strong><br><strong>这个时候切记不能先用idea直接打开项目！</strong></p><h3 id="打包环境"><a href="#打包环境" class="headerlink" title="打包环境"></a>打包环境</h3><p>kafka自带了一些Gradle的Task，可以生成出导入Eclipse或者Idea配置。<br>在Kafka目录下执行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./gradlew jar</span><br><span class="line">./gradlew idea</span><br></pre></td></tr></table></figure><p>这个时候目录下会出现一个文件叫<code>kafka.ipr</code><br>在finder中双击这个文件，idea会自动打开并导入项目。<br><strong>注：也就是这个时候才会打开Idea</strong></p><h3 id="配置Gradle"><a href="#配置Gradle" class="headerlink" title="配置Gradle"></a>配置Gradle</h3><p>一般Idea打开会，右下角会弹出一个框，大致意思是：</p><blockquote><p>我们检测出这个是Gradle项目，需要导入Gradle的配置吗？</p></blockquote><p>这个时候，点击确认就行。</p><p>如果打开Idea啥也没发生，那么就需要我们自己打开文件<code>build.gradle</code><br>然后进行刷新之类的操作，具体我也忘了怎么操作的。</p><h3 id="修改配置"><a href="#修改配置" class="headerlink" title="修改配置"></a>修改配置</h3><p>一些配置的修改是比较重要的</p><ol><li>文件build.gradle<br>第一处修改：<br>找到<code>tasks.withType(ScalaCompile) {</code>这一行<br>修改<code>scalaCompileOptions.additionalParameters</code>的配置<figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">    scalaCompileOptions.additionalParameters = [</span><br><span class="line">      <span class="string">"-nowarn"</span>,  <span class="comment">//新增</span></span><br><span class="line">      <span class="string">"-deprecation"</span>,</span><br><span class="line">      <span class="string">"-unchecked"</span>,</span><br><span class="line">      <span class="string">"-encoding"</span>, <span class="string">"utf8"</span>,</span><br><span class="line">      <span class="string">"-Xlog-reflective-calls"</span>,</span><br><span class="line">      <span class="string">"-feature"</span>,</span><br><span class="line">      <span class="string">"-language:postfixOps"</span>,</span><br><span class="line">      <span class="string">"-language:implicitConversions"</span>,</span><br><span class="line">      <span class="string">"-language:existentials"</span>,</span><br><span class="line"><span class="comment">//      "-Xlint:constant",  //注释</span></span><br><span class="line"><span class="comment">//      "-Xlint:delayedinit-select",</span></span><br><span class="line"><span class="comment">//      "-Xlint:doc-detached",</span></span><br><span class="line"><span class="comment">//      "-Xlint:missing-interpolator",</span></span><br><span class="line"><span class="comment">//      "-Xlint:nullary-override",</span></span><br><span class="line"><span class="comment">//      "-Xlint:nullary-unit",</span></span><br><span class="line"><span class="comment">//      "-Xlint:option-implicit",</span></span><br><span class="line"><span class="comment">//      "-Xlint:package-object-classes",</span></span><br><span class="line"><span class="comment">//      "-Xlint:poly-implicit-overload",</span></span><br><span class="line"><span class="comment">//      "-Xlint:private-shadow",</span></span><br><span class="line"><span class="comment">//      "-Xlint:stars-align",</span></span><br><span class="line"><span class="comment">//      "-Xlint:type-parameter-shadow",</span></span><br><span class="line"><span class="comment">//      "-Xlint:unused"</span></span><br><span class="line">    ]</span><br></pre></td></tr></table></figure></li></ol><p>第二处修改：<br>还有<code>tasks.withType(JavaCompile) {</code>这一行<br>修改为<br><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">  tasks.withType(JavaCompile) &#123;</span><br><span class="line">    <span class="keyword">options</span>.encoding = <span class="string">'UTF-8'</span></span><br><span class="line"><span class="comment">//    options.compilerArgs &lt;&lt; "-Xlint:all"</span></span><br><span class="line">    <span class="comment">// temporary exclusions until all the warnings are fixed</span></span><br><span class="line"><span class="comment">//    options.compilerArgs &lt;&lt; "-Xlint:-rawtypes"</span></span><br><span class="line"><span class="comment">//    options.compilerArgs &lt;&lt; "-Xlint:-serial"</span></span><br><span class="line"><span class="comment">//    options.compilerArgs &lt;&lt; "-Xlint:-try"</span></span><br><span class="line"><span class="comment">//    options.compilerArgs &lt;&lt; "-Werror"</span></span><br><span class="line">    <span class="comment">// --release is the recommended way to select the target release, but it's only supported in Java 9 so we also</span></span><br><span class="line">    <span class="comment">// set --source and --target via `sourceCompatibility` and `targetCompatibility`. If/when Gradle supports `--release`</span></span><br><span class="line">    <span class="comment">// natively (https://github.com/gradle/gradle/issues/2510), we should switch to that.</span></span><br><span class="line">    <span class="keyword">if</span> (JavaVersion.current().isJava9Compatible())</span><br><span class="line">      <span class="keyword">options</span>.compilerArgs &lt;&lt; <span class="string">"--release"</span> &lt;&lt; minJavaVersion</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p><p><strong>上面两个修改主要是为了Idea启动时编译，会把一堆warn当做Error报出来，Gradle不给启动</strong></p><p>第三处修改：<br>找到<code>project(&#39;:core&#39;) {</code>这一行<br>下面会有一堆<br><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">dependencies</span> &#123;</span><br><span class="line">  <span class="keyword">compile</span> <span class="keyword">project</span>(<span class="string">':clients'</span>)</span><br><span class="line">  <span class="keyword">compile</span> libs.jacksonDatabind</span><br><span class="line">  <span class="keyword">compile</span> libs.jacksonModuleScala</span><br><span class="line">~~~</span><br></pre></td></tr></table></figure></p><p>这种配置<br>在<code>compileOnly libs.log4j</code>这一行的下面，加上<br><code>compile libs.slf4jlog4j</code></p><p><strong>这个修改主要是终端启动Kafka的时候日志打印不出来的问题</strong></p><blockquote><p>很多的网上的答案都是让自己把两个依赖加进去，但是我发现其实Kafka配置了两个依赖，但是却没有Compile，所以不需要自己加进去，只要加上这行配置就行</p></blockquote><ol><li>配置log4j文件<br>第一步：把config目录下的log4j.properties文件复制到core/src/main/resources目录下<br>需要创建rescources目录<br>如图所示：<br><img src="/images/Kafka源码导入Idea/log4j1.png" alt=""></li></ol><p><strong>并不是很多网上说的复制到/scala目录下</strong></p><p>第二步：修改log4j.properties文件<br>主要是把很多的<code>${kafka.logs.dir}</code>这种变量去掉，换成自己电脑上的绝对路径</p><h2 id="启动配置"><a href="#启动配置" class="headerlink" title="启动配置"></a>启动配置</h2><p>下面就是启动配置了，这个网上都有，我就直接复制一下</p><p><strong>首先得自己启动一个Zookeeper进程</strong></p><h3 id="Broker"><a href="#Broker" class="headerlink" title="Broker"></a>Broker</h3><p><img src="/images/Kafka源码导入Idea/Kafka.png" alt=""></p><h3 id="Consumer"><a href="#Consumer" class="headerlink" title="Consumer"></a>Consumer</h3><p><strong>Program arguments可根据自己的情况修改</strong><br><img src="/images/Kafka源码导入Idea/consumer.png" alt=""></p><h3 id="produer"><a href="#produer" class="headerlink" title="produer"></a>produer</h3><p><strong>Program arguments可根据自己的情况修改</strong><br><img src="/images/Kafka源码导入Idea/producer.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;虽然网上教程很多，但是我依然要写系列&lt;br&gt;因为我踩到的坑有的是网上没有遇到过的&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kafka指南" scheme="https://blog.lovezhy.cc/categories/Kafka%E6%8C%87%E5%8D%97/"/>
    
    
      <category term="Kafka" scheme="https://blog.lovezhy.cc/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka指南-时间轮实现</title>
    <link href="https://blog.lovezhy.cc/2020/01/11/Kafka%E6%8C%87%E5%8D%97-%E6%97%B6%E9%97%B4%E8%BD%AE%E5%AE%9E%E7%8E%B0/"/>
    <id>https://blog.lovezhy.cc/2020/01/11/Kafka%E6%8C%87%E5%8D%97-%E6%97%B6%E9%97%B4%E8%BD%AE%E5%AE%9E%E7%8E%B0/</id>
    <published>2020-01-10T16:00:00.000Z</published>
    <updated>2020-02-29T14:26:48.032Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Kafka延迟任务的实现</p><a id="more"></a><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>延迟任务的实现，一般是利用有序队列，按照执行时间的顺序排列，然后有个线程不断的去取第一个元素，如果到了需要执行的时间，就去执行。</p><p>伪代码：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Delay</span> </span>&#123;</span><br><span class="line">    Queue&lt;Comparable&gt; taskQueue;</span><br><span class="line">    </span><br><span class="line">    <span class="function">func <span class="title">add</span><span class="params">(Comparable task)</span> </span>&#123;</span><br><span class="line">        taskQueue.add(task);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function">func <span class="title">pollAndRun</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">                var task = taskQueue.peek();</span><br><span class="line">                <span class="keyword">if</span> (task.expireTime &lt;= System.currentTime) &#123;</span><br><span class="line">                    run(taskQueue.poll());</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    Thread.sleep(task.expireTime - System.currentTime);</span><br><span class="line">                &#125;</span><br><span class="line">        &#125; </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><strong>注意：这里的伪代码不完善，在add方法中，一般来说在某种情况下要interrupt执行pollAndRun的线程。</strong></p><p>目前聚焦的主要问题是Queue是怎么个实现法。<br>在Java中有优先权队列可以进行排序，底层是基于最小堆做的，插入和删除的时间复杂度是O(logn)</p><p>当然正常情况下，这种实现可以了，Java中的标准实现也是这样。</p><p>但是呢，Kafka中有大量的<strong>低延迟</strong>的任务，如果都用最小堆去做，难免性能不太好<br>所以Kafka中实现了时间轮的算法，将插入和删除的时间复杂度降低到了O(1)。</p><p>下面细讲下实现：</p><h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><p>源码路径在：<code>package kafka.utils.timer</code>下。</p><h3 id="TimerTask"><a href="#TimerTask" class="headerlink" title="TimerTask"></a>TimerTask</h3><p>Task是队列中的执行元素</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">trait TimerTask extends Runnable &#123;</span><br><span class="line">    val delayMs: Long </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>实现了Runnable接口，delayMs是指的需要被执行的时间戳，不是相对时间</p><h3 id="TimerTaskList"><a href="#TimerTaskList" class="headerlink" title="TimerTaskList"></a>TimerTaskList</h3><p>看名字就知道是存储Task的集合类</p><p>但是其实它的定义并没有我开始想的那么简单</p><p>TimerTask在TimerTaskList内部的存储形式是双向链表</p><p>所以TimerTask其实被TimerTaskEntry的类包装了一层，增加了Prev和Next指针。</p><p><img src="/images/Kafka时间轮/TimerTaskList.png"></p><p>但是注意哦，这里虽然TimerTask实现了Comparable接口，但是TimerTaskList内部其实就是个简单的双向列表，并不会根据TimerTask的expireTime进行排序。</p><p>恰恰相反，TimerTaskList也实现了Comparable接口。</p><p>在TimerTaskList内部，有一个变量</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[<span class="keyword">this</span>] val expiration = <span class="keyword">new</span> AtomicLong(-<span class="number">1L</span>)</span><br></pre></td></tr></table></figure><p>从名字中看出其实是存放的是到期时间，TimerTask有过期时间我们可以理解，那么为什么TimerTaskList也有个过期时间？</p><p>这个过期时间是怎么定的，有什么用？</p><h3 id="TimingWheel"><a href="#TimingWheel" class="headerlink" title="TimingWheel"></a>TimingWheel</h3><p>来了，时间轮最主要的数据结构来了。</p><p><img src="/images/Kafka时间轮/TimerWheel.png"></p><p>首先，看图中，模仿了一个钟表的运行图。<br>每tick一下，就把当前指针指向下一个格子。<br>其中每个格子对应着一个TimerTaskList</p><p>格子在Kafka中叫bucket<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val buckets = Array.tabulate[TimerTaskList](wheelSize) &#123; _ =&gt; <span class="keyword">new</span> TimerTaskList(taskCounter) &#125;</span><br></pre></td></tr></table></figure></p><p>每一格代表的时间叫TickMs，整个表最长的跨度叫Interval。</p><p>如果TickMs=5，Bucket=4，就表示这个时间轮有4个格子，总共能执行20ms内的延迟任务，同时TickMs也就是该时间轮保证的延迟任务的延迟执行的单位。</p><p>什么意思呢？就是说如果一个任务是2ms后执行，一个是4ms后执行，但是整个时间轮的TickMs是5ms，那么这两个任务在时间轮看来其实是没区别，是同时执行。</p><p>所以时间轮的TickMs最小，时间就越精确。</p><p>如果延迟时间超过了该时间轮的Interval怎么办？</p><p>比如执行50ms后才运行的任务，则需要建立跨度更大的时间轮。</p><p>而Kafka中会自动建立跨度更大的时间轮，叫overflowWheel，<strong>更大的时间轮的TickMs是下一层的Interval</strong>。</p><p>看到这里，其实可以解答TimerTaskList中的expiration有什么用了。</p><p>这里的expiration其实就是整个TimerTaskList的过期时间，是TickMs的整数倍</p><p>与在TimerTaskList中每个Task的具体延迟时间关系是</p><p><code>TimerTaskList.expiration &lt;= Task.expiration &lt;= TimerTaskList.expiration + TickMs</code></p><p>在Kafka中，默认的时间轮配置TickMs=1，Bucket=20，也就是20MS内的延迟任务。</p><h2 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h2><p>讲完了数据结构，下面需要讲怎么运行了。<br>TimingWheel的运行，交给了Timer来操作。<br>Timer有两个方法<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//往时间轮中加入任务</span></span><br><span class="line"><span class="function">def <span class="title">add</span><span class="params">(timerTask: TimerTask)</span></span>&#123;&#125;</span><br><span class="line"><span class="comment">//驱动时间轮向前Tick</span></span><br><span class="line"><span class="function">def <span class="title">advanceClock</span><span class="params">(timeoutMs: Long)</span></span>&#123;&#125;</span><br></pre></td></tr></table></figure></p><h3 id="菜鸡的猜想方案"><a href="#菜鸡的猜想方案" class="headerlink" title="菜鸡的猜想方案"></a>菜鸡的猜想方案</h3><p>让我们暂时脱离源码，猜猜时间轮怎么运行的。</p><p><img src="/images/Kafka时间轮/tick.png" alt=""></p><p>正常来说，我们把任务分到具体的Bucket中，每隔一个TickMs，将当前的指针向下运行一格。</p><p>找到这一格中的TimerTaskList，将里面的任务全部拿出来run一遍。</p><p>伪代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">List&lt;TimerTaskList&gt; buckets;</span><br><span class="line"><span class="keyword">int</span> nextBucket;</span><br><span class="line"><span class="function">func <span class="title">tick</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  var timerTaskList = buckets.get(nextBucket % buckets.length)</span><br><span class="line">  <span class="keyword">if</span> (timerTaskList.expiration &lt;= System.currentTime) &#123;</span><br><span class="line">    timerTaskList.timerTaskEntrys.foreach(entry -&gt; entry.run()));</span><br><span class="line">    timerTaskList.timerTaskEntrys.foreach(TimerTaskList::remove);</span><br><span class="line">    nextBucket++;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在add元素的时候，先需要判断当前的时间轮是否能承载延迟时间，如果不能，则建立overflowWheel，加到overflowWheel中。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">List&lt;TimerTaskList&gt; buckets;</span><br><span class="line"><span class="function">func <span class="title">add</span><span class="params">(taskEntry)</span> </span>&#123;</span><br><span class="line">  var targetBucketId = (taskEntry.expiration - System.time) / tickMs + nextBucket;</span><br><span class="line">  var timerTaskList = buckets.get(targetBucketId % buckets.length)</span><br><span class="line">  timerTaskList.add(taskEntry);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>看起来非常完美，但是问题来了，这个tick函数，怎么个运行策略呢？</p><p>如果要要跑的非常精确的话，必须要有个线程去单独驱动是肯定的，线程里还得这么跑</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//1</span></span><br><span class="line"><span class="function">func <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">    timer.tick()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//2</span></span><br><span class="line"><span class="function">func <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">    timer.tick()</span><br><span class="line">    sleep(timer.tickms)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>有方案1和方案2两种，第二种肯定是有问题的，如果出现了FullGC的情况，那么整个时间轮就不准了。</p><p>只能选择第一种方案，那么第一种肯定是不行的，这样CPU就是100%了，即使时间轮中没有任何任务，很多时间都是无用功，太浪费CPU了。</p><p>其实这里还有个很严重的问题，我们没有考虑overflowWheel。</p><p>正常情况下，在overflowWheel中的任务，如果已经到了下一层TimingWheel的interval范围内，是需要手动放到下一层的。</p><p>如果是这种实现的话，对于overflowWheel的处理会更加的复杂。</p><h3 id="Kafka中的实现"><a href="#Kafka中的实现" class="headerlink" title="Kafka中的实现"></a>Kafka中的实现</h3><p>菜鸡的猜想方案是不行的，面试都是直接挂的节奏。</p><p>所以这种思路是不成立的，那么我们能不能换个思路呢？</p><p>我们沿用最基本的最小堆来实现延迟任务的思路，建立一个优先权队列</p><p>但是队列中的元素不再是TimerTask了，而是TimerTaskList，相比较最原始的方案，队列中的元素少了一个数量级。</p><p>这样，每次单独的线程进行Tick的时候，选出最早需要执行的TimerTaskList，如果还没到执行时间，就可以进行Sleep，而不是占满CPU。</p><p>所以在TimingWheel中增加一个数据结构</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">var queue = <span class="keyword">new</span> PriorityQueue&lt;TimerTaskList&gt;()</span><br></pre></td></tr></table></figure><p>每次进行add时，除了把TaskEntry添加到TimerTaskEntry中，还将TimerTaskList添加到queue中。</p><p>这样线程的驱动函数就是这么写：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">func <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">    var timerTaskList = timer.queue.poll();</span><br><span class="line">    <span class="keyword">if</span> (timerTaskList.expiration &lt; System.time) &#123;</span><br><span class="line">      sleep(System.time - timerTaskList.expiration);</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>虽然也使用了插入是O(logn)的最小堆结构，但是堆中元素不再是全量的Task了，而是TaskList，所以时间复杂度其实类似于O(1)了。</p><p>那么对于overflowWheel里面的Task怎么处理呢？</p><p>很简单，和第一层的timingWheel一样，将overFlowWheel中的TimerTaskList也加到queue中</p><p>但是从Queue取出的时候，就不是立即执行了，而是再走一遍add程序</p><p>下面是源码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">//类似于源代码中nextBuckets的作用，这里是绝对时间，startMs是时间轮的开始的绝对时间，这里计算成tickMs的整数倍</span><br><span class="line">private[this] var currentTime = startMs - (startMs % tickMs)</span><br><span class="line"></span><br><span class="line">//向时间轮中加入任务</span><br><span class="line">def add(timerTaskEntry: TimerTaskEntry): Boolean = &#123;</span><br><span class="line">   val expiration = timerTaskEntry.expirationMs</span><br><span class="line">   if (timerTaskEntry.cancelled) &#123;</span><br><span class="line">     //如果任务已经取消，添加失败，可以直接实行</span><br><span class="line">     false</span><br><span class="line">   &#125; else if (expiration &lt; currentTime + tickMs) &#123;</span><br><span class="line">     //如果已经到执行时间，那么也是可以直接执行</span><br><span class="line">     false</span><br><span class="line">   &#125; else if (expiration &lt; currentTime + interval) &#123;</span><br><span class="line">           //这里其实还挺难理解的，如果我们按照钟表的概念，指针每隔一段时间去转动一下，就很难理解下面的代码</span><br><span class="line">           //这里其实就是每隔tickMs，指针不转，整个表顺时针转tickMs圈</span><br><span class="line">     val virtualId = expiration / tickMs</span><br><span class="line">     val bucket = buckets((virtualId % wheelSize.toLong).toInt)</span><br><span class="line">     bucket.add(timerTaskEntry)</span><br><span class="line"></span><br><span class="line">     if (bucket.setExpiration(virtualId * tickMs)) &#123;</span><br><span class="line">       //如果Bucket的失效时间设置成功，就把这个TimerTaskList加入到queue中</span><br><span class="line">       queue.offer(bucket)</span><br><span class="line">     &#125;</span><br><span class="line">     true</span><br><span class="line">   &#125; else &#123;</span><br><span class="line">     //放不下，建立overflowWheel，overflowWheel和当前timingWheel公用一个queue</span><br><span class="line">     if (overflowWheel == null) addOverflowWheel()</span><br><span class="line">     overflowWheel.add(timerTaskEntry)</span><br><span class="line">   &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>timingWheel的advanceClock代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def advanceClock(timeMs: Long): Unit = &#123;</span><br><span class="line">  if (timeMs &gt;= currentTime + tickMs) &#123;</span><br><span class="line">    currentTime = timeMs - (timeMs % tickMs)</span><br><span class="line">    if (overflowWheel != null) overflowWheel.advanceClock(currentTime)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>主要就是调整下currentTime，其实currentTime在有了queue之后，就没有其他作用了，主要就是在add方法中拦住即将过期或者已经过期的任务</p><p>下面是伪代码中的run方法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">def advanceClock(timeoutMs: Long): Boolean = &#123;</span><br><span class="line">   var bucket = delayQueue.poll(timeoutMs, TimeUnit.MILLISECONDS)</span><br><span class="line">   if (bucket != null) &#123;</span><br><span class="line">     writeLock.lock()</span><br><span class="line">     try &#123;</span><br><span class="line">       while (bucket != null) &#123;</span><br><span class="line">         timingWheel.advanceClock(bucket.getExpiration())</span><br><span class="line">         //这里不能把bucket中的任务全部执行，因为可能是overFlowWheel中的TimerTaskList，还没到执行时间，直接再走一遍add程序</span><br><span class="line">         bucket.flush(reinsert)</span><br><span class="line">         bucket = delayQueue.poll()</span><br><span class="line">       &#125;</span><br><span class="line">     &#125; finally &#123;</span><br><span class="line">       writeLock.unlock()</span><br><span class="line">     &#125;</span><br><span class="line">     true</span><br><span class="line">   &#125; else &#123;</span><br><span class="line">     false</span><br><span class="line">   &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>注意一下这里的delayQueue，其中poll方法返回的是过期的任务，并不是集合中第一个元素。</p><p>也就是说，即使queue中元素，但是没有元素要过期，返回的也是null。</p><p>当时作者在哪儿晕了半天。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;Kafka延迟任务的实现&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kafka指南" scheme="https://blog.lovezhy.cc/categories/Kafka%E6%8C%87%E5%8D%97/"/>
    
    
      <category term="kafka" scheme="https://blog.lovezhy.cc/tags/kafka/"/>
    
      <category term="TimeWheel" scheme="https://blog.lovezhy.cc/tags/TimeWheel/"/>
    
      <category term="时间轮" scheme="https://blog.lovezhy.cc/tags/%E6%97%B6%E9%97%B4%E8%BD%AE/"/>
    
  </entry>
  
  <entry>
    <title>HotSpot原理指南-分层编译</title>
    <link href="https://blog.lovezhy.cc/2020/01/04/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-%E5%88%86%E5%B1%82%E7%BC%96%E8%AF%91/"/>
    <id>https://blog.lovezhy.cc/2020/01/04/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-%E5%88%86%E5%B1%82%E7%BC%96%E8%AF%91/</id>
    <published>2020-01-03T16:00:00.000Z</published>
    <updated>2020-02-29T14:36:30.467Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>HotSpot的初衷是将运行环境分为Client和Server，并且为他们定制了不同的JIT策略以及不同的JIT编译器（C1和C2）。</p><p>设计出ClientMode的年代，个人PC的性能还比较低，无论是CPU资源还是内存资源都比较稀少且价格较高，所以C1节约资源的快速编译是很有必要的。</p><p>随着时代的发展，个人计算机的配置在慢慢升级，同时价格也在慢慢降低，在这种环境下，ClientMode并不是那么适用了，所以HotSpot也就慢慢放弃了ClientMode，在个人计算机上默认采用Server模式。</p><a id="more"></a><h2 id="Oracle的想法"><a href="#Oracle的想法" class="headerlink" title="Oracle的想法"></a>Oracle的想法</h2><p>所有的场景都默认使用Server模式自然是没有什么问题的，但是Oracle并不甘心（作者脑补的），主要不甘心在两个方面：</p><ul><li>默认使用Server模式，那么相当于放弃了开发了很久的C1编译器</li><li>由于Server模式JIT编译策略问题，会导致应用的Warm-Up时间较长</li></ul><p>那么有没有什么方法可以结合C1和C2呢？</p><p>比如用C1解决Warm-Up时间过长的问题。</p><h2 id="分层编译"><a href="#分层编译" class="headerlink" title="分层编译"></a>分层编译</h2><p>前面提到过，Oracle想用C1解决Server模式中Warm-Up时间过长的问题，于是引入了分层编译的概念。</p><p>如下图所示：</p><p><img src="/images/HotSpot原理指南-分层编译/c1c2.png" alt=""></p><p>解释阶段主要是为了收集运行时Profile，Profile收集的越多，对JIT编译出的代码性能帮助越大。</p><p>先看上半部分图，如果我们采用传统的ServerMode运行，在一段时间X内，只能收集300份Profile，然后将这些Profile丢给C2去进行编译。</p><p>我们可以减少解释模式的运行时间，尽快用C1把字节码编译成机器码，用机器码去收集Profile。这就如下半部分图所示：</p><p>收集了100份Profile后，运行C1编译后的代码，在一段时间内，可以收集到更多的Profile。</p><p>上面是限制了收集Profile的时间是一定的，如果我们反过来，<strong>收集Profile的样本数是一定的</strong>：</p><ul><li>传统的Server模式，可能需要花费更多的时间进行收集到指定次数的样本</li><li>先利用C1进行代码编译，提升方法的运行速度，相对可以花费更少的时间进行收集</li></ul><p>如上的思想就是引入C1解决传统的ServerMode热身时间较少的问题，也就是分层编译：先采用C1进行编译，再采用C2进行编译。</p><p>具体的时间对比如下两张图所示：只使用C2 VS 分层编译</p><p><img src="/images/HotSpot原理指南-分层编译/only-c2.png" alt=""><br><img src="/images/HotSpot原理指南-分层编译/tier.png" alt=""></p><h2 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h2><p>分层编译在JDK7中就引入了，但是默认是不开启的</p><p>如果运行环境还是JDK7，可以使用<code>-XX:+TieredCompilation</code>开启</p><p>在JDK8中，分层编译就默认开启了，如果要关闭它，可以使用<code>-XX:-TieredCompilation</code>关闭</p><h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><p>正常的话，只要理解到上面就够了，分层大概分为两层，先是C1，然后是C2。</p><p>但是事实上，我们如果查看以Tier开头的HotSpot参数的话，会发现其包含的参数很多很多</p><p><img src="/images/HotSpot原理指南-分层编译/参数.png" alt=""></p><p>笔者第一次搜索出来时，实在是吃了一惊。<br>经过研究，其实发现分层编译，并不是分了两层，而是足足分了<strong>4</strong>层。</p><ul><li>第0层：解释阶段</li><li>第1-3层：C1编译<ul><li>第1层：C1编译出的<strong>不收集任何Profile</strong>的机器码</li><li>第2层：C1编译出的<strong>仅仅收集方法调用计数</strong>的机器码</li><li>第3层：C1编译出的<strong>收集全部Profile</strong>的机器码</li></ul></li><li>第4层：C2编译</li></ul><p>可以看到，在C1编译的阶段，还拆分成了三个小的阶段。<br>同时，对于这三个小的阶段，需要理解的是，<strong>运行上并不是递进关系</strong>，也就是说并不是先运行第1层，再运行第2层，再运行第3层。具体怎么运行，其实和很多因素有关。<br>我们先看看有哪些经典的分层流程：</p><p><img src="/images/HotSpot原理指南-分层编译/4个阶段.png" alt=""><br>如上图所示。</p><ul><li>流程1：正常的方法的编译流程，先是解释执行，然后直接跳到第3阶段，也就是C1编译出的收集全部Profile的机器码。然后再跳到第4层，也就是C2编译。深色的框表示是编译的终止阶段。</li><li>流程2：但是，如果第3层的等待队列太长，可能就先提交到第2层进行编译，等待一段时间后，再提交给第3层</li><li>流程3：如果该方法比较简单，是个Trivial方法，比如Getter方法，这种方法去收集Profile其实没有什么Profile，给C2去进行编译纯属于浪费资源，所以提交给第3层后，直接给第1层，然后终止。</li><li>流程4：同样也是Trivial方法，如果在解释阶段就发现其比较简单，也可以直接提交给第1层编译</li></ul><p>以上是一些经典的流程，还有一些流程，比如从解释阶段可以直接提交给C2等。</p><p>所以，虽说是分层编译，但是具体的编译流程是不确定的，这个各个编译器的状态以及方法的属性有关。</p><h2 id="C1和C2编译线程数"><a href="#C1和C2编译线程数" class="headerlink" title="C1和C2编译线程数"></a>C1和C2编译线程数</h2><p>各个编译的状态，最简单的就是负责编译的线程数<br>HotSpot分配给C1和C2编译器的线程数，和<strong>指定的启动参数</strong>以及<strong>机器的核心数</strong>有关。</p><p>启动参数：影响线程数的参数有CICompilerCount和CICompilerCountPerCPU两个，默认值如下，一般不会去改这些<br><img src="/images/HotSpot原理指南-分层编译/启动参数.png" alt=""></p><p>有了参数之后，具体的分配代码如下：<br><img src="/images/HotSpot原理指南-分层编译/启动参数2.png" alt=""></p><p>简单聊聊分配策略：</p><ul><li>C1+C2的总的线程数：log2(log2(CoreNum)) * 3 / 2</li><li>C1 / C2 = 1 / 2</li><li>C1和C2至少有一个线程</li></ul><p>下面表格简单显示了一些常见情况</p><table><thead><tr><th>CPU Core</th><th>C1</th><th>C2</th></tr></thead><tbody><tr><td>4</td><td>1</td><td>2</td></tr><tr><td>8</td><td>1</td><td>3</td></tr><tr><td>16</td><td>4</td><td>8</td></tr><tr><td>32</td><td>5</td><td>10</td></tr><tr><td>64</td><td>6</td><td>12</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;HotSpot的初衷是将运行环境分为Client和Server，并且为他们定制了不同的JIT策略以及不同的JIT编译器（C1和C2）。&lt;/p&gt;
&lt;p&gt;设计出ClientMode的年代，个人PC的性能还比较低，无论是CPU资源还是内存资源都比较稀少且价格较高，所以C1节约资源的快速编译是很有必要的。&lt;/p&gt;
&lt;p&gt;随着时代的发展，个人计算机的配置在慢慢升级，同时价格也在慢慢降低，在这种环境下，ClientMode并不是那么适用了，所以HotSpot也就慢慢放弃了ClientMode，在个人计算机上默认采用Server模式。&lt;/p&gt;
    
    </summary>
    
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/categories/HotSpot/"/>
    
    
      <category term="Java" scheme="https://blog.lovezhy.cc/tags/Java/"/>
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/tags/HotSpot/"/>
    
      <category term="JIT" scheme="https://blog.lovezhy.cc/tags/JIT/"/>
    
      <category term="JVM" scheme="https://blog.lovezhy.cc/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>HotSpot原理指南-JIT触发条件</title>
    <link href="https://blog.lovezhy.cc/2019/12/14/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-JIT%E8%A7%A6%E5%8F%91%E6%9D%A1%E4%BB%B6/"/>
    <id>https://blog.lovezhy.cc/2019/12/14/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-JIT%E8%A7%A6%E5%8F%91%E6%9D%A1%E4%BB%B6/</id>
    <published>2019-12-13T16:00:00.000Z</published>
    <updated>2020-02-29T14:36:09.667Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>通过前面我们知道，对于每个方法，HotSpot都维护两个计数器</p><ul><li>Invocation Counter：方法被调用次数，每被调用一次都会+1</li><li>BackEdge Counter：专业的说法就是字节码在执行时的回跳次数。通俗点说就是，在For或者While循环中，每执行一次，都会+1。</li></ul><p>并且我们知道对于一个方法，JIT有两种不同的编译方式</p><ul><li>完整的原方法编译，就是把原本的方法逻辑进行编译。入参和运行结果和解释运行都是一致的。</li><li>OSR编译，OSR后的方法入参以及运行流程和原方法有较大差异。</li></ul><p>很自然得我们就会想到，其实计数器和编译方式之间是有对应关系的。</p><ul><li>Invocation Counter -&gt; 完整的原方法编译</li><li>BackEdge Counter  -&gt; OSR编译</li></ul><p>当对应的方法计数器达到一定的次数，就会触发响应的编译</p><a id="more"></a><h2 id="编译流程图"><a href="#编译流程图" class="headerlink" title="编译流程图"></a>编译流程图</h2><p>完整的编译流程如下：</p><p><img src="/images/HotSpot原理指南-JIT触发条件/编译流程.png" alt=""></p><p><strong>注：该图引自R大的JVM分享PPT，如有侵权，请联系我删除</strong></p><p>图中的流程非常的清晰，这里提几个小点：</p><ul><li><p>问：对于同一方法，是否两种编译方式都可能会执行？</p><p>答：是的，而且两种代码可能同时被运行，但是正常情况下，只要运行的够久，都会运行完整的原方法编译后的代码。</p></li><li><p>问：具体哪种编译方式先触发？</p><p>答：其实无法确定，看哪个计数器先达到阈值</p></li></ul><h2 id="触发阈值"><a href="#触发阈值" class="headerlink" title="触发阈值"></a>触发阈值</h2><p>可能你还想更直观的了解下两个计数器的触发阈值到底是多少。</p><p>在HotSpot源码中，有这样两个参数：</p><ul><li><blockquote><p>intx CompileThreshold = 10000</p><p>globals.hpp &gt; ”number of interpreted method invocations before (re-)compiling” </p></blockquote></li><li><blockquote><p>intx BackEdgeThreshold = 100000</p><p>globals.hpp &gt; “Interpreter Back edge threshold at which an OSR compilation is invoked”</p></blockquote></li></ul><p>数值可能根据不同的发行版本略有不同，上面的数值是JDK7版本中的。</p><p>那么你可能以为</p><ul><li>当Invocation Counter &gt; Compile Threshold时，就会触发原来方法的JIT</li><li>当BackEdge Counter &gt; BackEdge Threshold时，就会触发方法的OSR编译</li></ul><p>但是事实并不是如此。</p><p>问题出在哪儿呢？难道官方的定义还会有错吗？</p><p>是的，问题出在BackEdgeThreshold上，虽然HotSpot中确实定义了该参数，描述中似乎也证实了该参数的作用，但是这个参数并没有实际使用过。</p><p>对于BackEdgeThreshold的计算，是另外一套公示。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (ProfileInterpreter) &#123;</span><br><span class="line">  InterpreterBackwardBranchLimit = </span><br><span class="line">                 (CompileThreshold * (OnStackReplacePercentage - InterpreterProfilePercentage)) / <span class="number">100</span>;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  InterpreterBackwardBranchLimit = </span><br><span class="line">                ((CompileThreshold * OnStackReplacePercentage) / <span class="number">100</span>) &lt;&lt; number_of_noncount_bits;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>首先解释下<code>ProfileInterpreter</code>参数，这个参数也是在HotSpot中定义的，之前在文章<code>HotSpot原理指南-C1和C2介绍</code>中也讲解过，就是是否在运行时收集方法的Profile信息，这个字段在Server模式默认是开启的。</p><p>所以大部分情况下，除非你的计算机比较老，都会根据第一个公示进行计算</p><p><code>(CompileThreshold * (OnStackReplacePercentage - InterpreterProfilePercentage)) / 100</code></p><p>其中<strong>OnStackReplacePercentage</strong>默认值是140，<strong>InterpreterProfilePercentage</strong>默认值是33。</p><p>由此我们可以计算出真实的BackEdge Invocation阈值大概是10700左右。</p><h2 id="衰减"><a href="#衰减" class="headerlink" title="衰减"></a>衰减</h2><p>假如方法计数器不会根据时间进行衰减的话，那么只要服务器运行的时间足够长，再罕见被调用的函数，也会触发到阈值，然后被JIT编译。</p><p>这显然是不合理的，因为我们知道JIT后的机器码数据，还是会保存在内存中的，这样相当于一段逻辑在内存中又保存了字节码，又保存了一份机器码，十分的浪费内存。</p><p>所以对于Invocation Counter而言，经过一段时间，个数就会进行减少。</p><p>具体的减少逻辑，读者有兴趣的可以自己去探索。</p><p>但是注意：对于BackEdge Counter，是不会作衰减的。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;通过前面我们知道，对于每个方法，HotSpot都维护两个计数器&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Invocation Counter：方法被调用次数，每被调用一次都会+1&lt;/li&gt;
&lt;li&gt;BackEdge Counter：专业的说法就是字节码在执行时的回跳次数。通俗点说就是，在For或者While循环中，每执行一次，都会+1。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;并且我们知道对于一个方法，JIT有两种不同的编译方式&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;完整的原方法编译，就是把原本的方法逻辑进行编译。入参和运行结果和解释运行都是一致的。&lt;/li&gt;
&lt;li&gt;OSR编译，OSR后的方法入参以及运行流程和原方法有较大差异。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;很自然得我们就会想到，其实计数器和编译方式之间是有对应关系的。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Invocation Counter -&amp;gt; 完整的原方法编译&lt;/li&gt;
&lt;li&gt;BackEdge Counter  -&amp;gt; OSR编译&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当对应的方法计数器达到一定的次数，就会触发响应的编译&lt;/p&gt;
    
    </summary>
    
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/categories/HotSpot/"/>
    
    
      <category term="Java" scheme="https://blog.lovezhy.cc/tags/Java/"/>
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/tags/HotSpot/"/>
    
      <category term="JIT" scheme="https://blog.lovezhy.cc/tags/JIT/"/>
    
  </entry>
  
  <entry>
    <title>HotSpot原理指南-OSR是什么</title>
    <link href="https://blog.lovezhy.cc/2019/11/30/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-OSR%E6%98%AF%E4%BB%80%E4%B9%88/"/>
    <id>https://blog.lovezhy.cc/2019/11/30/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-OSR%E6%98%AF%E4%BB%80%E4%B9%88/</id>
    <published>2019-11-29T16:00:00.000Z</published>
    <updated>2020-02-29T14:36:16.869Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>前面我们讲解了C1和C2的基本知识，但是我们还未触及一个核心的策略，就是<strong>什么时候触发即使编译</strong>，也就是<strong>when</strong>的问题。</p><p>对于when的问题，相信大家多多少少都大概知道，每个方法都会有一个调用次数的计数器，当这个计数器的次数到达一定的次数时，就会被认为是热点方法，继而触发JIT编译。</p><p>但是本文要科普另外一种触发条件，和方法计数器类似。</p><a id="more"></a><h2 id="方法计数器的问题"><a href="#方法计数器的问题" class="headerlink" title="方法计数器的问题"></a>方法计数器的问题</h2><p>大部分人看来，维护一个方法被调用次数计数器当然是一个很完美的方案</p><p>但是有一类方法，即使在我们认知范围内，属于热点方法，但是却无法享受到这个计数器的好处。</p><p>如下代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OSRExample</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">200000</span>; i++) &#123;</span><br><span class="line">            <span class="comment">//do a lot of things</span></span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(sum);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在Main函数中，有一个循环，在循环中并没有调用某个方法，而是一直在线性执行一些逻辑。</p><p>假如我们把循环中的逻辑看做一个函数，这个函数肯定是热点函数，需要进行JIT编译的，但是在这种场景下，并不是一个函数，也就是无法进行JIT。</p><p>如果JIT无法处理这种情况，将是非常可惜的。</p><h2 id="Hot-Loop优化"><a href="#Hot-Loop优化" class="headerlink" title="Hot Loop优化"></a>Hot Loop优化</h2><p>但是如果我们构造一个上面的代码的情况，并且使用计数器给每次循环的执行时间进行计时。</p><p>会发现下面这张时间和次数的图</p><p><img src="/images/HotSpot原理指南-OSR是什么/hotLoop耗时.png" alt=""></p><p>从图中我们可以看出，大概在150次的时候，整个Loop的耗时突发的大大降低。</p><p>说明在HotSpot的JIT中，是可以处理这种情况的。</p><p>那么HotSpot究竟是怎么做的呢？</p><p>前面我们提到过，如果在Loop中调用的是方法，将不会存在上述的问题，但是实际的情况并不是调用的方法。</p><p>那么，我们能不能，把它包装成一个函数呢？</p><p>举个例子，原方法如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OSRExample</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">20000</span>; i++) &#123;</span><br><span class="line">            sum += i;</span><br><span class="line">          sum *= sum;</span><br><span class="line">          sum |= sum;</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(sum);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们把它改成如下的方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OSRExample</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">20000</span>; i++) &#123;</span><br><span class="line">sum = doLoop(sum);</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(sum);</span><br><span class="line">    &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">doLoop</span><span class="params">(<span class="keyword">int</span> sum)</span> </span>&#123;</span><br><span class="line">      sum += i;</span><br><span class="line">      sum *= sum;</span><br><span class="line">      sum |= sum;</span><br><span class="line">      <span class="keyword">return</span> sum;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样可以不可以呢？</p><p>当然是可以的。</p><p>但是！这是作者的猜测，HotSpot真实的情况并不是这样。</p><p>事实上，这种割裂整个main方法，动态把一部分代码进行修改的操作似乎消耗太大了，性价比并不高。</p><p>HotSpot并不会把Loop的内容动态生成一个函数，然后对该函数进行JIT。</p><p>而是对包含这个Loop的<strong>整个方法进行了JIT</strong>。</p><p>什么？对整个方法进行JIT？</p><p>要知道，这个方法在运行中啊，可能再也不会运行第二次，对整个方法进行JIT有什么意义呢？</p><p>稍安勿躁，虽然对整个方法进行了JIT，但是JIT后的代码和原来的函数其实还是有区别的。</p><p>如果我们需要将运行到一半的函数，从一个源代码替换到另外一个源代码，遇到的问题是什么呢？</p><p>首先，这个方法的循环执行到一半，这个i的具体数值肯定不是0了，是一个不可预测的值。</p><p>同时这个sum的值，肯定也是一个不好预测的值。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">20000</span>; i++) &#123;</span><br><span class="line">sum = doLoop(sum);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果要进行替换，需要把替换时的i和sum的值记录下来，那么替换后的源代码大概就长这样</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">public static void main#jit(int i, int sum) &#123;</span><br><span class="line"><span class="keyword">for</span> (; i &lt; <span class="number">20000</span>; i++) &#123;</span><br><span class="line">        sum += i;</span><br><span class="line">      sum *= sum;</span><br><span class="line">      sum |= sum;</span><br><span class="line">    &#125;</span><br><span class="line">    System.out.println(sum);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>没错！把运行中动态的值作为参数传给JIT后的函数，就是HotSpot的JIT对于这种HotLoop的优化。</p><h2 id="OSR"><a href="#OSR" class="headerlink" title="OSR"></a>OSR</h2><p>OSR的全称是On-Stack-Replacement。也就是栈上替换。</p><p>从上一节我们了解的可以知道，对于main函数，JIT进行编译的时候，直接把运行中的main函数源代码进行了替换，替换成了修改后的main函数。那么之前的main函数栈帧其实就完全失效了，被替换成了新的函数的栈帧。</p><p>这种JIT编译的方式就叫OSR编译。</p><p>这种栈上替换的方式其实并不是HotSpot独有的，很多其他的语言中也有这样的优化，如V8。</p><h2 id="后续问题"><a href="#后续问题" class="headerlink" title="后续问题"></a>后续问题</h2><p>OSR能够解决HotLoop的优化问题，但是其实在HotSpot中还是有几个值得深究的点。</p><ol><li><p>如果这个main函数方法非常大，Loop只是很小的一部分，那么把整个函数进行JIT编译的性价比就值得商榷了。核心问题其实是，为什么必须要编译整个方法呢？</p><p>这个问题R大也给了我们解释，详细看文章</p><p><a href="https://github.com/AdoptOpenJDK/jitwatch/wiki/Understanding-the-On-Stack-Replacement-(OSR)-optimisation-in-the-HotSpot-C1-compiler" target="_blank" rel="noopener">https://github.com/AdoptOpenJDK/jitwatch/wiki/Understanding-the-On-Stack-Replacement-(OSR)-optimisation-in-the-HotSpot-C1-compiler</a></p></li><li><p>OSR其实并不是完美的解决方案，在某些场景下它会生成非常丑陋的代码，如果有多个Loop或者Loop进行嵌套的方法。</p><p>HotSpot在一篇文章中进行了解释，有兴趣可以看文章</p><p><a href="https://www.h2o.ai/blog/what-the-heck-is-osr-and-why-is-it-bad-or-good/" target="_blank" rel="noopener">What ths heck is osr and why is it bad or good?</a></p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;前面我们讲解了C1和C2的基本知识，但是我们还未触及一个核心的策略，就是&lt;strong&gt;什么时候触发即使编译&lt;/strong&gt;，也就是&lt;strong&gt;when&lt;/strong&gt;的问题。&lt;/p&gt;
&lt;p&gt;对于when的问题，相信大家多多少少都大概知道，每个方法都会有一个调用次数的计数器，当这个计数器的次数到达一定的次数时，就会被认为是热点方法，继而触发JIT编译。&lt;/p&gt;
&lt;p&gt;但是本文要科普另外一种触发条件，和方法计数器类似。&lt;/p&gt;
    
    </summary>
    
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/categories/HotSpot/"/>
    
    
      <category term="Java" scheme="https://blog.lovezhy.cc/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>银行报考指北</title>
    <link href="https://blog.lovezhy.cc/2019/11/30/%E9%93%B6%E8%A1%8C%E6%8A%A5%E8%80%83%E6%8C%87%E5%8C%97/"/>
    <id>https://blog.lovezhy.cc/2019/11/30/%E9%93%B6%E8%A1%8C%E6%8A%A5%E8%80%83%E6%8C%87%E5%8C%97/</id>
    <published>2019-11-29T16:00:00.000Z</published>
    <updated>2020-02-29T14:44:02.280Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>看到标题，你可能会疑问，为什么我会去报考银行，我不是在互联网公司上班吗？难道是想逃离互联网回家养老去了？</p><a id="more"></a><p>当然，这个是个多因一果的事情。我确实报考了银行，并且顺利拿到了Offer。但是我并不是想逃离互联网，而是一次尝试，很大程度上只是去看看，顺便敷衍一下我妈。</p><p>当我说到敷衍我妈时，其实我比较伤心的，因为我妈一直觉得做技术太苦了，天天加班，不仅压力大，而且到了35岁会面临辞退的危险，所以希望我回家安安稳稳的过日子。</p><p>讲道理，我也有这种疑虑，但是目前并没有回家养老的意思，所以还是会继续留在南京上班。</p><p>扯了一堆，这次报考流程也算是踩了一次坑，这里记录下来，留给后人参考。</p><h2 id="报名"><a href="#报名" class="headerlink" title="报名"></a>报名</h2><p>一般我不会关注银行的招聘的，但是消息是我妈发给我的</p><p><a href="http://www.yinhangzhaopin.com/yzrcb/2019/0929/85386.html" target="_blank" rel="noopener">http://www.yinhangzhaopin.com/yzrcb/2019/0929/85386.html</a></p><p>后来我才发现原来有个网站专门就是收集各种银行招聘的信息。</p><p>报名在51Job上报名，上去填写一些资料就行了。</p><p>然后它会审核你的资料，算是一个初审，初审过了之后，会再发一封邮件给你告诉你初审过了，可以去缴费了。</p><p><img src="/images/银行报考指北/资料审核通过.png" alt=""></p><p>但是这个缴费网站，要到一定时间才会开通。</p><p>等到开通之后，登录到这个网站，付报名费，大概100块左右，然后选择考场。</p><p>这个考场并不是你报哪儿就必须去哪儿考试的。</p><p>比如我在南京，但是我报的是扬州的农商行，并不是一定要去扬州考试。他在每个城市都会有考点的。</p><p>在南京有4个考点，我记得有林业大学考点，金陵科技学院考点，还有两个记不得了。</p><p>我报的是金陵科技学院的考点。</p><p>好消息就是它考试是在周末考，这样如果是上学或者是上班的话，就不用请假了。</p><p>交完费之后，它还会给你一封邮件，让你准备笔试。</p><p><img src="/images/银行报考指北/笔试通知.png" alt=""></p><h2 id="考试"><a href="#考试" class="headerlink" title="考试"></a>考试</h2><p>周末那一天考试是从9：00到11：30。时间还是挺长的。</p><p>准考证需要提前打印好，然后考试带自己身份证就行了。也可以带一支笔，因为题目可能有数学题。</p><p>写到这个章节，你可能最想知道的是考试考什么题目。</p><p>题目其实是分岗位的，通用岗的我不是很清楚，我报的是科技岗，而且可能各个银行之间又不太一样。</p><p>首先题量很大。题型主要分为：</p><ul><li>找病句</li><li>句子排序</li><li>数学题。比如一排数字，让你找规律那种，那种题基本看一会儿看不出来就过吧</li><li>图形题。和公务员那种差不多，给三个奇怪的组合图形，然后让你选下一个和他们属性一致的图形是什么，这个看一会儿看不出来也过吧</li><li><p>材料题。给一些数据的图标，然后给4个选择题，让你从图标中找答案。还挺难找的。题量少。</p></li><li><p>英语题，缺词填空那种。大概有20道</p></li><li>计算机专业的题目。设计网络，操作系统，Java等。大概有80题。</li><li>考验智商的。比如给你个矩阵，会随机出现几个图形，5秒后消失，然后让你点击刚才出现的图形的位置。</li></ul><p>总而言之，有几点值得关注</p><ul><li>题量大。如果每道题都细做肯定来不及的，有点数学题不会就直接瞎选的。</li><li>不需要专业知识。我考之前有人和我说要很多经济学知识的，其实发现并不需要。</li></ul><p>我当时高估了自己，再加上其实去的意愿不高，做了一个半小时就赶紧溜了去上班了。</p><p>大概百分之60的题目，我都是瞎选的。</p><h2 id="面试"><a href="#面试" class="headerlink" title="面试"></a>面试</h2><p>其实我笔试考完觉得自己肯定挂了，但是过了两天打电话告诉我过了。</p><p>过了就过了吧，大概就是通知我去面试了。</p><p>让我周六去扬州交材料，周日面试。</p><p>我正好有朋友在扬州，所以就打算去顺便找他玩一下。</p><p>交材料的话，需要毕业证的复印件。身份证的正反面复印件，学信网的电子备案表的打印件。</p><p>周六去交了材料，顺便问了我的成绩。</p><p>傍晚的时候发短信通知我明天中午去面试。</p><p>我中午到的时候，发现大家都是穿正装来的，就我穿的花里胡哨的。心想大概率是凉了。</p><p>哈哈，所以这里提醒大家最好穿正装去面试，没有正装也穿个黑色的衣服去。</p><p>然后就是签到。</p><p>到了时间又让我们做了一个半小时的题目，题目大概和笔试的差不多，不知道这个是什么套路。</p><p>这个题目并不包括计算机的题目，我估计通用的和科技岗的都一样。</p><p>做完题目，需要把手机交上去，然后排队去面试。</p><p>流程是这样的，一个一个进去面试，当一个人进去时，后面一个人去等候区，等候区就一个人，有张桌子，上面有张纸，记着三个题目，有人给你计时4分钟，你看完题目想想怎么回答。</p><p>然后前一个出来时，你进去，然后对面三个面试官，面试官不会多对你说什么，你就把三个问题的答案说一遍就行。每个题目计时2分钟，说完也没有其他的问题，你就可以直接走了。</p><p>具体的题目其实和计算机的关系不大，属于需要总结概括的题目，需要的话可能私聊我。</p><p>面完就直接回去了，也没管什么。</p><h2 id="体检"><a href="#体检" class="headerlink" title="体检"></a>体检</h2><p>其实我面完之后感觉自己肯定差不多挂了，下面应该没后续流程了。</p><p>然后过了两天，大概是周二的时候，银行打电话告诉我过了面试。</p><p>下面的流程是体检，而且就在明天，银行的人问我能不能去。</p><p>我一想这也太突然了，我今天就得再去扬州，这也不太可能啊，所以我直接拒绝了。</p><p>以为这个机会就没了，但是她告诉我明天不去，那就等下一批的通知吧。</p><p>感情原来体检还是分批来的，我说好的。</p><p>其实我比较奇怪的地方是为什么直接去体检了，而不是先谈工资待遇啥的，这是明摆着面试通过了大家就肯定先去吗？</p><p>然后我问了在银行工作的同学，似乎他们都是这样的，都不知道具体的待遇什么的，都是上了一个月的班才知道具体的工资是多少。</p><p>这就有点坑了。</p><p>我回去也和我爸妈商量了下，我说我其实不太想回去。我爸妈也表示明白。</p><p>然后下一次打电话来的时候，我就直接拒绝了。</p><p>我以为银行的人会问问为什么，结果她直接说好的。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这次的银行面试经历就是如上了，我顺利的度过了笔试和面试，中间决定不去了。</p><p>整体上的体验一般般，流程拉的太长了，而且面试和体检都是在固定的地方，所以导致体验不会太好。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;看到标题，你可能会疑问，为什么我会去报考银行，我不是在互联网公司上班吗？难道是想逃离互联网回家养老去了？&lt;/p&gt;
    
    </summary>
    
    
      <category term="我的生活" scheme="https://blog.lovezhy.cc/categories/%E6%88%91%E7%9A%84%E7%94%9F%E6%B4%BB/"/>
    
    
      <category term="生活" scheme="https://blog.lovezhy.cc/tags/%E7%94%9F%E6%B4%BB/"/>
    
  </entry>
  
  <entry>
    <title>HotSpot原理指南-内联</title>
    <link href="https://blog.lovezhy.cc/2019/11/28/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-%E5%86%85%E8%81%94/"/>
    <id>https://blog.lovezhy.cc/2019/11/28/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-%E5%86%85%E8%81%94/</id>
    <published>2019-11-27T16:00:00.000Z</published>
    <updated>2020-02-29T14:36:23.516Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>内联是编程语言编译器中常规的优化操作，几乎所有的语言在编译时或者在执行时都会有内联操作。</p><p>内联的本质是把几个方法合并成一个方法</p><p>从一方面讲，内联减少了函数调用的栈帧创建和销毁的时间消耗</p><p>从另一方面讲，内联为很多其他的优化方法提供了更多的可能，比如逃逸分析，无用代码消除，虚函数优化等，这也是内联被叫做<strong>优化之母</strong>（The Mother Of All Optimization）的原因。</p><a id="more"></a><h2 id="HotSpot-JIT"><a href="#HotSpot-JIT" class="headerlink" title="HotSpot-JIT"></a>HotSpot-JIT</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>对于HotSpot的JIT而言，内联是一个渐进的过程，这个渐进表现在两方面</p><ul><li>C1和C2两个JIT编译器的内联策略不同，C2可能更加激进一些</li><li>内联策略和很多因素有关<ul><li>内联发起函数大小，被内联函数大小</li><li>被内联函数的调用次数</li><li>内联深度</li><li>中间表示的NodeCount</li><li>函数方法签名</li></ul></li></ul><h3 id="初步体验"><a href="#初步体验" class="headerlink" title="初步体验"></a>初步体验</h3><p>先看一段代码，初步的了解下HotSpot的内联，以下代码的执行参数<code>-XX:CompileCommand=exclude,Inline.main</code></p><p>这个参数的意义是禁止<code>main</code>函数内联<code>inline</code>方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Inline</span> </span>&#123;</span><br><span class="line">  </span><br><span class="line"><span class="keyword">static</span> Random random = <span class="keyword">new</span> Random();</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span> ; i &lt; <span class="number">1000000</span>; i++) &#123;</span><br><span class="line">            inline();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">inline</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> add(random.nextInt(), </span><br><span class="line">               random.nextInt());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> a, <span class="keyword">int</span> b)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> a + b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="/images/HotSpot原理指南-内联/inline.png" alt="inline"></p><p>上图中展示了经过C2编译后，整个<code>inline</code>函数的内联状态</p><p>可以看到不仅仅内联了<code>random.nextInt()</code>方法，还将<code>nextInt</code>方法中的<code>next</code>方法等等好几个再下层的方法也内联了进来</p><h3 id="HotSpot参数"><a href="#HotSpot参数" class="headerlink" title="HotSpot参数"></a>HotSpot参数</h3><p><code>java -XX:+PrintFlagsFinal | grep &quot;Inlin&quot;</code></p><p><img src="/images/HotSpot原理指南-内联/内联参数.png" alt="内联参数"></p><p>可以看到HotSpot可以控制内联的参数很多很多，从侧面也表示HotSpot的内联策略是非常复杂的。</p><p>笔者也无法精通所有的内联策略，所以只挑选出比较重要的几个参数来讲解。</p><p>主要讲解如下几个参数</p><table><thead><tr><th>参数</th><th>默认值</th></tr></thead><tbody><tr><td>MaxTrivialSize</td><td>6</td></tr><tr><td>MaxInlineSize</td><td>35</td></tr><tr><td>FreqInlineSize</td><td>350</td></tr><tr><td>MinInliningThreshold</td><td>250</td></tr><tr><td>InlineSmallCode</td><td>1000(No-Tier)  2000(Tier)</td></tr><tr><td>MaxInlineLevel</td><td>9</td></tr><tr><td>MaxRecursiveInlineLevel</td><td>1</td></tr></tbody></table><h2 id="内联策略"><a href="#内联策略" class="headerlink" title="内联策略"></a>内联策略</h2><h3 id="MaxTrivialSize"><a href="#MaxTrivialSize" class="headerlink" title="MaxTrivialSize"></a>MaxTrivialSize</h3><p>对于Trivial方法，在HotSpot中有着严格的定义</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">bool</span> SimpleThresholdPolicy::is_trivial(Method* method) &#123;</span><br><span class="line">  <span class="keyword">if</span> (method-&gt;is_accessor() ||</span><br><span class="line">      method-&gt;is_constant_getter()) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (method-&gt;has_loops() || method-&gt;code_size() &gt;= <span class="number">15</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  MethodData* mdo = method-&gt;method_data();</span><br><span class="line">  <span class="keyword">if</span> (mdo != <span class="literal">NULL</span> &amp;&amp; !mdo-&gt;would_profile() &amp;&amp;</span><br><span class="line">      (method-&gt;code_size() &lt; <span class="number">5</span>  || (mdo-&gt;num_blocks() &lt; <span class="number">4</span>))) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从上面的代码可以看出，常见的Getter方法，肯定是trivial方法</p><p>而函数中有循环，或者函数大小超过15bytes，则不是trivial方法</p><p>对于trivial方法，如果它的函数字节码小于<strong>MaxTrivialSize</strong>，那么即使它在调用方至今一次也没有被执行过，HotSpot也会将它内联进来。</p><p>这是对于C1而言，对于C2而言，则不会进行内联，而是会生成<code>UnCommon Trap</code></p><h3 id="MaxInlineSize"><a href="#MaxInlineSize" class="headerlink" title="MaxInlineSize"></a>MaxInlineSize</h3><p>我们了解了MaxTrivialSize，那么对于MaxInlineSize则很容易理解。</p><p>对于调用方至少执行过一次的方法，如果它的大小小于MaxInlineSize，那么就会考虑将它内联进去</p><h3 id="FreqInlineSize和MinInliningThreshold"><a href="#FreqInlineSize和MinInliningThreshold" class="headerlink" title="FreqInlineSize和MinInliningThreshold"></a>FreqInlineSize和MinInliningThreshold</h3><p>了解了以上两个参数后，你可能会问，如果被调用的函数既不符合Trivial方法，大小也大于MaxInlineSize，但是这个方法非常的Hot，就没有机会被内联了吗</p><p>并不是，FreqInlineSize和MinInliningThreshold这两个参数就是为这种方法设置的。</p><p>当一个方法既不是Trivial方法，而且大于MaxInlineSize，如果他的调用次数大于MinInliningThreshold，也就是250次，且它的大小小于FreqInlineSize，那么它也会被内联</p><h3 id="InlineSmallCode"><a href="#InlineSmallCode" class="headerlink" title="InlineSmallCode"></a>InlineSmallCode</h3><p>我们知道，调用方进行方法内联的时候，函数本身的大小会越来越大。</p><p>这时候你又会问了，那调用方内联可以无限内联吗，内联后的大小肯定会有限制的吧。</p><p>对的！InlineSmallCode就是限制的大小</p><p>如果是非分层编译的环境，阈值是1000bytes</p><p>如果是分层编译的环境，那么阈值是2000bytes</p><h3 id="MaxInlineLevel"><a href="#MaxInlineLevel" class="headerlink" title="MaxInlineLevel"></a>MaxInlineLevel</h3><p>对于一个函数进行其他函数的内联，除了内联后的大小限制，内联的深度也是有限制的。</p><p>在HotSpot中，默认的内联最大深度是MaxInlineLevel控制，也就是9层。</p><p>为什么要限制内联的最大深度呢？</p><p>在stackoverflow上有个我认为比较中肯的答案</p><p><a href="https://stackoverflow.com/questions/32503669/why-does-the-jvm-have-a-maximum-inline-depth" target="_blank" rel="noopener">Why does the JVM have a maximum inline depth?</a></p><blockquote><p>Not exactly, but I guess the basic reason is to keep things simple. Unlimited inlining depth would increase complexity, the compilation time and memory usage might be less predictable (that is OK for AOT compilers, but not for JIT). Also mind that compiled code should keep track of the whole inlining tree at run-time (to be able to unwind and deoptimize). Though I think the default value of 9 is outdated. It has not been changed for ages, but nowadays, with much more resources available, with streams and lamdas in mind, there is definitely a place for improvement</p></blockquote><p>总结一下答案：</p><ul><li>为了保持内联的简单性。无限制的内联会增加复杂度。</li><li>内联后的编译代码，需要记录整个内联树。</li><li>编译时间和内存消耗会变得不可预测。</li></ul><p>当然，作者也认为默认值9已经很久没有改动了，随着计算机资源变得不再那么昂贵，完全可以适当调大这个值。</p><h3 id="MaxRecursiveInlineLevel"><a href="#MaxRecursiveInlineLevel" class="headerlink" title="MaxRecursiveInlineLevel"></a>MaxRecursiveInlineLevel</h3><p>对于递归的方法，它内联自己最多只能内联MaxRecursiveInlineLevel层，也就是1次。</p><h2 id="查看内联结果"><a href="#查看内联结果" class="headerlink" title="查看内联结果"></a>查看内联结果</h2><p>如果想要知道我们的代码在编译时，内联了哪些方法，那么可以加上参数</p><p><code>java -XX:+UnlockDiagnosticVMOptions -XX:+PrintInlining</code></p><p>对于上面的inline.java的结果输出如下</p><p><img src="/images/HotSpot原理指南-内联/内联输出结果.png" alt="内联输出结果"></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;内联是编程语言编译器中常规的优化操作，几乎所有的语言在编译时或者在执行时都会有内联操作。&lt;/p&gt;
&lt;p&gt;内联的本质是把几个方法合并成一个方法&lt;/p&gt;
&lt;p&gt;从一方面讲，内联减少了函数调用的栈帧创建和销毁的时间消耗&lt;/p&gt;
&lt;p&gt;从另一方面讲，内联为很多其他的优化方法提供了更多的可能，比如逃逸分析，无用代码消除，虚函数优化等，这也是内联被叫做&lt;strong&gt;优化之母&lt;/strong&gt;（The Mother Of All Optimization）的原因。&lt;/p&gt;
    
    </summary>
    
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/categories/HotSpot/"/>
    
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/tags/HotSpot/"/>
    
      <category term="JVM" scheme="https://blog.lovezhy.cc/tags/JVM/"/>
    
      <category term="内联" scheme="https://blog.lovezhy.cc/tags/%E5%86%85%E8%81%94/"/>
    
  </entry>
  
  <entry>
    <title>HotSpot原理指南-C1和C2编译流程</title>
    <link href="https://blog.lovezhy.cc/2019/11/27/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-C1%E5%92%8CC2%E7%BC%96%E8%AF%91%E6%B5%81%E7%A8%8B/"/>
    <id>https://blog.lovezhy.cc/2019/11/27/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-C1%E5%92%8CC2%E7%BC%96%E8%AF%91%E6%B5%81%E7%A8%8B/</id>
    <published>2019-11-26T16:00:00.000Z</published>
    <updated>2020-02-29T14:36:21.235Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>前文讲述了C1和C2的功能定位，以及引出了Client和Server模式的区别。</p><p>这回抛开功能和定位的角度，简单看看从设计与实现角度的区别。</p><a id="more"></a><h2 id="前导知识"><a href="#前导知识" class="headerlink" title="前导知识"></a>前导知识</h2><p>要讲解设计与实现角度的区别，需要了解很多的编译原理知识。</p><p>😄编译原理是科班必学的一门课，当时作者上的迷迷糊糊的，觉得没什么用，也没怎么听。</p><p>现在看到C1和C2的东西，真的是一筹莫展。</p><p>相信很多科班和非科班的人也是。</p><p>不过大家不用担心，作者水平有限，更是不会瞎写自己根本不会的东西，所以涉及到编译原理的东西讲的都很简单。</p><h3 id="IR"><a href="#IR" class="headerlink" title="IR"></a>IR</h3><p>IR，中文中间表示，全称是intermediate representation。</p><p>其实它和中间语言的定义类似，但是中间语言的定义更加狭义，只规定必须是某种语言，而中间表示则扩宽了范围，可以是树类型或者是图类型的表示。</p><p>在维基百科上，中间语言的定义是</p><blockquote><p><strong>中间语言</strong>（英语：Intermediate language），在计算机科学中，是指一种应用于抽象机器（abstract machine）的编程语言，它设计的目的，是用来帮助我们分析计算机程序。这个术语源自于编译器，在编译器将源代码编译为目的码的过程中，会先将源代码转换为一个或多个的中间表述，以方便编译器进行最佳化，并产生出目的机器的机器语言</p></blockquote><p>其实更简单的定义，我觉得就是源代码的另一种表达形式。</p><p>比如Java代码，会被编译成字节码，字节码也是一种IR，是Java代码的中间表示。</p><p>IR在编译原理中的作用个人理解其实起到两种：</p><ul><li>统一后端语言。比如JRuby，Scala，Kotlin等，他们的解释器其实都是JVM。但是他们的源代码都是不一样的。倘若对于每种语言的处理都是不一样的，那其实JVM的实现就没什么意义了，所以将所有语言的源代码都编译成同一种IR，然后JVM不用关心源语言是什么，只要符合该IR定义的都可以执行。</li><li>方便优化。很多的优化技术，其实人眼可以简单看出的，很难归一化到程序去理解。但是通过一些IR的表示，使用特定的规则，就可以进行优化。就行我们在拼魔方时的公式一样。那为什么有这么多种IR呢，很大一个程度的区别就是他们在解决一些特定优化时各有优势。比如SSA在进行复制传播时就很方便。</li></ul><h3 id="寄存器分配"><a href="#寄存器分配" class="headerlink" title="寄存器分配"></a>寄存器分配</h3><p>一个解释器执行的程序和以机器码执行的程序的一个很大的区别就是对于系统寄存器的使用。</p><p>比如对于下面的函数</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> i, <span class="keyword">int</span> j)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> k = i + j;</span><br><span class="line">    k += <span class="number">2</span>;</span><br><span class="line">    k *= <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">return</span> i + j;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果是以解释的形式而言，则需要把k存在内存的变量中，然后再进行运算，每一步的运算都要把k的值写回到内存中。</p><p>但是如果是C++的话，完全可以给k分配一个寄存器，把k放到寄存器中，然后直接对寄存器中的值进行运算就行。</p><p>所以，如果能够很好的利用系统现有的寄存器，那么程序执行的性能将提升一个档次。</p><p>对于寄存器的分配算法，有很多论文可以参考，作者水平有限，还没能学会一种。</p><p>读者有兴趣可以自己去搜索相关论文进行了解。</p><h2 id="C1流程"><a href="#C1流程" class="headerlink" title="C1流程"></a>C1流程</h2><p><img src="/images/HotSpot原理指南-C1和C2流程/C1流程.png" alt=""></p><p>C1的流程较为简单，如上图所示。</p><p>首先，字节码会经过转换，变成HIR，也就是High Level的IR，高级中间表示。</p><p>在HIR中，会进行一些优化，比如</p><ul><li>GVN优化</li><li>基本块优化</li><li>null检查消除</li><li>…</li></ul><p>经过HIR优化之后，转换成LIR，也就是Low-Level的IR，低级中间表示。</p><p>这个阶段的IR其实已经很接近机器码了</p><p>在LIR时，进行</p><ul><li>寄存器分配。这里的寄存器分配算法是线性扫描，时间消耗短，但是分配效果有限</li><li>窥孔优化</li></ul><p>在LIR的优化过后，就是机器码的生成。</p><p>对于C1的更详细的流程，笔者也从网上找到了当时作者的一个PPT，有兴趣的可以自行下载</p><p><a href="http://compilers.cs.uni-saarland.de/ssasem/talks/Christian.Wimmer.pdf" target="_blank" rel="noopener">http://compilers.cs.uni-saarland.de/ssasem/talks/Christian.Wimmer.pdf</a></p><p>同时，如果有人对线性扫描寄存器分配算法有兴趣，也可以参照论文</p><p><a href="http://web.cs.ucla.edu/~palsberg/course/cs132/linearscan.pdf" target="_blank" rel="noopener">http://web.cs.ucla.edu/~palsberg/course/cs132/linearscan.pdf</a></p><h2 id="C2流程"><a href="#C2流程" class="headerlink" title="C2流程"></a>C2流程</h2><p>通过前面我们已经知道C2相对于C1编译过程，更加的耗时，这个耗时可以体现在两方面</p><ul><li>比C1有更多的优化</li><li>同一种优化使用的算法不同，C2的结果更好</li></ul><p>对于C2而言，它的IR只有一种，叫<code>Sea Of Nodes</code></p><p>就笔者了解到的知识来看，这个IR非常的牛逼，在V8引擎中，也是使用的这种IR。</p><p>不过这种IR的资料似乎非常少，笔者也仅仅是搜到了论文，没什么更深层次的讲解。</p><p>如果有人想要了解Sea Of Nodes的原理，那么大家可以从网上搜集资料来看。</p><p><strong>比C1拥有更多的优化</strong></p><p>相比较于C1，C2几乎会做所有的经典优化。如下图所示</p><p><img src="/images/HotSpot原理指南-C1和C2流程/C2优化.png" alt=""></p><p><strong>同一种优化使用不同的算法</strong></p><p>这个体现在寄存器分配算法上，我们知道对于C1而言，使用的较为简单的线性扫描的分配算法，执行较快。</p><p>而C2使用了叫图染色的算法，消耗的时间更久，但是产生的解法比线性扫描更优。</p><p>对于图染色算法，在经典的编译原理书中都有解答。</p><p>笔者这里就不赘述了（其实是笔者也没看懂）</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;前文讲述了C1和C2的功能定位，以及引出了Client和Server模式的区别。&lt;/p&gt;
&lt;p&gt;这回抛开功能和定位的角度，简单看看从设计与实现角度的区别。&lt;/p&gt;
    
    </summary>
    
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/categories/HotSpot/"/>
    
    
      <category term="Java" scheme="https://blog.lovezhy.cc/tags/Java/"/>
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/tags/HotSpot/"/>
    
      <category term="JVM" scheme="https://blog.lovezhy.cc/tags/JVM/"/>
    
      <category term="C1和C2" scheme="https://blog.lovezhy.cc/tags/C1%E5%92%8CC2/"/>
    
  </entry>
  
  <entry>
    <title>HotSpot原理指南-C1和C2介绍</title>
    <link href="https://blog.lovezhy.cc/2019/11/24/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-C1%E5%92%8CC2%E4%BB%8B%E7%BB%8D/"/>
    <id>https://blog.lovezhy.cc/2019/11/24/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-C1%E5%92%8CC2%E4%BB%8B%E7%BB%8D/</id>
    <published>2019-11-23T16:00:00.000Z</published>
    <updated>2020-02-29T14:36:19.131Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>HotSpot是一款Java虚拟机的实现，除了基本的解释功能以外，该虚拟机还拥有将字节码编译成机器码的并执行的能力，我们知道，直接执行机器码肯定比解释更快。</p><p>HotSpot最初会通过解释的方式执行程序，当它发现某个方法运行得特别频繁时，就会将这些热点（Hot Spot）代码进行编译，编译成平台相关的机器码。这个过程也叫做JIT（Just In Time），与之相对的是AOT（Ahead Of Time），比较典型的是C和C++语言。</p><p>HotSpot进行JIT编译的编译器有两个，分别叫做<strong>C1</strong>和<strong>C2</strong>，或者也可以叫做<strong>Client Compiler</strong>和<strong>Server Compiler</strong>。这两种编译器编译策略不同，运用在不同的场景，下面会详细的说明。</p><a id="more"></a><h2 id="JIT编译"><a href="#JIT编译" class="headerlink" title="JIT编译"></a>JIT编译</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Add</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">200</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">long</span> start = System.nanoTime();</span><br><span class="line">            add();</span><br><span class="line">            <span class="keyword">long</span> end = System.nanoTime();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">add</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1000</span>; i++) &#123;</span><br><span class="line">            sum += i;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> sum;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面这段代码，我们有一个<code>add</code>方法，如果我们对改方法进行时间统计，我们会得到下面的曲线。</p><p>X轴是次数，Y轴是时间的log2。</p><p><img src="/images/HotSpot原理指南-C1和C2/add.png" alt=""></p><p>从这个曲线我们可以看出，在第大概100次的时间，时间消耗会下滑，也就是性能提升了一个档次。</p><p>由此我们可以猜到，前100次的add方法是由解释执行的，在100次后，执行的是由JIT编译器编译过的机器码。所以性能会有较大的提升。</p><h2 id="Profile"><a href="#Profile" class="headerlink" title="Profile"></a>Profile</h2><p>在详细讲述C1和C2之前，我们还有一个内容需要科普，就是方法的Profile信息。</p><p>除了最基本的用于判定某个方法是否是HotSpot的方法调用次数（Invocation Counter）信息外，对于某个方法，还有一些信息是会在运行时进行收集的。</p><p>比如我们看下面这段代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">record</span><span class="params">(List&lt;String&gt; list)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (list != <span class="keyword">null</span>) &#123;</span><br><span class="line">list.add(<span class="string">"大骚包卢布"</span>);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    log.warn(<span class="string">"我不是大骚包"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>record</code>函数的功能很简单，入参是一个List，如果List不为空，那么就把<code>大骚包卢布</code>这个字符串传递进去。不然的话就打出一个warn级别的日志<code>我不是大骚包</code>。</p><p>那么在调用这个方法的时候，HotSpot还会记录哪些信息呢</p><ul><li>List的真实类。因为List在Java中是一个接口，具体的传入可能是ArrayList或者LinkedList或者其他的。HotSpot需要记录具体的类为了以后的优化。</li><li>Log的真实类，理由和List一样。</li><li>进入if的次数，以及进入else的次数，更通俗的说是条件选择的实际情况。</li></ul><p>有人可能会问统计这些Profile有什么用。</p><p>举个最简单的例子，如果我们需要对<code>list.add</code>做内联，那么我们到底内联那个实现呢，这个就需要我们收集list的真实实现是什么。</p><h2 id="C1和C2"><a href="#C1和C2" class="headerlink" title="C1和C2"></a>C1和C2</h2><table><thead><tr><th></th><th>C1</th><th>C2</th></tr></thead><tbody><tr><td>编译时间</td><td>快</td><td>慢（x4）</td></tr><tr><td>执行时间</td><td>慢</td><td>快（30%）</td></tr><tr><td>输出代码</td><td>多</td><td>少</td></tr></tbody></table><p>上表是C1和C2在编译时间，执行时间，输出代码的区别</p><ul><li>编译时间：同样一段代码，C1需要时间比C2短，也就是需求的CPU资源较少</li><li>执行时间：C1编译时间短，通常意味着优化不如C2，所以C2编译出的机器码执行效率较高</li><li>输出代码：C1编译时间短，最终也就导致输出的机器码占用的内存要比C2多的</li></ul><p>总结：同一段代码，C1消耗的CPU资源较少，但是输出的代码质量不如C2。但是毋庸置疑的事，无论是C1还是C2输出的机器码，执行效率肯定都比解释快的。</p><p>C1又称<strong>Client Compiler</strong>，C2又称<strong>Server Compiler</strong>，不是没有历史渊源的。</p><p>或许我们都听过java在启动的时候可以执行是<code>client</code>模式还是<code>server</code>模式。</p><p>当我们使用client模式时，一般运行的是应用程序，比如java swing，awt之类的图形软件，对于这些桌面软件，作为使用者而言，并不希望哪个桌面应用占用大量的CPU，所以非常适合C1的场景</p><ul><li>编译速度快</li><li>占用CPU资源少</li></ul><p>而对于Server模式而言，一般是公司的服务器上跑的稳定的服务应用，服务器的资源一般较为丰富，同时一个应用并不会像桌面应用一样频繁的开关，一般都要跑几周或者几个月甚至几年。这种应用，当然速度越快越好。所以非常适合C2的场景</p><ul><li>编译消耗更多的CPU资源</li><li>代码质量更高，也就是性能更好</li></ul><h2 id="C1和C2和Profile"><a href="#C1和C2和Profile" class="headerlink" title="C1和C2和Profile"></a>C1和C2和Profile</h2><p>前面提到过的Profile信息，你可能会疑惑这个和C1和C2有什么联系。</p><p>其实我们需要先明白一个概念，就是收集那些Profile不仅仅会占用程序以外的更多的内容，而且会占用很多的CPU消耗。同样一段代码，插入了收集Profile逻辑和没有插入收集Profile逻辑，执行性能是不同的。</p><p>结合我们提到的C1和C2的使用场景的区别，可以得出这样的结论，这个收集Profile的消耗，对于桌面应用而言，是非常<strong>不合适</strong>的。</p><p>但是C2则需要这些Profile去做更好的性能优化。</p><p>所以对于Client模式的应用而言，解释器不会去收集程序的Profile信息，而Server模式在解释器阶段，则会进行Profile的收集，这也就导致了Client模式的起步性能是比Server模式的起步性能要好很多。</p><h2 id="启动模式"><a href="#启动模式" class="headerlink" title="启动模式"></a>启动模式</h2><p>在JDK1.6之前，指定是<code>client</code>还是<code>server</code>模式，我们在java程序启动时直接加参数就行了</p><p><code>java -client Hello</code></p><p><strong>但是</strong></p><p>注意我这个但是</p><p>其实自从JDK6的某个版本开始，你已经控制不了这个参数了</p><p><a href="https://docs.oracle.com/javase/7/docs/technotes/guides/vm/server-class.html" target="_blank" rel="noopener">https://docs.oracle.com/javase/7/docs/technotes/guides/vm/server-class.html</a></p><p>从这个网站可以看到，默认如果你是64位的机器并且至少有2G内存和2核心的CPU，默认都是Server模式了。</p><p><code>-client</code>这个参数会被忽略</p><p>但是也并不是没有办法指定client模式</p><p>不仅仅要在启动参数中加上<code>-client</code></p><p>还需要去修改文件<code>jre/lib/jvm.cfg</code></p><p>比如我的文件中默认是这个状态</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">-server KNOWN</span><br><span class="line">-client IGNORE</span><br><span class="line">-hotspot ERROR</span><br><span class="line">-classic WARN</span><br><span class="line">-native ERROR</span><br><span class="line">-green ERROR</span><br></pre></td></tr></table></figure><p>注意到我的<code>-client</code>后面跟的是<code>IGNORE</code>，所以我指定<code>-client</code>模式其实是不生效的</p><p>我需要改成<code>-client KNOWN</code>才行。</p><p>当然Oracle选择忽略<code>-client</code>模式也不是没有道理的</p><ul><li>Java的桌面应用已经很少了，Swing基本已经死了</li><li>现在大家的笔记本的CPU和内容资源都很充足</li></ul><p>所以全部使用<code>server</code>模式也没问题。</p><h2 id="后续"><a href="#后续" class="headerlink" title="后续"></a>后续</h2><p>当然C1和C2的故事并没有这么简单</p><p>同时JIT编译的策略也不是非C1就是C2，在JDK7中引入了分层编译，结合了C1和C2的优点。</p><p>这些会在后面的文章讲述。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;HotSpot是一款Java虚拟机的实现，除了基本的解释功能以外，该虚拟机还拥有将字节码编译成机器码的并执行的能力，我们知道，直接执行机器码肯定比解释更快。&lt;/p&gt;
&lt;p&gt;HotSpot最初会通过解释的方式执行程序，当它发现某个方法运行得特别频繁时，就会将这些热点（Hot Spot）代码进行编译，编译成平台相关的机器码。这个过程也叫做JIT（Just In Time），与之相对的是AOT（Ahead Of Time），比较典型的是C和C++语言。&lt;/p&gt;
&lt;p&gt;HotSpot进行JIT编译的编译器有两个，分别叫做&lt;strong&gt;C1&lt;/strong&gt;和&lt;strong&gt;C2&lt;/strong&gt;，或者也可以叫做&lt;strong&gt;Client Compiler&lt;/strong&gt;和&lt;strong&gt;Server Compiler&lt;/strong&gt;。这两种编译器编译策略不同，运用在不同的场景，下面会详细的说明。&lt;/p&gt;
    
    </summary>
    
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/categories/HotSpot/"/>
    
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/tags/HotSpot/"/>
    
  </entry>
  
  <entry>
    <title>给RedisTemplate插入Cat打点</title>
    <link href="https://blog.lovezhy.cc/2019/11/08/%E7%BB%99RedisTemplate%E6%8F%92%E5%85%A5Cat%E6%89%93%E7%82%B9/"/>
    <id>https://blog.lovezhy.cc/2019/11/08/%E7%BB%99RedisTemplate%E6%8F%92%E5%85%A5Cat%E6%89%93%E7%82%B9/</id>
    <published>2019-11-07T16:00:00.000Z</published>
    <updated>2020-02-29T14:42:31.295Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Cat是美团开源的一套监控系统，功能非常强大<br>一般对方法进行打点，它会自动生成每个方法的耗时，同时也会记录全链路的每个调用方法的耗时</p><p>对于查系统的性能瓶颈和稳定性有非常大的帮助</p><a id="more"></a><p>基本用法<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Transaction tranx = Cat.newTransaction(<span class="string">"Cache"</span>, <span class="string">"get"</span>);</span><br><span class="line">tranx.addData(<span class="string">"key"</span>, <span class="string">"name"</span>);</span><br><span class="line"><span class="comment">//do something</span></span><br><span class="line">tranx.setStatus(<span class="string">"0"</span>);</span><br><span class="line">tranx.complete();</span><br></pre></td></tr></table></figure></p><p>上面的方法就是对中间的代码执行进行耗时打点，这里假设的是我们对Redis的get方法进行打点</p><ul><li>第一句：new一个Transaction出来，Type是Cache，也就是Transaction属于Cache，然后具体的方法是get</li><li>第二句：addData，在执行过程中进行关键日志的记录，我们这里记录了get的key是name，方面查询长耗时的方法，增加一些提示性的参数</li><li>第三句：执行具体的方法</li><li>第四句：执行成功，设置status=0，0表示成功的意思，当然也有失败的方法，可以把具体的Exception传递进去</li><li>第五句：标记Transaction完成</li></ul><h2 id="框架集成"><a href="#框架集成" class="headerlink" title="框架集成"></a>框架集成</h2><p>Cat只是提供了一些工具，并没有直接提供方法与常见的方法集成，让我们在业务代码的每个方法都手动编码上面这些流程肯定不现实，可以借助于很多的方法进行隐式的插入逻辑。</p><h3 id="与Dubbo集成"><a href="#与Dubbo集成" class="headerlink" title="与Dubbo集成"></a>与Dubbo集成</h3><p>Dubbo提供了Filter机制，可以声明一个Filter进行对Dubbo服务方法的打点</p><p><a href="https://github.com/dianping/cat/tree/master/integration/dubbo" target="_blank" rel="noopener">Dubbo</a></p><p>在Cat的官方仓库中收集了此集成方式，可以直接使用</p><h2 id="与Mybatis集成"><a href="#与Mybatis集成" class="headerlink" title="与Mybatis集成"></a>与Mybatis集成</h2><p>和Dubbo一个，Mybatis也提供了Filter插件</p><p><a href="https://github.com/dianping/cat/tree/master/integration/mybatis" target="_blank" rel="noopener">Mybatis</a></p><p>在Cat的官方仓库中收集了此集成方式，可以直接使用</p><p>上面两种插件几乎是最常用的两个了，但是Redis的需求也比较强烈</p><h2 id="Redis打点"><a href="#Redis打点" class="headerlink" title="Redis打点"></a>Redis打点</h2><p>Cat的官方仓库并没有提供Redis的打点插件，借着Filter的简单的逻辑，我准备找找现有框架的逻辑插入方法</p><p>在正常的SpringBoot应用中，默认的Redis使用类是RedisTemplate，如果具体到某个操作，在内部声明了多个具体的类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedisTemplate</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt;    </span>&#123;</span><br><span class="line">  <span class="comment">// cache singleton objects (where possible)</span></span><br><span class="line">    <span class="keyword">private</span> <span class="meta">@Nullable</span> ValueOperations&lt;K, V&gt; valueOps;</span><br><span class="line">    <span class="keyword">private</span> <span class="meta">@Nullable</span> ListOperations&lt;K, V&gt; listOps;</span><br><span class="line">    <span class="keyword">private</span> <span class="meta">@Nullable</span> SetOperations&lt;K, V&gt; setOps;</span><br><span class="line">    <span class="keyword">private</span> <span class="meta">@Nullable</span> ZSetOperations&lt;K, V&gt; zSetOps;</span><br><span class="line">    <span class="keyword">private</span> <span class="meta">@Nullable</span> GeoOperations&lt;K, V&gt; geoOps;</span><br><span class="line">    <span class="keyword">private</span> <span class="meta">@Nullable</span> HyperLogLogOperations&lt;K, V&gt; hllOps;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>比如当我们调用</p><p><code>redisTemplate.opsForSet().members(cacheName)</code>时，</p><p>调用的是</p><p><code>DefaultSetOperations.members(K key)</code>方法</p><p>所以我们只要对上面提到的具体操作的类的一些方法进行打点就行</p><p>但是很可惜，RedisTemplate并没有提供</p><h2 id="方案一"><a href="#方案一" class="headerlink" title="方案一"></a>方案一</h2><p>直接使用SpringAop对具体的类进行代理</p><p>这当时是我觉得最简单的方法，但是很遗憾</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DefaultSetOperations</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">AbstractOperations</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; <span class="keyword">implements</span> <span class="title">SetOperations</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; </span>&#123;&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DefaultValueOperations</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">AbstractOperations</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; <span class="keyword">implements</span> <span class="title">ValueOperations</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; </span>&#123;&#125;</span><br></pre></td></tr></table></figure><p>这些具体实现类都不是public的，对这些方法进行切面处理是处理不了的</p><h2 id="方案二"><a href="#方案二" class="headerlink" title="方案二"></a>方案二</h2><p>最简单的方法被否决了，于是只能找一些其他的方法</p><p>当时看到Java的Agent可以在类被加载时进行一些修改，于是产生了写一个javaagent的方法</p><p>目标效果</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">get</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> execute(<span class="keyword">new</span> ValueDeserializingRedisCallback(key) &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">protected</span> <span class="keyword">byte</span>[] inRedis(<span class="keyword">byte</span>[] rawKey, RedisConnection connection) &#123;</span><br><span class="line">            <span class="keyword">return</span> connection.get(rawKey);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;, <span class="keyword">true</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">=&gt;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">get</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">    Transaction tranx = Cat.newTransaction(<span class="string">"Cache"</span>, <span class="string">"get"</span>); </span><br><span class="line">    tranx.addData(<span class="string">"key"</span>, key);</span><br><span class="line">    V res = execute(<span class="keyword">new</span> ValueDeserializingRedisCallback(key) &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">protected</span> <span class="keyword">byte</span>[] inRedis(<span class="keyword">byte</span>[] rawKey, RedisConnection connection) &#123;</span><br><span class="line">            <span class="keyword">return</span> connection.get(rawKey);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;, <span class="keyword">true</span>);</span><br><span class="line">    </span><br><span class="line">    tranx.setStatus(<span class="string">"0"</span>);</span><br><span class="line">    tranx.complete();</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>但是为了得到失败的效果，同时防止Cat方法抛出异常影响正常逻辑，需要多加几个try catch</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">get</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">    Transaction tranx = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      tranx = Cat.newTransaction(<span class="string">"Cache"</span>, <span class="string">"get"</span>);</span><br><span class="line">      tranx.addData(<span class="string">"key"</span>, key);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable e) &#123;&#125;</span><br><span class="line">    </span><br><span class="line">    V res = <span class="keyword">null</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        V res = execute(<span class="keyword">new</span> ValueDeserializingRedisCallback(key) &#123;</span><br><span class="line"></span><br><span class="line">              <span class="meta">@Override</span></span><br><span class="line">              <span class="keyword">protected</span> <span class="keyword">byte</span>[] inRedis(<span class="keyword">byte</span>[] rawKey, RedisConnection connection) &#123;</span><br><span class="line">                  <span class="keyword">return</span> connection.get(rawKey);</span><br><span class="line">              &#125;</span><br><span class="line">          &#125;, <span class="keyword">true</span>);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">       <span class="keyword">try</span> &#123;</span><br><span class="line">         <span class="keyword">if</span> (tranx != <span class="keyword">null</span>) &#123;</span><br><span class="line">           tranx.setStatus(e);</span><br><span class="line">           tranx.complete();</span><br><span class="line">         &#125;</span><br><span class="line">       &#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">         </span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">throw</span> e;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (tranx != <span class="keyword">null</span>) &#123;</span><br><span class="line">        tranx.setStatus(<span class="string">"0"</span>);</span><br><span class="line">        tranx.complete();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span>(Throwable e) &#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到，代码非常长，但是不用担心性能，经过编译优化之后很多其实都被优化掉了</p><h2 id="java-lang-instrument包"><a href="#java-lang-instrument包" class="headerlink" title="java.lang.instrument包"></a>java.lang.instrument包</h2><blockquote><p>Provides services that allow Java programming language agents to instrument programs running on the JVM. The mechanism for instrumentation is modification of the byte-codes of methods.<br>Package Specification</p></blockquote><p>Oracle的官网上对这个包的定义如上，简单的说就是给与我们能力动态的修改Java类的字节码<br>一般可以用来监控，织入类似于AOP的逻辑</p><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p>当时选择了javaassit进行字节码的织入，但是javaassit有一个很大的局限就是不能使用本地变量</p><p>比如<code>Transaction tranx</code>这个我们在声明出来之后，在下面的代码就获取不到这个变量了</p><p>但是整个方法不会触及多线程的场景，所以想到的方案就是放在一个ThreadLocal中</p><p>先构造出一个ThreadLocal的类进行封装</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedisCatLog</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> ThreadLocal&lt;RedisCatLog&gt; THREAD_LOCAL_CAT_LOG = <span class="keyword">new</span> ThreadLocal&lt;&gt;();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">startLog</span><span class="params">(String action, Object data)</span> </span>&#123;</span><br><span class="line">        THREAD_LOCAL_CAT_LOG.remove();</span><br><span class="line">        RedisCatLog redisCatLog = <span class="keyword">new</span> RedisCatLog(action);</span><br><span class="line">        redisCatLog.before(String.valueOf(data));</span><br><span class="line">        THREAD_LOCAL_CAT_LOG.set(redisCatLog);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">endLog</span><span class="params">(<span class="keyword">boolean</span> success)</span> </span>&#123;</span><br><span class="line">        RedisCatLog redisCatLog = THREAD_LOCAL_CAT_LOG.get();</span><br><span class="line">        <span class="keyword">if</span> (Objects.nonNull(redisCatLog)) &#123;</span><br><span class="line">            redisCatLog.after(success);</span><br><span class="line">            THREAD_LOCAL_CAT_LOG.remove();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String action;</span><br><span class="line">    <span class="keyword">private</span> Transaction tranx;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">RedisCatLog</span><span class="params">(String action)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.action = action;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">before</span><span class="params">(String data)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.tranx = Cat.newTransaction(<span class="string">"Cache."</span>, <span class="keyword">this</span>.action);</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>.tranx <span class="keyword">instanceof</span> NullMessage) &#123;</span><br><span class="line">            log.error(<span class="string">"is null message"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">this</span>.tranx.addData(<span class="string">"key"</span>, data);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">after</span><span class="params">(<span class="keyword">boolean</span> success)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (!success) &#123;</span><br><span class="line">            <span class="keyword">this</span>.tranx.setStatus(<span class="string">"failed"</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">this</span>.tranx.setStatus(<span class="string">"0"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">this</span>.tranx.complete();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样，有了这个类之后，我们的织入代码就比较简单了</p><ul><li>给现有方法的开始加入RedisCatLog.startLog()</li><li>给方法的结尾加上RedisCatLog.endLog()</li><li>给原有的完整代码加上try catch</li></ul><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">public V get(Object key) &#123;</span><br><span class="line">    try &#123;RedisCatLog.startLog("get", key);&#125; catch(Throwable e) &#123;&#125;</span><br><span class="line">  </span><br><span class="line">    try &#123;</span><br><span class="line">        V res = execute(new ValueDeserializingRedisCallback(key) &#123;</span><br><span class="line">              @Override</span><br><span class="line">              protected byte[] inRedis(byte[] rawKey, RedisConnection connection) &#123;</span><br><span class="line">                  return connection.get(rawKey);</span><br><span class="line">              &#125;</span><br><span class="line">          &#125;, true);</span><br><span class="line">    &#125; catch(Throwable e) &#123;</span><br><span class="line">        try &#123;RedisCatLog.endLog(false);&#125; catch(Throwable e) &#123;&#125;</span><br><span class="line">        throw e;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    try &#123;RedisCatLog.endLog(true);&#125; catch(Throwable e) &#123;&#125;</span><br><span class="line">    return res;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>整体来看是不是简单的了很多</p><p>下面就是具体的javaassit代码编写了</p><p>在编写时参考了文档，并没有系统的学习javaassit</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">String methodName = methods[i].getName();</span><br><span class="line">CtClass etype = ClassPool.getDefault().get(<span class="string">"java.lang.Throwable"</span>);</span><br><span class="line">methods[i].addCatch(<span class="string">"&#123; RedisCatLog.endLog(false); throw $e; &#125;"</span>, etype);</span><br><span class="line">methods[i].insertBefore(before(classMethodNameInfo.getType() + <span class="string">"-"</span> + methodName));</span><br><span class="line">methods[i].insertAfter(after());</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">before</span><span class="params">(String action)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> String.format(<span class="string">"try &#123; RedisCatLog.startLog(\"%s\", $1); &#125; catch (Throwable e) &#123;&#125;"</span>, action);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">after</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="string">"try&#123; RedisCatLog.endLog(true);&#125; catch (Throwable e) &#123;&#125;"</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>大概的整体逻辑如下</p><p>项目我传到了Github上，<a href="https://github.com/zhyzhyzhy/CatRedisLogAspect" target="_blank" rel="noopener">https://github.com/zhyzhyzhy/CatRedisLogAspect</a></p><p>大家可以参考文档进行使用</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;Cat是美团开源的一套监控系统，功能非常强大&lt;br&gt;一般对方法进行打点，它会自动生成每个方法的耗时，同时也会记录全链路的每个调用方法的耗时&lt;/p&gt;
&lt;p&gt;对于查系统的性能瓶颈和稳定性有非常大的帮助&lt;/p&gt;
    
    </summary>
    
    
      <category term="SpringBoot" scheme="https://blog.lovezhy.cc/categories/SpringBoot/"/>
    
    
      <category term="Spring" scheme="https://blog.lovezhy.cc/tags/Spring/"/>
    
      <category term="Cat" scheme="https://blog.lovezhy.cc/tags/Cat/"/>
    
  </entry>
  
  <entry>
    <title>Raft实现指北</title>
    <link href="https://blog.lovezhy.cc/2019/09/05/Raft%E5%AE%9E%E7%8E%B0%E6%8C%87%E5%8C%97/"/>
    <id>https://blog.lovezhy.cc/2019/09/05/Raft%E5%AE%9E%E7%8E%B0%E6%8C%87%E5%8C%97/</id>
    <published>2019-09-04T16:00:00.000Z</published>
    <updated>2020-02-29T14:53:02.382Z</updated>
    
    <content type="html"><![CDATA[<p>Raft实现指北<br><a id="more"></a></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>自己陆陆续续花了一些时间完成了一个Raft的库，目前基本的流程都完成了，下面要继续做的话，就是要进行一些优化的逻辑了。<br><a href="https://github.com/zhyzhyzhy/Rub-Raft" target="_blank" rel="noopener">Rub-Raft</a><br>取名叫Rub，就是卢布的意思，纪念雯姐今年去世的花枝鼠[2016-2019]。<br>卢布是我见过最乖的鼠，很聪明，她喜欢睡在吊床上，不会像其他的鼠去啃吊床的线。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>一个很好的博文<br><a href="https://lichuang.github.io/post/20180921-raft/" target="_blank" rel="noopener">https://lichuang.github.io/post/20180921-raft/</a>  </p><p>《CONSENSUS: BRIDGING THEORY AND PRACTICE》论文<br><a href="https://ramcloud.stanford.edu/~ongaro/thesis.pdf" target="_blank" rel="noopener">https://ramcloud.stanford.edu/~ongaro/thesis.pdf</a>  </p><p>动画讲解<br><a href="https://raft.github.io/" target="_blank" rel="noopener">https://raft.github.io/</a></p><h2 id="整体流程"><a href="#整体流程" class="headerlink" title="整体流程"></a>整体流程</h2><p>集群的整体状态一般分为三种</p><ul><li>选举</li><li>日志添加<ul><li>正常添加</li><li>非正常添加</li><li>新节点获取日志</li></ul></li><li>新增节点</li></ul><p>我可能不太会对所有流程做详细的阐述，只是一些简单的问答和心得。</p><p>整个RPC的方法其实只要4个就可以完成Raft，前两个和选举有关，后两个和日志有关</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">VoteResponse <span class="title">requestPreVote</span><span class="params">(VoteRequest voteRequest)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function">VoteResponse <span class="title">requestVote</span><span class="params">(VoteRequest voteRequest)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function">ReplicatedLogResponse <span class="title">requestAppendLog</span><span class="params">(ReplicatedLogRequest replicatedLogRequest)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function">InstallSnapshotResponse <span class="title">requestInstallSnapShot</span><span class="params">(InstallSnapshotRequest installSnapShotRequest)</span></span>;</span><br></pre></td></tr></table></figure><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><h3 id="需要节点的自动注册和发现吗"><a href="#需要节点的自动注册和发现吗" class="headerlink" title="需要节点的自动注册和发现吗"></a>需要节点的自动注册和发现吗</h3><p>一开始我还是RPC的实现思路，以为需要一个自动的节点注册和发现机制<br>当然其实并不需要，集群启动的时候，只要我们把初始的节点信息写死在启动Config文件中就好  </p><p>那么可不可以有呢，我理解是不可以的，因为选举的时候，节点需要知道当前节点的个数，来判断自己得到的选票是不是已经有集群节点的一半了。<br>如果你还搞个节点自动注册，那么到底集群有几个节点呢？</p><h2 id="节点的RPC连接"><a href="#节点的RPC连接" class="headerlink" title="节点的RPC连接"></a>节点的RPC连接</h2><p>讲道理其实RPC连接并不是什么大问题，但是我们不能先入为主的当做DUBBO这种RPC框架去实现我们的RPC框架。<br>这个问题的根源是：正常的RPC模型并不是互相问答的模式<br>都是C/S模型<br>一个节点一般会开一个Server，让其他的节点来连接，并提出请求，这个Server并不会主动向其他的Node发送消息。 </p><p>这个时候会想到，我们每个节点都当做是一个Server，然后对每个其他的Node，开对应的Client连接。我就是这么实现的，这样的情况其实对于两个节点而言，互相的连接通过了两个不同的Channel来实现。</p><p>后来发现其实这样还有问题。<br>问题是在无法重新连接的情况<br>假设这样的情形，3Node互相连接，过程中Node1断开，其他两个Node互相连接，过一阵子，Node1又启动，开启自己的RpcServer，并顺利连接到其他两个Node的RpcServer<br>而其他两个Node并不会主动的去连接Node1的RpcServer</p><p>这个就需要一种机制，当其他的节点连接上自己的RpcServer的时候，获得感知，然后自己也去连接对方的RpcServer</p><p>那么这个感知机制，放在哪里去做呢。<br>放在Rpc层面吗？我感觉侵入性很大，一方面作为一个Rpc并不需要这种机制，需要的话，也是一个抽象度很高的东西，类似于连接上的回调之类。</p><p>我这里另外开了一个RPC方法，叫<code>requestConnect</code>，当每个节点RPCClient或者RPCServer启动的时候，都会向其他的节点发送<code>requestConnect</code>请求，其他节点接收到这个请求，会检查自己与发送请求的节点的链路是否已经失效，如果失效，则请求重新连接。</p><p>这样完成的很好，但是就是RPC请求的次数会有点多。</p><h2 id="RPC请求的异步与同步"><a href="#RPC请求的异步与同步" class="headerlink" title="RPC请求的异步与同步"></a>RPC请求的异步与同步</h2><p>这个问题不是很复杂，但是我们如果自己实现RPC的话，要注意的一点就是不能不支持异步的方式。<br>我的RPC的实现中，支持3种请求方式</p><ul><li>SYNC 同步请求</li><li>ASYNC 异步请求</li><li>ONE_WAY 不需要返回的请求</li></ul><p>不过异步请求说白了就是RPC框架帮你封装好了SYNC的Future的方式</p><p>上面提到了Raft的需要的5种方法，那些需要异步呢</p><ul><li>requestConnect =&gt; ONE_WAY</li><li>requestPreVote =&gt; ASYCN</li><li>requestVote =&gt; ASYNC</li><li>requestAppendLog =&gt; SYNC</li><li>requestInstallSnapShot =&gt; SYNC</li></ul><h2 id="选举"><a href="#选举" class="headerlink" title="选举"></a>选举</h2><h3 id="节点启动顺序"><a href="#节点启动顺序" class="headerlink" title="节点启动顺序"></a>节点启动顺序</h3><p>节点启动的顺序要注意什么吗？<br>还是不需要，选举要得到一般的选票才能成为Leader，即使有一个节点最后启动，此时集群中已经选举出一个Leader了，最后启动的那个节点收到AppendLog的消息，就会自动变成Follower。</p><h3 id="节点初始化"><a href="#节点初始化" class="headerlink" title="节点初始化"></a>节点初始化</h3><p>节点初始化要做的事不多，就是设置自己的状态为<code>Follower</code><br>然后启动一个选举超时的定时器</p><h3 id="选举超时时间"><a href="#选举超时时间" class="headerlink" title="选举超时时间"></a>选举超时时间</h3><p>节点刚启动的状态是<code>Follower</code>，并且启动一个超时定时器，当时间到了的时候开始进行选举<br>那么这个超时的时间是多少呢？论文中给出的范围是150 - 300ms[章节3.4]  </p><h3 id="超时期间收到Request"><a href="#超时期间收到Request" class="headerlink" title="超时期间收到Request"></a>超时期间收到Request</h3><p>我们知道当选举超时之后，节点把自己的状态设为<code>pre_candidate</code>，并且发送消息给其他节点进行选举。<br>如果超时期间收到消息呢<br>论文中写，<code>A server remains in follower state as long as it receives valid RPCs from a leader or candidate.</code></p><p>很明晰，超时期间收到其他节点的Request，那么就不会进入选举流程，依然是一个Follower。</p><h3 id="超时方法什么时候调用"><a href="#超时方法什么时候调用" class="headerlink" title="超时方法什么时候调用"></a>超时方法什么时候调用</h3><p>在接收到PreVote，Vote，AppendLog的RPC请求接收到之后都要开始调用  </p><h3 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h3><p>要加锁吗，当然是要的<br>上一个我们提到<br>节点超时，开始发起选举RPC之前，启动超时，如果到超时结束，还没有选举出一个Leader，那么就把自己的term加一再次发起选举</p><p>这个过程中有两个事件需要一些条件的同步</p><ul><li>超时线程：没有收到Leader的信息和其他节点的选举信息，就执行，也就是心跳有更新</li><li>接收vote线程：收到Leader和其他节点的信息，还在超时未完成状态，就更新心跳信息</li></ul><p>如果分为两个方法的话，最简单的就是给整个方法都加锁<br>但是这样锁的粒度太大了，能不能把条件抽象出来呢</p><p>我想的是对Node的状态进行cas的修改<br>超时线程，首先判断心跳有没有更新，如果有更新就不进行选举，如果没有更新，就加锁的对NodeStatus进行CAS更新，从Follower更新到Pre_Candidate<br>接收Vote线程，首先对NodeStatus进行CAS的更新，从Follower更新到Follower，然后更新心跳时间<br>我们分析两个线程的流程<br>超时线程</p><ul><li>1.判断心跳有没有更新</li><li>2.NodeStatus从Follower更新到Pre_Candidate</li></ul><p>接收Vote线程</p><ul><li>3.首先对NodeStatus进行CAS的更新，从Follower更新到Follower</li><li>4.更新心跳时间</li></ul><p>如果不加锁，流程从3 - 1 - 2 - 4就出问题了</p><p>这个思路很麻烦</p><p>我们再换个思路</p><p>超时线程进行vote的时候，需要对term进行+1<br>接收Vote线程，如果成功接收其他节点的信息维持Follower的话，那么对面的term肯定比自己大的，那么也就是需要对Term进行加1</p><p>所以我们对Term进行cas操作，谁成功了谁进行操作</p><h3 id="PreVote"><a href="#PreVote" class="headerlink" title="PreVote"></a>PreVote</h3><p>其实论文中并没有很直观的提到PreVote的阶段<br>需要PreVote的原因也不复杂，可以百度一下。</p><h3 id="VoteFor可以进行修改吗"><a href="#VoteFor可以进行修改吗" class="headerlink" title="VoteFor可以进行修改吗"></a>VoteFor可以进行修改吗</h3><p><code>Vote</code>阶段<br>假设这样一种场景：<br>我们有节点1 2 3<br>2最后启动<br>1，3同时超时，且3的请求先到2<br>3，term = 1，2投票给他，1拒绝，于是3变成leader<br>1，term=1，2拒绝了他，3也拒绝了他</p><p>这个时候Term2其实已经有Leader了，是3，那么1也要变成Follower<br>这个时候1收到HeartBeat就要把自己变成Follower<br>那么这里的1的Term=1的votedfor其实已经设置为自己了<br>所以VotedFor还是可以进行修改的  </p><h3 id="Leader发现更高任期的Server"><a href="#Leader发现更高任期的Server" class="headerlink" title="Leader发现更高任期的Server"></a>Leader发现更高任期的Server</h3><p>这种情况也是会发现的，就是Leader进行了STW的GC，然后其他的节点进行了超时选举，选出了Leader。<br>这种时候，原来的Leader的GC结束，进行进行AppendLogRequest，就会发现更高任期的Server<br>这种情况直接自己变成Follower就行</p><h3 id="日志比较的原则"><a href="#日志比较的原则" class="headerlink" title="日志比较的原则"></a>日志比较的原则</h3><p><a href="https://zhuanlan.zhihu.com/p/32052223" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/32052223</a><br>日志比较的原则是，如果本地的最后一条log entry的term更大，则term大的更新，如果term一样大，则Log Index更大的更新</p><h3 id="选举模型"><a href="#选举模型" class="headerlink" title="选举模型"></a>选举模型</h3><p>5个节点中，如果有两个节点同意，那么就可以成为Leader<br>但是反过来说，如果3个节点拒绝了，那么就不能成为Leader</p><p>第一个条件我们可以使用Latch<br>第二个条件我们还是可以使用Latch</p><p>那么怎么组合这两个Latch呢<br>答案就是<br>所以总而言之，不能用Latch<br>只能加锁唤醒了</p><p>我这里自己实现了一个类专门用来进行选举的计数。</p><h2 id="日志复制"><a href="#日志复制" class="headerlink" title="日志复制"></a>日志复制</h2><h3 id="Peer状态管理"><a href="#Peer状态管理" class="headerlink" title="Peer状态管理"></a>Peer状态管理</h3><p>这个也是我实现的时候遇到的比较棘手的问题<br>一开始也没有什么好的解决思路</p><p>因为每个节点的任务执行的状态在同一个时刻肯定是不一致的，有可能这个快一点，那个慢一点</p><p>也有可能就是有的是正常发送心跳，有的则是刚刚重启需要进行日志的同步  </p><p>但是有一个很明确的点就是每个Follower节点都是不同的状态管理</p><p>同时我们再关注下Leader向Follower节点发送心跳或者AppendLogRequest的频率，会发现每次只能有一个请求过去，当这个请求没有返回或者未超时失败时，是不能够发送下一个Rpc的。</p><p><img src="/images/raft/peer.png" alt=""></p><p>综合以上两点，我的设计就是为每个PeerNode分配一个任务队列，每个PeerNode都有一个单独的线程去拿队列的第一个任务，然后同步的执行。</p><p>当Leader需要进行发送心跳或者AppendLogRequest或者其他的请求时，直接Append一个Task到PeerNode的任务队列就行。</p><h3 id="除了AppendLog还要做什么"><a href="#除了AppendLog还要做什么" class="headerlink" title="除了AppendLog还要做什么"></a>除了AppendLog还要做什么</h3><p>这个也是一个误区，因为心跳的RpcRequest就是一个空的AppendLogRequest<br>我开始的实现中，会判断如果需要Append的Log为空，那么就重置一下选举定时器，然后就直接返回了。  </p><p>这个其实是错误的，我们对每一个AppendLogRequest都要进行日志的比对，把还没有Commit的日志，如果需要，给删了或者覆盖了。  </p><p>这么说可能不太明白，假设这样一种场景。<br>一共三个节点，Node1是Leader，三个节点的日志都是1，2，3，一致的。<br><img src="/images/raft/log.png" alt="">  </p><p>然后发生了网络分区，Leader被隔绝了，但是Node1并不知道，同时客户端的请求也过来了，虽然日志无法commit，但是还是Append到了Node1中。  </p><p>如果网络分区结束，Node2变成了Leader，Node2给Node1发送心跳的时候，这时候就需要根据Log的index和Leader的commitIndex，把4和5删掉。<br>这个BUG我也是找了很久，当初图省事简单也没考虑到这些。  </p><h3 id="ReplicatedLogResponse的变更"><a href="#ReplicatedLogResponse的变更" class="headerlink" title="ReplicatedLogResponse的变更"></a>ReplicatedLogResponse的变更</h3><p>如果是节点Down了之后重启，Leader发现nextIndex对不上的时候，会一步一步的退一个NextIndex把日志发送过去，但是每次都发送后续的全量的Log，开销会很大，所以这里可能可以加一个优化，就是在ReplicatedLogResponse加上自己的lastCommitIndex，让Leader可以一次定位到matchIndex。</p><h2 id="成员变更"><a href="#成员变更" class="headerlink" title="成员变更"></a>成员变更</h2><p>论文中讲了，如果3台节点中突然加了两台，可能出现两个Leader，一个通过新配置，一个通过旧配置。</p><p>所以一般的实现是一次只增加一个节点，这个增加的行为其实是人为控制的。</p><p>这个地方的实现也有一些坑点存在。</p><p>比如论文中写新配置是通过日志的形式进行Append进去的，那么这个日志的格式是啥样的呢。<br>一开始我们定义成了增加节点和删除节点的形式，比如<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ClusterChangeLog</span> </span>&#123;</span><br><span class="line">Type type; <span class="comment">//表示是增加节点还是删除节点</span></span><br><span class="line">NodeId nodeId; <span class="comment">//需要增加的节点Id或者删除的节点Id</span></span><br><span class="line">EndPoint endPoint; <span class="comment">//需要增加的节点Id或者删除的节点Id的IP和端口地址</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>像这种形式的日志进行Append，但是其实是不行的。</p><p>我们需要的Log要包含新的集群的所有的节点信息，是否是删除还是增加，删除还是增加的节点信息由节点的日志模块自己去解析。<br>所以正确的形式应该是这样<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ClusterChangeLog</span> </span>&#123;</span><br><span class="line">List&lt;NodeConfig&gt; nodeConfigs;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>为什么说第一种的形式是行不通的或者说实现起来有BUG呢？<br>主要的问题还是在要新增的那个节点上，</p><ul><li>首先新增的节点会有个像Leader获取日志的情况，在获取日志的时候，新增的节点还不属于集群，也就是说，在日志中并没有体现，除了Leader节点，其他的follower节点并不知道该节点的存在。也就是说，我们在开启新增的节点的时候，是不能够将现有的集群的配置写给他启动的，不然就自动连接到其他的节点上去了。</li><li>第二种情况就是，如果我们把当前的集群配置写给新增的那个节点，然后启动它，再把新的集群配置写给Leader，在Leader还没发送时，Leader挂了，那么这个新增的节点咋办呢，能办也能办，但是搞起来会很复杂</li></ul><p>所以我们需要在启动新的节点时，不给它写当前的集群的配置，然后把新增的集群信息写给Leader，Leader也不会立即写日志，而是会进行日志的同步，</p><ul><li>如果日志同步的过程中，Leader挂了，那么没关系，因为新的配置还没写日志，挂了就人为的再写给新的Leader就行，不会影响当前的集群</li><li>日志同步结束之后，把日志进行Append，然后发送给所有的节点，包括新增的节点，那么即使这中间Leader挂了，因为集群更改日志是只要Append就生效的，按照日志最新的才能当前Leader的原则，新的Leader出现之后，会把更改日志再同步到其他的节点，包括新增的节点。</li></ul><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>好的，代码写完了，那么你怎么测试你的代码的正确性呢。<br>这个是我当初头疼的一点，没什么办法进行测试，我到底有没有写对。</p><p>首先这是个分布式的应用，我们除了模拟分布式的环境，还要模拟网络的各种情况，这些肯定不是我们真实模拟硬件和网络情况的，所以肯定要侵入代码的。<br>但是这种需要侵入代码的方法，没有一个方法论在里面的话很容易写乱。</p><p>这里我参考了MIT6.824的课程代码<br><a href="https://github.com/chaozh/MIT-6.824/blob/master/src/raft/test_test.go" target="_blank" rel="noopener">MIT-6.824/blob/master/src/raft/test_tes</a> </p><p>这里模拟了诸多情况</p><ul><li>Leader断网</li><li>Leader断网又恢复</li><li>集群整体掉线恢复</li><li>网络分区</li></ul><p>等诸多情况</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Raft实现指北&lt;br&gt;
    
    </summary>
    
    
      <category term="分布式" scheme="https://blog.lovezhy.cc/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="raft" scheme="https://blog.lovezhy.cc/tags/raft/"/>
    
  </entry>
  
  <entry>
    <title>HotSpot原理指南-基本知识</title>
    <link href="https://blog.lovezhy.cc/2019/07/26/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/"/>
    <id>https://blog.lovezhy.cc/2019/07/26/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/</id>
    <published>2019-07-25T16:00:00.000Z</published>
    <updated>2020-02-29T14:36:27.956Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>作为写了好几年Java的人，自然想去深入了解一下JVM的构造，它的具体实现。</p><p>Clone了代码，运行了起来，看了《HotSpot实战》和《揭秘Java虚拟机-JVM设计原理与实现》，但是能力一般，水平有限，对JVM还是知之甚少，发现继续研究下去将是一种苦修，要做好看很久代码都毫无进展的准备。但是本人志不在此，还是想去研究分布式与数据库，精力有限，只有暂且放弃JVM的深入研究。</p><p>如此直接放弃还是有点可惜，虽然目前学到的不成体系，但是还是想写一篇Blog记录一下。</p><p>所以此博客是上文提到的两本书的摘要+自己的一些学习理解，内容会很散，同时为了省力，摘要部分不特别标出。</p><a id="more"></a><h2 id="源码目录"><a href="#源码目录" class="headerlink" title="源码目录"></a>源码目录</h2><p>HotSpot源码目录较多，有几个是比较重要的</p><ul><li>/c1 =&gt; 客户端解释器</li><li>/classfile =&gt; Class文件解析</li><li>/gc =&gt; gc相关</li><li>/interpreter =&gt; C++解释器和模板解释器都在里面</li><li>/oops =&gt; Java的类模型，也就是OOP-KLASS模型</li><li>/opto =&gt; c2解释器，也就是服务端解释器</li><li>/prims =&gt; 供外部程序访问JVM的通道，比如JNI，Perf，JMX等</li><li>/runtime =&gt; 运行时模块，包括frame，thread，VMOptions等</li><li>/shark =&gt; 基于LLVM实现的JIT编译器</li></ul><h2 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h2><p>JMM开头的方法，和Memory没关系，指的是Management的意思</p><h2 id="命令行选项"><a href="#命令行选项" class="headerlink" title="命令行选项"></a>命令行选项</h2><p>JRockit JVM中命令行选项分为三种</p><ul><li>系统属性，-D开头</li><li>标准选项，-X,-Xms其实我觉得全拼是-X:memory-start?</li><li>非标准选项,-XX</li></ul><h2 id="Class文件解析"><a href="#Class文件解析" class="headerlink" title="Class文件解析"></a>Class文件解析</h2><p>Class文件的解析的代码都在/classfile目录下</p><p><img src="/images/JVM杂记/class文件格式.jpg" alt=""></p><p>HotSpot构建了一个叫systemDictionary的字典，结构是<code>[class name,class loader] -&gt; class</code>，用来存储系统中已经加载的类，从这个Map中我们可以看到一些类加载器的条件，双亲委派的概念。</p><p>在classFileParser.cpp中，宏定义了Class文件开头的MagicWord和Java_Version的对应关系<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> JAVA_CLASSFILE_MAGIC              0xCAFEBABE</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> JAVA_MIN_SUPPORTED_VERSION        45</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> JAVA_MAX_SUPPORTED_VERSION        53</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> JAVA_MAX_SUPPORTED_MINOR_VERSION  0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> JAVA_1_5_VERSION                  49</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> JAVA_6_VERSION                    50</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> JAVA_7_VERSION                    51</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> JAVA_8_VERSION                    52</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> JAVA_9_VERSION                    53</span></span><br></pre></td></tr></table></figure></p><p>文件解析后，各个Class文件是独立的，而各个类之间的联系其实是通过符号引用来串联在一起，JVM在进行符号引用的解析之后，就可以进行类型的相互引用和方法调用</p><p>JVM的链接分为三个部分：</p><ul><li>验证：对方法进行一系列的检查，方法的访问控制，参数和静态类型检查等</li><li>准备：为类静态变量分配内存空间，但是不会初始化值</li><li>解析：将常量池中的4类符号引用转换为直接引用(用常量池项表示的字符串 -&gt; 实际内存地址)<ul><li>类</li><li>接口</li><li>字段</li><li>类方法和接口方法</li></ul></li></ul><p>链接完之后就是进行初始化，也就是调用static {}方法</p><p>对于方法的链接，运用的是链接解析器，LinkResolver对方法进行解析和查找<br>对一个方法进行解析时，需要对instanceKlass中的method表进行查找，找到目标方法后转换成MethodHandle类型句柄返回<br>对方法的权限检查（public，private这种）是在找到之后进行</p><h2 id="runtime模块与Shutdown-Hook"><a href="#runtime模块与Shutdown-Hook" class="headerlink" title="runtime模块与Shutdown Hook"></a>runtime模块与Shutdown Hook</h2><p>runtime模块主要定义HotSpot运行时数据</p><p><code>frame.hpp</code>定义了栈帧的结构，包括Java栈帧，C栈帧。</p><p><code>destroy_vm</code>的退出流程中，会运行JVM层的关闭钩子函数。<br>这里的关闭钩子函数就是提到的<code>Runtime.getRuntime().addShutdownHook();</code><br>书中提到的File.deleteOnExit方法，也是调用的这个，但是获取方式看起来不太一样<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sun.misc.SharedSecrets.getJavaLangAccess()</span><br><span class="line">            .registerShutdownHook(<span class="number">2</span> <span class="comment">/* Shutdown hook invocation order */</span>,</span><br><span class="line">                <span class="keyword">true</span> <span class="comment">/* register even if shutdown in progress */</span>,</span><br><span class="line">                <span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                       runHooks();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br></pre></td></tr></table></figure></p><p>而且参数也是不止一个，看起来还可以指定顺序<br>但是不管咋样，最后两种方式其实都是调用的<code>Shutdown.add</code>方法<br>Runtime中的调用<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Shutdown.add(<span class="number">1</span> <span class="comment">/* shutdown hook invocation order */</span>,</span><br><span class="line">               <span class="keyword">false</span> <span class="comment">/* not registered if shutdown in progress */</span>,</span><br><span class="line">               <span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">                   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                       runHooks();</span><br><span class="line">                   &#125;</span><br><span class="line">               &#125;</span><br><span class="line">           );</span><br></pre></td></tr></table></figure></p><p>看Order的参数来说的话，其实Runtime的优先级更高，而File.deleteOnExit的优先级第二。</p><h2 id="synchronized实现"><a href="#synchronized实现" class="headerlink" title="synchronized实现"></a>synchronized实现</h2><p>synchronized方法或者代码块，会生成两个特殊的字节码  </p><ul><li>monitorenter  </li><li>monitorexit<br>对于解释器而言，具体的执行逻辑在<br><code>intercepter/bytecodeIntercepter.cpp 1803行 JDK9</code><br>也就是<code>CASE(_monitorenter)</code>中<br>具体的实现分为偏向锁，轻量级锁，重量级锁<br>最后会调用<code>InterpreterRuntime::monitorenter</code>方法，这个方法定义在<code>interpreter/interpreterRuntime.cpp</code>中<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">IRT_ENTRY_NO_ASYNC(<span class="keyword">void</span>, InterpreterRuntime::monitorenter(JavaThread* thread, BasicObjectLock* elem))</span><br><span class="line">...</span><br><span class="line">  <span class="keyword">if</span> (PrintBiasedLockingStatistics) &#123;</span><br><span class="line">    Atomic::inc(BiasedLocking::slow_path_entry_count_addr());</span><br><span class="line">  &#125;</span><br><span class="line">  Handle h_obj(thread, elem-&gt;obj());</span><br><span class="line">  assert(Universe::heap()-&gt;is_in_reserved_or_null(h_obj()),</span><br><span class="line">         <span class="string">"must be NULL or an object"</span>);</span><br><span class="line">  <span class="keyword">if</span> (UseBiasedLocking) &#123;</span><br><span class="line">    <span class="comment">// Retry fast entry if bias is revoked to avoid unnecessary inflation</span></span><br><span class="line">    ObjectSynchronizer::fast_enter(h_obj, elem-&gt;lock(), <span class="literal">true</span>, CHECK);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    ObjectSynchronizer::slow_enter(h_obj, elem-&gt;lock(), CHECK);</span><br><span class="line">  &#125;</span><br><span class="line"> ...</span><br></pre></td></tr></table></figure></li></ul><p>仔细看会使用到<code>ObjectSynchronizer</code>的两个方法，如果使用了偏向锁，那么就是<code>fast_enter</code>，如果不允许偏向锁，那么就是<code>slow_enter</code></p><p>在<code>slow_enter</code>的最后，如果还是不行，就会进入锁膨胀的状态，也就是重量级锁</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ObjectSynchronizer::inflate(THREAD,</span><br><span class="line">                            obj(),</span><br><span class="line">                            inflate_cause_monitor_enter)-&gt;enter(THREAD);</span><br></pre></td></tr></table></figure><p>这个时候就要用到<code>ObjectMonitor</code>类中的方法，最后还会涉及到<code>ObjectWaiter</code>类，这个类就是设计了一个链表，类似于<code>ReententLock</code>中的等待链表。</p><p>最后还是很好奇最终的互斥锁到底是怎么实现的，代码在<code>runtime/mutex.cpp</code>中，仔细看了一下，并没有使用到c语言中的Mutex库，最终还是依赖于CAS实现的。</p><p>其实说到底，最后所有的锁都是基于CAS + 链表。</p><p>这里有一个概念上的观念，就是<a href="https://stackoverflow.com/questions/1898374/does-the-jvm-create-a-mutex-for-every-object-in-order-to-implement-the-synchron" target="_blank" rel="noopener">https://stackoverflow.com/questions/1898374/does-the-jvm-create-a-mutex-for-every-object-in-order-to-implement-the-synchron</a>该问题中提到的</p><blockquote><p>Ask: Using only CAS instructions, how do you get the OS scheduler to put a thread to sleep? </p><p>Answer: you don’t. You only use CAS to acquire / release the lock in the uninflated / uncontended case. If contention is detected, the locking/unlocking code would then do the relevant thread scheduling syscalls … or whatever.</p></blockquote><p>如果你查看ReentrentLock的最后将等待的线程放入等待链表中，对线程调用的是<code>LockSupport.park()</code>方法，这是一个native方法，要去源码中找实现，在<code>hotspot/src/os/linux/vm/os_linux.cpp</code>中，可以看到这里为了让线程能够进入os的调度，也就是放弃CPU资源，还是需要进行<code>pthread_cond_wait</code>的调用的。最后对线程的唤醒，还是需要进行notify的。</p><p>在synchronized的底层实现中，最后也是进行park，调用的是<code>os::PlatformEvent::park</code>方法，使用的类是</p><p><code>class ParkEvent : public os::PlatformEvent</code></p><p>所以，(CAS+链表+pthread_mutex)才是真正的实现机制。</p><p>而如果是多线程争用的情况，其实最终的目的还是要保证原子释放CPU资源。</p><p>说了一堆，其实核心在锁的实现上，基本都放弃了直接使用pthread_mutex的方法，而是运用<strong>CAS的方式进行自旋</strong>，而pthread_mutex的使用仅仅是为了将线程进行操作系统的重新调度。</p><p>参考文章：</p><ul><li><a href="https://github.com/farmerjohngit/myblog/issues/15" target="_blank" rel="noopener">https://github.com/farmerjohngit/myblog/issues/15</a></li><li><a href="https://www.jianshu.com/p/c5058b6fe8e5" target="_blank" rel="noopener">https://www.jianshu.com/p/c5058b6fe8e5</a></li></ul><p>偏向锁<br>这个名词看名字不是那么容易理解，在JRockit中描述为延迟解锁</p><p><img src="/images/JVM杂记/锁转换.png" alt=""></p><blockquote><p>在上图中，有三种锁类型，其中胖锁和瘦锁在之前中介绍过，这里新增了延迟锁，用来解释 锁在大部分情况下都只作用于线程局部场景下的情况。<br>正如之前介绍过的，对象首先是未加锁状态的，然后线程 T1 执行 monitorenter 指令，使 之进入延迟加锁状态。但如果线程 T1 在该对象上执行了 monitorexit 指令，这时系统会假装 已经解锁了，但实际上仍是锁定状态，锁对象的锁字中仍记录着线程 T1 的线程 ID。在此之后， 线程 T1 如果再执行加锁操作，就不用再执行相关操作了。<br>如果另一个线程 T2 试图获取同一个锁，则之前所做“该锁绝大部分被线 T1 程使用”的假 设不再成立，会受到性能惩罚，将锁字中的线程 ID 由线程 T1 的 ID 替换为线程 T2 的。如果这 种情况经常出现，那么可能会禁用该对象作为延迟锁，并将该对象作为普通的瘦锁使用。假设这 是线程 T2 第一次在该对象上调用 monitorenter 指令，则程序会进入瘦锁控制流程。在上图中， 被禁用于延迟解锁的对象用星号(*)做了标记。此时，当线程 T3 试图在某个已被禁用于延迟解 锁的对象上加锁，如果该对象还未被锁定，则此时仍会使用瘦锁。<br>使用瘦锁时，如果竞争激烈，或者在锁对象上调用了 wait 方法或 notify 方法，则瘦锁会 膨胀为胖锁，需要等待队列来处理。从图中可以看到，处于延迟解锁状态的对象直接调用 wait 方法或 notify 方法的话，也会膨胀为胖锁</p></blockquote><p>单例模式的双重校验锁的实现其实是有问题的，加了volatile能解决问题，但是会带来略微的性能问题</p><h2 id="内存-OOP"><a href="#内存-OOP" class="headerlink" title="内存 OOP"></a>内存 OOP</h2><p>虚拟机中内存空间按照内存的用途，可以划分为<strong>堆和非堆</strong></p><ul><li>堆：用于对象的分配空间</li><li>非堆：包括方法区和Code Cache</li></ul><p>Perf Data区域，有perfMemory模块管理<br>为了支持虚拟机性能监控，在虚拟机中开辟了一块共享内存，专门存储一些性能指标<br>虚拟机使用共享内存方式向外部进程提供了一种通信手段，允许外部监控进程attach至虚拟机进程，从共享内存中读取这些perf Data</p><p>oop-klass模型<br>这个感觉是比较重要的点了<br>还是一个老生长谈的问题，why的问题<br>运用C++的基础模型去实现有没有问题呢？<br>其实我感觉是没有问题的，但是相对于C++的模型，Java这种方式，其实主要是更省内存。<br>同一个类的所有对象维护同一个VTable，其次就是和C++的多态方式不同，Java是模型每一个函数都是可以被子类覆盖的，而C++的只有是虚函数才能，换句话说，Java里面每个函数都是虚函数。<br>虚函数暴增的情况下，显然这种方式更加的省内存。<br>//fixMe</p><blockquote><p>而且我感觉还和Java的类加载机制有关，因为Java的符号引用转换为直接引用的解析过程，是可以再运行中才进行的，如果父类的方法被动态改变了，函数的地址肯定也需要进行相应的改变，而现有子类的对于这个方法的指向，只要改变一次Klass就行。</p></blockquote><p>在该模型中，Java的method也作为一种OOP存在</p><p><img src="/images/JVM杂记/markword.jpg" alt=""></p><p>实例对象的创建 分为快速分配和慢速分配  </p><ul><li>快速分配就是必须是该类已经被加载和正确解析 因为类的解析，就是符号引用变直接引用的过程不一定就是ClassLoader的时候进行，HotSpot是类第一次被使用的时候解析<br>快速分配就是可以在TLAB，就是线程缓存中分配，而不必先分配到Eden区，如果开启了TLAB选项</li><li>慢速分配就是需要先解析，然后在Eden区分配</li></ul><p>对象在内存中的布局，也就是OOP对象，可以分为连续的两部分，也就是MarkWord对象头和实例数据部分<br>而在Klass模型中，存储着对象的每个变量在实例数据部分的偏移量和长度</p><p>Klass中，有一个和Java类对应的mirror成员</p><p>JVM为每个线程分配一个PC寄存器，在真实机器中，往往提供一个PC寄存器专门用来保存程序运行的指令在内存中的位置，在HotSpot的实现中，为每个线程分配了一个字长的存储空间，以实现类似硬件级的PC寄存器<br>如果当前执行方法不是本地方法，那么PC寄存器就保存的是JVM正在执行的字节码指令的地址，如果是本地方法，那么PC寄存器的值是未定义的，因为本地方法的执行依赖硬件PC寄存器，其值是由操作系统维护</p><p>Java虚拟机栈的作用：存储方法执行中的局部变量，中间演算结果以及方法返回结果</p><p>JVM允许Java虚拟机栈被实现为固定大小和动态收缩</p><ul><li><p>固定大小，顾名思义，如果超过，抛出StackOverflowError异常</p></li><li><p>动态扩展：OOM异常</p></li></ul><p>虚拟机规范对方法区实现的位置并没有明确要求，在HotSpot中，位于永久代中。<br>HotSpot会收集方法区，主要是常量池的收集和类的卸载<br>在HotSpot内部，Java方法也是由一个内部对象表示的，对象的类型是methodOop，是Java方法在JVM内部的表示方式<br>methodOop内部有指向所在类的运行时常量池的指针<br>methodOop内部有个_constMethod指针，类型是constMethodOop，用来存储和定位方法中的只读数据，如字节码，方法引用，方法名，方法签名，异常表等信息</p><p>Perf Data区域，有perfMemory模块管理<br>为了支持虚拟机性能监控，在虚拟机中开辟了一块共享内存，专门存储一些性能指标<br>虚拟机使用共享内存方式向外部进程提供了一种通信手段，允许外部监控进程attach至虚拟机进程，从共享内存中读取这些perf Data</p><p>Java类的生命周期的第一个阶段，加载，就是为了在JVM内部创建一个与Java类结构对等的数据对象</p><p>如果想要破坏双亲委派的机制，自定义类加载器加载核心类库，还是会被拒绝，因为在defineClass方法中，会提供保护，对类名为Java开头的类，直接抛出异常</p><p>同样的，类型转换需要两个类都是同一个类加载器加载的，不然会报错，上次那个Dubbo的问题就这样，报错是两个一样的类，无法进行cast</p><h2 id="GC"><a href="#GC" class="headerlink" title="GC"></a>GC</h2><p>GC的几个策略</p><ul><li>GC工作线程：串行还是并行</li><li>GC工作线程和应用线程：并发执行还是暂停应用</li><li>基本收集算法：压缩，非压缩还是拷贝</li></ul><p>吞吐量：应用程序运行时间/(应用程序运行时间 + 垃圾收集时间)</p><p>HotSpot每个线程在Eden区都有自己的一小块区域，用于TLAB分配<br>通常情况下，系统中有大量连续的内存块可以用来进行分配的话，碰撞指针算法进行分配，效率很高。思路就是记录上一次分配对象的位置，当有新对象要分配的时候，只需要一次移动位置就可以完成内存的分配<br>在TLAB中进行分配，也就是碰撞指针(bump-the-pointer)分配，效率很高</p><p>不然就需要全局锁进行在Eden区分配</p><p>还有另外一种优化，叫栈上分配</p><p>栈上分配需要对方法的对象进行逃逸分析<br>如果局部变量的作用域仅限于方法内部，则JVM直接在栈帧内分配对象，避免在堆中分配<br>但是这里引用R大的话</p><blockquote><p>嗯但是Oracle/Sun的HotSpot VM从来没在产品里实现过栈上分配，而只实现过它的一种特殊形式——标量替换（scalar replacement）。这俩是不一样的喔。栈上分配还是要分配完整的对象结构，只不过是在栈帧里而不在GC堆里分配；标量替换则不分配完整的对象，直接把对象的字段打散看作方法的局部变量，也就是说标量替换后就没有对象头了，也不需要把该对象的字段打包为一个整体。<br><a href="https://book.douban.com/people/RednaxelaFX/annotation/25847620/" target="_blank" rel="noopener">https://book.douban.com/people/RednaxelaFX/annotation/25847620/</a></p></blockquote><p>有个类叫GCCause，里面定义了一些枚举，就是引起GC的一些情况<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum</span> Cause &#123;</span><br><span class="line"><span class="comment">/* public */</span></span><br><span class="line">_java_lang_system_gc,</span><br><span class="line">_full_gc_alot,</span><br><span class="line">_scavenge_alot,</span><br><span class="line">_allocation_profiler,</span><br><span class="line">_jvmti_force_gc,</span><br><span class="line">_gc_locker,</span><br><span class="line">_heap_inspection,</span><br><span class="line">_heap_dump,</span><br><span class="line">_wb_young_gc,</span><br><span class="line">_wb_conc_mark,</span><br><span class="line">_wb_full_gc,</span><br><span class="line">_update_allocation_context_stats_inc,</span><br><span class="line">_update_allocation_context_stats_full,</span><br><span class="line"></span><br><span class="line"><span class="comment">/* implementation independent, but reserved for GC use */</span></span><br><span class="line">_no_gc,</span><br><span class="line">_no_cause_specified,</span><br><span class="line">_allocation_failure,</span><br><span class="line"></span><br><span class="line"><span class="comment">/* implementation specific */</span></span><br><span class="line"></span><br><span class="line">_tenured_generation_full,</span><br><span class="line">_metadata_GC_threshold,</span><br><span class="line">_metadata_GC_clear_soft_refs,</span><br><span class="line"></span><br><span class="line">_cms_generation_full,</span><br><span class="line">_cms_initial_mark,</span><br><span class="line">_cms_final_remark,</span><br><span class="line">_cms_concurrent_mark,</span><br><span class="line"></span><br><span class="line">_old_generation_expanded_on_last_scavenge,</span><br><span class="line">_old_generation_too_full_to_scavenge,</span><br><span class="line">_adaptive_size_policy,</span><br><span class="line"></span><br><span class="line">_g1_inc_collection_pause,</span><br><span class="line">_g1_humongous_allocation,</span><br><span class="line"></span><br><span class="line">_dcmd_gc_run,</span><br><span class="line"></span><br><span class="line">_last_gc_cause</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><p>收集算法</p><ul><li>标记-清除 Mark-Sweep</li><li>复制算法 Copying</li><li>标记-压缩算法 Mark-Compact</li></ul><p>堆的类型</p><p>不同的收集器可能对应着不同类型的堆</p><p><code>CollectedHeap &lt;- ParallelScavengeHeap</code></p><p><code>CollectedHeap &lt;- SharedHeap &lt;- G1CollectedHeap</code></p><p>CMS的创新之处在于把标记分为两个阶段，初始标记和并发标记</p><p>但是引入了新的缺点，就是并发收集失败的问题，在并发标记时，内存使用过度，只有STW，采取线性标记和收集</p><p>而且只能由于并发清除的问题，只能进行标记-清除，将产生内存碎片，而新生代由于其特殊性，将产生更多的内存碎片，所以CMS在新生代并不适用，只运用在老年代</p><p>安全点</p><blockquote><p>由于JVM系统运行期间的复杂性，不可能做到随时暂停，因此引入了安全点（safepoint）：程序只有在运行到安全点的时候，才准暂停下来。HotSpot采取主动中断的方式，让执行线程在运行时轮询是否需要暂停的标识，若需要则中断挂起。</p></blockquote><p>//fixme<br>其实我觉得这里说的不对，应该不是不可能做到随时暂停，而是随时暂停的消耗太大了，因为后面也写到是主动中断的方式，如果在每个字节码后面都插入check是否需要中断的代码，则消耗确实是太大了<br>参考文章：<a href="https://www.jianshu.com/p/c79c5e02ebe6" target="_blank" rel="noopener">https://www.jianshu.com/p/c79c5e02ebe6</a></p><p>G1收集器<br>G1重新定义了堆空间，打破了原有的分代模型，将堆划分为一个个区域<br>在进行收集的时候，不必在全堆的范围内进行，好吃就是带来了停顿时间的可预测<br>G1会通过一个合理的计算模型，计算出每个region的收集成本并量化</p><p>分代模型的写屏障<br>这个是比较重要的一个，一开始是比较难理解的<br><img src="/images/JVM杂记/写屏障.png" alt=""><br>我们从正常的新生代的GC开始说，从图中看到，如果只从GCRoot出发，其实是扫描不到F的，如果扫描不到，说明F是需要被清除的<br>但是其实F被老年代的E所引用，也就是说他不能被清除<br>这就是说，GCRoot需要包含新生代中的被老年代引用的对象。<br>但是如果要实现这个功能，可能要扫描所有的老年代对象了，如果每次进行新生代的GC时都扫描老年代，那么分代GC的意义就不是那么明显了<br>所以这里用了一个写屏障，底层使用的是卡表的概念进行标记。<br>简单的说就是每当有老年代对象引用新生代对象时，就把老年代对象所在的位置标记一下，然后进行新生代GC时，把老年代标记了的位置进行扫描进行，而不用全部扫描<br><a href="https://juejin.im/post/5c39920b6fb9a049e82bbf94" target="_blank" rel="noopener">https://juejin.im/post/5c39920b6fb9a049e82bbf94</a></p><p>压缩指针<br>指针的大小一般是平台的决定的，但是在64位的机器上，但是还是可以进行一些优化，优化的基础是内存的申请是一下子一大片连续的内存<br>举个例子就是在64位机器上，如果我们要申请的一块内存小于4G，那么完全可以只用32位就可以进行指针的保存</p><p>JRockit里面提到了一种伪优化<br>就是对象池，有人认为，保留一个存活对象池来重新使用已创建的对象可以提升垃圾回收的性能</p><blockquote><p>但实际上，对象池不仅增加了应用程序的复杂度，还很容易出错。对于现代垃圾收集器来说，使用 java.lang. ref.Reference 系列类实现缓存，或者直接将无用对象的引用置为 null 就好了，不用多操心。<br>此外，长期持有无用的对象其实是个大麻烦，分代式垃圾回收器可以很好地处理临时对象，但如果这些临时对象被人为保存下来，无法被回收掉的话，最终就会被提升到老年代，并将其挤满。</p></blockquote><h2 id="栈帧"><a href="#栈帧" class="headerlink" title="栈帧"></a>栈帧</h2><p>如果函数要返回整数或者指针的话，寄存器%eax可以用来返回值<br>寄存器eax，edx，ecx被划分为调用者保存<br>而寄存器ebx，esi，edi寄存器划分为被调用者保存<br>栈是以帧为单位保存当前线程的运行状态<br>当线程执行一个方法时，它会跟踪当前常量池<br>栈帧存储了方法的局部变量表，操作数栈，动态链接和方法返回地址</p><p><img src="/images/JVM杂记/栈帧结构.png" alt=""><br><img src="/images/JVM杂记/解释器帧.png" alt=""></p><p>局部变量表</p><ul><li>局部变量表被组织为一个字长为单位，从0开始计数的数组</li><li>存储时以slot为单位，一个slot一般为32位，short，byte，char在存入表中要先转换为int</li><li>一般会存储的类型除了基本类型和引用，还有returnAddress类型，它指向了一个字节码指令的地址</li><li>参数值到参数变量列表的传递依赖于局部变量表</li><li>第0位索引的slot默认是用于传递方法所属对象实例的引用</li></ul><p>局部变量表的描述</p><ul><li>start_pc，length：描述局部变量的作用域</li><li>name_index：描述局部变量名的常量池索引，对应Class文件中的Name</li><li>descriptor_index:描述局部变量类型的常量池索引，对应Class文件中的Signature</li><li>index：描述局部变量在当前栈帧的局部变量索引</li></ul><p>局部变量表的大小在编译期就可以确定，在Code属性中明确了大小</p><p>操作数栈</p><ul><li>操作数栈的深度由Code属性max_stacks在编译期确定</li><li>和局部变量表不同的是，操作数栈不是通过索引来访问的，而是通过入栈和出栈来访问</li><li>还有一个比较重要的点，就是操作数栈和下一个栈帧的参数列表是可以复用的，不然我们在HSDB调试操作数栈的时候看起来会比较迷惑</li></ul><p>异常表<br>为了处理Java方法中的异常情况，帧数据区还必须保存一个对此方法异常表的引用，当异常抛出时，JVM给catch块中的代码<br>如果没发现，方法立即终止，然后JVM用帧区数据的信息回复发起调用的方法的帧，然后再发起调用方法的上下文重新抛出同样的异常</p><p>Hotspot解释器执行引擎在执行字节码时，实际上是执行一段已经被编译成本地机器直接运行的指令<br>在JVM启动期间，解释器模块就会将每个字节码转换成与之等价的机器指令，放在Code Cache中<br>所以HotSpot充分利用了计算机的资源，包括寄存器</p><h2 id="JavaCalls"><a href="#JavaCalls" class="headerlink" title="JavaCalls"></a>JavaCalls</h2><p>JavaCalls，说白了就是JVM调用Java方法</p><p>然后CallStub，是一个函数指针，在调用Java程序的Main函数时，需要使用这个函数指针</p><p>但是CallStub指向的函数是一个entry_point，是一个例程</p><p>当然这里其实是有歧义的例程在JVM的概念就是提前用机器码写好的函数，而entry_point虽然也是例程，然后它主要突出entry这个词，主要是在方法调用切换时进行调用的例程</p><p>再说回CallStub，它指向的例程，就是为所有Java程序的唯一一个Main方法构造他的前一个栈帧</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;&#125;</span><br></pre></td></tr></table></figure><p>最直接的就是参数args，在栈中需要使用CallStub指向的例程构建好，然后CallStub的函数指针的函数中，还需要传入一个entry_point，这个就是在进行Java函数调用的时候，需要进行寄存器的保存等之类的操作，而这些操作由不同的entry_point来操作。</p><p>//fix me</p><p>个人理解就是在各种invoke的字节码指令中，会频繁的调用这些不同的entry_point。</p><h2 id="常量池"><a href="#常量池" class="headerlink" title="常量池"></a>常量池</h2><p>其实JVM中常量池有两种不同的概念<br>第一种是Class文件的常量池<br>虚拟机在创建一个类或者接口时候，按照Class文件的定义创建相应的常量池，也就是Class文件中的constant_pool表。<br>第二种是方法区中的常量池，虚拟机在对类进行解析和连接之后，将在内存中为该类生成一套运行时常量池，常量池在运行时动态分配<br>第三种是代码中我们提到的常量池，也就是String常量池，JVM中创建了一个String的Table</p><p>参考<a href="https://blog.csdn.net/zm13007310400/article/details/77534349" target="_blank" rel="noopener">https://blog.csdn.net/zm13007310400/article/details/77534349</a></p><p>那么为什么要有常量池呢<br>Answer：</p><blockquote><p>常量池的出现，解决了JVM定位字段和方法的问题，它在不破坏指令集的简洁性的前提下，仅仅通过少量字节就能定位到目标。<br>更详细的说，以字符串数据aVeryLongFunctionName为例，如果在编译时每次都要重新避免这个字符串的话，那么字节码就谈不上压缩了</p></blockquote><p>但是每次字段或者方法的访问都需要解析常量池项的话，将不可避免的造成性能下降<br>对于类文件的运行时常量池，JVM内还会有它的高速缓冲ConstantPoolCache</p><h2 id="解释器"><a href="#解释器" class="headerlink" title="解释器"></a>解释器</h2><p>HotSpot的解释器分为了两种<br>一种是CPP解释器，也就是最原始的解释器，类似于Case，Case这种形式，文件是intercepter/bytecodeIntercepter.cpp<br>一种是模板解释器，现在默认是这样，这种是在JVM启动时对每一个字节码都进行了当前平台的机器码转换，具体的是维护了一个平台相关TemplateTable，可以在cpu/x86/vm中的templateTable_XX.cpp中找到，相对于CPP解释器，其实这也是一种解释的方法，虽然第一种最终执行的也是C++编译成的机器码，但是模板解释器相对于CPP解释器，机器码是手动写的，可以进行一些优化，比如TOS，还有就是对于取出下一个执行进行运行，也可以直接插入到当前字节码的机器码中</p><p>对于模板解释器的取指令的操作，其实在写在每一个字节码指令的最后。<br>HotSpot在为每一个字节码指令生成其机器逻辑指令时，会同时为该字节码指令生成其取址逻辑</p><p>PC计数器，在x86平台上就是esi寄存器，所以在JVM中并不是完全不使用CPU的寄存器</p><p>面向栈式的指令，可以省去很多的操作数，所以一定程度上也减少了代码体积<br>这话其实不对，因为相对于寄存器式的指令，寄存器式的一个指令就能完成的事，其实栈式需要多个指令</p><p>栈帧重叠<br>就是前面提到的上一个方法的操作数栈可以直接成为下一个方法的参数表</p><p>栈上替换 OSR<br>个人理解就是在一个方法里遇到了Loop非常久的情况，对方法进行了JIT编译，但是由于这个Loop非常长，JIT编译完还未结束，所以为了将当前方法替换到新的栈帧，使用栈上替换<br>具体的解释在R大这儿<br><a href="https://www.zhihu.com/question/45910849" target="_blank" rel="noopener">OSR（On-Stack Replacement）是怎样的机制？</a><br>JRockit没有实现OSR，因为太复杂了</p><p>JIT编译器<br>为什么不直接全部aot编译一下，而是选择了解释+JIT的方式<br>R大这里也回答了[<a href="https://www.zhihu.com/question/37389356)(https://www.zhihu.com/question/37389356" target="_blank" rel="noopener">https://www.zhihu.com/question/37389356)(https://www.zhihu.com/question/37389356</a>)<br>我总结一下</p><ul><li>时间开销，aot的启动时间肯定很慢</li><li>空间开销，字节码到机器码会代码膨胀</li><li>编译时机，一些profile的收集对编译有很大的影响<blockquote><p>JIT是一个充满希望的方向，因为它可以搜集到程序在AOT编译时得不到的runtime数据，在优化时，有更多的上下文可以依靠，理论上应该有更好的优化特性</p></blockquote></li></ul><p>在JRockit中，讲了aot其实在90年代就已经出现了，但是这种方式虽然快了很多，但是抛弃了很多Java的动态特性，提到了一个很重要的场景，就是在JSP的应用中，我们知道JSP其实就是b被编译成class文件，做的事也仅仅是疯狂的sout，如果aot一下，效率不会提高太多，但是代码体积会提高很多</p><p>其实aot与全部JIT编译并不是一个概念，一个好的办法是，给JIT的编译加上不同层级的编译，一开始可能是优化不高的，后面收集到profile后再进行深层次的profile</p><p>判断热方法</p><ul><li>counter，但是会降低效率</li><li>基于软件的线程采样，周期性的获取活动线程的上下文</li></ul><p>JVM字节码的表现力其实比Java语言强，所以需要对字节码进行校验，防止一些恶意的技巧</p><h2 id="TOS"><a href="#TOS" class="headerlink" title="TOS"></a>TOS</h2><p>TosState的取值范围为0-8，共计9种</p><ul><li>byte，bool</li><li>char</li><li>short</li><li>int</li><li>long</li><li>float</li><li>double</li><li>object</li><li>void</li></ul><p>最后一种其实就是空，参见R大的笔记，HotSpot实战中写的是tos类型，我还去百度了tos类型是啥类型😓 </p><h2 id="VM选项"><a href="#VM选项" class="headerlink" title="VM选项"></a>VM选项</h2><table><thead><tr><th>配置</th><th>解释</th><th>备注</th></tr></thead><tbody><tr><td>-XX:UseG1GC</td><td>配置G1收集器</td><td></td></tr><tr><td>-Xint</td><td>配置虚拟机以纯解释方式运行</td><td></td></tr><tr><td>-XX:+MaxFDLimit</td><td>最大文件描述符数量</td><td></td></tr><tr><td>-XX:DisableExplicitGC</td><td>Parallel Scanvenge收集器的配置，屏蔽System.gc()</td></tr></tbody></table><h2 id="Tools"><a href="#Tools" class="headerlink" title="Tools"></a>Tools</h2><p>实际的性能分析可以查看《HotSpot实战》的5.3小节，讲的很详细</p><ul><li>HSDB：可以用来看JVM的运行时数据，查看线程栈，对象的数据</li><li>jps：查看Java进程信息</li><li>jinfo：</li><li>jmap：</li><li>jhat：</li><li>jstat：</li><li>jstack：</li></ul><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://book.douban.com/people/RednaxelaFX/annotation/25847620/?start=0" target="_blank" rel="noopener">RednaxelaFX对《HotSpot实战》的笔记</a><br><a href="https://book.douban.com/subject/25847620/" target="_blank" rel="noopener">HotSpot实战</a><br><a href="https://book.douban.com/subject/30394745/" target="_blank" rel="noopener">JRockit权威指南：深入理解JVM</a><br><a href="https://book.douban.com/subject/27086821/" target="_blank" rel="noopener">https://book.douban.com/subject/27086821/</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;作为写了好几年Java的人，自然想去深入了解一下JVM的构造，它的具体实现。&lt;/p&gt;
&lt;p&gt;Clone了代码，运行了起来，看了《HotSpot实战》和《揭秘Java虚拟机-JVM设计原理与实现》，但是能力一般，水平有限，对JVM还是知之甚少，发现继续研究下去将是一种苦修，要做好看很久代码都毫无进展的准备。但是本人志不在此，还是想去研究分布式与数据库，精力有限，只有暂且放弃JVM的深入研究。&lt;/p&gt;
&lt;p&gt;如此直接放弃还是有点可惜，虽然目前学到的不成体系，但是还是想写一篇Blog记录一下。&lt;/p&gt;
&lt;p&gt;所以此博客是上文提到的两本书的摘要+自己的一些学习理解，内容会很散，同时为了省力，摘要部分不特别标出。&lt;/p&gt;
    
    </summary>
    
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/categories/HotSpot/"/>
    
    
      <category term="JVM" scheme="https://blog.lovezhy.cc/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>Java中FileLock的实现细节</title>
    <link href="https://blog.lovezhy.cc/2019/03/29/Java%E4%B8%ADFileLock%E7%9A%84%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82/"/>
    <id>https://blog.lovezhy.cc/2019/03/29/Java%E4%B8%ADFileLock%E7%9A%84%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82/</id>
    <published>2019-03-28T16:00:00.000Z</published>
    <updated>2020-02-23T10:30:12.584Z</updated>
    
    <content type="html"><![CDATA[<h2 id="起因"><a href="#起因" class="headerlink" title="起因"></a>起因</h2><p>开始看Lucene源代码，找了个最简单的FSLockFactory开始看。<br>然而还是看出了不明白的地方  </p><p>在NativeFSLockFactory的close方法中有这么一段注释</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// <span class="doctag">NOTE:</span> we don't validate, as unlike SimpleFSLockFactory, we can't break others locks</span></span><br></pre></td></tr></table></figure><p>我从网上找到了当初的Bug的讨论帖<br><a href="https://issues.apache.org/jira/browse/LUCENE-6507" target="_blank" rel="noopener">https://issues.apache.org/jira/browse/LUCENE-6507</a>  </p><p>从里面讨论了NativeFSLock了一些关于这个文件锁的实现的问题</p><a id="more"></a><h2 id="JDK的BUG"><a href="#JDK的BUG" class="headerlink" title="JDK的BUG"></a>JDK的BUG</h2><blockquote><p>On some systems, closing a channel releases all locks held by the Java virtual machine on the underlying file regardless of whether the locks were acquired via that channel or via another channel open on the same file. It is strongly recommended that, within a program, a unique channel be used to acquire all locks on any given file. </p></blockquote><p>这个JDK的文档中写的就是这么一种场景，在某些操作系统上，如果我们把channel直接关闭，那么其他的在这个文件上的Lock会直接失效，当然前提是在同一个JVM进程中</p><p>如果没有这个BUG，我们会怎么写这个LOCK的获取代码呢<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">FileChannel channel = <span class="keyword">null</span>;</span><br><span class="line">FileLock lock = <span class="keyword">null</span>;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    channel = FileChannel.open(realPath, StandardOpenOption.CREATE, StandardOpenOption.WRITE);</span><br><span class="line">    lock = channel.tryLock();</span><br><span class="line">    <span class="keyword">if</span> (lock != <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">new</span> NativeFSLock(lock, channel, realPath, creationTime);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> LockObtainFailedException(<span class="string">"Lock held by another program: "</span> + realPath);</span><br><span class="line">    &#125;</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (lock == <span class="keyword">null</span>) &#123; <span class="comment">// not successful - clear up and move out</span></span><br><span class="line">      IOUtils.closeWhileHandlingException(channel); <span class="comment">// <span class="doctag">TODO:</span> addSuppressed</span></span><br><span class="line">      clearLockHeld(realPath);  <span class="comment">// clear LOCK_HELD last </span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>很简单的，就是先拿channel，然后tryLock，如果失败，就是记得关闭channel就行了。</p><p>但是有个JDK的这个问题，还能直接关闭吗？<br>显然是不能的，你关闭channel，会把其他在这个channel的锁给invalid掉。</p><h2 id="Lucene的实现"><a href="#Lucene的实现" class="headerlink" title="Lucene的实现"></a>Lucene的实现</h2><p>这个帖子最后的解决方案，就是加了一个类似于双重校验锁的东西。<br>在同一个进程中，设置一个<br><code>Set&lt;String&gt; LOCK_HELD</code></p><p>要想获取文件锁，首先得成功把LockName加个Lock_HELD中。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://github.com/frohoff/jdk8u-dev-jdk/blob/master/src/share/classes/java/nio/channels/FileLock.java" target="_blank" rel="noopener"><code>java.nio.channel.FileLock</code>注释</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;起因&quot;&gt;&lt;a href=&quot;#起因&quot; class=&quot;headerlink&quot; title=&quot;起因&quot;&gt;&lt;/a&gt;起因&lt;/h2&gt;&lt;p&gt;开始看Lucene源代码，找了个最简单的FSLockFactory开始看。&lt;br&gt;然而还是看出了不明白的地方  &lt;/p&gt;
&lt;p&gt;在NativeFSLockFactory的close方法中有这么一段注释&lt;/p&gt;
&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// &lt;span class=&quot;doctag&quot;&gt;NOTE:&lt;/span&gt; we don&#39;t validate, as unlike SimpleFSLockFactory, we can&#39;t break others locks&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;我从网上找到了当初的Bug的讨论帖&lt;br&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-6507&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://issues.apache.org/jira/browse/LUCENE-6507&lt;/a&gt;  &lt;/p&gt;
&lt;p&gt;从里面讨论了NativeFSLock了一些关于这个文件锁的实现的问题&lt;/p&gt;
    
    </summary>
    
    
      <category term="Lucene" scheme="https://blog.lovezhy.cc/categories/Lucene/"/>
    
    
      <category term="Lucene" scheme="https://blog.lovezhy.cc/tags/Lucene/"/>
    
  </entry>
  
  <entry>
    <title>h2database的MVStore解析</title>
    <link href="https://blog.lovezhy.cc/2019/02/18/H2database%E7%9A%84MVStore%E8%A7%A3%E6%9E%90/"/>
    <id>https://blog.lovezhy.cc/2019/02/18/H2database%E7%9A%84MVStore%E8%A7%A3%E6%9E%90/</id>
    <published>2019-02-17T16:00:00.000Z</published>
    <updated>2019-02-28T14:06:05.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>MVStore是h2数据库的底层的存储文件格式<br>在1.4版本之前底层的文件存储都是<code>org.h2.store.*</code>包中的<br>然后1.4之后默认改为了<code>org.h2.mvstore.*</code>包中的  </p><p>官方的介绍说是根据<code>Log Structed FS</code>设计的，顺序写提高性能</p><p>MV的意思是<code>multi-version</code></p><p>同类型的项目有个叫<code>mapDB</code>的项目<br><a href="https://github.com/jankotek/mapdb" target="_blank" rel="noopener">https://github.com/jankotek/mapdb</a>  </p><p>还有一个Apache的项目<code>mavibot</code><br><a href="http://directory.apache.org/mavibot/downloads.html" target="_blank" rel="noopener">http://directory.apache.org/mavibot/downloads.html</a>  </p><a id="more"></a><h1 id="简单使用"><a href="#简单使用" class="headerlink" title="简单使用"></a>简单使用</h1><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.h2.mvstore.*;</span><br><span class="line"></span><br><span class="line"><span class="comment">// open the store (in-memory if fileName is null)</span></span><br><span class="line">MVStore s = MVStore.open(fileName);</span><br><span class="line"></span><br><span class="line"><span class="comment">// create/get the map named "data"</span></span><br><span class="line">MVMap&lt;Integer, String&gt; map = s.openMap(<span class="string">"data"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// add and read some data</span></span><br><span class="line">map.put(<span class="number">1</span>, <span class="string">"Hello World"</span>);</span><br><span class="line">System.out.println(map.get(<span class="number">1</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// close the store (this will persist changes)</span></span><br><span class="line">s.close();</span><br></pre></td></tr></table></figure><p>来自官网的例子<br>就当做一个普通的Map使用就行，不过这里支持持久化到磁盘上</p><h1 id="文件格式"><a href="#文件格式" class="headerlink" title="文件格式"></a>文件格式</h1><p>在参考文档中有详细的讲述，不过和最新的代码版本有一些出入<br><img src="/images/mvstore/fileformat.png" alt=""></p><p>先谈谈<code>block</code>的概念<br><code>block</code>是一个扇区的大小，也就是磁盘一次读取的大小。<br>所以H2里定为<strong>4k</strong>，然后无论是<code>file header</code>还是<code>chunk</code>，都是对齐到<code>block</code>的整数倍 </p><h2 id="总体"><a href="#总体" class="headerlink" title="总体"></a>总体</h2><p><code>[ file header 1 ] [ file header 2 ] [ chunk ] [ chunk ] ... [ chunk ]</code></p><p>整个文件的格式是这样<br>其中<code>file header</code>是个KV的格式，<strong>大小是一个<code>block</code></strong><br>形如<br><code>H:2,blockSize:1000,created:167a11ebf8d,format:1,fletcher:9f80997e</code></p><ul><li><code>H:2</code>:固定的，表示这个是h2数据库文件</li><li><code>blockSize:1000</code>：<code>block</code>的大小，size是16进制的，换成存储的就是4K</li><li><code>created:167a11ebf8d</code>：创建时间，v也是16进制的</li><li><code>format:1</code>：文件格式版本，为了防止后续如果新版本文件格式更改，现在都是1</li><li><code>fletcher:9f80997e</code>：checkSum</li></ul><p><code>file header</code>写了两份，header1和header2内容是一样的，官网的描述是防止文件损坏破坏了一份，也是有道理的。</p><h2 id="Chunk"><a href="#Chunk" class="headerlink" title="Chunk"></a>Chunk</h2><p>由于是Version的概念，所以每一次Commit，都会把这个阶段进行了修改的Page都放在新的Chunk中，Version++ （当然如果这段时间内没有修改，就不会commit）</p><p>每次Commit结束，只保留RootPage，把Children的Page缓存全部清空</p><p>下面的<code>chunk</code>是真正存储数据的地方，格式如下：<br><code>[ header ] [ page ] [ page ] ... [ page ] [ footer ]</code></p><p><code>Chunk</code>的大小是不固定的，但是肯定是<code>block</code>的整数倍大小  </p><p>header也是KV的格式，长度限定了最大值<code>Chunk.MAX_HEADER_LENGTH = 1k</code><br>header的header生成来自函数<code>Chunk#asString</code><br>结果是header形如：<br><code>chunk:5,block:5,len:1,map:c,max:980,next:6,pages:5,root:14000016194,time:102cc,version:5</code></p><ul><li><code>chunk:5</code>: 每个chunk都有一个id，这里的id为5，id是原子自增的</li><li><code>block:5</code>：chunk开始的block，用<code>5*blockSize</code>就可以定为到chunk在file中的offset</li><li><code>len:1</code>:chunk的长度，单位为block</li><li><code>map:c</code>：最新的map的id，这里是16进制，每新建一个Map都会分配一个id，自增的，其实我觉得是记录map的个数</li><li><code>max:980</code>:每个Page有个MaxLen（见下面Page的格式)，这里是chunk中所有的maxLen加起来的值</li><li><code>next:6</code>：预测的下一个chunk的开始位置，单位为block</li><li><code>pages:5</code>：此chunk中的包含的page的个数</li><li><code>root:14000016194</code>: MetaMap Root Page的位置，但不是指在文件中的绝对位置，参见Page中的Children编码，一般是chunkId+offset来表示</li><li><code>time:102cc</code>：时间戳，16进制，从文件创建后到chunk写入的时间差</li><li><code>version:5</code>：版本号，一般来说一个commit就会创建一个chunk，每个chunk都是一个新的版本号，这里的chunk包含的数据版本是5</li></ul><p>除了上面这些，可能还有</p><ul><li><code>liveMax</code>:  回去看max的含义，是每个Page的MaxLen的和，就是无论这个Page是否还被使用，liveMax就是所有还在被使用的Page的MaxLen的和</li><li><code>livePages</code>：和上面的Pages的对应，也是还在被使用的Page的个数，而Pages统计的是所有<br>那么统计上面这个两个参数有啥含义呢，当我们回收一个Chunk的时候，如果其中Pages很多，但是目前还在被使用的极少，那么就会进行compact，把还在使用的移动到新的Chunk中，然后回收这个Chunk</li></ul><p>footer的信息和header其实和一部分是一样的<br>写入footer我感觉是为了文件初始化的时候直接从文件末尾开始构建MetaMap准备的<br><code>chunk:5,block:5,version:5,checkSum:{checkSum}</code></p><h2 id="Page"><a href="#Page" class="headerlink" title="Page"></a>Page</h2><p><code>page</code><br>page是进行数据读写和操作的最小单位<br>但是和其他的框架中的Page定义不同的是，这里的<strong>page的大小并不一定</strong>，虽然不固定，但是也有一个阈值的<br>当超过阈值条件后，会进行页分裂，关于页分裂的参见下文</p><p>每一个Map的底层都是一个B+树，然后每一个节点都是一个Page<br>但是其实不是标准的B+树，是一种变形，叫<code>Counted B+ Tree</code><br>这个奇怪的结构，网上并没有找到介绍，但是其实就是进行了B+Tree的优化<br>参见我的另一个文章<strong>Counted-B+Tree原理</strong></p><p>一个Page的结构是<br><code>[length][checkSum][mapId][len][type][children][childCount][keys][values]</code></p><ul><li><code>length</code>：page的大小，int类型</li><li><code>checkSum</code>: checkSum，计算方式是<code>chunkId ^ page在chunk中的offset ^ length</code>，short类型</li><li><code>mapId</code>：page所属的map的id，variable size int类型 </li><li><code>len</code>：key的个数，variable size int类型</li><li><code>type</code>：page的类型，0代表叶子节点，1代表内部节点，如果值+2了表示key和value进行了LZF压缩，如果值+6表示key和value进行了Deflate压缩，byte类型</li><li><code>children</code>：long[]类型，值为子节点的位置，其中<ul><li>26bit为chunkId，</li><li>32bit为page在chunk中的offset，</li><li>5bit位lengthCode，标志page的maxLen<ul><li>0 =&gt; 32bytes</li><li>1 =&gt; 48bytes</li><li>2 =&gt; 64bytes</li><li>3 =&gt; 96bytes</li><li>…</li></ul></li><li>1bit为children的type，叶子节点还是内部节点</li></ul></li><li><code>childCount</code>：表示子节点中的key个数，类型是variable size long数组</li><li><code>keys</code>:放的是key，byte[]类型</li><li><code>values</code>：只有子节点有，放的是值，byte[]类型</li></ul><p>问：为什么不用绝对位置的信息来存放Page的位置呢<br>答：这样灵活性更大，可以移动整个chunk而不用进行Page位置的修改<br>问：什么时候会移动Chunk呢<br>答：目前没看到</p><h1 id="metaMap"><a href="#metaMap" class="headerlink" title="metaMap"></a>metaMap</h1><p>在文件初始化的时候，会创建一个metaMap<br>这个Map中存放的是文件的一些元信息<br>每次Chunk进行写入的时候，最后写入metaMap的Page的信息</p><p>metaMap中存放着这些信息</p><ul><li><code>name.{mapName}</code> =&gt; mapId，由map的名字对应MapId，mapId是16进制</li><li><code>map.{id}</code> =&gt; <code>name:{mapName}</code></li><li><code>root.{mapId}</code>：mapId所指的map的RootPage的位置</li><li><code>chunk.{chunkId}</code> =&gt; <code>chunk:2,block:3,len:1,liveMax:100,livePages:1,map:1,max:3c0,next:4,pages:5,root:800000be0a,time:824,version:2</code> 表示chunk为id的信息</li></ul><p>但是整个MVStore会进行GC的，就是定期清除那些有用的Page不多的Chunk，然后把空出来的空间放新的Chunk。<br>这就导致了一个问题，就是<strong>最新的Chunk不一定就是就在文件的最后</strong><br>所以怎么找到最新的MetaMap的地址呢<br>记得每个Chunk里有个next的KV吗，在MVStore进行初始化的时候，会直接读取最后一个Chunk，然后依次根据他的next值寻找下去，从而找到最后一个Chunk。</p><h1 id="文件新建"><a href="#文件新建" class="headerlink" title="文件新建"></a>文件新建</h1><p>h2抽象出了操作文件接口和上层的业务<br>文件的实现都是在<code>org.h2.store.fs.*</code>中，读写接口是FileChannel。<br>当我们调用</p><p><code>MVStore s = MVStore.open(&quot;/Users/zhuyichen/h2/data.mv&quot;);</code></p><p>时，MVStore会打开一个新的文件，当然是文件不存在的时候<br>写上<code>file header</code>部分，写两份<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">storeHeader.put(<span class="string">"H"</span>, <span class="number">2</span>);</span><br><span class="line">storeHeader.put(<span class="string">"blockSize"</span>, BLOCK_SIZE); <span class="comment">//BLOCK_SIZE = 4 * 1024</span></span><br><span class="line">storeHeader.put(<span class="string">"format"</span>, FORMAT_WRITE);  <span class="comment">//FORMAT_WRITE = 1</span></span><br><span class="line">storeHeader.put(<span class="string">"created"</span>, creationTime);</span><br></pre></td></tr></table></figure></p><h1 id="文件打开"><a href="#文件打开" class="headerlink" title="文件打开"></a>文件打开</h1><p>如果是打开旧的文件，那么会分为下面几个步骤</p><ul><li>读取Header信息</li><li>读取最后一个Chunk的Footer信息</li><li>读取最后一个Chunk的Header信息</li><li>定位MetaMap的位置</li><li>读取MetaMap的信息，定位所有Map的RootPage的信息</li></ul><p>所以其实整个核心就是找到MetaMap的位置，然后读取，只要得到MetaMap的信息，就可以找到所有的Map的位置了</p><p>这里还是略复杂，为了讲清楚，我们举例子<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">MVStore s = MVStore.open(<span class="string">"/Users/zhuyichen/h2/data.mv"</span>);</span><br><span class="line">MVMap&lt;Integer, String&gt; map1 = s.openMap(<span class="string">"data1"</span>);</span><br><span class="line">MVMap&lt;Integer, String&gt; map2 = s.openMap(<span class="string">"data2"</span>);</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++) &#123;</span><br><span class="line">    map1.put(i, <span class="string">"Hello1"</span>);</span><br><span class="line">    map2.put(i, <span class="string">"hello2"</span>);</span><br><span class="line">&#125;</span><br><span class="line">s.commit();</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">50</span>; i++) &#123;</span><br><span class="line">    map1.put(i, <span class="string">"hi1"</span>);</span><br><span class="line">    map2.put(i, <span class="string">"hi2"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">s.close();</span><br></pre></td></tr></table></figure></p><p>我们在运行上面的代码之后，会产生两个Chunk<br><img src="/images/mvstore/fileformat2.png" alt=""><br>如上图<br>第一个Chunk中包含了两个B+树  每一个RootPage包含四个Leaf Page<br>在第二次修改中，我们只修改了50个元素，所以没有动到第4个Leaf Page的数据<br>当我们进行commit之后，只save了3个Page，第4个没有动Page，我们还是指向了Chunk1的数据  具体的基于Page的B+树，请看下面</p><p>这里我们知道了文件的布局，下面看看文件的打开流程<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MVStore s = MVStore.open(<span class="string">"/Users/zhuyichen/h2/data.mv"</span>);</span><br></pre></td></tr></table></figure></p><p>当我们调用这句话的时候</p><h1 id="新建Map"><a href="#新建Map" class="headerlink" title="新建Map"></a>新建Map</h1><p>打开文件之后，新建一个Map实例</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MVMap&lt;String, String&gt; map = mvStore.openMap(<span class="string">"data"</span>);</span><br></pre></td></tr></table></figure><p>其实还有第二个参数，是Map的一些可配置参数<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">MVMap.Builder&lt;Integer, String&gt; mvMapConfig = <span class="keyword">new</span> MVMap.Builder&lt;&gt;();</span><br><span class="line">MVMap&lt;Integer, String&gt; map = s.openMap(<span class="string">"data1"</span>, mvMapConfig);</span><br></pre></td></tr></table></figure></p><p>参数列表</p><ul><li>keyType:  默认是ObjectDataType</li><li>valueType:  默认是ObjectDataType</li><li>singleWriter: </li></ul><p>我们假设文件是新建的，也就是metaMap中查询不到这个Map的信息<br>然后会给这个Map分配一个唯一的ID<br>然后向metaMap中写入自己的信息</p><p>然后新建一个空Leaf作为Map的RootPage，keys和values都是长度为0的数组</p><h1 id="基于Page的B-树"><a href="#基于Page的B-树" class="headerlink" title="基于Page的B+树"></a>基于Page的B+树</h1><p>每个Page上能放的key的个数是限制的</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">map.put(<span class="string">"key1"</span>, <span class="string">"value1"</span>);</span><br></pre></td></tr></table></figure><p>假设我们这么进行写入<br>假设我们是新打开的Map，那么此时Map上只有一个空的Leaf数组  </p><p>在进行写入之前，会对整个MVStore进行一个检查，检查文件的有效性<br>类似于JVM会检查Class文件的MagicWord，cafebabe一样。</p><p>下面就是查找过程，由于是Empty-Leaf，所以找到的index是-1。<br>继而把这个Leaf进行扩容，把<code>key1</code>放到Page对应的keys数组中<br>既然扩容values，把<code>value1</code>放到数组中</p><h2 id="页分裂"><a href="#页分裂" class="headerlink" title="页分裂"></a>页分裂</h2><p>页分裂的条件<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(keyCount = p.getKeyCount()) &gt; store.getKeysPerPage() || </span><br><span class="line">p.getMemory() &gt; store.getMaxPageSize() &amp;&amp; keyCount &gt; (p.isLeaf() ? <span class="number">1</span> : <span class="number">2</span>)</span><br></pre></td></tr></table></figure></p><p>看起来还是挺简单的</p><p>store.getKeysPerPage默认是48<br>store.getMaxPageSize和Cache有关，不过默认是64K<br>如果Page是Leaf的话，还必须至少有一个Value，是Node的话，至少有两个子节点<br>但是我理解的话，如果是因为内存过大而分裂，那么Node节点其实是不太可能的</p><h1 id="持久化流程"><a href="#持久化流程" class="headerlink" title="持久化流程"></a>持久化流程</h1><p>和正常的数据库一样，当我们读取和写入数据的时候，都会先从磁盘上把该数据所在的Page加载到内存中<br>然后持久化的最小单位也是Page<br>也就是说，如果Chunk 1中的Leaf Page中有48个KeyValue，但是我们只修改了<strong>一个Value</strong>，然后整个Page还是会持久化到Chunk 2中  </p><h2 id="手动持久化"><a href="#手动持久化" class="headerlink" title="手动持久化"></a>手动持久化</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mvStore.commit();</span><br><span class="line">mvStore.close();</span><br></pre></td></tr></table></figure><p>当我们手动进行commit或者直接close的时候，其实就是告诉MVStore进行一次Version的持久化<br>结果就是创建一个<code>Version = currentVersion</code>的Chunk</p><p>写chunk的时候，首先写入header<br>然后开始写Page的信息</p><p>写完用户的Map的Page信息之后，最后写入MetaMap的Pages</p><h2 id="后台定时持久化"><a href="#后台定时持久化" class="headerlink" title="后台定时持久化"></a>后台定时持久化</h2><p>在MVStore进行初始化之后，会启动一个后台线程<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">BackgroundWriterThread</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">while</span> (store.backgroundWriterThread != <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">synchronized</span> (sync) &#123;</span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        sync.wait(sleep);</span><br><span class="line">                    &#125; <span class="keyword">catch</span> (InterruptedException ignore) &#123;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (store.backgroundWriterThread == <span class="keyword">null</span>) &#123;</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                store.writeInBackground();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>同时传递给它一个sleep的time，每隔sleepTime，就进行一次commit，默认的sleep的时间是1000ms<br>当他醒来之后，如果发现数据有改变，就会进行一次commit</p><p>由于时间很短，所以正常情况下，不需要手动进行commit</p><p>在我们调用<code>MVStore#close</code>的时候，也会调用一次进行commit</p><h1 id="GC"><a href="#GC" class="headerlink" title="GC"></a>GC</h1><p>随着使用时间变长，肯定不会没有限制的创建Chunk的，MVStore也有回收机制，去回收很久之前的版本的Chunk<br>在官方文档中写的是</p><blockquote><p>Old data is kept for at least 45 seconds (configurable), so that there are no explicit sync operations required to guarantee data consistency. An application can also sync explicitly when needed. To reuse disk space, the chunks with the lowest amount of live data are compacted (the live data is stored again in the next chunk). To improve data locality and disk space usage, the plan is to automatically defragment and compact data.  </p></blockquote><p>我们知道MVStore不会保存所有的Version，很久之前的Version肯定会清除<br>那么就需要一个文件空间标记机制，标记那一块没有被使用已经被Free了，然后下面的Chunk进行写入的时候，可以复写那一块磁盘地址  </p><p>这个机制在MVStore的底层文件操作类FileStore中<br>底层使用了BitSet来表示，单位为BLOCK_SIZE<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">#FileStore</span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">final</span> FreeSpaceBitSet freeSpace =</span><br><span class="line">            <span class="keyword">new</span> FreeSpaceBitSet(<span class="number">2</span>, MVStore.BLOCK_SIZE);</span><br><span class="line">            </span><br><span class="line">            </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">markUsed</span><span class="params">(<span class="keyword">long</span> pos, <span class="keyword">int</span> length)</span> </span>&#123;</span><br><span class="line">        freeSpace.markUsed(pos, length);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="comment">//这个是核心方法，从FileStore中寻找length长度的位置</span></span><br><span class="line"><span class="comment">//注意，不是直接从文件末尾找一块地方</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">allocate</span><span class="params">(<span class="keyword">int</span> length)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> freeSpace.allocate(length);</span><br><span class="line">    &#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">predictAllocation</span><span class="params">(<span class="keyword">int</span> length)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> freeSpace.predictAllocation(length);</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">//free从pos开始的空间</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">free</span><span class="params">(<span class="keyword">long</span> pos, <span class="keyword">int</span> length)</span> </span>&#123;</span><br><span class="line">        freeSpace.free(pos, length);</span><br><span class="line">    &#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getFillRate</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> freeSpace.getFillRate();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">long</span> <span class="title">getFirstFree</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> freeSpace.getFirstFree();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">long</span> <span class="title">getFileLengthInUse</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> freeSpace.getLastFree();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p><p>在我们进行store的时候<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">MVStore#storeNow()</span><br><span class="line"><span class="keyword">long</span> filePos = allocateFileSpace(length, !reuseSpace);</span><br></pre></td></tr></table></figure></p><p>就能看到分配的逻辑在里面</p><p>同时我们还能看到Free的方法在里面，就是标记一块Chunk所在的地方已经可以进行reuse<br>那么怎么进行判定了，从上图我们可以知道其实即使在Chunk2中，还是有Page是引用的Chunk1</p><p>MVStore解决的方法也比较简单，就是DFS<br>遍历所有的Map的Node和Page，找到一个Chunk，就把ChunkId放在一个Map中，最后遍历当前文件中的所有Chunk，如果在Map中未找到，那么就是可以回收的<br>有点类似引用计数的方法，但是会不会出现循环引用呢<br>由于所有的Map的RootMap都是存在最新的Chunk中，所有不会出现循环引用的情况</p><p>方法在<code>MVStore#collectReferencedChunks</code><br>这里为了加速DFS的速度，还启动了一个线程池</p><p>带来的问题：<br>GC的机制也带来了问题，就是最新的Chunk在哪儿的问题<br>我们知道如果真的是Log Structed FS的格式的话，那么最新写入的肯定是在最后，而MetaMap的Root Page是在最新的Chunk中的<br>所以我们需要一个机制在打开文件的时候，找到最新的Chunk的位置<br>这个查找的过程，前面已经描述了一遍了</p><h1 id="Compact"><a href="#Compact" class="headerlink" title="Compact"></a>Compact</h1><p>当一个Chunk中LivePages比较少的时候，H2会进行Compact<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MVStore#compact</span><br></pre></td></tr></table></figure></p><p>Compact的方式<br>我只能表示非常的tricky<br>把LivePages中比较少的Page上的数据，全部replace了一遍，这样Chunk1指向chunk0的数据相当于全部update了一遍，但是数据没有变化</p><p>等Compact完之后，再进行上面一步</p><h1 id="Page-Cache"><a href="#Page-Cache" class="headerlink" title="Page Cache"></a>Page Cache</h1><p>Page的Cache机制不是LRU，而是LIRS<br>说实话这种Cache机制我是第一次见</p><h1 id="Debug技巧"><a href="#Debug技巧" class="headerlink" title="Debug技巧"></a>Debug技巧</h1><h2 id="源码环境导入Idea"><a href="#源码环境导入Idea" class="headerlink" title="源码环境导入Idea"></a>源码环境导入Idea</h2><p>会出现提示<code>configure OSGI</code>，<strong>别点</strong></p><h2 id="dump-file"><a href="#dump-file" class="headerlink" title="dump file"></a>dump file</h2><p>如果想要观察Commit发生了什么<br>可以把<code>BackgroundWriterThread</code>给关闭了，防止在背后每隔1s自己<code>commit</code><br>h2的作者提供了一个dump方法<br><code>MVStoreTool.dump()</code><br>可以把文件的内容打印出来</p><h1 id="PR"><a href="#PR" class="headerlink" title="PR"></a>PR</h1><p>在阅读MVStore源码的过程中，还发现了一个comment的错误<br>已经提了PR进行了修复</p><h1 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h1><ul><li><a href="http://www.h2database.com/html/mvstore.html" target="_blank" rel="noopener">http://www.h2database.com/html/mvstore.html</a></li><li><a href="https://en.wikipedia.org/wiki/Variable-length_quantity" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Variable-length_quantity</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;MVStore是h2数据库的底层的存储文件格式&lt;br&gt;在1.4版本之前底层的文件存储都是&lt;code&gt;org.h2.store.*&lt;/code&gt;包中的&lt;br&gt;然后1.4之后默认改为了&lt;code&gt;org.h2.mvstore.*&lt;/code&gt;包中的  &lt;/p&gt;
&lt;p&gt;官方的介绍说是根据&lt;code&gt;Log Structed FS&lt;/code&gt;设计的，顺序写提高性能&lt;/p&gt;
&lt;p&gt;MV的意思是&lt;code&gt;multi-version&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;同类型的项目有个叫&lt;code&gt;mapDB&lt;/code&gt;的项目&lt;br&gt;&lt;a href=&quot;https://github.com/jankotek/mapdb&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/jankotek/mapdb&lt;/a&gt;  &lt;/p&gt;
&lt;p&gt;还有一个Apache的项目&lt;code&gt;mavibot&lt;/code&gt;&lt;br&gt;&lt;a href=&quot;http://directory.apache.org/mavibot/downloads.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://directory.apache.org/mavibot/downloads.html&lt;/a&gt;  &lt;/p&gt;
    
    </summary>
    
    
      <category term="数据库" scheme="https://blog.lovezhy.cc/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="h2" scheme="https://blog.lovezhy.cc/tags/h2/"/>
    
  </entry>
  
  <entry>
    <title>HotSpot原理指南-oop-klass模型</title>
    <link href="https://blog.lovezhy.cc/2019/02/16/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-oop-klass%E6%A8%A1%E5%9E%8B/"/>
    <id>https://blog.lovezhy.cc/2019/02/16/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-oop-klass%E6%A8%A1%E5%9E%8B/</id>
    <published>2019-02-15T16:00:00.000Z</published>
    <updated>2020-02-29T14:36:13.102Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>看任何JVM的书，oop-klass总是绕不去的坎<br>我一直想理解这些，但是就是理解不了，但是也说不出哪里不明白。</p><p>这篇文章不会对这个模型做系统的阐述，假设读者已经看过oop-klass模型，但是还是有点一知半解的状态。</p><h2 id="oop-klass"><a href="#oop-klass" class="headerlink" title="oop-klass"></a>oop-klass</h2><p><strong>为什么要这么设计？</strong><br>其实很多书也提到，既然HotSpot完全基于C++去编写，要实现多态完全可以进行C++层面的转换就行。<br>但是C++的多态其实每一个对象都维护了一个VTable，就是虚函数表，函数表可以理解为一个函数指针的数组，这个数组在内存上和一个对象是一起的。<br>但是很多书中提到，为了避免每个对象都有一个VTable，JVM定义了oop-klass模型，其中oop就是保存数据结构的，而klass则担当了一部分VTable的功能，这样的话，<strong>VTable就是每个类只存在一个</strong>。<br>也就是说，对oop而言，它对应的klass是单例的，而Java层面每New一个对象，都会在JVM生成一个oop。</p><p>所以在Java中，类和对象的关系更像是这样:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Student student1 = <span class="keyword">new</span> Student(<span class="string">"zhang"</span>, <span class="number">19</span>);</span><br><span class="line">        Student student2 = <span class="keyword">new</span> Student(<span class="string">"wang"</span>, <span class="number">20</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> age;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Student</span><span class="params">(String name, <span class="keyword">int</span> age)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">        <span class="keyword">this</span>.age = age;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><img src="/images/oop-klass/oop1.png" alt="">  </p><h2 id="动态绑定与VTable"><a href="#动态绑定与VTable" class="headerlink" title="动态绑定与VTable"></a>动态绑定与VTable</h2><p>这里再提一个我对动态绑定的理解。<br>其实动态绑定这个概念，大家都知道大概是个什么意思，但是再详细的说，就理不清很多细节。 </p><p>现在我们都知道动态绑定是和虚表有关，在Java字节码中，需要动态绑定的指令是<code>invokevirtual</code>。<br><a href="https://cs.au.dk/~mis/dOvs/jvmspec/ref--35.html" target="_blank" rel="noopener">https://cs.au.dk/~mis/dOvs/jvmspec/ref–35.html</a><br>这个ref中讲的是，动态绑定需要一个寻找函数的过程</p><blockquote><p>invokevirtual retrieves the Java class for objectref, and searches the list of methods defined by that class and then its superclasses, looking for a method called methodname, whose descriptor is descriptor.</p></blockquote><p>这当然我感觉是一种很扯淡的说法，要是这么来，运行时时间都花在匹配函数上去了。<br>而寻找函数的过程，我理解<strong>完全可以放在编译期去完成</strong>。<br>我更认同是这种方式，就是不需要进行运行时的函数匹配，动态绑定的意思是需要在运行时改变代码段的函数指针，类似于下面文章中提到的<br><a href="https://www.jianshu.com/p/fa50296b301c" target="_blank" rel="noopener">https://www.jianshu.com/p/fa50296b301c</a></p><blockquote><p>编译器内部会发生转换，产生类似下面的代码：<br>( <em>( p-&gt;vptr )[0] ) (p);  //</em>( p-&gt;vptr )[0]是函数入口地址</p></blockquote><p>这段代码的生成，对于C++而言是编译时，对于Java则是ClassLoader的时候，并不是运行时。</p><p>关于动态绑定，还有一些其他模棱两可的说法<br>比如这个文章中<br><a href="https://zhuanlan.zhihu.com/p/24317613" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/24317613</a></p><p>它提到在<code>invokevirtual</code>的调用过程，需要去查父类的方法表</p><blockquote><p>(2) 在Father类型的方法表中查找方法f1，如果找到，则将方法f1在方法表中的索引项11(如上图)记录到AutoCall类的常量池中第15个常量表中(常量池解析 )。这里有一点要注意：如果Father类型方法表中没有方法f1，那么即使Son类型中方法表有，编译的时候也通过不了。因为调用方法f1的类的对象father的声明为Father类型。</p></blockquote><p>这我也是觉得是脱裤子放屁的说法，为啥要去查父类的方法表，要知道父类的方法表，是在另外一个Klass对象里，要是继承链比较长，那么需要很多次指针寻址才能找到。</p><p>其实这个和另外一个比较经典的动态绑定的解释很像：</p><blockquote><p>如果子类Son中定义了 method() 的方法，则直接调用子类中的相应方法；如果子类Son中没有定义相应的方法，则到其父类中寻找method()方法。</p></blockquote><p>很多人把这个过程理解为动态绑定，这个的问题也是一样的，它的假设是子类的Klass对象中没有父类的方法指针，所以需要去父类的Klass的VTable中去找。</p><p>但是通过一些文章我们可以看出，其实子类的VTable完全的Copy了一份父类的VTable。<br><a href="https://stackoverflow.com/questions/18082651/how-does-dynamic-binding-happens-in-jvm" target="_blank" rel="noopener">https://stackoverflow.com/questions/18082651/how-does-dynamic-binding-happens-in-jvm</a><br><a href="https://cloud.tencent.com/developer/article/1180981" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/1180981</a>  </p><p>所以至此，整个动态绑定的过程我们就已经理解，所谓动态绑定，就是比静态绑定多了一个指针寻址，去Klass中找VTable的过程。</p><h2 id="1-7到1-8"><a href="#1-7到1-8" class="headerlink" title="1.7到1.8"></a>1.7到1.8</h2><p>很多书中都提到，oop-klass模型在1.8中改变较大。<br>原因是1.8中去掉了永久代（Perm），而改为了元空间(MetaSpace)。</p><p>我们先看看1.7中的oop-klass的继承链<br><a href="https://github.com/openjdk-mirror/jdk7u-hotspot/blob/master/src/share/vm/oops/oopsHierarchy.hpp" target="_blank" rel="noopener">https://github.com/openjdk-mirror/jdk7u-hotspot/blob/master/src/share/vm/oops/oopsHierarchy.hpp</a>   </p><p>oop继承链<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">typedef <span class="class"><span class="keyword">class</span> <span class="title">oopDesc</span>*                            <span class="title">oop</span></span>;</span><br><span class="line">typedef <span class="class"><span class="keyword">class</span>   <span class="title">instanceOopDesc</span>*            <span class="title">instanceOop</span></span>;</span><br><span class="line">typedef <span class="class"><span class="keyword">class</span>   <span class="title">methodOopDesc</span>*                    <span class="title">methodOop</span></span>;</span><br><span class="line">typedef <span class="class"><span class="keyword">class</span>   <span class="title">constMethodOopDesc</span>*            <span class="title">constMethodOop</span></span>;</span><br><span class="line">typedef <span class="class"><span class="keyword">class</span>   <span class="title">methodDataOopDesc</span>*            <span class="title">methodDataOop</span></span>;</span><br><span class="line">typedef <span class="class"><span class="keyword">class</span>   <span class="title">arrayOopDesc</span>*                    <span class="title">arrayOop</span></span>;</span><br><span class="line">typedef <span class="class"><span class="keyword">class</span>     <span class="title">objArrayOopDesc</span>*            <span class="title">objArrayOop</span></span>;</span><br><span class="line">typedef <span class="class"><span class="keyword">class</span>     <span class="title">typeArrayOopDesc</span>*            <span class="title">typeArrayOop</span></span>;</span><br><span class="line">typedef <span class="class"><span class="keyword">class</span>   <span class="title">constantPoolOopDesc</span>*            <span class="title">constantPoolOop</span></span>;</span><br><span class="line">typedef <span class="class"><span class="keyword">class</span>   <span class="title">constantPoolCacheOopDesc</span>*   <span class="title">constantPoolCacheOop</span></span>;</span><br><span class="line">typedef <span class="class"><span class="keyword">class</span>   <span class="title">klassOopDesc</span>*                    <span class="title">klassOop</span></span>;</span><br><span class="line">typedef <span class="class"><span class="keyword">class</span>   <span class="title">markOopDesc</span>*                    <span class="title">markOop</span></span>;</span><br><span class="line">typedef <span class="class"><span class="keyword">class</span>   <span class="title">compiledICHolderOopDesc</span>*    <span class="title">compiledICHolderOop</span></span>;</span><br></pre></td></tr></table></figure></p><p>klass继承链<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Klass</span></span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span>   <span class="title">instanceKlass</span></span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span>     <span class="title">instanceMirrorKlass</span></span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span>     <span class="title">instanceRefKlass</span></span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span>   <span class="title">methodKlass</span></span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span>   <span class="title">constMethodKlass</span></span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span>   <span class="title">methodDataKlass</span></span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span>   <span class="title">klassKlass</span></span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span>     <span class="title">instanceKlassKlass</span></span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span>     <span class="title">arrayKlassKlass</span></span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span>       <span class="title">objArrayKlassKlass</span></span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span>       <span class="title">typeArrayKlassKlass</span></span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span>   <span class="title">arrayKlass</span></span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span>     <span class="title">objArrayKlass</span></span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span>     <span class="title">typeArrayKlass</span></span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span>   <span class="title">constantPoolKlass</span></span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span>   <span class="title">constantPoolCacheKlass</span></span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span>   <span class="title">compiledICHolderKlass</span></span>;</span><br></pre></td></tr></table></figure></p><p>可以说是非常多</p><p>但是到了1.8中，就变的很少<br>oop继承链<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">class</span> <span class="title">oopDesc</span>*                            <span class="title">oop</span>;</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">class</span>   <span class="title">instanceOopDesc</span>*            <span class="title">instanceOop</span>;</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">class</span>   <span class="title">arrayOopDesc</span>*                    <span class="title">arrayOop</span>;</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">class</span>     <span class="title">objArrayOopDesc</span>*            <span class="title">objArrayOop</span>;</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">class</span>     <span class="title">typeArrayOopDesc</span>*            <span class="title">typeArrayOop</span>;</span></span><br></pre></td></tr></table></figure></p><p>klass继承链<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Klass</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span>   <span class="title">InstanceKlass</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span>     <span class="title">InstanceMirrorKlass</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span>     <span class="title">InstanceClassLoaderKlass</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span>     <span class="title">InstanceRefKlass</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span>   <span class="title">ArrayKlass</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span>     <span class="title">ObjArrayKlass</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span>     <span class="title">TypeArrayKlass</span>;</span></span><br></pre></td></tr></table></figure></p><p>而少掉的那部分，其实只是换了个名字，叫做Metadata<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//      class MetaspaceObj</span></span><br><span class="line"><span class="class"><span class="keyword">class</span>   <span class="title">ConstMethod</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span>   <span class="title">ConstantPoolCache</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span>   <span class="title">MethodData</span>;</span></span><br><span class="line"><span class="comment">//      class Metadata</span></span><br><span class="line"><span class="class"><span class="keyword">class</span>   <span class="title">Method</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span>   <span class="title">ConstantPool</span>;</span></span><br><span class="line"><span class="comment">//      class CHeapObj</span></span><br><span class="line"><span class="class"><span class="keyword">class</span>   <span class="title">CompiledICHolder</span>;</span></span><br></pre></td></tr></table></figure></p><p>可能你已经猜到了，Metadata的这部分，已经全部转移到了元空间。</p><p>以下是 JDK 1.7 中的类在 JDK 1.8 中的存在形式：</p><ul><li>klassOop -&gt; Klass*</li><li>klassKlass 不再需要</li><li>methodOop -&gt; Method*</li><li>methodDataOop -&gt; MethodData*</li><li>constMethodOop -&gt; ConstMethod*</li><li>constantPoolOop -&gt; ConstantPool*</li><li>constantPoolCacheOop -&gt; ConstantPoolCache*</li></ul><p>Klass少掉的部分，还可以理解，但是为啥oop会少了这么多。</p><p>这里就牵扯到永久代和元空间的区别了。</p><p>首先的问题是，为什么撤销永久代而换成元空间<br>我找到了当初的JEP<br><a href="http://openjdk.java.net/jeps/122?spm=a2c4e.11153940.blogcont20279.13.13fd33dbw7ltIv" target="_blank" rel="noopener">http://openjdk.java.net/jeps/122?spm=a2c4e.11153940.blogcont20279.13.13fd33dbw7ltIv</a></p><blockquote><p>永久代的调优非常难，永久代的大小很难确定，其中涉及到太多因素，如类的总数、常量池大小和方法数量等，而且永久代的数据可能会随着每一次Full GC而发生移动。</p></blockquote><p>这里就要提到元空间的特点</p><blockquote><p>Symbols were moved to the native heap<br>Interned strings were moved to the Java Heap<br>Class statics were moved to the Java Heap</p></blockquote><ul><li>永久代属于堆，有大小限制。元空间使用堆外内存，理论上无内存限制</li><li>JDK7之前的HotSpot，字符串常量池的字符串被存储在永久代中，因此可能导致一系列的性能问题和内存溢出错误。在JDK8中，字符串常量池中只保存字符串的引用。</li></ul><p>而如果你去看JDK1.7的oopDesc的定义，你会发现一个奇怪的事<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">oopDesc</span> &#123;</span></span><br><span class="line">  <span class="keyword">friend</span> <span class="class"><span class="keyword">class</span> <span class="title">VMStructs</span>;</span></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="keyword">volatile</span> markOop  _mark;</span><br><span class="line">  <span class="keyword">union</span> _metadata &#123;</span><br><span class="line">    wideKlassOop    _klass;</span><br><span class="line">    narrowOop       _compressed_klass;</span><br><span class="line">  &#125; _metadata;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>这里的Klass，为什么是Oop对象？</p><p>这里引用R大的解释<br><a href="https://rednaxelafx.iteye.com/blog/858009" target="_blank" rel="noopener">https://rednaxelafx.iteye.com/blog/858009</a></p><blockquote><p>因为HotSpot 1.7之前，包括Class在内的元数据对象都需要被GC管理，因此这四列的对象其实都是oopDesc类型，只不过第一列是描述实例的instanceOopDes, 第二三四列为klassOopDesc；这个klassOopDesc可以看作是klass的一个wrapper，仅仅为了被gc更容易滴管理和表示，它的内部有一个klass成员来表达klass的信息。<br>所以第二列的 klassOopDesc 内部的klass 乃Integer类的klass，第三列的klass为 klassOopDesc这个对象的klass——instanceKlassKlass，那第三列这个类的klass是什么呢？由于描述instanceKlassKlass，methodKlassKlass，xxxxKlassKlass等一大票KlassKlass需要的元数据实际上是相同的，他们就是第四列的KlassKlass，第四列的KlassKlass的klass可以用它自己来描述，于是就圆满了。</p></blockquote><p>简单说就是为了偷懒，用Oop包裹一层，让GC一同管理了。<br>到了元方法区，已经不属于堆了，自然不需要这个了，自然可以去掉。</p><p>所以到了1.8，就变成了正常的状态<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">oopDesc</span> &#123;</span></span><br><span class="line">  <span class="keyword">volatile</span> markOop _mark;</span><br><span class="line">  <span class="keyword">union</span> _metadata &#123;</span><br><span class="line">    Klass*      _klass;</span><br><span class="line">    narrowKlass _compressed_klass;</span><br><span class="line">  &#125; _metadata;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="MarkOop"><a href="#MarkOop" class="headerlink" title="MarkOop"></a>MarkOop</h2><p>还有一些细节，我还是比较困惑的。<br>比如这个MarkOop的定义<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">markOopDesc</span>:</span> <span class="keyword">public</span> oopDesc &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>它是继承于oopDesc的<br>但是在oopDesc的定义中<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">oopDesc</span> &#123;</span></span><br><span class="line">  <span class="keyword">volatile</span> markOop _mark;</span><br><span class="line">  <span class="keyword">union</span> _metadata &#123;</span><br><span class="line">    Klass*      _klass;</span><br><span class="line">    narrowKlass _compressed_klass;</span><br><span class="line">  &#125; _metadata;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>又用到了markOop</p><p>好吧，这个是一件比较奇怪的是。</p><p>上面R大提到，继承与oopDesc的都是被GC管理的，<br>但是这里有个奇怪的点</p><p>MarkOop存在于OopDesc中，讲道理应该是个对象才是，但是它的作用却只是作为对象头。<br>在Java层面没有与之对应的东西。<br>更没有道理要被GC管理着啊</p><p>我翻阅文档的注释<br>发现了这么一句话<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Note that the mark is not a real oop but just a word.</span></span><br><span class="line"><span class="comment">// It is placed in the oop hierarchy for historical reasons.</span></span><br><span class="line"><span class="comment">//</span></span><br></pre></td></tr></table></figure></p><p>既然官方解释是<strong>历史原因</strong>，那就不追究这个问题了。</p><h2 id="JIT热点探测"><a href="#JIT热点探测" class="headerlink" title="JIT热点探测"></a>JIT热点探测</h2><p>这个算是一个小发现<br>我们查看oop的体系，发现Method也有对应的oop<br>在method的oop中，有个变量叫MethodCounters<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MethodCounters</span> :</span> <span class="keyword">public</span> Metadata &#123;</span><br><span class="line"> <span class="keyword">friend</span> <span class="class"><span class="keyword">class</span> <span class="title">VMStructs</span>;</span></span><br><span class="line"> <span class="keyword">friend</span> <span class="class"><span class="keyword">class</span> <span class="title">JVMCIVMStructs</span>;</span></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> INCLUDE_AOT</span></span><br><span class="line">  Method*           _method;                     <span class="comment">// Back link to Method</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> defined(COMPILER2) || INCLUDE_JVMCI</span></span><br><span class="line">  <span class="keyword">int</span>               _interpreter_invocation_count; <span class="comment">// Count of times invoked (reused as prev_event_count in tiered)</span></span><br><span class="line">  u2                _interpreter_throwout_count; <span class="comment">// Count of times method was exited via exception while interpreting</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> INCLUDE_JVMTI</span></span><br><span class="line">  u2                _number_of_breakpoints;      <span class="comment">// fullspeed debugging support</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">  InvocationCounter _invocation_counter;         <span class="comment">// Incremented before each activation of the method - used to trigger frequency-based optimizations</span></span><br><span class="line">  InvocationCounter _backedge_counter;           <span class="comment">// Incremented before each backedge taken - used to trigger frequencey-based optimizations</span></span><br></pre></td></tr></table></figure></p><p>这个类维护了几个关于方法调用次数的计数器，和JIT的热点探测有关</p><p>具体的细节可以查看<br><a href="https://www.jianshu.com/p/1ea9b3d1abb9" target="_blank" rel="noopener">https://www.jianshu.com/p/1ea9b3d1abb9</a> </p><p><a href="http://mail.openjdk.java.net/pipermail/hotspot-compiler-dev/2011-June/005750.html" target="_blank" rel="noopener">http://mail.openjdk.java.net/pipermail/hotspot-compiler-dev/2011-June/005750.html</a></p><h2 id="HSDB"><a href="#HSDB" class="headerlink" title="HSDB"></a>HSDB</h2><p>这个工具，可以用来查看运行时的oop和klass数据<br>简单的使用，网上可以随便百度到，这里介绍下怎么查看虚表<br><a href="https://cloud.tencent.com/developer/article/1180981" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/1180981</a>  </p><h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><ul><li><a href="https://www.sczyh30.com/posts/Java/jvm-klass-oop/" target="_blank" rel="noopener">https://www.sczyh30.com/posts/Java/jvm-klass-oop/</a></li><li><a href="https://book.douban.com/subject/25847620/" target="_blank" rel="noopener">《HotSpot实战》</a></li><li><a href="https://book.douban.com/subject/27086821/" target="_blank" rel="noopener">《揭秘Java虚拟机》</a></li><li><a href="https://www.cnblogs.com/paddix/p/5309550.html" target="_blank" rel="noopener">https://www.cnblogs.com/paddix/p/5309550.html</a></li><li><a href="https://www.slideshare.net/cafusic/jvm20101228?from_action=save" target="_blank" rel="noopener">R大的JVM分享，强烈推荐</a></li><li><a href="https://blogs.oracle.com/poonam/about-g1-garbage-collector,-permanent-generation-and-metaspace" target="_blank" rel="noopener">oracle文档中对元空间的解释</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;看任何JVM的书，oop-klass总是绕不去的坎&lt;br&gt;我一直想理解这些，但是就是理解不了，但是也说不出哪里不明白。&lt;/p&gt;
&lt;p&gt;这篇文
      
    
    </summary>
    
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/categories/HotSpot/"/>
    
    
      <category term="JVM" scheme="https://blog.lovezhy.cc/tags/JVM/"/>
    
      <category term="OopKlass" scheme="https://blog.lovezhy.cc/tags/OopKlass/"/>
    
  </entry>
  
  <entry>
    <title>十万嬉皮</title>
    <link href="https://blog.lovezhy.cc/2019/01/05/%E5%8D%81%E4%B8%87%E5%AC%89%E7%9A%AE/"/>
    <id>https://blog.lovezhy.cc/2019/01/05/%E5%8D%81%E4%B8%87%E5%AC%89%E7%9A%AE/</id>
    <published>2019-01-04T16:00:00.000Z</published>
    <updated>2020-02-29T14:43:57.539Z</updated>
    
    <content type="html"><![CDATA[<h1 id="十万嬉皮-万能青年旅店"><a href="#十万嬉皮-万能青年旅店" class="headerlink" title="十万嬉皮 - 万能青年旅店"></a><strong>十万嬉皮 - 万能青年旅店</strong></h1><p>大梦一场的董二千先生</p><a id="more"></a><p>推开窗户，举起望远镜</p><p>眼底映出，一阵浓烟</p><p>前已无通路，后不见归途</p><p>敌视现实，虚构远方</p><p>东张西望，一无所长</p><p>四体不勤，五谷不分</p><p>文不能测字，武不能防身</p><p>喜欢养狗，不爱洗头</p><p>不事劳作，一无所获</p><p>厌恶争执，不善言说</p><p>终于沦为沉默的帮凶</p><p>借酒浇愁，不太能喝</p><p>蛊惑他人，麻醉内心</p><p>浇上汽油，舒展眉头</p><p>纵火的青年，迫近的时间</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;十万嬉皮-万能青年旅店&quot;&gt;&lt;a href=&quot;#十万嬉皮-万能青年旅店&quot; class=&quot;headerlink&quot; title=&quot;十万嬉皮 - 万能青年旅店&quot;&gt;&lt;/a&gt;&lt;strong&gt;十万嬉皮 - 万能青年旅店&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;大梦一场的董二千先生&lt;/p&gt;
    
    </summary>
    
    
      <category term="我的生活" scheme="https://blog.lovezhy.cc/categories/%E6%88%91%E7%9A%84%E7%94%9F%E6%B4%BB/"/>
    
    
      <category term="Life" scheme="https://blog.lovezhy.cc/tags/Life/"/>
    
  </entry>
  
</feed>
