<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>LoveZhy</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://blog.lovezhy.cc/"/>
  <updated>2020-06-08T15:21:22.775Z</updated>
  <id>https://blog.lovezhy.cc/</id>
  
  <author>
    <name>zhy</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>论文翻译-What’s-Really-New-wit-NewSQL</title>
    <link href="https://blog.lovezhy.cc/2020/06/08/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91-What%E2%80%99s-Really-New-with-NewSQL/"/>
    <id>https://blog.lovezhy.cc/2020/06/08/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91-What%E2%80%99s-Really-New-with-NewSQL/</id>
    <published>2020-06-07T16:00:00.000Z</published>
    <updated>2020-06-08T15:21:22.775Z</updated>
    
    <content type="html"><![CDATA[<p><strong><a href="/files/newsql.pdf">论文PDF下载</a></strong></p><a id="more"></a><h2 id="标题"><a href="#标题" class="headerlink" title="标题"></a>标题</h2><p><strong>What’s Really New with NewSQL?</strong></p><p>Andrew Pavlo Carnegie Mellon University pavlo@cs.cmu.edu</p><p>Matthew Aslett 451 Research matthew.aslett@451research.com</p><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>一类新的数据库管理系统(DBMSs)被称为NewSQL，它声称自己有能力以传统系统所不具备的方式扩展现代在线交易处理(OLTP)的工作负载。</p><p>这篇论文的作者之一（论文的两位作者分别是pavlo和matthew.aslett）在2011年的一份商业分析报告中首次使用了NewSQL这个术语，该报告讨论了新的数据库系统作为对这些老牌厂商（Oracle、IBM、微软）的挑战者的崛起。</p><p>而另一位作者则是第一批研究NewSQL DBMS的人。</p><p>从那时起，一些公司和研究项目都用这个词来描述他们的系统（无论他们是否使用正确）。</p><p><br><br>考虑到关系型DBMS已经有四十多年的历史，我们有理由问一下，NewSQL的优越性的说法是真的，还是仅仅是营销手段。</p><p>如果它们确实能够获得更好的性能，那么接下来的问题是，它们是否有什么新技术使它们能够获得这些优势，还是说硬件已经进步了很多，以至于现在早些年的瓶颈不再是问题。</p><p><br><br>为了做到这一点，我们首先讨论数据库的历史，以说明NewSQL系统是如何产生的。</p><p>然后，我们将详细解释NewSQL这个词的含义，以及属于这个定义下的不同类别的系统。</p><h2 id="1-DBMS简史"><a href="#1-DBMS简史" class="headerlink" title="1. DBMS简史"></a>1. DBMS简史</h2><p>最早的DBMS是在1960年代中期上线的。</p><p>最早的其中一个是IBM的IMS系统，用于跟踪土星五号和阿波罗太空探索项目的物资和零件库存。</p><p>它引入了应用程序的代码应该和它所操作的数据分开的理念。这使得开发人员可以编写的应用程序只关注数据的访问和操作，而不是与如何实际执行这些操作相关的复杂性和开销。</p><p>IMS之后，在20世纪70年代初，IBM公司的System R和加州大学的INGRES等第一批关系型DBMS的开创性工作也随之而来。INGRES很快被其他大学的信息系统所采用，并在70年代末实现了商业化。</p><p>大约在同一时间，甲骨文公司发布了他们的第一个DBMS版本，与System R的设计相似。<br>1980年代初，其他的公司也纷纷成立，试图重复第一批商业化DBMS的成功，包括Sybase和Informix。</p><p>尽管IBM从未向公众提供过System R，但它后来在1983年发布了一个新的关系型DBMS (DB2)，其使用了System R的部分代码库。</p><p><br><br>20世纪80年代末和90年代初诞生了一类新的DBMS，这些DBMS的设计是为了克服关系模型和面向对象编程语言之间的阻抗不匹配的问题。</p><p>然而，这些面向对象的DBMS从未在市场上得到广泛的应用，因为它们缺乏像SQL那样的标准接口。</p><p>但是当十年后各大厂商增加了对对象和XML的支持时，其中的许多想法最终被纳入到了面向对象的<br>DBMS中，20多年后又在面向文档的NoSQL系统中再次被纳入。</p><p><br><br>在90年代，另一个值得注意的事件是今天的两个主要的开源DBMS项目的开始。</p><p>MySQL是1995年在瑞典开始的，它是基于早期基于ISAM的mSQL系统。</p><p>PostgreSQL开始于1994年，当时两个伯克利大学的研究生fork了20世纪80年代原始的基于QUEL的Post-gres代码，增加了对SQL的支持。</p><p><br><br>2000年代，互联网应用的出现，对硬件资源的要求比前几年的应用更具挑战性。</p><p>它们需要扩大规模以支持大量的并发用户，并且必须一直在线。<br>但这些新应用使用的数据库一直是一个瓶颈，因为资源需求远远超过了当时的DBMS和硬件所能支持的范围。  </p><p>许多人尝试了最简单的选择，即通过将数据库移动到具有更好的硬件的机器上，垂直扩展他们的DBMS。<br>然而，这样做只能提高性能，回报率却越来越低。  </p><p>此外，将数据库从一台机器移动到另一台机器是一个复杂的过程，往往需要大量的停机时间，这对于这些基于Web的应用来说是不可接受的。  </p><p>为了克服这个问题，一些公司创建了定制的中间件，将单节点的DBMS分片到成本较低的机器集群上。这样的中间件向应用程序展示了一个存储在多个物理节点上的单一逻辑数据库。</p><p>当应用程序针对这个数据库发出查询时，中间件会重定向和/或重写它们，将它们分配到集群中的一个或多个节点上执行。</p><p>节点执行这些查询，并将结果发送回中间件，中间件再将其汇总成一个单一的响应给应用。</p><p>这种中间件方法的两个显著例子是eBay的基于Oracle的集群和Google的基于MySQL的集群。</p><p>这种方法后来被Facebook采用，他们自己的MySQL集群至今仍在使用。</p><p><br><br>Sharding 中间件对于简单的操作，如读取或更新一条记录，效果很好。</p><p>但要在事务或联接表中执行更新一条以上记录的查询则比较困难。</p><p>因此，这些早期的中间件系统并不支持这些类型的操作。例如，eBay在2002年的中间件，要求其开发人员在应用级代码中实现所有的join操作。</p><p><br><br>最终，这些公司中的一些脱离了中间件，开发了自己的分布式DBMS。</p><p>这样做的动机有三个方面。</p><p>最重要的是，当时传统的DBMS注重一致性和正确性，而牺牲了可用性和性能。但这种权衡被认为不适合于需要一直在线并需要进行大量并发操作的基于Web的应用程序。</p><p>其次，有人认为使用像MySQL这样的全功能DBMS作为 “哑巴 “数据存储，会有太多的开销。</p><p>同样，也有人认为关系型模型不是表示应用程序数据的最佳方式，使用SQL对于简单的查询查询来说是一种过度的做法。</p><p><br><br>这些问题被证明是2000年代中后期NoSQL1运动的推动力的起源。</p><p>这些NoSQL系统的核心是放弃了传统DBMS的强大的事务保证和关系模型，而倾向于最终的一致性和替代性数据模型（例如，键/值、图、文档）。</p><p>这是因为有些人认为，现有的DBMS的特点抑制了它们的扩展能力和实现Web的应用所需的高可用<br>性。</p><p>最早遵循这一信条最著名的两个系统是Google的BigTable和Amazon的Dynamo。</p><p>这两个系统一开始都不在各自公司之外出现（尽管它们现在是以云服务的形式出现），因此，其他组织创建了自己的开源克隆系统。</p><p>这些包括Facebook的Cassandra（基于BigTable和Dynamo）和PowerSet的Hbase（基于BigTable）。</p><p>其他初创公司创建了自己的系统，这些系统不一定是Google或Amazon的系统的复制品，但仍然遵循NoSQL哲学的原则；其中最著名的是MongoDB。</p><p><br><br>到了2000年代末，现在已经有了多种多样的、可扩展的、更实惠的分布式DBMS。</p><p>使用NoSQL系统的好处是，开发人员可以专注于他们的应用中对他们的业务或组织更有利的方面，而不必担心如何扩展DBMS。</p><p>然而，许多应用无法使用这些NoSQL系统，因为它们不能放弃强大的交易和一致性要求。</p><p>这种情况对于处理高等级数据的企业系统（例如，财务和订单处理系统）很常见。</p><p>一些组织，最明显的是Google，发现NoSQL DBMS导致他们的开发人员花了太多时间编写代码来处理一致的数据，而使用事务使他们的工作效率更高，因为它们提供了一个有用的抽象，更容易被人类理解。</p><p>因此，这些组织唯一的选择是，要么购买更强大的单节点机器，并对DBMS进行动态扩展，要么开发自己的支持事务的自定义分片中间件。</p><p>这两种方法都非常昂贵，因此对很多人来说都不是一个选择。正是在这种环境下，NewSQL系统应运而生。</p><h2 id="2-NewSQL的崛起"><a href="#2-NewSQL的崛起" class="headerlink" title="2. NewSQL的崛起"></a>2. NewSQL的崛起</h2><p>我们对NewSQL的定义是，它们是一类现代关系型DBMS，试图为OLTP读写工作负载提供与NoSQL相同的可扩展性能，同时仍然保持事务的ACID保证。</p><p>换句话说，这些系统希望实现与2000年代的NoSQL DBMS一样的可扩展性，但仍然保持1970-80年代的传统DBMS的关系模型（带SQL）和事务支持。</p><p>这使得应用程序可以执行大量的并发事务来获取新的信息，并使用SQL（代替专有的API）修改数据库的状态。</p><p>如果一个应用程序使用了NewSQL DBMS，那么开发人员就不需要像在NoSQL系统中那样编写逻辑来处理最终一致的更新。</p><p>正如我们在下面讨论的那样，这种解释涵盖了许多学术和商业系统。</p><p><br><br>我们注意到，在2000年代中期，有一些人认为符合这个标准的数据仓库DBMS出现了（如Vertica、Greenplum、Aster Data）。</p><p>这些DBMS针对的是在线分析处理（OLAP）工作负载，不应该被认为是NewSQL系统。</p><p>OLAP DBMS专注于执行复杂的只读查询（即聚合、多路join），这些查询需要很长时间来处理大数据集（例如，几秒钟甚至几分钟）。</p><p>这些查询中的每个查询都可能与前者有明显的不同。</p><p>另一方面，NewSQL DBMS所针对的应用的特点是执行读写事务，这些事务(1)是短暂的(即没有用户停顿)，(2)使用索引查找触及一小部分数据(即没有完整的表扫描或大型分布式join)，(3)是重复性的(即用不同的输入执行相同的查询)。</p><p>其他的人认为，NewSQL系统的实现必须使用(1)无锁并发控制方案和(2)无共享的分布式架构。</p><p>所有我们在第3节中将其归类为NewSQL的DBMS确实具有这些属性，因此我们同意这一定义。</p><h2 id="3-NewSQL分类"><a href="#3-NewSQL分类" class="headerlink" title="3. NewSQL分类"></a>3. NewSQL分类</h2><p>鉴于上述定义，我们现在来看看今天的NewSQL DBMS的情况。</p><p>为了简化分析，我们将根据系统的优点对系统进行分类。</p><p>我们认为最能代表NewSQL系统的三类是：(1)使用新的架构从头开始构建的新型系统，(2)重新实现与Google等人在2000年代开发的分片基础架构相同的中间件，以及(3)同样基于新架构的云计算供应商提供的数据库即服务。</p><p><br><br>两位作者之前都将替换现有的单节点DBMS的存储引擎的方案纳入了我们对NewSQL系统的分类中。</p><p>其中最常见的例子是对MySQL默认的InnoDB存储引擎的替代（例如TokuDB、ScaleDB、Akiban、deepSQL）。</p><p>使用新引擎的好处是，企业可以获得更好的性能，而不需要改变他们的应用中的任何东西，并且仍然可以利用DBMS的现有生态系统（如工具、API）。</p><p>其中最有趣的是ScaleDB，因为它通过在存储引擎之间重新分配执行，在不使用中间件的情况下提供了透明的分片，而不需要使用中间件；不过，该公司后来转向了另一个领域。</p><p>除了MySQL之外，还有其他类似的系统扩展。</p><p>微软为SQL Server的内存中的Hekaton OLTP引擎几乎与传统的磁盘驻留表无缝集成。</p><p>其他的引擎则使用Postgres的外来数据封装器和API钩子来实现相同类型的集成，但以OLAP工作负载为目标（如Vitesse、CitusDB）。</p><p><br><br>我们现在断定，这样的存储引擎和单节点DBMS的扩展并不代表NewSQL系统，因此我们将其从我们的分类中省略。</p><p>MySQL的InnoDB在可靠性和性能方面已经有了很大的改进，所以切换到另一个引擎用于OLTP应用的好处并不明显。</p><p>我们承认，从面向行的InnoDB引擎切换到OLAP工作负载的列存储引擎的好处更明显（例如Infobright、InfiniDB）。</p><p>但总的来说，针对OLTP工作负载的MySQL存储引擎替换业务是失败的数据库项目的墓地。</p><h3 id="3-1-采用新型架构"><a href="#3-1-采用新型架构" class="headerlink" title="3.1 采用新型架构"></a>3.1 采用新型架构</h3><p>这一类包含了对我们来说最有趣的NewSQL系统，因为它们都是从头开始构建的。</p><p>也就是说，它们不是扩展现有的系统（例如，基于微软SQL Server的Hekaton），而是从一个新的代码库中设计出来的，没有传统系统的任何架构包袱。</p><p>这一类中的所有DBMS都是基于分布式架构的，它们在shared-nothing的架构上运行，并包含支持多节点并发控制、基于复制的错误容忍、流程控制和分布式查询处理的组件。</p><p>使用为分布式处理而构建的新DBMS的优势在于，系统的所有部分都可以针对多节点环境进行优化。</p><p>这包括查询优化器和节点之间的通信协议等。</p><p>例如，大多数NewSQL DBMS能够在节点之间直接发送节点内的查询数据，而不是像一些中间件系统那样将数据路由到中心位置。</p><p><br><br>这类DBMS中的每一个DBMS（除了Google Spanner之外）也都管理着自己的主存储系统，无论是内存中的还是磁盘上的。</p><p>这意味着他们用一个定制的存储引擎，并在其中分配数据库，而不是依赖现成的分布式文件系统（如HDFS）或存储结构（如Apache Ignite）。</p><p>这是它们的非常重要的一点，因为它允许DBMS “把查询送到数据中去”，而不是 “把数据带到查询中去”，这样做的结果是大大减少了网络流量，因为传输查询通常比必须把数据（不仅仅是图元，还包括索引和物化视图）传输到计算中去的网络流量要少得多。</p><p><br><br>管理自己的存储也使 DBMS 能够采用比 HDFS 中使用的基于块的复制方案更复杂的复制方案。</p><p>一般来说，它允许这些DBMS比其他建立在其他现有技术之上的系统获得更好的性能；这方面的例子包括像Trafodion和Splice Machine这样的 “SQL on Hadoop “系统，它们在Hbase之上提供事务处理。</p><p>因此，我们认为这样的系统不应该被认为是NewSQL。</p><p><br><br>但是，使用基于新架构的DBMS也有其弊端。</p><p>最重要的是，很多公司对采用太新的技术抱有戒心，还未被大规模使用。</p><p>这意味着与更受欢迎的DBMS厂商相比，有经验的人要少得多。</p><p>这也意味着企业将有可能无法访问现有管理和报告工具。</p><p>一些DBMS，如Clustrix和MemSQL，通过保持与MySQL线协议的兼容性来避免这个问题。</p><p><strong>比如： Clustrix, CockroachDB, Google Spanner, H-Store, HyPer, MemSQL, NuoDB, SAP HANA, VoltDB.</strong></p><h3 id="3-2-透明的分片中间件"><a href="#3-2-透明的分片中间件" class="headerlink" title="3.2 透明的分片中间件"></a>3.2 透明的分片中间件</h3><p>现在有一些产品可以提供与eBay、Google、Facebook和其他公司在2000年代开发的同类分片中间件功能。</p><p>这些产品允许一个公司将数据库分割成多个分片，这些分片存储在一个单节点的DBMS实例集群中。</p><p>Sharding技术与20世纪90年代的数据库联盟技术不同，因为每个节点(1)运行着相同的DBMS，(2)只有整体数据库的一部分，(3)不是由应用程序独立地访问和更新。</p><p><br><br>集中化的中间件组件负责路由查询、协同管理事务，以及管理节点间的数据放置、复制和分区。</p><p>通常，每个DBMS节点上都安装有一个与中间件通信的shim层。</p><p>这个组件负责在其本地DBMS实例中代表中间件执行查询并返回结果。</p><p>所有这些加在一起，使得中间件产品可以向应用程序展示一个单一的逻辑数据库，而不需要修改底层DBMS。</p><p><br><br>使用分片式中间件的关键优势在于，它们通常是对已经在使用现有单节点DBMS的应用程序的即插即用替代。</p><p>开发人员不需要对他们的应用程序做任何改动，就可以使用新的分片数据库。</p><p>中间件系统最常见的目标是MySQL。</p><p>这意味着，为了与MySQL兼容，中间件必须支持MySQL线协议。</p><p>Oracle提供了MySQL Proxy和Fabric工具包来完成这个任务，但其他的人也编写了自己的协议处理程序库，以避免GPL许可问题。</p><p><br><br>尽管中间件使企业很容易将数据库扩展到多个节点上，但这样的系统仍然必须在每个节点上使用传统的DBMS（如MySQL、Postgres、Oracle）。</p><p>这些DBMS是基于20世纪70年代开发的面向磁盘的架构，因此它们不能像一些基于新架构的NewSQL系统中那样，使用面向内存的存储管理器或并发控制方案进行优化。</p><p>之前的研究表明，面向磁盘的架构的组件是一个重要的障碍，使这些传统的DBMS无法扩展到更高的CPU内核数和更大的内存容量。</p><p>中间件的方法也会在碎片化的节点上产生冗余的查询规划和优化（即在中间件上和单个DBMS节点上分别进行一次查询），但这也允许每个节点对每个查询应用自己的本地优化。</p><p><strong>例如: AgilData Scalable Cluster 2, MariaDB MaxScale, ScaleArc, ScaleBase3.</strong></p><h3 id="3-3-Database-as-a-Service"><a href="#3-3-Database-as-a-Service" class="headerlink" title="3.3 Database-as-a-Service"></a>3.3 Database-as-a-Service</h3><p>最后，还有一些云计算供应商提供NewSQL数据库即服务（DBaaS）产品。</p><p>通过这些服务，企业无需在自己的私有硬件或云托管的虚拟机（VM）上维护DBMS。</p><p>相反，DBaaS提供商负责维护数据库的物理配置，包括系统调整（如缓冲池大小）、复制和备份。</p><p>客户将获得一个连接到DBMS的URL，以及一个仪表板或API来控制数据库系统。</p><p><br><br>DBaaS的用户根据其预期的应用程序的资源利用率支付费用。</p><p>由于数据库不同的查询语句在使用计算资源的方式上有很大的差异，因此DBaaS提供商通常不会像在面向块的存储服务（如亚马逊的S3、谷歌的云存储）中那样，以同样的方式来计量查询调用。</p><p>取而代之的是，客户订阅一个定价层，该定价层指定了提供商将保证的最大资源利用率阈值（例如，存储大小、计算能力、内存分配）。</p><p><br><br>与云计算的因素一样，由于经济规模限制，DBaaS领域的主要参与者仍然是最大的那几个公司。</p><p>但几乎所有的DBaaS都只是提供了传统的单节点DBMS（如MySQL）的托管实例：著名的例子包括Google Cloud SQL、Microsoft Azure SQL、Rackspace云数据库和Sales-force Heroku。</p><p>我们不认为这些都是NewSQL系统，因为它们使用的是基于20世纪70年代架构的面向磁盘的DBMS。</p><p>一些厂商，如微软，对他们的DBMS进行了改造，为多租户部署提供了更好的支持。</p><p><br><br>相反，我们只把那些基于新架构的DBaaS产品视为NewSQL。</p><p>最显著的例子是Amazon的Aurora为他们的MySQL RDS。</p><p>与InnoDB相比，它的显著特点是使用日志结构化存储管理器来提高I/O并行性。</p><p><br><br>还有一些公司不维护自己的数据中心，而是销售运行在这些公共云平台之上的DBaaS软件。</p><p>ClearDB提供了自己的定制DBaaS，可以部署在所有主要的云平台上。</p><p>这样做的好处是可以将数据库分布在同一地理区域的不同供应商之间，避免因服务中断而造成的停机。</p><p><br><br>截至2016年，Aurora和ClearDB是这个NewSQL类别中仅有的两个产品。</p><p>我们注意到，这个领域的几家公司已经失败了（例如，GenieDB、Xeround），迫使他们的客户争相寻找新的提供商，并在这些DBaaS被关闭之前将数据迁移出这些DBaaS。</p><p>我们将其失败的原因归结为超前于市场需求，以及被各大厂商压价。</p><p><strong> Examples: Amazon Aurora, ClearDB.</strong></p><h2 id="4-NewSQL现状"><a href="#4-NewSQL现状" class="headerlink" title="4. NewSQL现状"></a>4. NewSQL现状</h2><p>接下来，我们讨论NewSQL DBMS的特点，以说明这些系统中的新奇之处（如果有的话）。</p><p>我们的分析总结如表1所示。</p><p><img src="/Users/zhuyichen/Documents/翻译/What's-really-new-with-newsql.assets/image-20200525195922408.png" alt="image-20200525195922408" style="zoom:50%;"></p><h3 id="4-1-内存存储"><a href="#4-1-内存存储" class="headerlink" title="4.1 内存存储"></a>4.1 内存存储</h3><p>所有主要的DBMS都使用了基于70年代原始DBMS的面向磁盘的存储架构。</p><p>在这些系统中，数据库的主要存储位置被认为是在一个可块寻址的耐用存储设备上，如SSD或HDD。</p><p>由于对这些存储设备的读写速度很慢，因此DBMS使用内存来缓存从磁盘上读取的块，并缓冲事务的更新。</p><p>这是很有必要的，因为历史上，内存的价格要贵得多，而且容量有限。</p><p>然而，当下容量和价格已经到了可以完全用内存来存储所有的OLTP数据库的地步，但最大的OLTP数据库除外。</p><p>这种方法的好处是，它可以实现某些优化，因为DBMS不再需要假设一个事务可能在任何时候访问不在内存中的数据而不得不停滞不前。</p><p>因此，这些系统可以获得更好的性能，因为许多处理这些情况所需要的组件，如缓冲池管理器或重量级并发控制方案等，都不需要了。</p><p><br><br>有几种基于内存存储架构的NewSQL DBMS，包括学术型（如H-Store、HyPer）和商业型（如MemSQL、SAP HANA、VoltDB）系统。</p><p>这些系统在OLTP工作负载方面的表现明显优于基于磁盘的DBMS，因为使用内存的原因。</p><p><br><br>完全在内存中存储数据库的想法并不是一个新的想法。</p><p>20世纪80年代初，威斯康星大学麦迪逊分校的开创性研究为主内存DBMS的许多方面奠定了基础，包括索引、查询处理和恢复算法。</p><p>在这十年中，第一个分布式主内存DBMS-&gt;PRISMA/DB，也是在这十年中开发出来的。<br>第一批商业化的主内存DBMS出现在20世纪90年代，如Altibase、Oracle的TimesTen和AT&amp;T的DataBlitz。</p><p><br><br>在内存NewSQL系统中，有一件事是具有创新的，那就是能够将数据库的子集持久化到持久化存储中，以减少其内存占用。</p><p>这使得DBMS能够支持比可用内存更大的数据库，而不必切换回面向磁盘的架构。</p><p>一般的方法是在系统内部使用一个内部跟踪机制来识别哪些数据行不再被访问，然后选择它们进行持久化。</p><p>H-Store的反缓存组件将冷数据移动到磁盘存储，然后在数据库中安装一个带有原始数据位置的 “墓碑 “记录。</p><p>当一个事务试图通过其中一个墓碑访问一行记录时，它会被中止，然后一个单独的线程异步检索该记录并将其移回内存。</p><p>另一个支持大于内存的数据库的变体是EPFL的一个学术项目，它在VoltDB中使用操作系统虚拟内存分页。</p><p>为了避免误报，所有这些DBMS都在数据库的索引中保留了被持久化的数据行的键，这抑制了那些有许多二级索引的应用程序的潜在内存节省。（就是有许多二级索引的表的也没怎么节省内存）</p><p>虽然不是NewSQL DBMS，但微软为Hekaton开发的Project Siberia在每个索引中保留了一个Bloom过滤器，以减少跟踪被持久化的数据行的内存存储开销。</p><p><br><br>另一个对内存数据库采取不同的方法的是MemSQL，管理员可以手动指示DBMS以列式格式存储一个表。</p><p>MemSQL不为这些磁盘驻留的数据行维护任何内存跟踪元数据。</p><p>它以日志结构化(log-structured)存储的方式组织这些数据，以减少更新的开销，因为在OLAP数据仓库中，更新速度传统上是很慢的。</p><h3 id="4-2-分区-分片"><a href="#4-2-分区-分片" class="headerlink" title="4.2 分区/分片"></a>4.2 分区/分片</h3><p>几乎所有的分布式NewSQL DBMS 的扩展方式都是将数据库分割成不相干的子集，称为分区或分片。</p><p><br><br>基于分区数据库上的分布式事务处理并不是一个新概念。</p><p>这些系统的许多基本原理来自于伟大的Phil Bernstein（和其他人）在1970年代末的SDD-1项目中的开创性工作。</p><p>在20世纪80年代初，两个开创性的单节点DBMS的背后团队—System R和INGRES，也都创建了各自系统的分布式版本。</p><p>IBM的R*是一个类似于SDD-1的shared-nothing、面向磁盘的分布式DBMS。</p><p>INGRES的分布式版本的动态查询优化算法将分布式查询递归分解成更小的块而被人记住。</p><p>后来，威斯康星大学麦迪逊分校的GAMMA项目探索了不同的分区策略。</p><p><br><br>但是，这些早期的分布式DBMS始终没有得到普及，原因有两个。</p><p>其中第一个原因是20世纪的计算硬件非常昂贵，以至于大多数公司无法负担得起在集群机器上部署数据库。</p><p>第二个问题是，对高性能分布式DBMS的应用需求根本不存在。</p><p>当时，DBMS的预期峰值吞吐量通常以每秒几十到几百个事务来衡量。</p><p>而当今社会，这两种假设都不存在了。</p><p>现在创建一个大规模的、数据密集型的应用比以往任何时候都要容易，部分原因在于开源的分布式系统工具、云计算平台和大量的廉价的移动设备的出现。</p><p><br><br>数据库的表被水平地分成多个分片，其边界基于表的一个（或多个）列的值（即分区属性）。</p><p>DBMS根据这些属性的值将每行数据分配到一个分片，使用范围或哈希分区法将每行记录分配到一个分片。</p><p>来自多个表的相关分片被组合在一起，形成一个由单个节点管理的分区。</p><p>该节点负责执行任何需要访问其分区中存储的数据的查询。</p><p>只有DBaaS系统（Amazon Aurora、ClearDB）不支持这种类型的分区。</p><p><br><br>理想情况下，DBMS也应该能够将一个查询的执行分配到多个分区，然后将它们的结果合并成一个结果。</p><p>除了ScaleArc之外，所有支持原生分区的NewSQL系统都提供了这种功能。</p><p><br><br>许多OLTP应用的数据库都有一个关键的属性，使其可以进行分区。</p><p>它们的数据库模式可以被移植到类似于树状的结构中，其中树的子节点与树根有外键关系。</p><p>然后根据这些关系中所涉及的属性对表进行分区，这样一来，单个实体的所有数据都被共同定位在同一个分区中。</p><p>例如，树的根可以是客户表，而数据库的分区是这样的，每个客户以及他们的订单记录和账户信息都存储在一起。</p><p>这样做的好处是，它允许大多数（如果不是全部）事务只需要在一个分区访问数据。</p><p>这反过来又降低了系统的通信开销，因为它不需要使用原子承诺协议（例如，两阶段承诺）来确保事务在不同的节点上正确完成。</p><p><br><br>偏离同源集群节点架构的NewSQL DBMS有NuoDB和MemSQL。</p><p>对于NuoDB来说，它指定一个或多个节点作为存储管理器（SM），每个节点存储数据库的一个分区。</p><p>SM的分区分为块（NuoDB中称为 “原子”）。</p><p>集群中所有其他节点都被指定为事务引擎（TE），作为原子的内存缓存。</p><p>为了处理一个查询，一个TE节点会检索它所需要的所有原子（从相应的SMs或其他TE中检索）。</p><p>TE 会在数据行上获取写锁，然后将原子的任何更改广播给其他 TE 和 SM。</p><p>为了避免原子在节点之间来回移动，NuoDB采用了负载平衡方案来确保一起使用的数据经常驻留在同一个TE上。</p><p>这意味着NuoDB最终采用了和其他分布式DBMS一样的分区方案，但不需要预先对数据库进行分区，也不需要识别表之间的关系。</p><p><br><br>MemSQL也使用了类似的异构架构，由只执行的聚合节点和存储实际数据的叶子节点组成。</p><p>这两个系统的区别在于它们如何减少从存储节点拉到执行节点的数据量。</p><p>在NuoDB中，TE缓存数据（atoms）来减少从SM读取的数据量。</p><p>MemSQL的聚合器节点不缓存任何数据，但叶子节点执行部分查询，以减少发送至聚合器节点的数据量；而在NuoDB中，这一点是不可能的，因为SM只是一个数据存储。</p><p><br><br>这两个系统能够在DBMS的集群中增加额外的执行资源（NuoDB的TE节点、MemSQL的聚合节点），而不需要重新划分数据库。</p><p>SAP HANA的一个研究原型也探索了使用这种方法。</p><p>然而，这样的异构架构在性能或操作复杂性方面是否优于同源架构（即每个节点既存储数据又执行查询），还有待观察。</p><p><br><br>NewSQL系统中分区的另一个创新的方面是，有些系统支持实时迁移。</p><p>这使得DBMS可以在物理资源之间移动数据来重新平衡和缓解热点，或者在不中断服务的情况下增加/减少DBMS的容量。</p><p>这与NoSQL系统中的再平衡类似，但难度较大，因为NewSQL DBMS在迁移过程中必须保持事务的ACID。</p><p>DBMS有两种方法来实现这个目标。</p><p>第一种是将数据库组织成许多粗粒度的 “虚拟”（即逻辑）分区，这些分区分布在物理节点之间。</p><p>然后，当DBMS需要重新平衡时，它将这些虚拟分区在节点之间移动。这是Clustrix和AgilData，以及Cassandra和DynamoDB等NoSQL系统中使用的方法。</p><p>另一种方法是DBMS通过范围分区来重新分配单个图例或图例组，以执行更精细的再平衡。这类似于MongoDB NoSQL DBMS中的自动分片功能。它在ScaleBase和H-Store等系统中得到了应用。</p><h3 id="4-3-并发控制"><a href="#4-3-并发控制" class="headerlink" title="4.3 并发控制"></a>4.3 并发控制</h3><p>并发控制方案是事务处理DBMS中最重要的实现细节，因为它几乎影响到系统的所有方面。</p><p>并发控制允许终端用户并发的访问数据库，同时给每个用户一种假象，让他们以为在只有自己在单独执行事务。</p><p>它本质上提供了系统中的原子性和隔离保证，因此它影响着整个系统的行为。</p><p><br><br>除了系统采用哪种并发控制方案外，分布式DBMS设计的另一个重要方面是系统采用中心化还是去中心化事务协调协议。</p><p>在一个采用中心化协调器的系统中，所有事务的操作都必须经过协调器，然后由协调器决定是否允许事务进行。</p><p>这与20世纪70-80年代的TP监控器（如IBM CICS、Oracle Tuxedo）采用的方法相同。</p><p>在一个去中心化的系统中，每个节点维护访问它所管理的数据的事务的状态。<br>然后，各节点之间必须相互协调，以确定并发事务是否冲突。</p><p>去中心化协调器的可扩展性更好，但要求DBMS节点中的时钟高度同步，以产生全局性的事务排序。</p><p><br><br>1970-80年代的第一批分布式DBMS使用了两阶段锁定（2PL）方案。</p><p>SDD-1是第一个专门为分布式事务处理而设计的DBMS，它是由一个中心化协调器管理的共享节点集群。</p><p>IBM的R*与SDD-1类似，但主要的区别在于R*中事务的协调是完全去中心化的；它使用分布式的2PL协议，即事务直接在节点上锁定其访问的数据项。</p><p>分布式版本的INGRES也使用了去中心化2PL，并采用了中心化死锁检测。</p><p><br><br>因为处理死锁的复杂性，几乎所有基于新架构的NewSQL系统都放弃了2PL。</p><p>相反，目前的趋势是使用时间戳顺序（TO）并发控制的各种变体方案，此方案中，DBMS假定事务不会以非线性顺序的执行。</p><p>NewSQL系统中最广泛使用的协议是去中心化的多版本并发控制（MVCC），当一行数据被事务更新时，DBMS会在数据库中创建一行新版本的数据。</p><p>维护多个版本允许某个事务在另一个事务更新相同的数据时仍能完成。</p><p>它还允许长期运行的、只读的事务不对写入者进行阻塞。</p><p>几乎所有基于新架构的NewSQL系统，如MemSQL、HyPer、HANA和CockroachDB，都使用了这个协议。虽然这些系统在其MVCC实现中使用了一些工程优化和微调来提高性能，但该方案的基本概念并不新鲜。</p><p>第一个描述MVCC的已知工作是1979年的一篇MIT博士论文[49]，而最早使用MVCC的商用DBMS是Digital公司的VAX Rdb和80年代初的InterBase。</p><p>我们注意到，InterBase的架构是由Jim Starkey设计的，他也是NuoDB和失败的Falcon MySQL存储引擎项目的原设计者。</p><p><br><br>其他系统则组合了2PL和MVCC。</p><p>使用这种方案，事务仍然必须在2PL方案下获得锁来修改数据库。</p><p>当一个事务修改一条记录时，DBMS会创建一个新的记录版本，就像使用MVCC一样。</p><p>这种方案允许只读查询，从而避免了获取锁，从而不阻塞写事务。这种方法最著名的实现是MySQL的InnoDB，但它也在Google的Spanner、NuoDB和Clustrix中使用。</p><p>NuoDB在原有的MVCC的基础上进行了改进，采用了gossip协议在节点之间广播版本信息。</p><p><br><br>所有的中间件和DBaaS服务都继承了其底层DBMS体系结构的并发控制方案；</p><p>由于它们大多使用MySQL，这使得它们都是带MVCC的2PL方案。</p><p><br><br>我们认为Spanner中的并发控制实现（连同它的后代F1和SpannerSQL）是NewSQL系统中最新颖的方案之一。</p><p>实际方案本身是基于前几十年开发的2PL和MVCC组合。但Spanner的不同之处在于，它使用硬件设备（如GPS、原子钟）进行高精度时钟同步。</p><p>DBMS使用这些时钟来为事务分配时间戳，以便在广域网络上实现多版本数据库的一致视图。</p><p>CockroachDB也声称要为跨数据中心的事务提供与Spanner相同的一致性，但没有使用原子钟。<br>相反，它们依赖于一种混合时钟协议，将松散同步的硬件时钟和逻辑计数器结合在一起。</p><p><br><br>Spanner还有一点值得注意，就是它预示着Google重新转向使用事务处理最关键的服务。</p><p>Spanner的作者甚至表示，让他们的应用程序员来处理由于过度使用事务而导致的性能问题，比起像NoSQL DBMS那样编写代码来处理缺乏事务的问题要好得多。</p><p><br><br>最后，唯一没有使用MVCC变体的商用NewSQL DBMS是VoltDB。</p><p>这个系统仍然使用TO并发控制，但它没有像MVCC那样将事务交织在一起，而是安排事务在每个分区一次执行。</p><p>它还采用了混合架构，其中单分区事务以分散的方式进行调度，但多分区事务则由集中式协调器调度。</p><p>VoltDB根据逻辑时间戳对事务进行排序，然后在轮到事务时安排它们在某个分区执行。</p><p>当一个事务在一个分区执行时，它对该分区的所有数据都有独占的访问权限，因此系统不需要在其数据结构上设置细粒度的锁和锁存。</p><p>这使得只需要访问单一分区的事务能够有效地执行，因为没有来自其他事务的争夺。</p><p>基于分区的并发控制的缺点是，如果事务跨越多个分区，它的工作效果并不好，因为网络通信延迟会导致节点在等待消息的时候闲置。</p><p>这种基于分区的并发控制并不是一个新的想法。</p><p>它的一个早期变体是由Hector Garcia-Molina[34]在1992年的一篇论文中首次提出，并在20世纪90年代末的kdb系统[62]和H-Store（也就是VoltDB的学术前身）中实现。</p><p><br><br>总的来说，我们发现NewSQL系统中的核心并发控制方案除了让这些算法在现代硬件和分布式操作环境下很好地运行外，并没有什么明显的新意。</p><h3 id="4-4-二级索引"><a href="#4-4-二级索引" class="headerlink" title="4.4 二级索引"></a>4.4 二级索引</h3><p>二级索引是一个表所有属性的子集，这些属性和主键不同。</p><p>这使得DBMS能够支持超过主键或分区键查询性能的快速查询。</p><p>在非分区DBMS中支持二级索引是不值得拿出来说的，因为整个数据库位于单一节点上。</p><p>二级索引在非分区DBMS中面临的挑战是，它们不能以与数据库其他部分相同的方式进行分区。</p><p>举个例子，假设数据库的表是根据客户表的主键来分区的。</p><p>但又有一些查询想要进行从客户的电子邮件地址到账户反向查询。</p><p>由于表是根据主键分区的，所以DBMS必须将这些查询广播到每一个节点，这显然是低效的。</p><p><br></p><p>在分布式DBMS中支持二级索引的两个设计问题是：</p><p>(1)系统将在哪里存储二级索引；(2)如何在事务的上下文中维护它们。</p><p>在一个具有中心化协调器的系统中，就像sharding中间件一样，二级索引可以同时驻留在协调器节点和分片节点上。</p><p>这种方法的优点是，整个系统中只有一个版本的索引，因此更容易维护。</p><p><br></p><p>所有基于新架构的NewSQL系统都是去中心化的，并且使用分区二级索引。</p><p>这意味着每个节点存储索引的一部分，而不是每个节点都有一个完整的副本。</p><p>分区索引和复制索引之间的权衡是，对于前者，查询可能需要跨越多个节点才能找到他们要找的东西，但如果一个事务更新一个索引，它只需要修改一个节点。</p><p>在复制索引中，角色是相反的：查找查询可以只由集群中的一个节点来满足，但任何时候一个事务修改二级索引底层表中引用的属性（即键或值）时，DBMS必须执行一个分布式事务，更新索引的所有副本。</p><p><br>Clustrix是一个混合了这两个概念的去中心化二级索引的例子。</p><p>DBMS首先在每个节点上存储一个冗余的，粗粒度的（即，基于范围的）索引，它将值映射到分区。</p><p>这个映射让DBMS使用一个不是表的分区属性的属性将查询路由到适当的节点。</p><p>然后，这些查询将访问该节点的第二个分区索引，该索引将精确值映射到某一行数据。</p><p>这种两层方法重新减少了在整个集群中保持复制索引同步所需的协调量，因为它只映射范围而不是单个值。</p><p><br></p><p>当使用不支持二级索引的NewSQL DBMS时，开发人员创建二级索引最常见的方法是使用内存中的分布式缓存部署索引，例如Memcached。</p><p>但是使用外部系统需要应用程序维护缓存，因为DBMS不会自动失效外部缓存。</p><h3 id="4-5-副本"><a href="#4-5-副本" class="headerlink" title="4.5 副本"></a>4.5 副本</h3><p>一个公司能够保证其OLTP应用的高可用和数据持久化的最好方法是为他们的数据库建立副本。</p><p>所有现代DBMS，包括NewSQL系统，都支持某种副本机制。</p><p>DBaaS在这方面具有明显的优势，因为它们向客户隐藏了设置副本的所有粗暴细节。</p><p>它们使得部署一个有副本的DBMS变得很容易，管理员不必担心日志传输和确保节点同步。</p><p><br></p><p>在数据库复制方面，有两个设计方案需要决策。</p><p>第一个是DBMS如何在节点间确保数据一致性。</p><p>在一个强一致性的DBMS中，所有的写入操作必须在所有的副本中被确认和执行，这个事务才算成功执行。</p><p>这种方法的优点是，副本在执行读查询时仍然是一致的。</p><p>也就是说，如果应用程序收到了一个事务已经提交的确认，那么该事务所做的任何修改对未来的任何后续事务都是可见的，无论他们访问的是哪个DBMS节点。</p><p>这也意味着，当一个副本失败时，不会丢失更新，因为所有其他节点都是同步的。</p><p>但是维持这种同步重新要求DBMS使用原子承诺协议（例如，两阶段提交）来确保所有的副本与事务的结果一致，这有额外的开销，并且如果一个节点失败或者有网络分区延迟，可能会导致停滞。</p><p>这就是为什么NoSQL系统选择弱一致性模型（也称为最终一致性），在这种模型中，即使有副本没有确认修改成功，DBMS也可以通知应用程序已经执行成功。</p><p><br></p><p>我们所知道的所有NewSQL系统都支持强一致的复制。</p><p>但是这些系统如何保证这种一致性并没有什么创新。</p><p>DBMS的状态机复制的基本原理早在20世纪70年代就被研究出来了（引用37，42）。</p><p>NonStop SQL是20世纪80年代建立的第一批使用强一致性复制以这种同样的方式提供容错的分布式DBMS之一（引用59）。</p><p><br></p><p>除了DBMS何时向副本传播更新的策略外，对于DBMS如何执行这种传播，还有两种不同的执行模式。</p><p>第一种，称为主动-主动复制，即每个副本节点同时处理同一个请求。</p><p>例如，当一个事务执行一个查询时，DBMS会在所有的副本节点上并行执行该查询。</p><p>这与主动-被动复制不同，主动被动复制是先在单个节点处理一个请求，然后DBMS将结果状态传输到其他副本。</p><p>大多数NewSQL DBMS实现了第二种方法，因为它们使用了一个非确定性的并发控制方案。</p><p>这意味着它们不能在查询到达leader副本时向其他副本发送查询，因为它们可能会在其他副本上以不同的顺序被执行，导致数据库的状态会在每个副本上出现分歧。</p><p>这是因为它们的执行顺序取决于几个因素，包括网络延迟、缓存停顿和时钟偏移。</p><p><br></p><p>而确定性的DBMS（如H-Store、VoltDB、ClearDB）则不执行这些额外的协调步骤。</p><p>这是因为DBMS保证事务的操作在每个副本上以相同的顺序执行，从而保证数据库的状态是相同的[44]。</p><p>VoltDB和ClearDB还确保应用程序不会执行利用DBMS外部信息源的查询，而这些信息源在每个副本上可能是不同的（例如，将时间戳字段设置为本地系统时钟）。</p><p><br></p><p>NewSQL系统与以往学术界以外的工作不同的一个方面是考虑在广域网（WAN）上进行复制。</p><p>这是现代操作环境的一个副产品，现在，将系统部署在地理差异较大的多个数据中心是轻而易举的事情。</p><p>任何NewSQL DBMS都可以被配置为通过广域网提供数据的同步更新，但这将会对正常的操作造成明显的减速。</p><p>因此，它们反而提供了异步复制方法。</p><p>据我们所知，Spanner和CockroachDB是唯一的提供了一个优化的复制方案的NewSQL系统，他们可以在广域网上进行强一致的复制。</p><p>同样的，它们通过原子钟和GPS硬件时钟（在Spanner[24]的情况下）或混合时钟（在CockroachDB[41]的情况下）的组合来实现的。</p><h3 id="4-6-崩溃恢复"><a href="#4-6-崩溃恢复" class="headerlink" title="4.6 崩溃恢复"></a>4.6 崩溃恢复</h3><p>NewSQL DBMS提供容错性的另一个重要功能是其崩溃恢复机制。</p><p>但与传统的DBMS不同的是，传统DBMS容错的主要关注点是确保不丢失更新[47]，新的DBMS还必须尽量减少停机时间。因为现代网络应用系统要一直在线，而网站中断的代价很高。</p><p>在没有副本的单节点系统中，传统的恢复方法是，当DBMS在崩溃后重新上线时，它从磁盘上加载最后一个检查点，然后重播它的写前日志（WAL），重新将数据库的状态转到崩溃时的状态。  </p><p>这种方法的典范方法被称为ARIES[47]，由IBM研究人员在20世纪90年代发明。所有主要的DBMS都实现了ARIES的某种变体。</p><p><br></p><p>然而，在有副本的分布式DBMS中，传统的单节点方法并不直接适用。</p><p>这是因为当主节点崩溃时，系统会将其中一个从节点作为新的主节点。当上一个主节点重新上线时，它不能只加载它的最后一个检查点并重新运行它的WAL，因为DBMS还在继续处理事务，因此数据库的状态已经向前移动。</p><p>恢复中的节点需要从新的主节点（以及可能的其他副本）获取它在宕机时错过的更新。</p><p>有两种潜在的方法可以做到这一点。</p><p>第一种是让恢复节点从本地存储中加载它的最后一个检查点和WAL，然后从其他节点提取它错过的日志条目。</p><p>只要该节点处理日志的速度能快于新更新附加到它身上的速度，该节点最终会收敛到与其他复制节点相同的状态。</p><p>如果DBMS使用物理或逻辑日志，这是有可能的，因为将日志更新直接应用于数据行的时间远远小于执行原始SQL语句的时间。</p><p>为了减少恢复所需的时间，另一种选择是让恢复中的节点丢弃它的检查点，让系统取一个新的检查点，节点将从中恢复。这种方法的另外一个好处是，在DBMS中也可以使用这种相同的机制来增加一个新的复制节点。</p><p><br>中间件和DBaaS系统依赖于其底层单节点DBMS的内置机制，但增加了额外的基础设施，用于领导者选举和其他管理功能。</p><p>基于新架构的NewSQL系统使用现成的组件（如ZooKeeper、Raft）和自己对现有算法的定制实现（如Paxos）相结合。</p><p>所有这些都是20世纪90年代以来商业分布式系统中的标准程序和技术。</p><h2 id="未来趋势"><a href="#未来趋势" class="headerlink" title="未来趋势"></a>未来趋势</h2><p>我们预计，在不久的将来，数据库应用的下一个趋势是能够在新数据上执行分析查询和机器学习算法。</p><p>这种工作方式，通俗地讲就是 “实时分析 “或混合事务分析处理(HTAP)，试图通过分析历史数据集与新数据的组合来推断洞察力和知识[35]。</p><p>不同于前十年的传统商业智能业务只能对历史数据进行这种分析。</p><p>在现代应用中，拥有较短的周转时间是很重要的，因为数据刚创建时具有巨大的价值，但这种价值会随着时间的推移而减少。</p><p><br></p><p>在数据库应用中支持HTAP管道的方法有三种：最常见的是部署单独的DBMS：一个用于事务，另一个用于分析查询。</p><p>在这种架构下，前端OLTP DBMS存储了所有事务中产生的新信息。</p><p>然后在后台，系统使用提取-转换-加载的方式将数据从这个OLTP DBMS迁移到第二个后端数据仓库DBMS。</p><p>应用程序在后端 DBMS 中执行所有复杂的 OLAP 查询，以避免减慢 OLTP 系统的速度。</p><p>从 OLAP 系统生成的任何新信息都会被推送到前端 DBMS 中。</p><p><br></p><p>另一种盛行的系统设计，即所谓的lambda架构[45]，是使用一个独立的批处理系统（如Hadoop、Spark）来计算历史数据的综合视图，同时使用一个流处理系统（如Storm[61]、Spark Streaming[64]）来提供传入数据的视图。</p><p>在这种分体式架构中，批处理系统定期重新扫描数据集，并将结果进行批量上传至流处理系统，然后流处理系统根据新的更新进行修改。</p><p><br></p><p>这两种方法的分叉环境本身就存在几个问题。</p><p>最重要的是，在不同的系统之间传播变化所需的时间通常是以分钟甚至以小时为单位的。</p><p>这种数据传输抑制了应用程序在数据库中输入数据时立即采取行动的能力。</p><p>其次，部署和维护两个不同的DBMS的管理开销是不小的，因为据估计，人员费用几乎占到了一个大型数据库系统总成本的50%[50]。</p><p>如果应用开发者要将不同数据库的数据结合起来，还需要为多个系统编写查询。</p><p>一些系统，试图通过隐藏这种拆分系统架构来实现单一平台；一个例子是Splice Machine[16]，但这种方法还有其他技术问题，因为要把数据从OLTP系统（Hbase）复制到OLAP系统（Spark）中去。</p><p><br></p><p>第三种（我们认为更好的）方法是使用单一的HTAP DBMS，它支持OLTP工作负载的高吞吐量和低延迟需求，同时还允许复杂的、运行时间较长的OLAP查询对热数据（事务性）和冷数据（历史）进行操作。</p><p>这些较新的HTAP系统与传统的通用DBMS的不同之处在于，它们结合了过去十年中专门的OLTP(如内存存储、无锁执行)和OLAP(如列式存储、矢量执行)系统的进步，但却在一个DBMS中。</p><p><br>SAP HANA和MemSQL是第一个以HTAP系统自居的NewSQL DBMS。</p><p>HANA通过在内部使用多个执行引擎来实现：一个引擎用于面向行的数据，更适合交易；另一个不同的引擎用于面向列的数据，更适合分析查询。</p><p>MemSQL使用两个不同的存储管理器（一个用于行，一个用于列），但将它们混合在一个执行引擎中。</p><p>HyPer从专注于OLTP的H-Store式并发控制的面向行的系统，转而使用带有MVCC的HTAP列存储架构，使其支持更复杂的OLAP查询[48]。</p><p>甚至VoltDB也将其市场策略从单纯的OLTP性能转向提供流式语义。</p><p>同样，S-Store项目也试图在H-Store架构之上增加对流处理操作的支持[46]。</p><p>从2000年中期开始，专门的OLAP系统(如Greenplum)将开始增加对更好的OLTP的支持。</p><p><br></p><p>然而，我们注意到，HTAP DBMS的兴起确实意味着巨大的单体OLAP仓库的结束。</p><p>这种系统在短期内仍然是必要的，因为它们是一个组织所有前端OLTP孤岛的通用后端数据库。</p><p>但最终，数据库联合的复兴将使公司能够执行跨越多个OLTP数据库（甚至包括多个供应商）的分析查询，而无需移动数据。</p><h2 id="6-总结"><a href="#6-总结" class="headerlink" title="6. 总结"></a>6. 总结</h2><p>从我们的分析中得到的主要启示是，NewSQL数据基础系统并不是对现有系统架构的彻底背离，而是代表了数据库技术持续发展的下一个篇章。</p><p>这些系统所采用的大部分技术都存在于学术界和工业界以往的DBMS中。</p><p>但其中许多技术只是在单个系统中逐一实现，从未全部实现。</p><p>因此，这些NewSQL DBMS的创新之处在于，它们将这些思想融入到单一的平台中。</p><p>实现这一点绝不是一个微不足道的工程努力。</p><p>它们是一个新时代的副产品，在这个时代，分布式计算资源丰富且价格低廉，但同时对应用的要求也更高。</p><p><br></p><p>此外，考虑NewSQL DBMS在市场上的潜在影响和未来发展方向也很有意思。</p><p>鉴于传统的DBMS厂商已经根深蒂固，而且资金充裕，NewSQL系统要想获得市场份额，将面临一场艰苦的战斗。</p><p>自我们首次提出NewSQL这个术语[18]以来，在过去的五年里，有几家NewSQL公司已经倒闭（如GenieDB、Xeround、Translattice），或者转而专注于其他领域（如ScaleBase、ParElastic）。</p><p>根据我们的分析和对几家公司的访谈，我们发现NewSQL系统的被接受的速度相对较慢，特别是与开发者驱动的NoSQL吸收相比。</p><p>这是因为NewSQL DBMS的设计是为了支持事务性工作场景，而这些工作场景大多出现在企业应用中。</p><p>与新的Web应用工作场景相比，这些企业应用的数据库选择决策可能更加保守。</p><p>这一点从以下事实也可以看出，我们发现NewSQL DBMS被用来补充或替换现有的RDBMS部署，而NoSQL则被部署在新的应用工作场景中[19]。</p><p><br></p><p>与2000年代的OLAP DBMS初创公司不同，当时几乎所有的厂商都被大型技术公司收购，到目前为止，只有一家收购NewSQL公司。</p><p>2016年3月，Tableau宣布收购了为HyPer项目组建的初创公司。</p><p>另外两个可能的例外是：（1）Ap-ple在2015年3月收购了FoundationDB，但我们把它们排除在外，因为这个系统的核心是一个NoSQL键值存储，上面嫁接了一个低效的SQL层；（2）ScaleArc收购了ScaleBase，但这是一个竞争对手收购了另一个竞争对手。 </p><p>这些例子都不是那种传统厂商收购后起之秀系统的收购（比如2011年Teradata收购Aster Data Systems）。</p><p>我们反而看到，大型厂商选择创新和改进自己的系统，而不是收购NewSQL新秀。</p><p>微软在2014年在SQL Server中加入了内存Hekaton引擎，以改善OLTP工作负载。</p><p>甲骨文和IBM的创新速度稍慢；他们最近在其系统中增加了面向列的存储扩展，以与惠普Vertica和亚马逊Redshift等日益流行的OLAP DBMS竞争。它们有可能在未来为OLTP工作负载增加内存选项。</p><p><br></p><p>从更长远的角度来看，我们认为，在我们这里讨论的四类系统中，将出现功能的融合。</p><p>(1)1980-1990年代的老式DBMS，(2)2000年代的OLAP数据仓库，(3)2000年代的NoSQL DBMS，(4)2010年代的NewSQL DBMS。</p><p>我们预计，这些分类中的所有关键系统都将支持某种形式的关系模型和SQL（如果它们还没有的话），以及像HTAP DBMS那样同时支持OLTP操作和OLAP查询。当这种情况发生时，这种分类将毫无意义。</p><p><br></p><p><strong> 鸣谢 </strong></p><p>The authors would like to thank the following people for their feedback: Andy Grove (AgilData), Prakhar Verma (Amazon), Cashton Coleman (ClearDB), Dave Anselmi (Clustrix), Spencer Kimball (CockroachDB), Peter Mattis (CockroachDB), Ankur Goyal (MemSQL), Seth Proctor (NuoDB), Anil Goel (SAP HANA), Ryan Betts (VoltDB). This work was supported (in part) by the National Science Foundation (Award CCF-1438955).</p><p>For questions or comments about this paper, please call the CMU Database Hotline at <strong>+1-844-88-CMUDB</strong>.</p><h2 id="7-引用"><a href="#7-引用" class="headerlink" title="7. 引用"></a>7. 引用</h2><p>略了</p><p>​     </p><p>​    </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;&lt;a href=&quot;/files/newsql.pdf&quot;&gt;论文PDF下载&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="论文翻译" scheme="https://blog.lovezhy.cc/categories/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/"/>
    
    
      <category term="NewSQL" scheme="https://blog.lovezhy.cc/tags/NewSQL/"/>
    
  </entry>
  
  <entry>
    <title>论文翻译 - Kafka~a Distributed Messaging System for Log Processing</title>
    <link href="https://blog.lovezhy.cc/2020/05/14/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91%20-%20Kafka~a%20Distributed%20Messaging%20System%20for%20Log%20Processing/"/>
    <id>https://blog.lovezhy.cc/2020/05/14/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91%20-%20Kafka~a%20Distributed%20Messaging%20System%20for%20Log%20Processing/</id>
    <published>2020-05-13T16:00:00.000Z</published>
    <updated>2020-05-17T07:57:24.778Z</updated>
    
    <content type="html"><![CDATA[<p>原文地址：<a href="http://notes.stephenholiday.com/Kafka.pdf" target="_blank" rel="noopener">http://notes.stephenholiday.com/Kafka.pdf</a></p><p>太长不看：</p><p>相对于JMS等其他的消息系统，Kafka舍弃了很多功能，以达到性能上的提升。</p><p>论文讲述了Kafka设计上的取舍，以及提升性能的很多点。</p><a id="more"></a><h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>日志处理已经成为消费互联网公司数据管道的重要组成部分。</p><p>我们将开始介绍Kafka，这是一个我们开发出用于收集和传递大批量的日志数据，并且具有低延迟的分布式消息传递系统。</p><p>Kafka融合了现有的日志聚合器和消息传递系统的思想，适用于消费离线和在线消息。</p><p>我们在Kafka中做了不少非常规但又实用的设计，使我们的系统具有高效和扩展性。</p><p>我们的实验结果表明，与两种流行的消息传递系统相比，Kafka具有优越的性能。</p><p>我们在生产中使用Kafka已经有一段时间了，它每天要处理数百GB的新数据。</p><h1 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1. 介绍"></a>1. 介绍</h1><p>任何一家大型互联网公司都会产生大量的 “日志 “数据。</p><p>这些数据通常包括：</p><ul><li><p>用户活动事件，包括登录、页面浏览、点击、”喜欢”、分享、评论和搜索查询</p></li><li><p>运营指标，如服务调用堆栈、调用延迟、错误，以及系统指标，如CPU、内存、网络或磁盘利用率等。</p></li></ul><p>长期以来，日志数据一直是分析的一个组成部分，用于跟踪用户参与度、系统利用率和其他指标。</p><p>然而最近互联网应用的趋势使得活动数据成为产品数据管道的一部分，直接用于网站功能中。</p><p>这些用途包括：</p><ul><li>搜索相关性</li><li>活动流中的受欢迎或共同出现的项目产生的推荐</li><li>广告定位和报告</li><li>防止滥用行为的安全应用，如垃圾邮件或未经授权的数据爬取</li><li>新闻联播功能，将用户的状态更新或行动汇总起来，供其 “朋友 “阅读。</li></ul><p>这种生产、实时使用的日志数据给数据系统带来了新的挑战，因为它的数据量比 “真实 “的数据要大好几个数量级。</p><p>例如，搜索、推荐和广告往往需要计算颗粒化的点击率，这不仅会产生每一个用户点击的日志记录，还会产生每个页面上几十个未点击的项目的日志记录。</p><p>中国移动每天收集5-8TB的电话通话记录，Facebook每天则收集了近6TB的各种用户活动事件。</p><p>许多早期处理这类数据的系统都是依靠从生产服务器上实际收集日志文件进行分析。</p><p>近年来，一些专门的分布式日志聚合器已经发布，包括Facebook的Scribe[6]、Yahoo的Data Highway和Cloudera的Flume。</p><p>这些系统主要是为了收集日志数据，并将日志数据加载到数据仓库或Hadoop[8]中进行离线消费。</p><p>在LinkedIn（一家社交网站），我们发现除了传统的离线分析之外，我们还需要以不超过几秒的延迟支持上述大部分实时应用。</p><p>我们构建了一种新型的日志处理的消息传递系统，称为Kafka，它结合了传统日志聚合器和消息传递系统的优点。</p><p>一方面，Kafka具有分布式和可扩展性，并提供了高吞吐量。</p><p>另一方面，Kafka提供了类似于消息传递系统的API，允许应用程序实时消耗日志事件。</p><p>Kafka已经开源，并在LinkedIn的生产中成功使用了6个多月。</p><p>它极大地简化了我们的基础设施，因为我们可以利用一个单一的软件来在线和离线消费各种类型的日志数据。</p><p>本文的其余部分安排如下。</p><ul><li>在第2节中，我们重新审视了传统的消息传递系统和日志聚合器。</li><li>在第3节中，我们描述了Kafka的架构及其关键设计原则。</li><li>在第4节中，我们描述了我们在LinkedIn上部署的Kafka</li><li>在第5节中描述了Kafka的性能结果。</li><li>我们在第6节中讨论了未来的工作</li><li>在第6节中做了总结。</li></ul><h1 id="2-相关工作"><a href="#2-相关工作" class="headerlink" title="2. 相关工作"></a>2. 相关工作</h1><p>传统的企业消息系统已经存在了很长时间，通常在处理异步数据流的事件总线中起着至关重要的作用。</p><p>然而，有几个原因导致它们往往不能很好地适应日志处理。</p><p>首先，企业级系统提供的特性与日志处理该有的不匹配。那些系统往往侧重于提供丰富的交付保证。</p><p>例如，IBM Websphere MQ具有事务式支持，允许一个应用程序将消息以原子方式插入到多个队列中。</p><p>而JMS规范允许每个消息在消费后被确认消费，消费顺序可能是无序的。（没看懂，对JMS不了解，脑补了下，乱序消费并幂等的意思？）</p><p>这样的交付保证对于收集日志数据来说往往是矫枉过正的。偶尔丢失几个页面浏览事件当然不是世界末日。</p><p>那些不需要的功能往往会增加这些系统的API和底层实现的复杂性。</p><p>其次，相比较首要设计约束功能，许多系统并不是那样强烈地关注吞吐量。例如，JMS没有API允许生产者明确地将多个消息批量化为一个请求。这意味着每个消息都需要进行一次完整的TCP/IP往返，这对于我们领域的吞吐量要求是不可行的。</p><p>第三，那些系统在分布式支持方面比较弱。没有简单的方法可以在多台机器上对消息进行分区和存储。</p><p>最后，许多消息系统假设消息会被近似实时消费掉，未被消费的消息量总是相当小。</p><p>导致如果出现消息累积，它们的性能就会大大降低。比如当数据仓库等离线消耗者对消息系统做周期性的大负载消费，而不是连续消费数据时。</p><p>在过去几年里，已经建立了一些专门的日志聚合器。</p><p>比如Facebook使用了一个叫Scribe的系统，每个前端机器可以通过网络向一组Scribe机器发送日志数据。</p><p>每台Scribe机器聚合日志条目，并定期将其转储到HDFS或NFS设备上。</p><p>雅虎的数据高速公路项目也有类似的数据传递方式，一组机器聚合来自客户端的事件，按分钟保存为文件，然后将</p><p>其添加到HDFS。</p><p>Flume是Cloudera开发的一个比较新的日志聚合器。它支持可扩展的 “管道 “和 “数据下沉”，使流式日志数据的传</p><p>输非常灵活。它也有更多的集成分布式支持。</p><p>但是，这些系统大多是为离线消耗日志数据而构建的，往往会将实现细节（如 “按分钟保存的文件”）不必要地暴露给消费者。</p><p>此外，他们中的大多数都采用了 “推送 “模式，即Broker将数据转发给消费者。</p><p>在LinkedIn，我们发现 “拉动 “模式更适合我们的应用，因为每个消费者都能以自己能承受的最大速率检索到消</p><p>息，避免被推送的消息淹没在比自己能承受的速度更快的消息中。</p><p>拉动模式还可以让消费者很容易回传，我们在</p><p>3.2节末尾讨论了这个好处的细节。</p><p>最近，雅虎研究公司开发了一种新的分布式pub/sub系统，名为HedWig。HedWig具有高度的可扩展性和可</p><p>用性，并提供了强大的持久性保证。不过，它主要是用于存储资料库（data store）的提交日志。</p><h1 id="3-Kafka架构和设计原则"><a href="#3-Kafka架构和设计原则" class="headerlink" title="3. Kafka架构和设计原则"></a>3. Kafka架构和设计原则</h1><p>由于现有的各种消息系统的局限性，我们开发了一种新的基于消息传递的日志聚合器Kafka。</p><p>我们首先介绍一下Kafka中的基本概念。</p><p>一个主题定义一个特定类型的消息流。</p><p>一个生产者可以向一个主题发布消息。然后，发布的消息被存储在一组称为Broker的服务器上。</p><p>一个消费者可以从Broker那里订阅一个或多个主题，并通过从Broker那里提取数据来消费订阅的消息。</p><p>从概念上讲，消息传递的定义是比较简单的。同样的，我们试图使Kafka API也一样简单。为了证明这一点，我们</p><p>不展示具体的API，而是介绍一些示例代码来展示API的使用方法。</p><p>下面给出了生产者的示例代码。一个消息被定义为只包含一个字节的内容。用户可以选择自己喜欢的序列化方</p><p>法对消息进行编码。为了提高效率，生产者可以在一次发布请求中发送一组消息。</p><blockquote><p><strong>Sample producer code</strong>:</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">producer = <span class="keyword">new</span> Producer(...);</span><br><span class="line">message = <span class="keyword">new</span> Message(“test message str”.getBytes()); </span><br><span class="line">set = <span class="keyword">new</span> MessageSet(message); </span><br><span class="line">producer.send(“topic1”, set);</span><br></pre></td></tr></table></figure><p>要订阅一个主题，消费者首先要为该主题创建一个或多个消息流（理解为分区）。</p><p>发布到该主题的消息将被平均分配到这些子消息流（分区）中。</p><p>关于Kafka如何分配消息的细节将在后面的3.2节中描述。</p><p>每个消息流在持续产生的消息流上提供了一个迭代器接口。</p><p>消费者对消息流中的每个消息进行迭代，并处理消息的内容。</p><p>与传统的迭代器不同，消息流迭代器永远不会终止。</p><p>如果当前没有更多的消息要消费，迭代器就会阻塞，直到新的消息被发布到主题上。</p><p>我们既支持点对点的传递模式，即多个消费者共同消费一个主题中所有消息的单一副本，也支持多个消费者各自检</p><p>索一个主题的副本的发布/订阅模式。</p><blockquote><p> <strong>Sample consumer code</strong>:</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">streams[] = Consumer.createMessageStreams(“topic1”, <span class="number">1</span>) <span class="keyword">for</span> (message : streams[<span class="number">0</span>]) &#123;</span><br><span class="line"></span><br><span class="line">bytes = message.payload();</span><br><span class="line"> <span class="comment">// do something with the bytes</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="/images/Kafka论文/1.png" alt="image-20200428203312364" style="zoom:50%;"></p><p>Kafka的整体架构如图1所示。</p><p>由于Kafka是分布式的，所以一个Kafka集群通常由多个Broker组成。</p><p>为了平衡负载，一个主题被划分成多个分区，每个Broker存储一个或多个分区。</p><p>多个生产者和消费者可以同时发布和消费消息。</p><p>在第3.1节中，我们将描述Broker上的单个分区的布局，以及我们选择的一些设计选择，以使访问分区的效率更高。</p><p>在第3.2节中，我们将描述生产者和消费者在分布式设置中如何与多个Broker交互。</p><p>在第3.3节中，我们将讨论Kafka的交付保证（delivery guarantees）。</p><h2 id="3-1-单分区的性能"><a href="#3-1-单分区的性能" class="headerlink" title="3.1 单分区的性能"></a>3.1 单分区的性能</h2><p>我们在Kafka中做了一些设计的决策，让系统更有效率。</p><p><strong>1. 简单的存储方式</strong>：Kafka有一个非常简单的存储布局。</p><p>一个主题的每个分区对应一个逻辑日志。</p><p>在物理上，一个日志被实现为一组大小大致相同的段文件（例如，1GB）。</p><p>每当生产者向分区发布消息时，Broker只需将消息附加到最后一个段文件中。</p><p>为了更好的性能，我们只有在发布了一定数量的消息后，或者在发布了一定时间后，才会将段文件刷新到磁盘上。</p><p>一个消息只有在刷新后才会暴露在消费者面前。</p><p>与典型的消息传递系统不同，Kafka中存储的消息没有明确的消息ID。</p><p>相反，每条消息都是通过其在日志中的逻辑偏移来寻址。</p><p>这避免了维护用于辅助查询的索引结构的开销，这些索引结构将消息id映射到实际的消息位置。</p><p>注意，我们提到的消息id是递增的，但不是连续的。为了计算下一条消息的id，我们必须将当前消息的长度加到它的id上。</p><p>从现在开始，我们将交替使用消息id和偏移量。</p><p>消费者总是顺序消费来自特定分区的消息。</p><p>如果消费者确认某个特定的消息偏移，就意味着消费者已经接收到了该分区中该偏移之前的所有消息。</p><p>在实际的运行中，消费者向Broker发出异步拉取消息请求，以便有一个缓冲区的数据准备好供应用程序消费。</p><p>每个拉取消息请求都包含消费开始的消息的偏移量和可接受的字节数。</p><p>每个Broker在内存中保存一个排序的偏移量列表，包括每个段文件中第一个消息的偏移量。Broker<br>通过搜索偏移量列表来定位所请求的报文所在的段文件，并将数据发回给消费者。</p><p>当消费者收到一条消息后，它计算出下一条要消费的消息的偏移量，并在下一次拉取请求中使用它。</p><p>Kafka日志和内存中索引的布局如图2所示。每个框显示了一条消息的偏移量。</p><p><img src="/images/Kafka论文/2.png" alt="image-20200506192830629" style="zoom:50%;"></p><p><strong>2. 高效的传输</strong>: 我们在Kafka中传输数据的时候非常谨慎。</p><p>早前，我们已经表明，生产者可以在一次发送请求中提交一组消息。</p><p>虽然消费者API每次迭代一条消息，但在实际运行中，每一个消费者的拉动请求也会检索到多个消</p><p>息。一次传输通常是几百个K字节的大小。</p><p>我们做出的另一个非常规的选择是避免在Kafka层面缓存消息在内存中。</p><p>相反，我们依赖底层文件系统的页面缓存。</p><p>这样做的主要好处是避免了双重缓冲，消息就只会缓存在页面缓存中。</p><p>这样做还有一个额外的好处，那就是即使在代理进程重启的时候，也能保留热缓存（warm cache)。</p><p>由于Kafka根本不在进程中缓存消息，所以它在垃圾回收内存方面的开销非常小，这使得在基于VM</p><p>的语言中高效实现是可行的。</p><p>最后，由于生产者和消费者都是按顺序访问段文件，而消费者往往会比生产者晚一点，所以正常的</p><p>操作系统缓存启发式缓存是非常有效的（缓存直写和预读）。</p><p>我们发现，生产者和消费者的性能都与数据大小呈线性关系，最大的数据量可以达到很多T字节。（没看懂）</p><p>此外，我们还对消费者的网络访问进行了优化。</p><p>Kafka是一个多消费者系统，一条消息可能被不同的消费者应用多次消耗。</p><p>从本地文件向远程socket发送字节的典型方法包括以下步骤。</p><ol><li>从存储介质中读取数据到操作系统中的页面缓存</li><li>将页面缓存中的数据复制到应用缓冲区</li><li>将应用缓冲区复制到另一个内核缓冲区</li><li>将内核缓冲区发送到Socket。</li></ol><p>其中包括4个数据复制和2个系统调用。</p><p>在Linux和其他Unix操作系统上，存在一个sendfile API，可以直接将字节从文件通道传输到socket</p><p>通道。这通常可以避免步骤（2）和（3）中介绍的2个复制和1个系统调用。</p><p>Kafka利用sendfile API来有效地将日志段文件中的字节从代理服务器向消费者传递。</p><p><strong>3. 无状态的Broker</strong>: 与大多数其他消息系统不同，在Kafka中，每个消费者消费了多少消息的信</p><p>息不是由Broker维护，而是由消费者自己维护。这样的设计减少了很多的复杂性，也减少了Broker</p><p>的开销。</p><p>但是，这使得删除消息变得很棘手，因为Broker不知道是否所有的用户都消费了这个消息。</p><p>Kafka通过使用简单的基于时间的SLA保留策略解决了这个问题。</p><p>如果一条消息在代理中保留的时间超过一定的时间，通常是7天，则会自动删除。</p><p>这个方案在实际应用中效果不错。大部分消费者包括离线的消费者，都是按日、按小时或实时完成</p><p>消费。由于Kafka的性能不会随着数据量的增大而降低，所以这种长时间保留的方案是可行的。</p><p>这种设计有一个重要的副作用。</p><p>一个消费者可以故意倒退到一个旧的偏移量，重新消费数据。</p><p>这违反了队列的通用规定，但事实证明，这对很多消费者来说是一个必不可少的功能。</p><p>例如，当消费者中的应用逻辑出现错误时，应用可以在错误修复后回放某些消息。这对我们的数据仓库或Hadoop系统中的ETL数据加载特别重要。</p><p>再比如，被消费的数据可能只是周期性地被刷新到一个持久化存储（例如，全文索引器）。</p><p>如果消费者崩溃，未冲洗的数据就会丢失。在这种情况下，消费者可以检查未冲洗的消息的最小偏移量，并在重启时从该偏移量中重新消费。</p><p>我们注意到，相比于推送模型，在拉动模型中支持消费者重新消费要容易得多。</p><h2 id="3-2-分布式协调处理"><a href="#3-2-分布式协调处理" class="headerlink" title="3.2 分布式协调处理"></a>3.2 分布式协调处理</h2><p>现在我们来解释一下生产者和消费者在分布式环境中的执行方式。</p><p>每个生产者可以向一个随机的或由分区key和分区函数语义决定的分区发布消息。我们将重点讨论消</p><p>费者是如何与Broker互动的。</p><p>Kafka有消费者组的概念。</p><p>每个消费组由一个或多个消费者组成，共同消费一组被订阅的主题，也就是说，每条消息只传递给</p><p>消费组内的一个消费者。</p><p>不同的消费者组各自独立消费全套订阅的消息，不需要跨消费者组的协调机制。</p><p>同一组内的消费者可以在不同的进程或不同的机器上。</p><p>我们的目标是在不引入过多的协调开销的情况下，将存储在Broker中的消息平均分配给组中的所有</p><p>消费者。</p><p>我们的第一个决定是将一个主题内的分区作为最小的并行单元。</p><p>这意味着，在任何时候一个分区的所有消息都只被每个消费组中的一个消费者消费。</p><p>假设我们允许多个消费者同时消费一个分区，那么他们就必须协调谁消费什么消息，这就需要加锁和维护状态，会造成一定的额外开销。</p><p>相反，在我们的设计中，消费进程只需要在消费者重新平衡负载时进行协调，正常来说这种情况不经常发生。</p><p>为了使负载真正平衡，我们需要一个主题中的分区比每个消费组中的消费者多很多。</p><p>我们可以通过对一个主题进行更多的分区来达到这个目的。</p><p>我们做的第二个决定是不设立中心化的”主控 “节点，而是让消费者以去中心化的方式相互协调。</p><p>增加一个主节点会使系统变得复杂化，因为我们不得不进一步担心主节点故障。</p><p>为了方便协调，我们采用了一个高度可用的共识服务Zookeeper。</p><p>Zookeeper有一个非常简单的、类似于文件系统的API。</p><p>人们可以创建一个路径，设置一个路径的值，读取一个路径的值，删除一个路径的值，以及列出一个路径的子路径。</p><p>它还可以做一些更有趣的事情。</p><ul><li>可以在路径上注册一个watcher，当路径的子路径或路径的值发生变化时，可以得到通知</li><li>可以将路径创建为临时的（相对于持久性的），这意味着如果创建的客户端不在了，路径会被Zookeeper服务器自动删除</li><li>zookeeper将数据复制到多个服务器上，这使得数据的可靠性和可用性很高。</li></ul><p>Kafka使用Zookeeper完成以下任务。</p><ul><li><p>检测Broker和消费者的添加和删除</p></li><li><p>当上述事件发生时，在每个消费者中触发一个再平衡过程</p></li><li><p>维护消费关系，并跟踪每个分区的消费偏移情况。</p></li></ul><p>具体来说，当每个Broker或消费者启动时，它将其信息存储在Zookeeper中的Broker或消费者注册表中。</p><p>Broker注册表包含Broker的主机名和端口，以及存储在其上的主题和分区。</p><p>消费者注册表包括消费者所属的消费组，以及它所订阅的主题集合。</p><p>每个消费组都与Zookeeper中的一个所有权注册表和一个偏移注册表相关联。</p><p>所有权注册表对每个订阅的分区都有一个路径，路径值是当前从这个分区消费的消费者id（我们使用的术语是消费者拥有这个分区）。</p><p>偏移注册表为每个订阅的分区存储了该分区中最后一个被消费的消息的偏移量。</p><p>Broker注册表、消费者注册表和所有权注册表在 Zookeeper 中创建的路径都是临时的。</p><p>偏移注册表中创建的路径是持久的。</p><p>如果一个Broker服务器发生故障，其上的所有分区都会自动从Broker注册表中删除。</p><p>消费者的故障会导致其在消费者注册表中的记录和所有权注册表中的所有分区记录丢失。</p><p>每个消费者都会在Broker注册表和消费者注册表上注册一个Zookeeper的Watcher，每当Broker集合或消费者组</p><p>发生变化时，都会收到通知。</p><p><img src="/images/Kafka论文/3.png" alt="image-20200507194132517" style="zoom:50%;"></p><p>在消费者的初始启动过程中，或者当消费者通过Watcher收到关于Broker/消费者变更的通知时，消费者会启动一</p><p>个重新平衡过程，以确定它应该消费的新分区。</p><p>在算法1中描述了这个过程。</p><p>通过从Zookeeper读取Broker和消费者注册表，消费者首先计算每个订阅主题T的可用分区集合（PT）和订阅T的消费者集合（CT）。</p><p>对于消费者选择的每个分区，它在所有权注册表中写入自己作为该分区的新所有者。</p><p>最后，消费者开始一个线程从拥有的分区中拉出数据，偏移量从存储在偏移注册表中的记录值开始。</p><p>当消息从分区中拉出时，消费者会定期更新偏移注册表中的最新消耗的偏移量。</p><p>当一个消费组内有多个消费者时，每个消费者都会收到Broker或消费者变更的通知。</p><p>但是，通知到达每个消费者的时间上略有不同。</p><p>因此，有可能是一个消费者试图夺取仍由另一个消费者拥有的分区的所有权。</p><p>当这种情况发生时，第一个消费者只需释放其当前拥有的所有分区，等待一段时间，然后重新尝试重新平衡。</p><p>在实践中，重新平衡过程通常只需重试几次就会稳定下来。</p><p>当创建一个新的消费者组时，偏移注册表中没有可用的偏移量。</p><p>在这种情况下，消费者将使用我们在Broker上提供的API，从每个订阅分区上可用的最小或最大的偏移量开始（取</p><p>决于配置）。</p><h2 id="3-3-传递保证"><a href="#3-3-传递保证" class="headerlink" title="3.3 传递保证"></a>3.3 传递保证</h2><p>一般来说，Kafka只保证至少一次交付语义。</p><p>确切一次交付语义通常需要两阶段提交，对于我们的应用来说并不是必须的。</p><p>大多数情况下，一个消息会准确地传递给每个消费组一次。</p><p>但是，当一个消费组进程崩溃而没有干净关闭的情况下，新接管的消费进程可能会得到一些重复的消息，这些消息</p><p>在最后一次偏移成功提交给zookeeper之后。</p><p>如果一个应用程序关心重复的问题，那么它必须添加自己的去重复逻辑，要么使用我们返回给消费者的偏移量，要</p><p>么使用消息中的一些唯一密钥。这通常是一种比使用两阶段提交更经济的方法。</p><p>Kafka保证来自单个分区的消息按顺序传递给消费者。</p><p>然而，对于来自不同分区的消息的顺序，Kafka并不保证。</p><p>为了避免日志损坏，Kafka在日志中为每个消息存储一个CRC。</p><p>如果Broker上有任何I/O错误，Kafka会运行一个恢复过程来删除那些具有不一致CRC的消息。</p><p>在消息级别拥有CRC也允许我们在消息产生或消费后检查网络错误。</p><p>如果一个Broker宕机，那么存储在其上的任何未被消费的信息都将不可用。</p><p>如果一个Broker上的存储系统被永久损坏，任何未被消费的消息都会永远丢失。</p><p>在未来，我们计划在Kafka中添加复制功能，以便在多个Broker上冗余存储每一条消息。</p><h1 id="4-Kafka在LinkedIn的实践"><a href="#4-Kafka在LinkedIn的实践" class="headerlink" title="4. Kafka在LinkedIn的实践"></a>4. Kafka在LinkedIn的实践</h1><p>在本节中，我们将介绍我们如何在LinkedIn使用Kafka。</p><p>图3显示了我们部署的简化版本。</p><p>在每个运行面向用户服务的数据中心，我们都会部署一个Kafka集群。</p><p>前端服务会生成各种日志数据，并分批发布到本地的Kafka的Broker中。</p><p>我们依靠硬件负载均衡器将发布请求均匀地分配给Kafka的Broker。</p><p>Kafka的在线消费者在同一数据中心内的服务中运行。</p><p><img src="/images/Kafka论文/6.png" alt="image-20200513201939870" style="zoom:50%;"></p><p>我们还在每个数据中心单独部署了一个Kafka集群，用于离线分析，该集群在地理位置上靠近我们的Hadoop集群</p><p>和其他数据仓库基础设施。</p><p>这个Kafka实例运行一组嵌入式消费者，实时从数据中心的Kafka实例中拉取数据。</p><p>然后，我们运行数据加载任务，将数据从这个Kafka的复制集群拉到Hadoop和我们的数据仓库中，在这里我们运</p><p>行各种报表作业和数据分析处理。</p><p>我们还使用这个Kafka集群进行原型开发，并有能力针对原始事件流运行简单的脚本进行实时查询。</p><p>无需过多的调整，整个管道的端到端延迟平均约为10秒，足以满足我们的要求。</p><p>目前，Kafka每天积累了数百G字节的数据和近10亿条消息。</p><p>随着我们完成对遗留系统的迁移，我们预计这个数字将大幅增长。</p><p>未来还会增加更多类型的消息。</p><p>当运营人员启动或停止Broker进行软件或硬件维护时，再平衡过程能够自动重定向消费。</p><p>我们的跟踪系统还包括一个审计系统，以验证整个管道中的数据没有丢失。</p><p>为了方便起见，每条消息都带有时间戳和服务器名称。</p><p>我们对每个生产者进行仪器化处理，使其定期生成一个监控事件，记录该生产者在固定时间窗口内为每个主题发布</p><p>的消息数量。</p><p>生产者将监控事件发布到Kafka的一个单独的主题中。</p><p>然后，消费者可以统计他们从一个给定的主题中收到的消息数量，并将这些计数与监测事件进行验证，以验证数据</p><p>的正确性。</p><p>加载到Hadoop集群中是通过实现一种特殊的Kafka输入格式来完成的，该格式允许MapReduce作业直接从Kafka</p><p>中读取数据。</p><p>MapReduce作业加载原始数据，然后将其分组和压缩，以便将来进行高效处理。</p><p>无状态的Broker和客户端存储消息偏移在这里再次发挥了作用，使得MapReduce任务管理（允许任务失败和重</p><p>启）以自然的方式处理数据负载，而不会在任务重启时重复或丢失消息。</p><p>只有在任务成功完成后，数据和偏移量才会存储在HDFS中。</p><p>我们选择使用Avro作为我们的序列化协议，因为它是高效的，并且支持模式演化。</p><p>对于每条消息，我们将其Avro模式的id和序列化的字节存储在有效payload中。</p><p>这个模式允许我们执行一个约定，以确保数据生产者和消费者之间的兼容性。</p><p>我们使用一个轻量级的模式注册服务来将模式id映射到实际的模式。</p><p>当消费者得到一个消息时，它在模式注册表中查找，以检索该模式，该模式被用来将字节解码成对象（这种查找只</p><p>需要对每个模式进行一次，因为值是不可更改的）。</p><h1 id="5-实验结果"><a href="#5-实验结果" class="headerlink" title="5. 实验结果"></a>5. 实验结果</h1><p>我们进行了一项实验性研究，将Kafka与Apache ActiveMQ v5.4（一种流行的JMS开源实现）和以性能著称的消息</p><p>系统RabbitMQ v2.4进行了比较。</p><p>我们使用了ActiveMQ的默认持久化消息存储KahaDB。</p><p>虽然这里没有介绍，但我们也测试了另一种AMQ消息存储，发现其性能与KahahaDB非常相似。</p><p>只要有可能，我们尽量在所有系统中使用可比性设置。</p><p>我们在2台Linux机器上进行了实验，每台机器都有8个2GHz核心，16GB内存，6个磁盘，带RAID 10。</p><p>这两台机器用1Gb网络链路连接。其中一台机器作为Broker，另一台机器作为生产者或消费者。</p><p><strong>Producer测试</strong>：</p><p>我们将所有系统中的Broker配置为异步刷新消息到其持久化磁盘中。</p><p>对于每个系统，我们运行了一个单一的生产者来发布总共1000万条消息，每条消息的大小为200字节。</p><p>我们将Kafka生产者配置为以1和50的大小分批发送消息。</p><p>ActiveMQ和RabbitMQ似乎没有一个简单的消息批处理方法，我们假设它使用的是1的批处理大小，结果如图4所示。</p><p>x轴代表的是随着时间的推移向Broker发送的数据量，单位为MB，y轴对应的是生产者吞吐量，单位为每秒的消息量。</p><p>平均而言，Kafka在批处理大小为1和50的情况下，Kafka可以以每秒5万条和40万条消息的速度分别发布消息。</p><p>这些数字比ActiveMQ高了好几个数量级，而且至少是比RabbitMQ高2倍。</p><p><img src="/images/Kafka论文/4.png" alt="image-20200514202746023" style="zoom:50%;"></p><p>Kafka的表现要好得多有几个原因。</p><p>首先，Kafka生产者目前不等待Broker的回执，以Broker能处理的速度发送消息。</p><p>这大大增加了发布者的吞吐量。</p><p>在批处理量为50个的情况下，单个Kafka生产者几乎打满了生产者和Broker之间的1Gb带宽。</p><p>这对于日志聚合的情况来说是一个有效的优化，因为数据必须异步发送，以避免在实时服务流量中引入任何延迟。</p><p>同时我们注意到，broker在没有回送ack的情况下，不能保证producer每一条发布的消息都能被broker实际接收到。</p><p>对于不同类型的日志数据，只要丢掉的消息数量相对较少，以持久化换取吞吐量是可取的。然而，我们确实计划在</p><p>未来解决更多关键数据的持久化问题。</p><p>其次，Kafka使用有更有效的存储格式。</p><p>正常来说，在Kafka中，每个消息的开销是9个字节，而在ActiveMQ中则是144个字节。</p><p>这意味着ActiveMQ比Kafka多用了70%的空间来存储同样的1000万条消息。</p><p>ActiveMQ的一个开销来自于JMS所要求的沉重的消息头。</p><p>另一个开销是维护各种索引结构的成本。</p><p>我们观察到，ActiveMQ中最繁忙的线程之一花了大部分时间访问B-Tree来维护消息元数据和状态。</p><p>最后，批处理通过摊销RPC开销，大大提高了吞吐量。在Kafka中，50条消息的批处理量几乎提高了一个数量级的</p><p>吞吐量。</p><p><strong>消费者测试</strong>：</p><p>在第二个实验中，我们测试了消费者的性能。</p><p>同样，对于所有系统，我们使用一个消费者来检索总共1000万条消息。</p><p>我们对所有系统进行了配置，使每个拉取请求预取的数据量大致相同–最多1000条消息或约200KB。</p><p>对于 ActiveMQ 和 RabbitMQ，我们将消费者确认模式设置为自动。</p><p>由于所有的消息都适合在内存中，所以所有的系统都是从底层文件系统的页面缓存或一些内存中的缓冲区中提供数</p><p>据。</p><p>结果如图5所示。</p><p><img src="/images/Kafka论文/5.png" alt="image-20200514203355691" style="zoom:50%;"></p><p>Kafka平均每秒消费22000条消息，是ActiveMQ和RabbitMQ的4倍多。</p><p>我们可以想到几个原因。</p><p>首先，由于Kafka有更有效的存储格式，所以消费者从Broker那里传输的字节数更少。</p><p>其次，ActiveMQ和RabbitMQ中的Broker都必须维护每一条消息的传递状态。</p><p>我们观察到ActiveMQ线程中的一个ActiveMQ线程在这个测试中忙于向磁盘写入KahaDB页面。</p><p>相比之下，Kafka代理上没有任何磁盘写入活动。</p><p>最后，通过使用sendfile API，Kafka降低了传输开销。</p><p>在这一节的最后，我们要指出，实验的目的并不是为了表明其他的消息传递系统不如Kafka。</p><p>毕竟，ActiveMQ和RabbitMQ都有比Kafka更多的功能。</p><p>主要是为了说明一个定制的系统可能带来的性能提升。</p><h1 id="6-总结与未来展望"><a href="#6-总结与未来展望" class="headerlink" title="6. 总结与未来展望"></a>6. 总结与未来展望</h1><p>我们提出了一个名为Kafka的新型系统，用于处理海量的日志数据流。</p><p>与普通消息传递系统一样，Kafka采用了一种基于拉取的消费模型，允许应用程序以自己的速度消费数据，并在需</p><p>要的时候随时倒带消费。</p><p>通过专注于日志处理应用，Kafka实现了比传统消息系统更高的吞吐量。</p><p>同时，它还提供了内置的分布式支持，并且可以进行扩展。我们已经在LinkedIn成功地将Kafka用于离线和在线应</p><p>用。</p><p>未来，我们有几个方向。</p><p>首先，我们计划在多个Broker之间添加内置的消息复制功能，即使在机器故障无法恢复的情况下，我们也可以提</p><p>供持久化和数据可用性保证。</p><p>我们希望同时支持异步和同步复制模型，以允许在生产者延迟和所提供的保证强度之间进行一些权衡。</p><p>一个应用可以根据自己对持久化、可用性和吞吐量的要求，选择合适的冗余级别。</p><p>其次，我们希望在Kafka中加入一些流处理能力。</p><p>在从Kafka中检索消息后，实时应用经常会执行类似的操作，例如基于窗口的计数，并将每条消息与二级存储中的</p><p>记录或与另一个流中的消息连接起来。</p><p>在最底层，在发布过程中，通过在join键上对消息进行语义上的分区来支持这种操作，这样，所有用特定键发送的</p><p>消息都会进入同一个分区，从而到达一个单一的消费进程。</p><p>这为在消费机集群中处理分布式流提供了基础。</p><p>在此基础上，我们觉得一个有用的信息流实用程序库，如不同的窗口化函数或连接技术将对这类应用有利。</p><h1 id="7-引用"><a href="#7-引用" class="headerlink" title="7. 引用"></a>7. 引用</h1><ol><li><a href="http://activemq.apache.org/" target="_blank" rel="noopener">http://activemq.apache.org/</a></li><li><a href="http://avro.apache.org/" target="_blank" rel="noopener">http://avro.apache.org/</a></li><li>Cloudera’s Flume, <a href="https://github.com/cloudera/flume" target="_blank" rel="noopener">https://github.com/cloudera/flume</a></li><li><a href="http://developer.yahoo.com/blogs/hadoop/posts/2010/06/ena" target="_blank" rel="noopener">http://developer.yahoo.com/blogs/hadoop/posts/2010/06/ena</a> bling_hadoop_batch_processi_1/</li><li>Efficient data transfer through zero copy: <a href="https://www.ibm.com/developerworks/linux/library/j-" target="_blank" rel="noopener">https://www.ibm.com/developerworks/linux/library/j-</a> zerocopy/</li><li>Facebook’s Scribe, <a href="http://www.facebook.com/note.php?note_id=32008268919" target="_blank" rel="noopener">http://www.facebook.com/note.php?note_id=32008268919</a></li><li>IBM Websphere MQ: <a href="http://www-" target="_blank" rel="noopener">http://www-</a> 01.ibm.com/software/integration/wmq/</li><li><a href="http://hadoop.apache.org/" target="_blank" rel="noopener">http://hadoop.apache.org/</a></li><li><a href="http://hadoop.apache.org/hdfs/" target="_blank" rel="noopener">http://hadoop.apache.org/hdfs/</a></li><li><a href="http://hadoop.apache.org/zookeeper/" target="_blank" rel="noopener">http://hadoop.apache.org/zookeeper/</a></li><li><a href="http://www.slideshare.net/cloudera/hw09-hadoop-based-" target="_blank" rel="noopener">http://www.slideshare.net/cloudera/hw09-hadoop-based-</a> data-mining-platform-for-the-telecom-industry</li><li><a href="http://www.slideshare.net/prasadc/hive-percona-2009" target="_blank" rel="noopener">http://www.slideshare.net/prasadc/hive-percona-2009</a></li><li><a href="https://issues.apache.org/jira/browse/ZOOKEEPER-775" target="_blank" rel="noopener">https://issues.apache.org/jira/browse/ZOOKEEPER-775</a></li><li>JAVA Message Service: <a href="http://download.oracle.com/javaee/1.3/jms/tutorial/1_3_1-" target="_blank" rel="noopener">http://download.oracle.com/javaee/1.3/jms/tutorial/1_3_1-</a> fcs/doc/jms_tutorialTOC.html.</li><li>Oracle Enterprise Messaging Service: <a href="http://www.oracle.com/technetwork/middleware/ias/index-" target="_blank" rel="noopener">http://www.oracle.com/technetwork/middleware/ias/index-</a> 093455.html</li><li><a href="http://www.rabbitmq.com/" target="_blank" rel="noopener">http://www.rabbitmq.com/</a></li><li>TIBCO Enterprise Message Service: <a href="http://www.tibco.com/products/soa/messaging/" target="_blank" rel="noopener">http://www.tibco.com/products/soa/messaging/</a></li><li>Kafka, <a href="http://sna-projects.com/kafka/" target="_blank" rel="noopener">http://sna-projects.com/kafka/</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;原文地址：&lt;a href=&quot;http://notes.stephenholiday.com/Kafka.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://notes.stephenholiday.com/Kafka.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;太长不看：&lt;/p&gt;
&lt;p&gt;相对于JMS等其他的消息系统，Kafka舍弃了很多功能，以达到性能上的提升。&lt;/p&gt;
&lt;p&gt;论文讲述了Kafka设计上的取舍，以及提升性能的很多点。&lt;/p&gt;
    
    </summary>
    
    
      <category term="论文翻译" scheme="https://blog.lovezhy.cc/categories/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/"/>
    
    
      <category term="Kafka" scheme="https://blog.lovezhy.cc/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>业务思考-点赞列表怎么做</title>
    <link href="https://blog.lovezhy.cc/2020/03/16/%E4%B8%9A%E5%8A%A1%E6%80%9D%E8%80%83-%E7%82%B9%E8%B5%9E%E5%88%97%E8%A1%A8%E6%80%8E%E4%B9%88%E5%81%9A/"/>
    <id>https://blog.lovezhy.cc/2020/03/16/%E4%B8%9A%E5%8A%A1%E6%80%9D%E8%80%83-%E7%82%B9%E8%B5%9E%E5%88%97%E8%A1%A8%E6%80%8E%E4%B9%88%E5%81%9A/</id>
    <published>2020-03-15T16:00:00.000Z</published>
    <updated>2020-03-17T15:34:22.000Z</updated>
    
    <content type="html"><![CDATA[<p>在小米有品的工作内容也算是和社交有点关系，会有类似微博的点赞，查看点赞列表的功能。<br>这个功能看起来简单，其实做起来一点都不容易。<br>为了避嫌，这里以微博为例，讲一讲自己的思考。<br>类似的，还有关注列表等。这里就简单思考点赞列表。</p><a id="more"></a><h1 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h1><p>微博上，我们可以给一个具体的微博点赞，然后个人中心页面可以查看自己点赞的内容的历史<br>所以基本功能概括起来如下：</p><ol><li>给微博点赞/取消点赞</li><li>查看是否给该微博点过赞</li><li>查看历史点赞记录</li></ol><p>在要应对的数据量比较大情况下，要完全实现上面这三个功能也不容易。尤其是这种很典型的具体冷热属性的数据。<br>所以会有一些产品妥协策略：</p><ol><li>时间久远的微博，默认返回未点过赞  //这种产品可能会比较同意</li><li>时间久远的微博，点赞记录中找不到  //这种一般不会同意的，放弃吧<br>为什么这么妥协会比较好做呢？下面再详细聊聊</li></ol><p>下面看看怎么实现</p><h1 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h1><p>这个是最简单的实现方式<br>其实还有更简单的，就是只有Mysql，但是这种一般都不会使用的，除非自己写写应用。</p><p>每个用户的点赞列表都存为一个ZSET<br><code>Key=weibo:like:${uid}</code><br><code>Value=${weiboId}，Score=${Time}</code></p><ol><li>点赞时加入到ZSET，取消点赞时从ZSET中删除</li><li>查询是否点过赞使用zscore</li><li>历史点赞记录用zrange</li></ol><h2 id="注意事项一"><a href="#注意事项一" class="headerlink" title="注意事项一"></a>注意事项一</h2><p>没问题吗？<br>是的，一般来说这么搞就行了，但是其实有个不小的瑕疵。<br>查询历史点赞记录用zrange。</p><p>想象如下的例子：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">request: &#123;</span><br><span class="line">page: 0,</span><br><span class="line">pageSize: 10</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>好，我们用<code>zrange(key, page, pageSize)</code>返回前十条</p><p>我看到自己的前十个点赞记录，卧槽太傻比了，全部取消点赞<br>ok，我们zrem() * 10次，把zset中前10个记录删除了。</p><p>再来请求下一页：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">request: &#123;</span><br><span class="line">page: 1,</span><br><span class="line">pageSize: 10</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>我们用<code>zrange(key, page, pageSize)</code>返回前十条</p><p>发现问题了吗？<br>第二次zrange的10条，其实是最原始数据的20-30条。<br>中间有一页的点赞记录因为我们zrem的原因，加载不出来。</p><p>这就是用zset做分页的普遍缺点。</p><p>怎么解呢？<br>有个简单的方法，我们用<code>rangeByScore</code>方法，其实参数最大值，是上一页的最小的一个<code>Score</code>。<br>这样，前端每次的请求其实是带上上一页的最小的那个时间戳<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">request: &#123;</span><br><span class="line">page: x,</span><br><span class="line">pageSize: 10,</span><br><span class="line">lastTime: 103232</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>这样就可以解决了。</p><h2 id="注意事项二"><a href="#注意事项二" class="headerlink" title="注意事项二"></a>注意事项二</h2><p>但是还有个问题：<br>我点赞了微博id=23。<br>然后这条微博被用户删除了。<br>那我从zset中拉到这个id，组装数据时会发现id=23查找不到。</p><p>这个时候其实有两种选择：</p><ol><li>告诉用户这个点赞内容被删除了，微博就是这么做的</li><li>返回空</li></ol><p>返回空其实又带来一个问题<br>如果我很不巧，第4页的点赞微博都是一个人的，她清空了微博<br>那请求和响应就会变成这样：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">request: &#123;</span><br><span class="line">page: 3,</span><br><span class="line">pageSize: 10,</span><br><span class="line">lastTime: 103232</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">response: &#123;</span><br><span class="line">[]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>后端返回了一个空数据。</p><p>如果这么定义的话，前端会以为已经请求空了，就会告诉用户已经没有数据了。</p><p>这个时候其实就出BUG了。</p><p>那这个怎么解呢？<br>很容易想到的就是：<br>response中带上total字段，前端判断后续有没有数据按照total来。<br>那其实和注意事项一又冲突了。不好。</p><p>还有个解法：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">response: &#123;</span><br><span class="line">[],</span><br><span class="line">hasNext: true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>用<code>hasNext</code>告诉前端有没有后续数据了<br><code>hasNext</code>怎么来呢？<br>我们从zset中range获取的时候，如果拉出来的个数小于pageSize，那么就是false。<br>如果等于pageSize，那么就是true。</p><h2 id="妥协策略"><a href="#妥协策略" class="headerlink" title="妥协策略"></a>妥协策略</h2><p>全存Redis，当然会有问题，数据量太大怎么办？<br>对于妥协策略1，我们定时的扫我们的Key（或者查询时，插入时异步操作），如果发现有些点赞记录太久远，就把Value删除。<br>这样我们的Redis负担就小点，<br>但是对不起，这样其实把妥协策略2也做了，是行不通的。</p><h1 id="类Redis数据库"><a href="#类Redis数据库" class="headerlink" title="类Redis数据库"></a>类Redis数据库</h1><p>但是又不想抛弃Redis，因为Redis实现起来确实简单啊。<br>那怎么办？<br>类Redis数据库来救场了。</p><p>类Redis说白了就是兼容Redis的指令，但是存储上，不全存内存，会存到磁盘上。<br>目前市面上比较流行的类Redis数据库有Pika，SSDB这种<br>具体笔者也没使用过，就不做评价，简单介绍下<br>小公司可以自己搭建着玩玩，但是大公司可能就没这个场景了，需要懂这个的运维来支持。</p><h2 id="Pika"><a href="#Pika" class="headerlink" title="Pika"></a>Pika</h2><h2 id="SSDB"><a href="#SSDB" class="headerlink" title="SSDB"></a>SSDB</h2><h1 id="Redis-Mysql"><a href="#Redis-Mysql" class="headerlink" title="Redis + Mysql"></a>Redis + Mysql</h1><p>这种比较少见其实，但是好歹这两数据库在公司都是标配。<br>主要是Redis存热数据，Mysql存冷数据。</p><p>写的时候双写<br>查询的时候先查Redis，Redis查不到再去查Mysql<br>分页查询的时候，查Redis，过期了就去Mysql捞一部分，然后存回Redis，设置个过期时间。<br>太久的就直接查Mysql，没必要存Redis了。</p><p>但是这里得考虑几个问题：</p><ol><li>这种行为数据，实时写数据库一般不会同意的，可以先写Redis，然后搞个消息队列慢慢写数据库</li><li>查是否给该文章点赞过，先查Redis，如果空了，再查Mysql。可能会出问题，有点隐患，不过也不用太担心，因为在Mysql中的一般就是冷数据库，问题不大。Redis存的容量大一点。</li><li>分页查询点赞历史，先查Redis，到底了去查Mysql，这里切换的衔接逻辑得好好想想。问题也不是很大。</li></ol><p>看起来很不错是不是，但是这种方案，最大的问题还是Mysql。<br>你想想这个表里的数据长啥样？<br>就几个字段：</p><ol><li>id：自增主键</li><li>uid：用户id</li><li>weiboId：微博id</li><li>createTime：点赞时间</li><li>del：是否删除了（这个看公司吧，有的只允许逻辑删除）</li></ol><p>这表数据太简单了，如果真到微博那种量级，增长速度会很快很快。<br>假设用户200w，每个人点赞2篇内容，那么一天增长400w条记录，一年就146000w，14亿。<br>这谁顶得住。</p><p>这种其实硬要解还是有点方法：</p><ol><li>压缩表：把字段weiboId，改成weiboIds，一行记录多存几个点赞记录。数据行数可以缩小几个量级，但是插入，查询和Redis衔接起来就比较复杂了。<strong>同时删除几乎不好做了。</strong></li><li>分库分表。其实我感觉分库分表意义不大。</li></ol><h2 id="妥协策略-1"><a href="#妥协策略-1" class="headerlink" title="妥协策略"></a>妥协策略</h2><p>来看看这种方案，如果产品妥协了，会不会简单点：<br>妥协策略1：查是否点过赞，Redis查不到，就默认未点赞，不用去查Mysql了。<br>妥协策略2：查完Redis，去查Mysql，可以支持。</p><p>其实再拓展下，如果产品妥协了策略1，那么写入的时候，只写Redis，然后再在某个时间点，把冷数据同步到Mysql就行。<br>这样就不用双写数据库了，同时同步的时候可以批量查入。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>所以综合来看，功能上，对热点数据的点赞/取消点赞/查询是否点赞比较好<br>如果你压缩数据行：对冷数据（Mysql中的数据），取消点赞，分页查询点赞记录比较复杂。<br>如果你不压缩：数据量太大</p><h1 id="Redis-Hbase"><a href="#Redis-Hbase" class="headerlink" title="Redis + Hbase"></a>Redis + Hbase</h1><p>Redis + Hbase算是比较终极的方案了。<br>其实笔者对Hbase也不是很了解。<br>了解了再说吧。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在小米有品的工作内容也算是和社交有点关系，会有类似微博的点赞，查看点赞列表的功能。&lt;br&gt;这个功能看起来简单，其实做起来一点都不容易。&lt;br&gt;为了避嫌，这里以微博为例，讲一讲自己的思考。&lt;br&gt;类似的，还有关注列表等。这里就简单思考点赞列表。&lt;/p&gt;
    
    </summary>
    
    
      <category term="业务思考" scheme="https://blog.lovezhy.cc/categories/%E4%B8%9A%E5%8A%A1%E6%80%9D%E8%80%83/"/>
    
    
      <category term="Redis" scheme="https://blog.lovezhy.cc/tags/Redis/"/>
    
      <category term="业务思考" scheme="https://blog.lovezhy.cc/tags/%E4%B8%9A%E5%8A%A1%E6%80%9D%E8%80%83/"/>
    
      <category term="Hbase" scheme="https://blog.lovezhy.cc/tags/Hbase/"/>
    
      <category term="Pika" scheme="https://blog.lovezhy.cc/tags/Pika/"/>
    
      <category term="分库分表" scheme="https://blog.lovezhy.cc/tags/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"/>
    
  </entry>
  
  <entry>
    <title>搞懂内存屏障-指令与JMM</title>
    <link href="https://blog.lovezhy.cc/2020/03/14/%E6%90%9E%E6%87%82%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C-%E6%8C%87%E4%BB%A4%E4%B8%8EJMM/"/>
    <id>https://blog.lovezhy.cc/2020/03/14/%E6%90%9E%E6%87%82%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C-%E6%8C%87%E4%BB%A4%E4%B8%8EJMM/</id>
    <published>2020-03-13T16:00:00.000Z</published>
    <updated>2020-03-14T14:55:25.770Z</updated>
    
    <content type="html"><![CDATA[<p>前面讲了CPU的演进，提出了StoreBuffer和InvalidateQueue的设计，并且讲解了这两个设计会带来的问题。<br>解决这两个问题就是引入内存屏障：强制刷新StoreBuffer和InvalidateQueue。</p><p>这里详细讲讲x86机器上的内存屏障指令与其他隐式的含有内存屏障的指令。<br>然后再聊一聊JMM与内存屏障的对应关系。</p><a id="more"></a><h1 id="x86与内存屏障"><a href="#x86与内存屏障" class="headerlink" title="x86与内存屏障"></a>x86与内存屏障</h1><p>前面提到的StoreBuffer和InvalidateQueue并不是所有的CPU都会去实现。<br>其中x86的机器上，遵循的内存一致性协议叫TSO协议。<br>在这个协议中，有个叫WriteBuffer的东西，就是对应StoreBuffer。<br>但是并没有InvalidateQueue的存在。</p><h1 id="内存屏障指令集"><a href="#内存屏障指令集" class="headerlink" title="内存屏障指令集"></a>内存屏障指令集</h1><p>上文中，提到了三个内存屏障的指令：</p><ol><li>lfence()：读屏障</li><li>sfence()：写屏障</li><li>mfence()：读写屏障</li></ol><p>那么在代码中是怎么定义的呢：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> barrier() __asm__ __volatile__(<span class="meta-string">""</span>: : :<span class="meta-string">"memory"</span>) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> mb() alternative(<span class="meta-string">"lock; addl $0,0(%%esp)"</span>, <span class="meta-string">"mfence"</span>, X86_FEATURE_XMM2) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> rmb() alternative(<span class="meta-string">"lock; addl $0,0(%%esp)"</span>, <span class="meta-string">"lfence"</span>, X86_FEATURE_XMM2)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> wmb() alternative(<span class="meta-string">"lock; addl $0,0(%%esp)"</span>, <span class="meta-string">"sfence"</span>, X86_FEATURE_XMM)   </span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> CONFIG_SMP </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_mb() mb() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_rmb() rmb() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_wmb() wmb() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_read_barrier_depends() read_barrier_depends() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> set_mb(var, value) do &#123; (void) xchg(&amp;var, value); &#125; while (0) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span> </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_mb() barrier() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_rmb() barrier() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_wmb() barrier() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_read_barrier_depends() do &#123; &#125; while(0) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> set_mb(var, value) do &#123; var = value; barrier(); &#125; while (0) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure></p><p>首先来看barrirer()的定义，这个是禁止编译器进行重排序的。<br>具体的解释可以参考笔者的另外一个文章：<a href="https://blog.lovezhy.cc/2020/03/08/volatile%E5%92%8C%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C/">volatile和内存屏障</a></p><p>然后我们看CONFIG_SMP，如果定义了这个，说明该机器上不止一个Core，否则就是单核心的机器。<br>在单核心的机器上，所有的CPU的内存屏障指令都是空指令，只有禁止编译器重排序的作用。<br>这个也好理解，就不多做解释了。</p><p>而在多核心的机器上，分别定义了:</p><ol><li>smp_mb()：读写屏障</li><li>smp_rmb()：读屏障</li><li>smp_wmb()：写屏障</li></ol><p>同时我们看具体的实现，也就是用到了我们上面提到了lfence，sfence，mfence。</p><p>但是我们再仔细看看这句话：<br><code>#define rmb() alternative(&quot;lock; addl $0,0(%%esp)&quot;, &quot;lfence&quot;, X86_FEATURE_XMM2)</code></p><p>如果CPU没有lfence指令，那么就用<code>lock; addl $0,0(%%esp)</code>代替。<br>为什么？难道<code>lock; addl $0,0(%%esp)</code>也能有内存屏障的语义吗？</p><p>是的！<br>除了fence指令，还有很多的其他的指令也隐藏了内存屏障的语义。<br>下面笔者来总结一下：</p><h2 id="常见的三种"><a href="#常见的三种" class="headerlink" title="常见的三种"></a>常见的三种</h2><p>x86/64系统架构提供了三种多核的内存屏障指令：(1) sfence; (2) lfence; (3) mfence</p><ol><li>sfence：在sfence指令前的写操作当必须在sfence指令后的写操作前完成。</li><li>lfence：在lfence指令前的读操作当必须在lfence指令后的读操作前完成。</li><li>mfence：在mfence指令前的读写操作当必须在mfence指令后的读写操作前完成。</li></ol><p>其实总结起来就是读屏障，写屏障，读写屏障。</p><p>上述的是显式的会起到内存屏障作用的指令，但是还有许多指令带有异常的内存屏障的作用。</p><h2 id="MMIO写屏障"><a href="#MMIO写屏障" class="headerlink" title="MMIO写屏障"></a>MMIO写屏障</h2><p>Linux 内核有一个专门用于 MMIO 写的屏障：<br><code>mmiowb()</code><br>笔者也不熟悉这个的作用，后续再补上</p><h2 id="隐藏的内存屏障"><a href="#隐藏的内存屏障" class="headerlink" title="隐藏的内存屏障"></a>隐藏的内存屏障</h2><p>Linux 内核中一些锁或者调度函数暗含了内存屏障。</p><p>锁函数：</p><ul><li>spin locks</li><li>R/W spin locks</li><li>mutexes</li><li>semaphores</li><li>R/W semaphores</li></ul><p>中断禁止函数：<br>启动或禁止终端的函数的作用仅仅是作为编译器屏障，所以要使用内存或者 I/O 屏障 的场合，必须用别的函数。</p><p>SLEEP和WAKE-UP以及其它调度函数：<br>使用 SLEEP 和 WAKE-UP 函数时要改变 task 的状态标志，这需要使用合适的内存屏 障保证修改的顺序。</p><h1 id="JMM"><a href="#JMM" class="headerlink" title="JMM"></a>JMM</h1><p>在JMM中，定义了4中内存可见性语义：</p><ol><li>LoadLoad</li><li>LoadStore</li><li>StoreStore</li><li>StoreLoad</li></ol><p>但是这些指令对应到x86的机器上，并不是都需要实现的。<br>因为x86的核心问题是有StoreBuffer，一个值被Core0写入了StoreBuffer，另外一个Core可能读不到最新的值，除非Flush StoreBuffer。所以StoreLoad语义需要内存屏障来维持。</p><p>例如以下的例子：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    x=<span class="number">1</span>;  <span class="comment">//S1</span></span><br><span class="line">    r1=y;  <span class="comment">//S2</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    y=<span class="number">1</span>;  <span class="comment">//L1</span></span><br><span class="line">    r2=x;<span class="comment">//L2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>在这个例子中，如果没有内存屏障，Core0执行foo，Core1执行bar，则r1和r2可能出现同时为0的情况。</p><p>再具体的这个文章讲的很好：<a href="https://zhuanlan.zhihu.com/p/81555436" target="_blank" rel="noopener">为什么在 x86 架构下只有 StoreLoad 屏障是有效指令？</a></p><h2 id="更具体的例子"><a href="#更具体的例子" class="headerlink" title="更具体的例子"></a>更具体的例子</h2><p>下面我们看看代码，经过JIT编译后的指令<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">int</span> a = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">int</span> b = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10000</span>; i++) &#123;</span><br><span class="line">        add();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++) &#123;</span><br><span class="line">        a++;</span><br><span class="line">        b += <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>如果a没有被volatile修饰：<br><img src="/images/搞定内存屏障-指令与JMM/1.png" alt="image-20200314152942448"><br>可以看到a和b的操作分别对应：<br><code>inc %r9d</code><br><code>add $0x2, %r9d</code><br>中间没有任何内存屏障的指令</p><p>如果我们加上volatile修饰呢？<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">volatile</span> <span class="keyword">int</span> a = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">volatile</span> <span class="keyword">int</span> b = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10000</span>; i++) &#123;</span><br><span class="line">        add();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++) &#123;</span><br><span class="line">        a++;</span><br><span class="line">        b += <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><img src="/images/搞定内存屏障-指令与JMM/2.png" alt="image-20200314153303884"><br>可以很明显的看到两个<code>lock</code>指令。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前面讲了CPU的演进，提出了StoreBuffer和InvalidateQueue的设计，并且讲解了这两个设计会带来的问题。&lt;br&gt;解决这两个问题就是引入内存屏障：强制刷新StoreBuffer和InvalidateQueue。&lt;/p&gt;
&lt;p&gt;这里详细讲讲x86机器上的内存屏障指令与其他隐式的含有内存屏障的指令。&lt;br&gt;然后再聊一聊JMM与内存屏障的对应关系。&lt;/p&gt;
    
    </summary>
    
    
      <category term="计算机基础" scheme="https://blog.lovezhy.cc/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"/>
    
    
      <category term="内存屏障" scheme="https://blog.lovezhy.cc/tags/%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C/"/>
    
  </entry>
  
  <entry>
    <title>搞懂内存屏障-CPU的演进</title>
    <link href="https://blog.lovezhy.cc/2020/03/14/%E6%90%9E%E6%87%82%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C-CPU%E7%9A%84%E6%BC%94%E8%BF%9B/"/>
    <id>https://blog.lovezhy.cc/2020/03/14/%E6%90%9E%E6%87%82%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C-CPU%E7%9A%84%E6%BC%94%E8%BF%9B/</id>
    <published>2020-03-13T16:00:00.000Z</published>
    <updated>2020-03-14T14:55:28.795Z</updated>
    
    <content type="html"><![CDATA[<p>内存屏障是随着SMP系统的出现而出现的，也就意味着在单核的机器上，不需要任何的内存屏障。</p><p>所以要想理解内存屏障的意义，我们需要知道CPU从单核到多核，究竟修改了什么，需要我们引入内存屏障</p><a id="more"></a><h1 id="单核时代"><a href="#单核时代" class="headerlink" title="单核时代"></a>单核时代</h1><p>如果我们把CPU看做黑盒的话，简单的计算机中，除了CPU负责运算外，还需要存储系统进行存储。这个存储系统就是主存。<br><img src="/images/cpu演进/1.png" alt=""></p><p>但是问题来了，我们知道cpu的速度其实是很快很快的，但是主存的写入和读取的速度过慢，如果这么运行的话，会导致cpu的很多时间都浪费了。</p><p>如果在cpu和主存中间，加入了很多的cache系统，通常来说有L1，L2，L3等。<br><img src="/images/cpu演进/2.png" alt=""><br>cache的速度比主存快的多，这样会大大的提高性能。</p><p>在单核的系统中，当然是没问题的，因为只有一个CPU，所有的读取和写入都是它。<br>虽然一个值可能在主存和Cache中都有，但是都以Cache中的为准就行了。</p><h1 id="多核时代"><a href="#多核时代" class="headerlink" title="多核时代"></a>多核时代</h1><p>但是引入了SMP多核系统后，每个核心都有一个属于他自己的Cache。<br><img src="/images/cpu演进/3.png" alt=""></p><p>这就导致了一个问题。<br>我们知道Cache中的值其实是主存中的拷贝。<br>对一个值的修改先写到Cache中，再写到主存中，具体写入延迟不定。<br>对一个值的读取也是先从主存中读取到Cache中，CPU再从Cache中读取，什么时候失效也是不定。</p><p>多核的系统中，每个核心都有自己的Cache，并且是互相不可见的。<br>这就导致值的写入延迟和延迟失效都会导致数据不一致的问题。</p><p>怎么解决呢？<br>这个时候其实有个简单的方案：</p><ol><li>每次写入Cache时，锁总线，同步再写入主存</li><li>每次读取值时，锁总线，从主存中读。</li></ol><p>但是如果使用这种方案的话，那Cache基本就废了，毫无用处。</p><p>那怎么办呢？<br>那就让CPU的Cache“互相可见”吧。<br>于是MESI协议就诞生了。</p><h1 id="MESI协议"><a href="#MESI协议" class="headerlink" title="MESI协议"></a>MESI协议</h1><p>MESI协议，是一种缓存一致性协议，顾名思义，就是解决各个核心的Cache之间，对于同一个值的一致性问题。</p><p>首先我们要知道，Cache其实是分块的，类似于磁盘的分页，Cache的每一块叫一个CacheLine，对于Cache的基本操作都是以CacheLine为基本单位。</p><p>MESI协议定义每个CacheLine有4种状态：</p><ol><li>Modified：表示这个CacheLine对应的主存数据，只在当前核心中，并且已经被当前核心修改过，和主存中不一样。</li><li>Exclusive：该CacheLine对应的主存数据只在当前核心中，当前核心还未修改该CacheLine。</li><li>Shared：该CacheLine对应的主存数据，也会在别的核心中，但是大家都不能修改，相当于只读。</li><li>Invalid：协议未使用</li></ol><p>同时定义了CPU之间可以互发的六种消息：</p><ol><li>Read：由某个cpu发出给其他的cpu和主存，包含要读的主存地址</li><li>Read Response：由主存或者其他的cpu发出的对于Read的响应，收到响应后把CacheLine放入自己的核心缓存中</li><li>Invalidate：请求中包含需要失效的数据地址，当收到Invalidate请求后，核心必须要删除这部分数据地址</li><li>Invalidate Ack：当核心删除Invalidate请求的数据地址后，发送Ack给来源的CPU</li><li>WriteBack：当CacheLine为Modify状态时，核心将该数据写回到主存时发出</li></ol><p>说到这里你可以明白了MESI大致的作用：<br>当某个核心想要修改某个CacheLine的数据时，由于该CacheLine可能也在其他的核心中，所以必须要发消息给其他的核心，先移除对应的CacheLine。<br>同时，如果其他的核心有对应的CacheLine，必须先从自己的Cache中移除。以免自己读到已经被修改过的数据。</p><p>具体的操作流程有点复杂，估计读者也没耐心读完，这里就略过了。<br>想要详细了解的可以阅读本文的参考文章。</p><h1 id="StoreBuffer和InvalidaQueue"><a href="#StoreBuffer和InvalidaQueue" class="headerlink" title="StoreBuffer和InvalidaQueue"></a>StoreBuffer和InvalidaQueue</h1><p>有了MESI协议，Cache还是派的上用场，但是每次写入都得通知其他的核心，同时接收到其他核心的写入，还得把自己的那部分CacheLine失效。<br>必然会拖慢很多的性能。</p><p>比如说，当Core0想要修改a的值，但是发现a并不在CacheLine中，或者在CacheLine中，是Shared状态，这个时候他并不能直接修改a的值，他需要发消息给其他的Core， Invalidate这部分CacheLine，等所有的Core返回Ack的时候，他才能修改。<br>这部分时间cpu属于Stall状态。<br>那怎么办呢？<br>于是在写入Cache前，加入了一个Store Buffer。<br><img src="/images/cpu演进/4.png" alt=""></p><p>当需要写入一个值的时候，如果这个值的CacheLine并不在当前核心，或者该CacheLine并不是Modified或者Exclusive状态，先写入StoreBuffer，等其他的CPU的Ack到来时候，再择机把StoreBuffer中的值写入Cache。<br>同时，由于对该核心而言，一个值可能已经被修改了，但是并不在Cache中，而是在StoreBuffer中，所以读取的时候，以StoreBuffer的为准。</p><p>除了写入一个值时，需要进行等待，当收到Invalidate请求时，CPU也得放下手中的活，把CacheLine删除发送Ack才能继续。<br>这部分时间能不能缩减呢？<br>我们引入InvalidateQueue。<br><img src="/images/cpu演进/5.png" alt=""><br>当接收到其他的Invalidate请求时，我们将请求放在InvalidateQueue中，并立马返回Ack。<br>再择机把InvalidateQueue中标志到的需要失效的CacheLine移除。</p><h1 id="StoreBuffer导致的问题"><a href="#StoreBuffer导致的问题" class="headerlink" title="StoreBuffer导致的问题"></a>StoreBuffer导致的问题</h1><p>我们首先看一段代码：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    a=<span class="number">1</span>;  <span class="comment">//S1</span></span><br><span class="line">    b=<span class="number">1</span>;  <span class="comment">//S2</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (b == <span class="number">0</span>) <span class="keyword">continue</span>;  <span class="comment">//L1</span></span><br><span class="line">    <span class="keyword">assert</span>(a == <span class="number">1</span>);           <span class="comment">//L2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>如果CPU0执行foo函数，CPU1执行bar函数。<br>同时a的值所在的CacheLine并不在CPU0中，b的值所在的CacheLine在CPU0中，并且是Exlusive状态。</p><ol><li>CPU0执行S1，发现a不在CacheLine中，发送Read Validate消息给主存和CPU1。同时把a=1的值放入StoreBuffer。</li><li>CPU0执行S2，b值所在的CacheLine在CPU0中，并且是Exlusive状态，于是直接修改为1，放入CPU缓存。</li><li>这个时候CPU1启动运行bar函数，发现b不在CacheLine中，于是广播Read，获取b的值</li><li>CPU0得到这个Read b的消息，把b的值发送回去</li><li>CPU1得到b的值为1，L1通过</li><li>CPU1执行L2，a在CacheLine中并且是0，assert fail</li><li>CPU1得到第1步的Read Validate消息，把a所在的CacheLine移除。</li></ol><p>步骤有点复杂，需要耐心阅读。<br>核心就是第1步的Read Validate消息，CPU1延迟到第7步才收到。</p><p>那怎么避免这种情况呢？<br>我们能不能让StoreBuffer退化到没有之前的流程？<br>也就是把第一步中的操作中，写入StoreBuffer后，不允许执行后续的操作，直到收到Validate Ack消息。<br>于是我们引入sfence()函数，遇到这个函数时，必须等到所有的Validate Ack，并且把StoreBuffer全部Flush到Cache，清空StoreBuffer。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    a=<span class="number">1</span>;  <span class="comment">//S1</span></span><br><span class="line">    sfence();</span><br><span class="line">    b=<span class="number">1</span>;  <span class="comment">//S2</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (b == <span class="number">0</span>) <span class="keyword">continue</span>;  <span class="comment">//L1</span></span><br><span class="line">    <span class="keyword">assert</span>(a == <span class="number">1</span>);           <span class="comment">//L2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h1 id="InvalidateQueue导致的问题"><a href="#InvalidateQueue导致的问题" class="headerlink" title="InvalidateQueue导致的问题"></a>InvalidateQueue导致的问题</h1><p>还是看这段代码：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    a=<span class="number">1</span>;  <span class="comment">//S1</span></span><br><span class="line">    sfence();</span><br><span class="line">    b=<span class="number">1</span>;  <span class="comment">//S2</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (b == <span class="number">0</span>) <span class="keyword">continue</span>;  <span class="comment">//L1</span></span><br><span class="line">    <span class="keyword">assert</span>(a == <span class="number">1</span>);           <span class="comment">//L2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>InvalidateQueue导致的就是，将CacheLine的移除时机变得不可确定。即使这个指示需要移除该CacheLine的Invalidate消息已经在InvalidateQueue中了，CPU还是会可能会从自己的Cache中读到旧的值。</p><p>比如例子中：<br>Core0执行foo函数，此时a在Core1中。<br>Core0发送Read Invalidate消息，Core1返回a的值，同时将Invalidate消息放入InvalidateQueue。<br>Core0将a=1推送到Cache中。<br>Core0执行b=1，放入缓存中。<br>Core1发送Read b的消息，Core0返回b=1；<br>L1执行成功，Core1获取a的值，由于移除该CacheLine的Invalidate消息还在InvalidateQueue中，所以发现a的值在Cache中，并且为0。<br>于是assert fail。</p><p>于是我们引入lfence()函数，该函数强制刷新InvalidateQueue。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    a=<span class="number">1</span>;  <span class="comment">//S1</span></span><br><span class="line">    sfence();</span><br><span class="line">    b=<span class="number">1</span>;  <span class="comment">//S2</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (b == <span class="number">0</span>) <span class="keyword">continue</span>;  <span class="comment">//L1</span></span><br><span class="line">    lfence();</span><br><span class="line">    <span class="keyword">assert</span>(a == <span class="number">1</span>);           <span class="comment">//L2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>前文提到的sfence()和lfence()，便是内存屏障。<br>一个是写屏障，也就是同步刷新StoreBuffer<br>一个是读屏障，也就是同步刷新InvalidateQueue。<br>也有mfence()，既刷新StoreBuffer，也刷新InvalidateQueue。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://zhuanlan.zhihu.com/p/48157076" target="_blank" rel="noopener">高并发编程–多处理器编程中的一致性问题(上)</a><br><a href="https://zhuanlan.zhihu.com/p/55767485" target="_blank" rel="noopener">为什么需要内存屏障</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;内存屏障是随着SMP系统的出现而出现的，也就意味着在单核的机器上，不需要任何的内存屏障。&lt;/p&gt;
&lt;p&gt;所以要想理解内存屏障的意义，我们需要知道CPU从单核到多核，究竟修改了什么，需要我们引入内存屏障&lt;/p&gt;
    
    </summary>
    
    
      <category term="计算机基础" scheme="https://blog.lovezhy.cc/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"/>
    
    
      <category term="内存屏障" scheme="https://blog.lovezhy.cc/tags/%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C/"/>
    
  </entry>
  
  <entry>
    <title>搞懂内存屏障-CPU重排序</title>
    <link href="https://blog.lovezhy.cc/2020/03/09/%E6%90%9E%E6%87%82%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C-CPU%E9%87%8D%E6%8E%92%E5%BA%8F/"/>
    <id>https://blog.lovezhy.cc/2020/03/09/%E6%90%9E%E6%87%82%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C-CPU%E9%87%8D%E6%8E%92%E5%BA%8F/</id>
    <published>2020-03-08T16:00:00.000Z</published>
    <updated>2020-03-14T14:55:31.926Z</updated>
    
    <content type="html"><![CDATA[<p>我决定写一个系列，从头到尾讲一讲我理解的内存屏障的起源。<br>要想真正理解内存屏障，其实要讲很多的东西。</p><p>第一节，先来讲讲CPU的执行与重排序。</p><a id="more"></a><h1 id="CPU的执行"><a href="#CPU的执行" class="headerlink" title="CPU的执行"></a>CPU的执行</h1><h2 id="流水线"><a href="#流水线" class="headerlink" title="流水线"></a>流水线</h2><p>当然我对CPU几乎没系统的学过，都是从网上看看博客学来的。</p><p>CPU执行一条指令需要4个步骤（当然网上可能有其他说法，比如三个步骤或者五个步骤，不过没关系，不影响下面我们的结论）：</p><ol><li>取址：从内存中取出指令</li><li>译码：翻译指令，生成响应的控制信号</li><li>执行：使用CPU的逻辑处理单元计算</li><li>回写：把结果写回到寄存器或者内存</li></ol><p>假设我们有三条指令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mov $0x0, %esi</span><br><span class="line">mov $0x0, %edi</span><br><span class="line">and $0xf, %ebx</span><br></pre></td></tr></table></figure></p><p>我们把这四个步骤都合并成一个组合逻辑去运行的话<br>架构图如下：<br><img src="/images/CPU重排序/1.png" alt=""></p><p>那么我们需要的时间其实就是串行的，如下图：<br><img src="/images/CPU重排序/2.png" alt=""></p><p>但是这样，太慢了。<br>于是CPU流水线技术就诞生了（大约在Intel 386里开始出现）。</p><p>原理大概是把一个组合逻辑，拆分成多个小的组合逻辑：<br><img src="/images/CPU重排序/3.png" alt=""><br>这样，第一个指令进行组合逻辑B的时候，第二个指令就可以进行组合逻辑A了。<br>我们的时间消耗可以大大减少：<br><img src="/images/CPU重排序/4.png" alt=""></p><h2 id="冒险"><a href="#冒险" class="headerlink" title="冒险"></a>冒险</h2><p>上面的例子中，流水线可以非常完美。因为我们的三个指令所需的数据都互不依赖。<br>但是如果指令是这样的：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Mov $0x0, %esi</span><br><span class="line">Mov $0x0, %edi</span><br><span class="line">Add %esi, %edi</span><br></pre></td></tr></table></figure></p><p>第三个指令，是把第一个指令和第二个指令的结果进行相加<br>如果我们仍采用上述的流水线去运行，就会出问题：<br><img src="/images/CPU重排序/5.png" alt=""><br>CPU在执行Add指令时，依赖第二步中%edi的值。<br>但是指令3执行到第二个组合逻辑时，第二个指令还没写回到寄存器。<br>这样下去，指令3的Add用到的%edi，其实就不是0。<br>和预期的结果不符合。</p><p>这个就叫冒险<br>其中冒险分为数据冒险和控制冒险，数据冒险就是我们上面提到的。<br>而控制冒险和数据冒险类似，不过一般涉及到跳转指令。</p><p>如：<br><img src="/images/CPU重排序/6.png" alt=""><br>我们在执行JE的时候，依赖上一步的CMP的结果，导致正常的流水线执行就会有问题。</p><h2 id="Bubble"><a href="#Bubble" class="headerlink" title="Bubble"></a>Bubble</h2><p>那怎么解决呢？<br>就是插入Nop指令。</p><p><img src="/images/CPU重排序/7.png" alt=""><br>如上图所示，我们在第二个指令和第三个指令中间加入一个Nop指令，空转一个流水线。</p><p>当然我们不需要编译器每次都进行加入Nop，CPU会自己加入。<br>这个就叫Bubble，而执行Bubble叫Stall。<br><img src="/images/CPU重排序/8.png" alt=""></p><p>对于分支预测而言，CPU除了Bubble，还可能会随机选择一个分支先去执行，等CMP的结果出来，如果预测错了，就把执行结果丢弃掉：<br><img src="/images/CPU重排序/9.png" alt=""><br>分支预测失败当然是比较消耗性能的，Google的报告上指出了一次错误的分支预测的耗时：<br><img src="/images/CPU重排序/10.png" alt=""></p><p><img src="/images/CPU重排序/11.png" alt=""></p><h1 id="重排序"><a href="#重排序" class="headerlink" title="重排序"></a>重排序</h1><p>除了Bubble和分支预测的解决方案，还有一种解决方案，就是CPU的重排序。</p><p>对于下面的指令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ADD AX, BX;   </span><br><span class="line">INC AX;         </span><br><span class="line">MOV CX, DX;</span><br></pre></td></tr></table></figure></p><p>ADD和INC操作都用到了AX，必然会导致Stall。<br>但是我们发现MOV指令和ADD和INC都没有关系，<br>那么我们能不能调换顺序：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ADD AX, BX;  </span><br><span class="line">MOV CX, DX; </span><br><span class="line">INC AX;</span><br></pre></td></tr></table></figure></p><p>在执行时使用这种次序呢？<br>毕竟这种次序，就不会产生Stall，性能必然会提升。</p><p>这种就是CPU的重排序。</p><h1 id="锅是谁的？"><a href="#锅是谁的？" class="headerlink" title="锅是谁的？"></a>锅是谁的？</h1><p>在x86的机器上，CPU会进行大量的指令重排序。<br>但是CPU重排序也不会想重排就重排的，而是需要遵守一定的规范，不然就会影响软件的正常运行。</p><p>比如说下面这段经典的代码：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> x = <span class="number">0</span>, y = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> a = <span class="number">0</span>, b = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">far</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    a=<span class="number">1</span>;</span><br><span class="line">    x=b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    b=<span class="number">1</span>;</span><br><span class="line">    y=a;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>如果我们启动两个线程分别去执行far和bar函数。<br>正常的情况下，要么x=1，要么y=1，要么x=y=1;<br>但是也可能是x=y=0;</p><p>怎么解释的呢？很多人是这么解释的，这里我找了一个博客的解释：</p><blockquote><p>这是处理器乱序执行的结果：<br>线程t1内部的两行代码之间不存在数据依赖<br>因此，可以将x = b乱序到a = 1前；<br>同时，线程t2中的y = a早于线程t1中的a = 1执行。<br>一个可能的执行序列如下：<br>t1: x = b<br>t2: b = 1<br>t2: y = a<br>t1: a = 1</p></blockquote><p>看起来非常的有道理，CPU乱序执行害死人。<br>但是事实确实如此吗？<br>这个锅真的是CPU重排序执行导致的吗？</p><h1 id="真的能观测到CPU的重排序吗"><a href="#真的能观测到CPU的重排序吗" class="headerlink" title="真的能观测到CPU的重排序吗"></a>真的能观测到CPU的重排序吗</h1><p>我对CPU不熟悉，这里我就举几个网上的答案反驳吧。</p><h2 id="反驳一"><a href="#反驳一" class="headerlink" title="反驳一"></a>反驳一</h2><p><a href="https://stackoverflow.com/questions/50307693/does-an-x86-cpu-reorder-instructions" target="_blank" rel="noopener">Does an x86 CPU reorder instructions?</a><br>这个是英文回答，内容有点多，我从里面摘抄几个：</p><blockquote><p>Yes, all modern x86 chips from Intel and AMD aggressively reorder instructions across a window which is around 200 instructions deep on recent CPUs from both manufacturers</p></blockquote><p>肯定了x86的CPU会执行很多的指令重排序</p><blockquote><p>That should answer the titular question, but then your second question is about memory barriers. It contains, however, an incorrect assumption that instruction reordering necessarily causes (and is the only cause of) visible memory reordering</p></blockquote><p>这个其实超纲了，他提到了内存可见性的重排序。<br>否定了CPU的指令执行重排序一定会导致内存可见性问题。</p><blockquote><p>At the same time, x86 defines quite a strict memory model, which bans most possible reorderings<br>So actually most memory re-orderings are not allowed</p></blockquote><p>重点来了，x86定义了一个严格的内存模型，这个内存模型禁止了大多数可能的重排序<br>后续的文章中，我会提到这个内存模型。</p><blockquote><p>So it is possible to define an ISA that doesn’t allow any re-ordering at all, but under the covers do re-ordering but carefully check that it isn’t observed</p></blockquote><p>注意看这个词，<strong>observed</strong>。<br>是的，CPU确实会做指令的重排序，但是如果出现了重排序可以被observe的情况，就是BUG。<br>这里我们假定CPU不会出BUG。</p><h2 id="反驳二"><a href="#反驳二" class="headerlink" title="反驳二"></a>反驳二</h2><p><a href="https://www.zhihu.com/question/53761499" target="_blank" rel="noopener">https://www.zhihu.com/question/53761499</a><br>有人问：</p><blockquote><p>如何辨识代码是否被CPU的乱序执行优化了？</p></blockquote><p>一个是<code>中央处理器 (CPU) 话题的优秀回答者</code>的回答：</p><blockquote><p>看不到，也无法控制，ROB存在的目的就是让上层程序员看到的执行结果回归顺序。有一些memory model带来的重排序是可以被上层检测到的，比如x86的TSO模型可以通过精心设计的load store序列检测到访存的乱序。</p></blockquote><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>总而言之，我们记得一个词就够了：<code>observed</code>。<br>CPU确实会进行重排序，但是这种重排序是无法被我们观测到和控制的。<br>如果CPU没有BUG的话（基本上没听过CPU出现BUG），那么程序出现与预期不一致的行为，和CPU的重排序没半点关系。</p><p>插一句，什么内存屏障之类的，和CPU的重排序也没有关系。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://uestc-dpz.github.io/blog/2016/11/17/Reordering.html" target="_blank" rel="noopener">指令重排序</a><br><a href="https://www.zhihu.com/question/53761499" target="_blank" rel="noopener">如何辨识代码是否被CPU的乱序执行优化了</a><br><a href="https://www.cs.utexas.edu/~lin/cs380p/Free_Lunch.pdf" target="_blank" rel="noopener">https://www.cs.utexas.edu/~lin/cs380p/Free_Lunch.pdf</a><br><a href="https://monkeysayhi.github.io/2017/12/28/%E4%B8%80%E6%96%87%E8%A7%A3%E5%86%B3%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C/" target="_blank" rel="noopener">https://monkeysayhi.github.io/2017/12/28/%E4%B8%80%E6%96%87%E8%A7%A3%E5%86%B3%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C/</a><br><a href="https://stackoverflow.com/questions/50307693/does-an-x86-cpu-reorder-instructions" target="_blank" rel="noopener">https://stackoverflow.com/questions/50307693/does-an-x86-cpu-reorder-instructions</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我决定写一个系列，从头到尾讲一讲我理解的内存屏障的起源。&lt;br&gt;要想真正理解内存屏障，其实要讲很多的东西。&lt;/p&gt;
&lt;p&gt;第一节，先来讲讲CPU的执行与重排序。&lt;/p&gt;
    
    </summary>
    
    
      <category term="计算机基础" scheme="https://blog.lovezhy.cc/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"/>
    
    
      <category term="内存屏障" scheme="https://blog.lovezhy.cc/tags/%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C/"/>
    
      <category term="CPU重排序" scheme="https://blog.lovezhy.cc/tags/CPU%E9%87%8D%E6%8E%92%E5%BA%8F/"/>
    
  </entry>
  
  <entry>
    <title>volatile和内存屏障</title>
    <link href="https://blog.lovezhy.cc/2020/03/08/volatile%E5%92%8C%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C/"/>
    <id>https://blog.lovezhy.cc/2020/03/08/volatile%E5%92%8C%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C/</id>
    <published>2020-03-07T16:00:00.000Z</published>
    <updated>2020-03-14T15:04:57.467Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>事实上，我很多次以为我懂了volatile的原理，最终都是错误的。<br>关于重排序，CPU，缓存一致性，内存可见性的话题，其实非常复杂。</p><p>这篇文章较为混乱，较为详细的可以看笔者的一个系列：</p><p><a href="https://blog.lovezhy.cc/2020/03/09/%E6%90%9E%E6%87%82%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C-CPU%E9%87%8D%E6%8E%92%E5%BA%8F/">搞懂内存屏障-CPU重排序</a></p><p><a href="https://blog.lovezhy.cc/2020/03/14/%E6%90%9E%E6%87%82%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C-CPU%E7%9A%84%E6%BC%94%E8%BF%9B/">搞懂内存屏障-CPU的演进</a></p><p><a href="https://blog.lovezhy.cc/2020/03/14/%E6%90%9E%E6%87%82%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C-%E6%8C%87%E4%BB%A4%E4%B8%8EJMM/">搞懂内存屏障-指令与JMM</a><br><a id="more"></a></p><p>很多文章提到的关于volatile的例子：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> data[<span class="number">5</span>] = &#123; <span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span>, <span class="number">9</span> &#125;;</span><br><span class="line">bool is_ready = <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">init_data</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span>( <span class="keyword">int</span> i=<span class="number">0</span>; i &lt; <span class="number">5</span>; ++i )</span><br><span class="line">    data[i] = i;</span><br><span class="line">  is_ready = <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">sum_data</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span>( !is_ready )</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">for</span>( <span class="keyword">int</span> i=<span class="number">0</span>; i &lt;<span class="number">5</span>; ++i )</span><br><span class="line">    sum += data[i];</span><br><span class="line">  printf( <span class="string">"%d"</span>, sum );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><blockquote><p>如果我们启动两个线程，线程1执行init_data()，另外一个线程不断执行sum_data()<br>正常的结果应该是0+1+2+3+4，但是由于重排序和内存可见性的问题，得到的结果是不一定的。</p></blockquote><p>其实我们很多人没有思考过一个问题：</p><blockquote><p>在这个例子中，是因为内存可见性的问题造成的，还是重排序的问题造成的？还是两个一起造成的</p></blockquote><p>太长不看：</p><ol><li>CPU对指令进行重排序的条件非常苛刻，在这个例子中，完全不存在CPU会将指令重排序的问题。这个代码运行出现的问题，完全是内存可见性的问题。</li><li>其实关于Volatile的所有问题都是内存可见性的问题，只不过看起来像是CPU重排序了。</li><li>内存屏障指令分编译器级别和CPU级别，内存屏障和CPU重排序没半点关系。</li><li>CPU的厂家使用的协议和CPU具体实现不尽相同，JVM定义的4种内存屏障指令，在x86的机器上，其实只有一种有用，其他的都是空指令。</li><li>JMM定义的”CPU缓存，主存“只是一种抽象，真正的CPU缓存实现，CPU之间在一定程度上是<strong>互相可见</strong>的。</li></ol><h1 id="我的思考"><a href="#我的思考" class="headerlink" title="我的思考"></a>我的思考</h1><p>上面的例子有点复杂，我们再举个简单的例子：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    a=<span class="number">1</span>;  <span class="comment">//S1</span></span><br><span class="line">    b=<span class="number">1</span>;  <span class="comment">//S2</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (b == <span class="number">0</span>) <span class="keyword">continue</span>;  <span class="comment">//L1</span></span><br><span class="line">    <span class="keyword">assert</span>(a == <span class="number">1</span>);           <span class="comment">//L2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>执行的流程和上面的例子一样，我们把步骤拆成了4个，分别为S1，S2，L1，L2。</p><h2 id="正常流程"><a href="#正常流程" class="headerlink" title="正常流程"></a>正常流程</h2><p>正常流程应该是：<br><code>S1 &gt; S2 &gt; L1 &gt; L2</code><br>也就是说，在执行L2的时候，a=1已经执行过了，所以这个断言是正确的。</p><h2 id="内存可见性导致的问题"><a href="#内存可见性导致的问题" class="headerlink" title="内存可见性导致的问题"></a>内存可见性导致的问题</h2><p>在JMM模型中，每个CPU都有自己的缓存，写入时，先写自己的缓存，然后再同步到主存中。<br>在这个例子中，如果还是<code>S1 &gt; S2 &gt; L1 &gt; L2</code>的执行顺序<br>但是S1执行结束后，a其实存在于三个地方，这三个地方的可能值为：</p><ol><li>foo线程所在的CPU缓存中，这个地方a=1</li><li>bar线程所在的CPU缓存中，这个地方a=0或者a=1</li><li>主存中，这个地方a=0或者a=1</li></ol><p>同样的S2执行结束后，b也存在于三个地方。</p><p>如果在bar线程中，b的值为1，但是a的值还是0，那么断言还是失败的。</p><p>这个时候有人会告诉你使用volatile<br>被volatile修饰的变量，每次写入时，会实时同步到主存中，每次读取时，实时从主存中读取<br>这个就会导致S1和S2执行完之后，L1和L2步骤的a和b的值都是最新的。<br>没毛病，说得通对吧。</p><h2 id="重排序导致的问题"><a href="#重排序导致的问题" class="headerlink" title="重排序导致的问题"></a>重排序导致的问题</h2><p>CPU在执行中会对指令进行重排序<br>比如S1和S2这两个操作，在CPU看来没有任何数据依赖顺序，所以它可以乱序执行<br>这下执行顺序可能就变成<code>S2 &gt; L1 &gt; L2 &gt; S1</code>。<br>也会导致断言失败。<br>这个时候Volatile也会保证执行的时候不会导致重排序。<br>也没毛病。</p><h2 id="内存屏障"><a href="#内存屏障" class="headerlink" title="内存屏障"></a>内存屏障</h2><p>Volatile的具体是怎么实现的呢？<br>实现就是插入内存屏障。<br>内存屏障是什么东西？<br>简单的说：保证内存屏障前的读写指令必须在屏障后的读写指令之前执行，通知被Volatile修饰的值，每次读取都从主存中读取，每次写入都同步写入主存（锁总线）。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>从这个例子中看到，其实重排序和内存可见性的问题都会导致程序产生和我们预期不一致的行为，<br>而Volatile恰好能解决这两个问题。</p><h1 id="内存屏障底层指令"><a href="#内存屏障底层指令" class="headerlink" title="内存屏障底层指令"></a>内存屏障底层指令</h1><p>其实正常来说，一般的Java开发者能理解到上面的层次就行了。<br>但是我还想理解的更多，比如这个重排序其实是CPU级别的，我们的Volatile关键词，肯定会映射成汇编指令，那么是哪些汇编指令呢？</p><p>我们先来了解一下<code>barrier()</code>函数。</p><h2 id="编译器重排序"><a href="#编译器重排序" class="headerlink" title="编译器重排序"></a>编译器重排序</h2><p>对于指令重排序，我一直以为只有CPU才会进行重排序，其实编译器也会对我们的指令进行重排序。<br>举个例子：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> x, y, r;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    x = r;</span><br><span class="line">    y = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>如果我们直接编译源文件：<code>g++ -S test.cpp</code><br>会得到这样的汇编文件：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">movl    r(%rip), %eax</span><br><span class="line">movl    %eax, x(%rip)</span><br><span class="line">movl    $<span class="number">1</span>, y(%rip)</span><br></pre></td></tr></table></figure></p><p>可以看到，这个结果并没有进行重排序</p><p>但是如果我们指定优化级别：<code>g++ -O2 –S test.cpp</code><br>得到的汇编指令如下：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">movl    r(%rip), %eax</span><br><span class="line">movl    $<span class="number">1</span>, y(%rip)</span><br><span class="line">movl    %eax, x(%rip)</span><br></pre></td></tr></table></figure></p><p>看，两个指令的顺序反了。<br>这也就是编译器的重排序。</p><p>那么怎么避免呢？<br>这个时候<code>barrier()</code>函数就派上用场了。</p><p>我们修改我们的代码：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> x, y, r;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">x = r;</span><br><span class="line">barrier();</span><br><span class="line">    y = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>这个时候我们再进行编译，会发现顺序并没有颠倒。</p><h2 id="内存屏障-1"><a href="#内存屏障-1" class="headerlink" title="内存屏障"></a>内存屏障</h2><p>我们从内核的代码中找出：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> barrier() __asm__ __volatile__(<span class="meta-string">""</span>: : :<span class="meta-string">"memory"</span>) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> mb() alternative(<span class="meta-string">"lock; addl $0,0(%%esp)"</span>, <span class="meta-string">"mfence"</span>, X86_FEATURE_XMM2) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> rmb() alternative(<span class="meta-string">"lock; addl $0,0(%%esp)"</span>, <span class="meta-string">"lfence"</span>, X86_FEATURE_XMM2)</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> CONFIG_SMP </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_mb() mb() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_rmb() rmb() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_wmb() wmb() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_read_barrier_depends() read_barrier_depends() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> set_mb(var, value) do &#123; (void) xchg(&amp;var, value); &#125; while (0) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span> </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_mb() barrier() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_rmb() barrier() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_wmb() barrier() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_read_barrier_depends() do &#123; &#125; while(0) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> set_mb(var, value) do &#123; var = value; barrier(); &#125; while (0) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure></p><p>别急，我们慢慢来看<br>内存屏障指令，大致有3个</p><ol><li><code>smp_mb</code></li><li><code>smp_rmb</code></li><li><code>smp_wmb</code></li></ol><p>但是看这个<code>#ifdef CONFGIG_SMP</code><br>SMP就是表示多核的意思。</p><blockquote><p>内存屏障指令，在单核和多核的系统中的实现定义是不一样的</p></blockquote><p>我们可以看到，如果计算机是单核的，那么其实所有的内存屏障指令都是编译器级别的，实际的实现都是<code>barrier()</code>函数，在CPU级别都是空操作。</p><h2 id="我的疑惑"><a href="#我的疑惑" class="headerlink" title="我的疑惑"></a>我的疑惑</h2><p>其实不对啊，既然CPU会进行重排序，那为什么单核中并没有使用任何CPU的指令避免重排序呢？</p><p>我们再回到那个例子：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    a=<span class="number">1</span>;  <span class="comment">//S1</span></span><br><span class="line">    b=<span class="number">1</span>;  <span class="comment">//S2</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (b == <span class="number">0</span>) <span class="keyword">continue</span>;  <span class="comment">//L1</span></span><br><span class="line">    <span class="keyword">assert</span>(a == <span class="number">1</span>);           <span class="comment">//L2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>假设这个程序是单核中执行的，也就是没有多核中的可见性的问题，但是CPU重排序的问题依然存在。<br>如果CPU进行重排序：<br><code>S2 &gt; L2 &gt; L2 &gt; S1</code><br>那不是仍然会出问题吗？</p><p>黑人问号？</p><p>带着这个问题，我继续开始了我的资料搜寻。</p><h1 id="内存一致性"><a href="#内存一致性" class="headerlink" title="内存一致性"></a>内存一致性</h1><blockquote><p>主要内容来自<a href="https://zhuanlan.zhihu.com/p/48157076" target="_blank" rel="noopener">高并发编程–多处理器编程中的一致性问题(上)</a><br>很多东西这个文章解释的很好，建议先读一读，有的我就直接略讲了</p></blockquote><p>我产生上述疑惑的前提其实就是默认CPU会对指令进行重排序。<br>很多书中对Volatile也提到了这一点，问题源头都是CPU会对指令重排序。<br>这个时候我们可能会觉得CPU厂家不给力，把这个锅丢给了开发者去解决。</p><p>其实不是的。</p><blockquote><p>那么为了保证不会出现这种超出预期的行为，我们就需要一种规则来约束这种行为不能出现。这个任务就是memory consistency需要保证的（这里指的是强一致性模型：SC/TSO， XC的memory consistency并不能保证这点）</p></blockquote><p>CPU的理论中，其实有一系列协议约束CPU的执行不能出现上述行为。<br>也就是memory consistency，内存一致性。或者也叫<code>Memory Model</code>。<br>中文资料关于这个话题确实很少被提到，这个知乎问答提到了哪儿可以去学习。<br><a href="https://www.zhihu.com/question/23572082" target="_blank" rel="noopener">如何系统的学习 Memory Model?</a><br>其实这个话题也分理论与工业实现，就跟操作系统一样。</p><p>笔者了解的也不多，这里就简单提一下。<br>关于内存一致性的问题，其实和分布式的精髓略相似，有强弱之分，不同的CPU架构上实现的强弱程度不同。</p><h2 id="Sequential-Consistency"><a href="#Sequential-Consistency" class="headerlink" title="Sequential Consistency"></a>Sequential Consistency</h2><p>在理论上，不得不提一个人，Lamport，就是Paxos理论的那个教授。<br>他提出了<code>Sequential Consistency</code>，就是顺序一致性，硬件层面的一致性。</p><p>在解释SC的理论之前，还得了解<code>Program Order</code>和<code>Memory Order</code></p><blockquote><p>Program Order: 就是我们写的代码的顺序，这个是静态的也是每个CPU core各自拥有的。<br>Memory Order: 就是代码执行的顺序，这个是全局的，每个CPU core对共享内存的执行都会出现在Memory order中。<br>用&lt;p 表示Program order的先于顺序，&lt;m表示Memory order的先于顺序。</p></blockquote><p>SC的形式化定义如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">If L(a) &lt;p L(b) ⇒ L(a) &lt;m L(b) /* Load→Load */</span><br><span class="line">If L(a) &lt;p S(b) ⇒ L(a) &lt;m S(b) /* Load→Store */</span><br><span class="line">If S(a) &lt;p S(b) ⇒ S(a) &lt;m S(b) /* Store→Store */</span><br><span class="line">If S(a) &lt;p L(b) ⇒ S(a) &lt;m L(b) /* Store→Load */</span><br></pre></td></tr></table></figure></p><p>在SC的理论中，这4种关系不允许被Reorder。<br>好了，根据这个理论，我们再看一看上面的代码：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    a=<span class="number">1</span>;  <span class="comment">//S1</span></span><br><span class="line">    b=<span class="number">1</span>;  <span class="comment">//S2</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (b == <span class="number">0</span>) <span class="keyword">continue</span>;  <span class="comment">//L1</span></span><br><span class="line">    <span class="keyword">assert</span>(a == <span class="number">1</span>);           <span class="comment">//L2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>在foo函数中，a的Store在程序顺序中是大于b的Store的，所以a=1的MemoryOrder是必须要大于b=1的MemoryOrder的。</p><p>也就说，如果CPU实现了SC协议，那么其实<code>S2 -&gt; S1</code>这个重排序是不允许的。</p><h2 id="Total-Store-Order"><a href="#Total-Store-Order" class="headerlink" title="Total Store Order"></a>Total Store Order</h2><p>当然理论归理论，实现不一定按照理论来。<br>前面提到了SC的理论，在SC理论的指导下，一切都是按照顺序来的，对CPU重排序的条件非常苛刻。</p><p>SC的问题：</p><blockquote><p>SC严格定义了对于共享内存的load和store操作，loadload，storestore，loadstore，storeload四种执行顺序是不允许reorder的。当下CPU的执行速度已经甩DRAM（memory）好几个量级，如果每次store，load操作都从DRAM读取会拖慢CPU的执行速度，在这个极度压榨硬件性能的时代，是不能接受这种行为的。因此在x86的架构实现中引入了TSO。</p></blockquote><p>简单说，就是CPU厂家觉得SC太严格，不利于性能提升，所以几乎没人用SC，而X86而言，他自己定义了一个叫Total Store Order的内存模型。</p><p>在讲TSO之前，在提一嘴前面提到的，内存一致性的协议有强弱之分，就像分布式协议中的强一致性，最终一致性一样。<br>SC显然是强一致性，但是TSO的一致性就略微弱与SC。</p><p>具体体现在哪儿呢：</p><blockquote><p>TSO在CPU与memory之间引入了write buffer。CPU写入的时候先写入write buffer然后就返回了，这样就将cpu与memory之间的差距隐藏了。</p></blockquote><p>引入了write buffer后，这里其实就是一个内存可见性的隐藏问题，在write buffer中的值，到memory中其实需要一段时间的，这个时间是不定的。</p><p>所以还是会导致一些其他的问题出现：</p><p>比如我们看这个例子：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    x=<span class="number">1</span>;  <span class="comment">//S1</span></span><br><span class="line">    r1=y;  <span class="comment">//L1</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    y=<span class="number">1</span>;  <span class="comment">//S2</span></span><br><span class="line">    r2=x;<span class="comment">//L2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><blockquote><p>还是上面这个例子，S1将x=1放到了core C1的write buffer中，S2将y=1放到了C2的write buffer中，那么在执行L1,L2的时候，r1与r2这时候从memory读到是0。这个是违背了SC的，但是这样的设计确实带来了性能的提升。</p></blockquote><p>怎么解决这个问题呢？</p><p>可能你想到了，就是我们使用某种指令，让CPU去同步Flush这个write buffer中的值。<br>这个指令就是我们提到的内存屏障。</p><p>在详细介绍内存屏障的指令前，我们在TSO模型下，看看我们之前举的例子，到底是什么原因导致的：<br>还是前面的例子：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    a=<span class="number">1</span>;  <span class="comment">//S1</span></span><br><span class="line">    b=<span class="number">1</span>;  <span class="comment">//S2</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (b == <span class="number">0</span>) <span class="keyword">continue</span>;  <span class="comment">//L1</span></span><br><span class="line">    <span class="keyword">assert</span>(a == <span class="number">1</span>);           <span class="comment">//L2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>在TOS的引入了write buffer后，我们再来看看上面的例子还会出现问题吗？<br>如果a=1，b=1先后被写入write buffer，并没有写入memory。但是如果把write buffer中的值flush到内存，b=1这个可见性的时间 &gt;= a=1的可见性。<br>所以如果bar中，读到b=1了，那么a肯定也已经读到等于1了。<br>就不会出现上面的问题。</p><p>这个时候，我们可以解答我的疑惑了<br>为什么单核的情况下，仅仅需要禁止编译器的重排序就行了？<br>答案就是在TSO模型下，在上面的例子中，CPU不会进行指令的重排序。</p><h2 id="内存屏障指令"><a href="#内存屏障指令" class="headerlink" title="内存屏障指令"></a>内存屏障指令</h2><p>让我们再回到这个代码：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> barrier() __asm__ __volatile__(<span class="meta-string">""</span>: : :<span class="meta-string">"memory"</span>) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> mb() alternative(<span class="meta-string">"lock; addl $0,0(%%esp)"</span>, <span class="meta-string">"mfence"</span>, X86_FEATURE_XMM2) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> rmb() alternative(<span class="meta-string">"lock; addl $0,0(%%esp)"</span>, <span class="meta-string">"lfence"</span>, X86_FEATURE_XMM2)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> wmb() alternative(<span class="meta-string">"lock; addl $0,0(%%esp)"</span>, <span class="meta-string">"sfence"</span>, X86_FEATURE_XMM)   </span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> CONFIG_SMP </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_mb() mb() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_rmb() rmb() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_wmb() wmb() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_read_barrier_depends() read_barrier_depends() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> set_mb(var, value) do &#123; (void) xchg(&amp;var, value); &#125; while (0) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span> </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_mb() barrier() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_rmb() barrier() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_wmb() barrier() </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> smp_read_barrier_depends() do &#123; &#125; while(0) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> set_mb(var, value) do &#123; var = value; barrier(); &#125; while (0) </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure></p><h3 id="常见的三种"><a href="#常见的三种" class="headerlink" title="常见的三种"></a>常见的三种</h3><p>x86/64系统架构提供了三种多核的内存屏障指令：(1) sfence; (2) lfence; (3) mfence</p><ol><li>sfence：在sfence指令前的写操作当必须在sfence指令后的写操作前完成。</li><li>lfence：在lfence指令前的读操作当必须在lfence指令后的读操作前完成。</li><li>mfence：在mfence指令前的读写操作当必须在mfence指令后的读写操作前完成。</li></ol><p>其实总结起来就是读屏障，写屏障，读写屏障。</p><p>上述的是显式的会起到内存屏障作用的指令，但是还有许多指令带有异常的内存屏障的作用。</p><h3 id="MMIO写屏障"><a href="#MMIO写屏障" class="headerlink" title="MMIO写屏障"></a>MMIO写屏障</h3><p>Linux 内核有一个专门用于 MMIO 写的屏障：<br><code>mmiowb()</code><br>笔者也不熟悉这个的作用，后续再补上</p><h3 id="隐藏的内存屏障"><a href="#隐藏的内存屏障" class="headerlink" title="隐藏的内存屏障"></a>隐藏的内存屏障</h3><p>Linux 内核中一些锁或者调度函数暗含了内存屏障。</p><p>锁函数：</p><ul><li>spin locks</li><li>R/W spin locks</li><li>mutexes</li><li>semaphores</li><li>R/W semaphores</li></ul><p>中断禁止函数：<br>启动或禁止终端的函数的作用仅仅是作为编译器屏障，所以要使用内存或者 I/O 屏障 的场合，必须用别的函数。</p><p>SLEEP和WAKE-UP以及其它调度函数：<br>使用 SLEEP 和 WAKE-UP 函数时要改变 task 的状态标志，这需要使用合适的内存屏 障保证修改的顺序。</p><h1 id="MESI缓存一致性"><a href="#MESI缓存一致性" class="headerlink" title="MESI缓存一致性"></a>MESI缓存一致性</h1><p>写不动了，缓存一致性的内容还是大家自己百度吧<br>其实简单点可以这么理解：</p><ol><li>JMM中的主存其实在实现上，包含了CPU的缓存</li><li>JMM中的CPU的缓存在x86机器上可以理解为write buffer。</li></ol><h1 id="JMM"><a href="#JMM" class="headerlink" title="JMM"></a>JMM</h1><p>写到这儿，基本把开头的一些结论说清楚了，但是还有一个：<br>JVM定义的4种内存屏障指令，在x86的机器上，其实只有一种有用，其他的都是空指令。</p><p>我们先来看JMM中的定义，根据Store和Load的操作，JMM分成了4中：</p><ol><li>LoadLoad</li><li>LoadStore</li><li>StoreStore</li><li>StoreLoad</li></ol><p>这4中都是为了禁止重排序的<br>这里的Load就是从主存中获取值，Store就是把值同步写入主存。</p><p>按照读屏障，写屏障，读写屏障划分的话，和fence的对应关系如下：</p><ol><li>LoadLoad -&gt; lfence</li><li>LoadStore -&gt; mfence</li><li>StoreStore -&gt; sfence</li><li>StoreLoad -&gt; mfence</li></ol><p>当然了解这些还是不够的，我们还需要JMM对应了哪种CPU模型。<br>在x86中，我们除了内存，还了解到有write buffer的存在。<br>然而事实上，CPU的实现中，还有一个东西的存在叫<code>invalidate queue</code></p><p>具体的演进与作用可以参照这篇文章：<br><a href="https://zhuanlan.zhihu.com/p/66085562" target="_blank" rel="noopener">内存屏障Memory Barrier: a Hardware View</a></p><p>StoreBuffer就是对应WriteBuffer<br>而Invalidate queue在x86的CPU上是不存在的。</p><p>再回到我们提到的例子：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    x=<span class="number">1</span>;  <span class="comment">//S1</span></span><br><span class="line">    r1=y;  <span class="comment">//S2</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">bar</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">    y=<span class="number">1</span>;  <span class="comment">//L1</span></span><br><span class="line">    r2=x;<span class="comment">//L2</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>在这个例子中，我们需要哪一种屏障呢？<br>就是StoreLoad屏障<br>按照TSO的协议解释，也就是我们读取y的值的之前，必须flush writebuffer。<br>这样，r1和r2就不会出现同时等于0的情况。</p><p>再具体的这个文章讲的很好：<a href="https://zhuanlan.zhihu.com/p/81555436" target="_blank" rel="noopener">为什么在 x86 架构下只有 StoreLoad 屏障是有效指令？</a></p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://mortoray.com/2010/11/18/cpu-reordering-what-is-actually-being-reordered/" target="_blank" rel="noopener">cpu-reordering-what-is-actually-being-reordered</a><br><a href="http://lday.me/2017/11/04/0016_what_is_memory_barriers/" target="_blank" rel="noopener">什么是内存屏障(Memory Barriers)</a><br><a href="https://www.linuxidc.com/Linux/2011-10/44623.htm" target="_blank" rel="noopener">Linux内核中的内存屏障</a><br><a href="https://quant67.com/post/linux/memory-barriers/memory-barriers.html#sec-2-6" target="_blank" rel="noopener">内存屏障</a><br><a href="https://zhuanlan.zhihu.com/p/33626920" target="_blank" rel="noopener">为什么我们需要内存屏障？</a><br><a href="https://blog.csdn.net/muxiqingyang/article/details/6615199" target="_blank" rel="noopener">《大话处理器》Cache一致性协议之MESI</a><br><a href="https://paulcavallaro.com/blog/x86-tso-a-programmers-model-for-x86-multiprocessors/" target="_blank" rel="noopener">x86 TSO: A Programmer’s Model for x86 Multiprocessors</a><br><a href="https://stackoverflow.com/questions/51292687/if-i-dont-use-fences-how-long-could-it-take-a-core-to-see-another-cores-write" target="_blank" rel="noopener">If I don’t use fences, how long could it take a core to see another core’s writes?</a><br><a href="https://blog.csdn.net/automan12138/article/details/104682093" target="_blank" rel="noopener">深入理解内存屏障</a><br><a href="https://www.cnblogs.com/aquester/p/10328479.html" target="_blank" rel="noopener">C和C++中的volatile、内存屏障和CPU缓存一致性协议MESI</a><br><a href="https://mp.weixin.qq.com/s?__biz=MzUzMDk3NjM3Mg==&amp;mid=2247483755&amp;idx=1&amp;sn=50f80e73f46fab04d8a799e8731432c6&amp;chksm=fa48da70cd3f5366d9658277cccd9e36fca540276f580822d41aef7d8af4dda480fc85e3bde4&amp;token=1910810820&amp;lang=zh_CN#rd" target="_blank" rel="noopener">从 Java 内存模型看内部细节</a><br><a href="https://www.zhihu.com/question/296949412/answer/864851230" target="_blank" rel="noopener">既然CPU有缓存一致性协议（MESI），为什么JMM还需要volatile关键字？</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;事实上，我很多次以为我懂了volatile的原理，最终都是错误的。&lt;br&gt;关于重排序，CPU，缓存一致性，内存可见性的话题，其实非常复杂。&lt;/p&gt;
&lt;p&gt;这篇文章较为混乱，较为详细的可以看笔者的一个系列：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.lovezhy.cc/2020/03/09/%E6%90%9E%E6%87%82%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C-CPU%E9%87%8D%E6%8E%92%E5%BA%8F/&quot;&gt;搞懂内存屏障-CPU重排序&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.lovezhy.cc/2020/03/14/%E6%90%9E%E6%87%82%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C-CPU%E7%9A%84%E6%BC%94%E8%BF%9B/&quot;&gt;搞懂内存屏障-CPU的演进&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://blog.lovezhy.cc/2020/03/14/%E6%90%9E%E6%87%82%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C-%E6%8C%87%E4%BB%A4%E4%B8%8EJMM/&quot;&gt;搞懂内存屏障-指令与JMM&lt;/a&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="计算机基础" scheme="https://blog.lovezhy.cc/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"/>
    
    
      <category term="内存屏障" scheme="https://blog.lovezhy.cc/tags/%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C/"/>
    
      <category term="volatile" scheme="https://blog.lovezhy.cc/tags/volatile/"/>
    
  </entry>
  
  <entry>
    <title>Kafka指南-分区副本详解</title>
    <link href="https://blog.lovezhy.cc/2020/03/03/Kafka%E6%8C%87%E5%8D%97-%E5%88%86%E5%8C%BA%E5%89%AF%E6%9C%AC/"/>
    <id>https://blog.lovezhy.cc/2020/03/03/Kafka%E6%8C%87%E5%8D%97-%E5%88%86%E5%8C%BA%E5%89%AF%E6%9C%AC/</id>
    <published>2020-03-02T16:00:00.000Z</published>
    <updated>2020-03-03T14:40:27.865Z</updated>
    
    <content type="html"><![CDATA[<p>分区副本是Kafka中重要的概念。<br>下面我们来详细谈一谈副本相关的概念。</p><a id="more"></a><h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><p>Kafka中，每个Topic，可能有多个分区，同时为了提高每个分区的可用性，每个分区会有多个冗余备份，这个备份就叫副本（Replica），Kafka集群会将一个分区的不同副本分配在不同的Broker上，这样即使一个Broker系统宕机，也不会影响该分区的可用性。</p><p>这也是分布式系统中常见的高可用实现方式。</p><p>但是Kafka中的关于副本，还有几个比较重要的概念。</p><h2 id="Leader副本，Follower副本"><a href="#Leader副本，Follower副本" class="headerlink" title="Leader副本，Follower副本"></a>Leader副本，Follower副本</h2><p>Leader副本，Follower副本：<br>虽然有多个副本，但是只会有一个Leader副本接收客户端的读写操作，其他的副本都叫Follower副本，Follower副本只做一件事，就是同步Leader副本的日志。</p><h2 id="AR（Assigned-Replica）"><a href="#AR（Assigned-Replica）" class="headerlink" title="AR（Assigned Replica）"></a>AR（Assigned Replica）</h2><p>AR（Assigned Replica）：<br>就是某分区所有副本的统称，包括Leader副本和Follower副本。</p><h2 id="优先副本（Preferred-Replica）"><a href="#优先副本（Preferred-Replica）" class="headerlink" title="优先副本（Preferred Replica）"></a>优先副本（Preferred Replica）</h2><p>优先副本（Preferred Replica)，也叫Preferred Leader：<br>Leader副本也不是随意选出的，前面提到过Leader副本是接收客户端的读写请求的，所有的Leader副本都集中在一个Broker上，那设立多个Broker进行负载均衡的意义就没有了。<br>所有控制器会选出每个分区的优先副本是那个，然后使用一些手段让优先副本变成Leader副本。</p><p>注意：不是每个Partition的优先副本都等于Leader副本，如果中途进行了Leader副本切换，Broker重启等事件，Leader副本就会变化，这种情况，有脚本可以手动操作。</p><h2 id="ISR（In-Sync-Replica"><a href="#ISR（In-Sync-Replica" class="headerlink" title="ISR（In-Sync Replica)"></a>ISR（In-Sync Replica)</h2><p>ISR（In-Sync Replica):<br>前面提到，所有的Follower副本，只做一件事，就是同步Leader副本的日志。<br>但是每个副本的同步进度有快有慢，我们将与Leader副本保持一定同步的Follower副本，包括Leader副本自己，叫In-Sync Replica。</p><p>那么你可能要问了，这个“保持一定同步”的标准是什么？<br>落后日志小于X条？</p><p>猜的没错，确实，在Kafka的0.9版本之前，有个参数叫<code>replica.lag.max.messages</code>，默认值是4000。如果一个Follower副本落后Leader副本4000条消息，那么就会被移出ISR集合。</p><p>你可能会注意到，这个是在0.9版本之前，那么在之后被改掉了，为什么呢？<br>因为这个参数很难设置。<br>如果业务系统的流量一直比较平稳也就算了，但是正常的业务流量难免有波动，高的时候可能QPS就超过了这个参数，很容易就触发，低的时候每秒就1条消息，那得4000s才能发现，那也没啥意义。<br>所以这个参数，很难设置。</p><p>从Kafka的0.9版本开始，Broker端有个参数叫<code>replica.lag.time.max.ms</code>，默认值是10000，Broker会启动一个参数定时的检查每个Follower副本上次和Leader副本日志完全一致的时间（注：并不完全等于上次通信时间），如果距离现在已经过去了10000ms，那么就会把这个Follower副本从ISR集合中移除。</p><h1 id="分区Leader"><a href="#分区Leader" class="headerlink" title="分区Leader"></a>分区Leader</h1><h2 id="Leader副本的产生"><a href="#Leader副本的产生" class="headerlink" title="Leader副本的产生"></a>Leader副本的产生</h2><p>一般来说，当我们创建一个Topic，进行分区的时候，Kafka控制器会决定分区分在哪些Broker上，同时也会决定那个副本是Leader副本，并且把这个信息写入ZK。同时通过Http请求通知其他的Broker。</p><h2 id="Leader副本的重新选取"><a href="#Leader副本的重新选取" class="headerlink" title="Leader副本的重新选取"></a>Leader副本的重新选取</h2><p>我们知道，每个Broker启动的时候，都会在ZK的目录下注册一个临时节点。<br>Kafka控制器对这个目录注册监听事件，当发生Broker断开，或者Broker新增的时候，就会触发一些响应的逻辑。</p><p>返回到我们的Leader副本，什么情况下Leader副本会不可用呢？通常来说就是Leader副本所在的Broker整个挂掉了。<br>Kafka控制器感应到这个事件后，就会重新指定一个副本为Leader副本。<br>到底指定哪一个呢？这里面有大文章。<br>我们慢慢来说。</p><p>在Raft中，重新选举一个Leader的条件就是谁的日志最新，谁就可以当Leader。<br>这样可以避免消息丢失。<br>在Kafka中类似，但是没有Raft中那么严格，Broker会从ISR集合中<strong>随机</strong>选取一个。<br>是的，随机选举一个当Leader。<br>我们知道，ISR集合中的副本，可不一定与Leader副本的日志完全一致的。<br><img src="/images/Kafka指南-分区/选举.png" alt=""><br>如上图所示，Leader副本如果挂掉，Follower1和2都属于ISR集合的话，虽然Follower1的日志比Follower2更新，但是Follower2也可以被选举为Leader。<br>当Follower2被选举为Leader后，Follower1的2003和2004的日志，都要被<strong>删除</strong>。</p><h2 id="分区的可用性，AP还是CP"><a href="#分区的可用性，AP还是CP" class="headerlink" title="分区的可用性，AP还是CP"></a>分区的可用性，AP还是CP</h2><p>分布式系统，有个著名的理论就是CAP理论，这里有个A就是可用性。<br>那么Kafka作为一个分布式的系统，其实也是遵循这个理论的。<br>那么你会问了，Kafka是个AP系统还是个CP系统。</p><p>说到这里，不得不提一个共识性算法，叫Raft，Raft协议其实是为了构建一个CP系统，它的A属性，是保证不能挂掉一半以上的节点。<br>而共识性算法中，有个微软的协议叫PacificA，kafka其实和这个系统相近。</p><p>不兜圈子了，直接明说，Kafka系统到底是AP还是CP其实是可以配置的。<br>在Raft中，一个数据的提交，Leader节点必须要接收到一半以上（包括自己）的节点的成功响应，才能告诉客户端，说你这条消息，提交成功，我们保证，肯定不会丢失了。</p><p>把这个概念移到Kafka中，我们的Producer的发送的数据，Leader副本自己Append后，要同步给多少节点才能响应成功呢？<br>这个是个参数，可以配置。<br><code>acks</code>：指明分区中必须要有多少个副本收到这条消息，Broker才能响应成功。</p><ol><li><code>acks=1</code>。这也是默认值，生产者发送消息后，只要分区的Leader成功写入，就会收到成功的响应。显然，这种是不能保证数据不被丢失的。万一写完，Leader副本就挂了，Follower副本还没来得及同步。</li><li><code>acks=0</code>：这个比等于1还夸张，完全随缘的，不关心服务端。一般不这么设置。</li><li><code>acks=-1,acks=all</code>：这个参数，要保证所有的ISR副本都写入成功，才可以返回成功。结合前面我们提到的ISR的概念，会发现，单独设置这个参数其实没啥用，因为ISR集合中副本的个数你根本不知道。所以这个选项，还需要我们设置出ISR集合中，至少有几个副本：<code>min.insync.replicas</code>。</li></ol><p>如果我们需要我们的Kafka是像Raft一样的CP系统，那么我们需要配置：</p><ol><li><code>acks=all</code></li><li><code>min.insync.replicas=${f/2 + 1}</code></li><li><code>unclean.leader.election.enable=false</code><br>显然这种，性能肯定不咋地，可用性也会大大折扣。</li></ol><p>如果我们需要我们的Kafka系统是AP系统，那么我们需要把</p><ol><li><code>min.insync.replicas=1</code></li><li><code>unclean.leader.election.enable=true</code><br>这样我们可以容忍最多（f-1）个副本失效。<br>但是会丢失数据。</li></ol><p>默认值：当然大部分人肯定没关心过这两个参数，其实从参数的设计来看，Kafka其实偏向于一个AP系统，<code>acks</code>的默认值为1，<code>min.insync.replicas</code>的默认值也是1，<code>unclean.leader.election.enable</code>的默认值是false。<br>这么配置的话，如果ISR集合中，某一时间只有Leader副本，同时恰好宕机了，那么整个分区就不可用了。</p><h1 id="ISR更新"><a href="#ISR更新" class="headerlink" title="ISR更新"></a>ISR更新</h1><p>对于ISR流程的更新，笔者也画了一些示意图，当然其实流程大家心里应该也清楚了。</p><h2 id="流程一"><a href="#流程一" class="headerlink" title="流程一"></a>流程一</h2><p><img src="/images/Kafka指南-分区/副本上下线1.png" alt=""><br>如上图所示，我们有3个Broker。<br>对于Topic=Hello而言，我们假设他有10个Partition，其中每个Partition有3个副本。<br>图中所示的是Partition5的副本分布情况。</p><blockquote><p>Leader副本，也就是Replica-0，在Broker-0节点上。</p><p>这个时候，ISR集合有[0,1,2]。</p></blockquote><p>在Kafka控制器和Zookeeper中都记录了该信息。<br>对于ZK而言，在<code>/state/Hello/5</code>节点中记录了该信息。<br>并且<code>/Isr_notification/</code>节点下，没有子节点。<br>图中没有标明的一点是：KafkaController监听了<code>/Isr_notification/</code>节点。</p><h2 id="流程二"><a href="#流程二" class="headerlink" title="流程二"></a>流程二</h2><p><img src="/images/Kafka指南-分区/副本上下线2.png" alt=""></p><p>渐渐的，副本2同步日志出现了落后，被Leader副本检测到了，下面Leader副本需要更新ISR集合。</p><h2 id="流程三"><a href="#流程三" class="headerlink" title="流程三"></a>流程三</h2><p><img src="/images/Kafka指南-分区/副本上下线3.png" alt=""></p><p>Leader副本所在的Broker0，会连接ZK，做两个操作：</p><ol><li>修改<code>/state/Hello/5/</code>的值，把ISR集合中的2移除</li><li>在<code>/Isr_notification/</code>下新增一个节点，表示Hello的Partition的ISR集合发生了变化</li></ol><h2 id="流程四"><a href="#流程四" class="headerlink" title="流程四"></a>流程四</h2><p><img src="/images/Kafka指南-分区/副本上下线4.png" alt=""><br>ZK会通知Kafka控制器</p><h2 id="流程五"><a href="#流程五" class="headerlink" title="流程五"></a>流程五</h2><p><img src="/images/Kafka指南-分区/副本上下线5.png" alt=""><br>Kafka控制器会做两个操作：</p><ol><li>更新自己的元数据，将副本2从ISR集合中删除</li><li>通知其他所有的Broker，更新其元数据。</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;分区副本是Kafka中重要的概念。&lt;br&gt;下面我们来详细谈一谈副本相关的概念。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kafka指南" scheme="https://blog.lovezhy.cc/categories/Kafka%E6%8C%87%E5%8D%97/"/>
    
    
      <category term="Kafka" scheme="https://blog.lovezhy.cc/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka指南-模块与职能划分</title>
    <link href="https://blog.lovezhy.cc/2020/02/29/Kafka%E6%8C%87%E5%8D%97-%E6%A8%A1%E5%9D%97%E4%B8%8E%E8%81%8C%E8%83%BD%E5%88%92%E5%88%86/"/>
    <id>https://blog.lovezhy.cc/2020/02/29/Kafka%E6%8C%87%E5%8D%97-%E6%A8%A1%E5%9D%97%E4%B8%8E%E8%81%8C%E8%83%BD%E5%88%92%E5%88%86/</id>
    <published>2020-02-28T16:00:00.000Z</published>
    <updated>2020-02-29T14:27:06.411Z</updated>
    
    <content type="html"><![CDATA[<p>Kafka的是个复杂的系统，除了基本的Producer，Consumer，Broker外，为了实现完备的功能，Kafka中有许多重要的模块，本文梳理一下这些模块的划分，与他们负责的功能。</p><a id="more"></a><h1 id="运行组件"><a href="#运行组件" class="headerlink" title="运行组件"></a>运行组件</h1><p>基本上来说，正常的一个运行Kafka的业务，都需要4个组件：</p><ol><li>Broker。也就是Kafka服务器。</li><li>Producer。也就是消息的生产者，负责把消息传入Broker。</li><li>Consumer。消息的消费者，负责从Broker拉取消息。</li><li>Zookeeper。Broker的运行需要Zookeeper保存一些元数据。</li></ol><p>这四大组件的关系如下图所示：<br><img src="../images/Kafka-模块划分/组件.png" alt=""></p><p>流程也不用我多介绍了。<br>这里要提的一点就是，<strong>Consumer端不再感知Zookeeper了</strong><br>这个其实是演进出来的，之前的Offset保存的方式导致了Consumer端必须要感知ZK的地址。<br>但是使用了新的Offset提交方式后，Consumer没有必要感知Zookeeper了，所以在新版本的启动参数中仅仅需要使用<code>--bootstrap-server</code>指定任意一个Broker地址就行了。</p><p>当然这个问题我也去搜集了一下答案：<br><a href="https://segmentfault.com/q/1010000015795614" target="_blank" rel="noopener">新版kafka消费者、生产者配置为何使用bootstrap-servers而不是zookeeper服务器地址？</a></p><p>答案中提到了一个Kafka的提案，就是要取代Zookeeper。也是值得看一看的。</p><h1 id="控制器"><a href="#控制器" class="headerlink" title="控制器"></a>控制器</h1><p>控制器，也叫Kafka Controller。<br>我们知道Kafka集群中，会有多个Broker，这些Broker并不是对等的关系，和Raft协议一样，其中一个Broker会被选举为Leader，也就是控制器，KafkaController。</p><p>为什么需要一个Leader呢？这个在我看来其实有两个原因。</p><ol><li>Zookeeper的性能有限。</li><li>避免复杂的逻辑。</li></ol><p>在早期的Kafka版本中，其实没有控制器这个概念，所有的Broker都是对等的，很多复杂的逻辑难以解决，以及对ZK会造成很大的负载，笔者列举几个：</p><ol><li>分区的ISR集合变更。每个分区的ISR集合，属于元数据，需要保存到每个Broker上的。分区的Leader副本所在的Broker会首先感知到该分区的ISR变更，它会把这个事件发布上ZK上，然后其他的Broker会监听到这个事件，更新自己的元数据。</li><li>Leader副本出现问题。当一个分区的Leader副本出现问题时，需要重新选举出新的Leader副本，这个事件也是通过注册ZK的监听器实现的。</li><li>Topic的分区分配，分区迁移，优先副本的选举：这是为了负载均衡的分布在不同的Broker上，如果没有Leader，随机的让这些决策由任意一个Broker去完成，会比较复杂。</li></ol><p>所有加入KafkaController后，这个被选为Leader的Broker需要做很多事：</p><ol><li>注册ZK的监听器，事件触发后，将信息传递给其他的Broker。</li><li>对集群的配置进行决策和任务发放</li></ol><p>再具体一点：</p><ol><li>分区Leader副本出现故障，选举出新的Leader副本</li><li>ISR集合变更，通知给其他的Broker</li><li>Topic的新增，删除，分区分配，分区迁移，副本管理</li><li>监听其他的Broker的变化，新增，删除等。</li></ol><h1 id="消费者协调器，组协调器"><a href="#消费者协调器，组协调器" class="headerlink" title="消费者协调器，组协调器"></a>消费者协调器，组协调器</h1><p>消费者协调器（ConsumerCoordinator），组协调器（GroupCoordinator）是为了解决旧版本的消费者再均衡问题而诞生的。</p><p>首先让我们思考一下消费组需要解决的问题。<br>通常来说，一个Topic会有多个分区，而每个分区，都会指派给一个Consumer会消费。<br><img src="../images/Kafka-模块划分/分区分配.png" alt=""><br>如上图所示，这个Topic共有4个partition，有3个Consumer。<br>Consumer0分配了P0和P1给它，Consumer1和Consumer2分别分配了P2和P3。</p><p>这样很美好，但是美好的事情总是不稳定。<br>如果Consumer0挂了呢？<br>那么我们需要把P0和P1分配给Consumer1和Consumer2。<br>如果多了一个Consumer加入，我们需要把P0分配给它。</p><p>这些就是消费者再均衡问题。<br>怎么解决这个问题呢？<br>旧版的Kafka中同样使用了很多的ZK的监听器去完成，很复杂。<br>问题有2：</p><ol><li>ZK负载较大。</li><li>ZK本身的脑裂问题，会导致各个消费者拿到的消费组的状态不一致，产生问题。</li></ol><p>解决这个问题的关键和Kafka的控制器的思路一致，我们需要引入Leader来完成重分配。<br>于是有了组协调器</p><h2 id="组协调器（GroupCoordinator）"><a href="#组协调器（GroupCoordinator）" class="headerlink" title="组协调器（GroupCoordinator）"></a>组协调器（GroupCoordinator）</h2><blockquote><p>组协调器：Kafka将全部的消费组分成了多个子集，每个消费组的子集在服务端对应一个GroupCoordinator对其进行管理</p></blockquote><p>组协调器是在服务端的，由某一个Broker担任。<br>有了组协调器后，某消费组中的所有消费者定时的向其发送心跳包，这样组协调器就能感知该消费组的消费者的个数变更，从而触发分区重分配。</p><p>好像解决重分配的问题，只要有了组协调器就行了？<br>是的，确实是的。</p><p>那么消费者协调器是干什么用的？<br>别急，等我慢慢道来。</p><h2 id="消费者协调器"><a href="#消费者协调器" class="headerlink" title="消费者协调器"></a>消费者协调器</h2><p>说到这个其实不能不提一个概念，<strong>分区分配规则</strong>。<br>X个分区，Y个消费者，怎么分配分区给消费者呢？<br>当然我们可以轮询着来，但是作为一个完备的框架，这一层分配策略是需要抽象出来的，甚至可以由用户自定义的。</p><p>Kafka提供了消费者参数<code>partition.assignment.strategy</code>来进行配置，可选值如下：</p><ol><li>RangeAssignor：按照消费者总数和分区总数进行整除运算来获得一个跨度，然后将分区按照跨度进行平均分配，也是默认的分配策略。</li><li>RoundRobinAssignor：轮询分配</li><li>StickyAssignor：前面两种分配方式，都没有考虑分区和Consumer的状态，消费情况，以及之前的分配情况，这种分配结合前面两种状态来决定分配方式。</li></ol><p>当然也可以进行自定义分配方式，需要我们在Consumer代码里进行编写。</p><p>所以问题来了，为什么配置是在Consumer端？<br>你可能想到了，<strong>灵活配置！</strong>。</p><p>写到这儿，消费者协调器的存在就可以理解了，真正的分配其实并不是组协调器进行的，而是组协调器会在所有的Consumer中指定一个Leader，这个Leader就叫消费者协调器，真正的分配结果由这个Consumer来执行，消费者协调器把分配结果告诉组协调器，组协调器再通知给所有的消费者结果。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Kafka的是个复杂的系统，除了基本的Producer，Consumer，Broker外，为了实现完备的功能，Kafka中有许多重要的模块，本文梳理一下这些模块的划分，与他们负责的功能。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kafka指南" scheme="https://blog.lovezhy.cc/categories/Kafka%E6%8C%87%E5%8D%97/"/>
    
    
      <category term="Kafka" scheme="https://blog.lovezhy.cc/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka指南-源码导入Idea</title>
    <link href="https://blog.lovezhy.cc/2020/02/23/Kafka%E6%8C%87%E5%8D%97-%E6%BA%90%E7%A0%81%E5%AF%BC%E5%85%A5Idea/"/>
    <id>https://blog.lovezhy.cc/2020/02/23/Kafka%E6%8C%87%E5%8D%97-%E6%BA%90%E7%A0%81%E5%AF%BC%E5%85%A5Idea/</id>
    <published>2020-02-22T16:00:00.000Z</published>
    <updated>2020-02-29T14:26:36.194Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>虽然网上教程很多，但是我依然要写系列<br>因为我踩到的坑有的是网上没有遇到过的</p><a id="more"></a><h2 id="详细步骤"><a href="#详细步骤" class="headerlink" title="详细步骤"></a>详细步骤</h2><h3 id="克隆源码"><a href="#克隆源码" class="headerlink" title="克隆源码"></a>克隆源码</h3><p><code>git clone https://github.com/apache/kafka.git</code></p><p><strong>这个时候切记不能先用idea直接打开项目！</strong><br><strong>这个时候切记不能先用idea直接打开项目！</strong><br><strong>这个时候切记不能先用idea直接打开项目！</strong></p><h3 id="打包环境"><a href="#打包环境" class="headerlink" title="打包环境"></a>打包环境</h3><p>kafka自带了一些Gradle的Task，可以生成出导入Eclipse或者Idea配置。<br>在Kafka目录下执行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./gradlew jar</span><br><span class="line">./gradlew idea</span><br></pre></td></tr></table></figure><p>这个时候目录下会出现一个文件叫<code>kafka.ipr</code><br>在finder中双击这个文件，idea会自动打开并导入项目。<br><strong>注：也就是这个时候才会打开Idea</strong></p><h3 id="配置Gradle"><a href="#配置Gradle" class="headerlink" title="配置Gradle"></a>配置Gradle</h3><p>一般Idea打开会，右下角会弹出一个框，大致意思是：</p><blockquote><p>我们检测出这个是Gradle项目，需要导入Gradle的配置吗？</p></blockquote><p>这个时候，点击确认就行。</p><p>如果打开Idea啥也没发生，那么就需要我们自己打开文件<code>build.gradle</code><br>然后进行刷新之类的操作，具体我也忘了怎么操作的。</p><h3 id="修改配置"><a href="#修改配置" class="headerlink" title="修改配置"></a>修改配置</h3><p>一些配置的修改是比较重要的</p><ol><li>文件build.gradle<br>第一处修改：<br>找到<code>tasks.withType(ScalaCompile) {</code>这一行<br>修改<code>scalaCompileOptions.additionalParameters</code>的配置<figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">    scalaCompileOptions.additionalParameters = [</span><br><span class="line">      <span class="string">"-nowarn"</span>,  <span class="comment">//新增</span></span><br><span class="line">      <span class="string">"-deprecation"</span>,</span><br><span class="line">      <span class="string">"-unchecked"</span>,</span><br><span class="line">      <span class="string">"-encoding"</span>, <span class="string">"utf8"</span>,</span><br><span class="line">      <span class="string">"-Xlog-reflective-calls"</span>,</span><br><span class="line">      <span class="string">"-feature"</span>,</span><br><span class="line">      <span class="string">"-language:postfixOps"</span>,</span><br><span class="line">      <span class="string">"-language:implicitConversions"</span>,</span><br><span class="line">      <span class="string">"-language:existentials"</span>,</span><br><span class="line"><span class="comment">//      "-Xlint:constant",  //注释</span></span><br><span class="line"><span class="comment">//      "-Xlint:delayedinit-select",</span></span><br><span class="line"><span class="comment">//      "-Xlint:doc-detached",</span></span><br><span class="line"><span class="comment">//      "-Xlint:missing-interpolator",</span></span><br><span class="line"><span class="comment">//      "-Xlint:nullary-override",</span></span><br><span class="line"><span class="comment">//      "-Xlint:nullary-unit",</span></span><br><span class="line"><span class="comment">//      "-Xlint:option-implicit",</span></span><br><span class="line"><span class="comment">//      "-Xlint:package-object-classes",</span></span><br><span class="line"><span class="comment">//      "-Xlint:poly-implicit-overload",</span></span><br><span class="line"><span class="comment">//      "-Xlint:private-shadow",</span></span><br><span class="line"><span class="comment">//      "-Xlint:stars-align",</span></span><br><span class="line"><span class="comment">//      "-Xlint:type-parameter-shadow",</span></span><br><span class="line"><span class="comment">//      "-Xlint:unused"</span></span><br><span class="line">    ]</span><br></pre></td></tr></table></figure></li></ol><p>第二处修改：<br>还有<code>tasks.withType(JavaCompile) {</code>这一行<br>修改为<br><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">  tasks.withType(JavaCompile) &#123;</span><br><span class="line">    <span class="keyword">options</span>.encoding = <span class="string">'UTF-8'</span></span><br><span class="line"><span class="comment">//    options.compilerArgs &lt;&lt; "-Xlint:all"</span></span><br><span class="line">    <span class="comment">// temporary exclusions until all the warnings are fixed</span></span><br><span class="line"><span class="comment">//    options.compilerArgs &lt;&lt; "-Xlint:-rawtypes"</span></span><br><span class="line"><span class="comment">//    options.compilerArgs &lt;&lt; "-Xlint:-serial"</span></span><br><span class="line"><span class="comment">//    options.compilerArgs &lt;&lt; "-Xlint:-try"</span></span><br><span class="line"><span class="comment">//    options.compilerArgs &lt;&lt; "-Werror"</span></span><br><span class="line">    <span class="comment">// --release is the recommended way to select the target release, but it's only supported in Java 9 so we also</span></span><br><span class="line">    <span class="comment">// set --source and --target via `sourceCompatibility` and `targetCompatibility`. If/when Gradle supports `--release`</span></span><br><span class="line">    <span class="comment">// natively (https://github.com/gradle/gradle/issues/2510), we should switch to that.</span></span><br><span class="line">    <span class="keyword">if</span> (JavaVersion.current().isJava9Compatible())</span><br><span class="line">      <span class="keyword">options</span>.compilerArgs &lt;&lt; <span class="string">"--release"</span> &lt;&lt; minJavaVersion</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p><p><strong>上面两个修改主要是为了Idea启动时编译，会把一堆warn当做Error报出来，Gradle不给启动</strong></p><p>第三处修改：<br>找到<code>project(&#39;:core&#39;) {</code>这一行<br>下面会有一堆<br><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">dependencies</span> &#123;</span><br><span class="line">  <span class="keyword">compile</span> <span class="keyword">project</span>(<span class="string">':clients'</span>)</span><br><span class="line">  <span class="keyword">compile</span> libs.jacksonDatabind</span><br><span class="line">  <span class="keyword">compile</span> libs.jacksonModuleScala</span><br><span class="line">~~~</span><br></pre></td></tr></table></figure></p><p>这种配置<br>在<code>compileOnly libs.log4j</code>这一行的下面，加上<br><code>compile libs.slf4jlog4j</code></p><p><strong>这个修改主要是终端启动Kafka的时候日志打印不出来的问题</strong></p><blockquote><p>很多的网上的答案都是让自己把两个依赖加进去，但是我发现其实Kafka配置了两个依赖，但是却没有Compile，所以不需要自己加进去，只要加上这行配置就行</p></blockquote><ol><li>配置log4j文件<br>第一步：把config目录下的log4j.properties文件复制到core/src/main/resources目录下<br>需要创建rescources目录<br>如图所示：<br><img src="/images/Kafka源码导入Idea/log4j1.png" alt=""></li></ol><p><strong>并不是很多网上说的复制到/scala目录下</strong></p><p>第二步：修改log4j.properties文件<br>主要是把很多的<code>${kafka.logs.dir}</code>这种变量去掉，换成自己电脑上的绝对路径</p><h2 id="启动配置"><a href="#启动配置" class="headerlink" title="启动配置"></a>启动配置</h2><p>下面就是启动配置了，这个网上都有，我就直接复制一下</p><p><strong>首先得自己启动一个Zookeeper进程</strong></p><h3 id="Broker"><a href="#Broker" class="headerlink" title="Broker"></a>Broker</h3><p><img src="/images/Kafka源码导入Idea/Kafka.png" alt=""></p><h3 id="Consumer"><a href="#Consumer" class="headerlink" title="Consumer"></a>Consumer</h3><p><strong>Program arguments可根据自己的情况修改</strong><br><img src="/images/Kafka源码导入Idea/consumer.png" alt=""></p><h3 id="produer"><a href="#produer" class="headerlink" title="produer"></a>produer</h3><p><strong>Program arguments可根据自己的情况修改</strong><br><img src="/images/Kafka源码导入Idea/producer.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;虽然网上教程很多，但是我依然要写系列&lt;br&gt;因为我踩到的坑有的是网上没有遇到过的&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kafka指南" scheme="https://blog.lovezhy.cc/categories/Kafka%E6%8C%87%E5%8D%97/"/>
    
    
      <category term="Kafka" scheme="https://blog.lovezhy.cc/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka指南-时间轮实现</title>
    <link href="https://blog.lovezhy.cc/2020/01/11/Kafka%E6%8C%87%E5%8D%97-%E6%97%B6%E9%97%B4%E8%BD%AE%E5%AE%9E%E7%8E%B0/"/>
    <id>https://blog.lovezhy.cc/2020/01/11/Kafka%E6%8C%87%E5%8D%97-%E6%97%B6%E9%97%B4%E8%BD%AE%E5%AE%9E%E7%8E%B0/</id>
    <published>2020-01-10T16:00:00.000Z</published>
    <updated>2020-02-29T14:26:48.032Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Kafka延迟任务的实现</p><a id="more"></a><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>延迟任务的实现，一般是利用有序队列，按照执行时间的顺序排列，然后有个线程不断的去取第一个元素，如果到了需要执行的时间，就去执行。</p><p>伪代码：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Delay</span> </span>&#123;</span><br><span class="line">    Queue&lt;Comparable&gt; taskQueue;</span><br><span class="line">    </span><br><span class="line">    <span class="function">func <span class="title">add</span><span class="params">(Comparable task)</span> </span>&#123;</span><br><span class="line">        taskQueue.add(task);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function">func <span class="title">pollAndRun</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">                var task = taskQueue.peek();</span><br><span class="line">                <span class="keyword">if</span> (task.expireTime &lt;= System.currentTime) &#123;</span><br><span class="line">                    run(taskQueue.poll());</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    Thread.sleep(task.expireTime - System.currentTime);</span><br><span class="line">                &#125;</span><br><span class="line">        &#125; </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><strong>注意：这里的伪代码不完善，在add方法中，一般来说在某种情况下要interrupt执行pollAndRun的线程。</strong></p><p>目前聚焦的主要问题是Queue是怎么个实现法。<br>在Java中有优先权队列可以进行排序，底层是基于最小堆做的，插入和删除的时间复杂度是O(logn)</p><p>当然正常情况下，这种实现可以了，Java中的标准实现也是这样。</p><p>但是呢，Kafka中有大量的<strong>低延迟</strong>的任务，如果都用最小堆去做，难免性能不太好<br>所以Kafka中实现了时间轮的算法，将插入和删除的时间复杂度降低到了O(1)。</p><p>下面细讲下实现：</p><h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><p>源码路径在：<code>package kafka.utils.timer</code>下。</p><h3 id="TimerTask"><a href="#TimerTask" class="headerlink" title="TimerTask"></a>TimerTask</h3><p>Task是队列中的执行元素</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">trait TimerTask extends Runnable &#123;</span><br><span class="line">    val delayMs: Long </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>实现了Runnable接口，delayMs是指的需要被执行的时间戳，不是相对时间</p><h3 id="TimerTaskList"><a href="#TimerTaskList" class="headerlink" title="TimerTaskList"></a>TimerTaskList</h3><p>看名字就知道是存储Task的集合类</p><p>但是其实它的定义并没有我开始想的那么简单</p><p>TimerTask在TimerTaskList内部的存储形式是双向链表</p><p>所以TimerTask其实被TimerTaskEntry的类包装了一层，增加了Prev和Next指针。</p><p><img src="/images/Kafka时间轮/TimerTaskList.png"></p><p>但是注意哦，这里虽然TimerTask实现了Comparable接口，但是TimerTaskList内部其实就是个简单的双向列表，并不会根据TimerTask的expireTime进行排序。</p><p>恰恰相反，TimerTaskList也实现了Comparable接口。</p><p>在TimerTaskList内部，有一个变量</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[<span class="keyword">this</span>] val expiration = <span class="keyword">new</span> AtomicLong(-<span class="number">1L</span>)</span><br></pre></td></tr></table></figure><p>从名字中看出其实是存放的是到期时间，TimerTask有过期时间我们可以理解，那么为什么TimerTaskList也有个过期时间？</p><p>这个过期时间是怎么定的，有什么用？</p><h3 id="TimingWheel"><a href="#TimingWheel" class="headerlink" title="TimingWheel"></a>TimingWheel</h3><p>来了，时间轮最主要的数据结构来了。</p><p><img src="/images/Kafka时间轮/TimerWheel.png"></p><p>首先，看图中，模仿了一个钟表的运行图。<br>每tick一下，就把当前指针指向下一个格子。<br>其中每个格子对应着一个TimerTaskList</p><p>格子在Kafka中叫bucket<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val buckets = Array.tabulate[TimerTaskList](wheelSize) &#123; _ =&gt; <span class="keyword">new</span> TimerTaskList(taskCounter) &#125;</span><br></pre></td></tr></table></figure></p><p>每一格代表的时间叫TickMs，整个表最长的跨度叫Interval。</p><p>如果TickMs=5，Bucket=4，就表示这个时间轮有4个格子，总共能执行20ms内的延迟任务，同时TickMs也就是该时间轮保证的延迟任务的延迟执行的单位。</p><p>什么意思呢？就是说如果一个任务是2ms后执行，一个是4ms后执行，但是整个时间轮的TickMs是5ms，那么这两个任务在时间轮看来其实是没区别，是同时执行。</p><p>所以时间轮的TickMs最小，时间就越精确。</p><p>如果延迟时间超过了该时间轮的Interval怎么办？</p><p>比如执行50ms后才运行的任务，则需要建立跨度更大的时间轮。</p><p>而Kafka中会自动建立跨度更大的时间轮，叫overflowWheel，<strong>更大的时间轮的TickMs是下一层的Interval</strong>。</p><p>看到这里，其实可以解答TimerTaskList中的expiration有什么用了。</p><p>这里的expiration其实就是整个TimerTaskList的过期时间，是TickMs的整数倍</p><p>与在TimerTaskList中每个Task的具体延迟时间关系是</p><p><code>TimerTaskList.expiration &lt;= Task.expiration &lt;= TimerTaskList.expiration + TickMs</code></p><p>在Kafka中，默认的时间轮配置TickMs=1，Bucket=20，也就是20MS内的延迟任务。</p><h2 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h2><p>讲完了数据结构，下面需要讲怎么运行了。<br>TimingWheel的运行，交给了Timer来操作。<br>Timer有两个方法<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//往时间轮中加入任务</span></span><br><span class="line"><span class="function">def <span class="title">add</span><span class="params">(timerTask: TimerTask)</span></span>&#123;&#125;</span><br><span class="line"><span class="comment">//驱动时间轮向前Tick</span></span><br><span class="line"><span class="function">def <span class="title">advanceClock</span><span class="params">(timeoutMs: Long)</span></span>&#123;&#125;</span><br></pre></td></tr></table></figure></p><h3 id="菜鸡的猜想方案"><a href="#菜鸡的猜想方案" class="headerlink" title="菜鸡的猜想方案"></a>菜鸡的猜想方案</h3><p>让我们暂时脱离源码，猜猜时间轮怎么运行的。</p><p><img src="/images/Kafka时间轮/tick.png" alt=""></p><p>正常来说，我们把任务分到具体的Bucket中，每隔一个TickMs，将当前的指针向下运行一格。</p><p>找到这一格中的TimerTaskList，将里面的任务全部拿出来run一遍。</p><p>伪代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">List&lt;TimerTaskList&gt; buckets;</span><br><span class="line"><span class="keyword">int</span> nextBucket;</span><br><span class="line"><span class="function">func <span class="title">tick</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  var timerTaskList = buckets.get(nextBucket % buckets.length)</span><br><span class="line">  <span class="keyword">if</span> (timerTaskList.expiration &lt;= System.currentTime) &#123;</span><br><span class="line">    timerTaskList.timerTaskEntrys.foreach(entry -&gt; entry.run()));</span><br><span class="line">    timerTaskList.timerTaskEntrys.foreach(TimerTaskList::remove);</span><br><span class="line">    nextBucket++;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在add元素的时候，先需要判断当前的时间轮是否能承载延迟时间，如果不能，则建立overflowWheel，加到overflowWheel中。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">List&lt;TimerTaskList&gt; buckets;</span><br><span class="line"><span class="function">func <span class="title">add</span><span class="params">(taskEntry)</span> </span>&#123;</span><br><span class="line">  var targetBucketId = (taskEntry.expiration - System.time) / tickMs + nextBucket;</span><br><span class="line">  var timerTaskList = buckets.get(targetBucketId % buckets.length)</span><br><span class="line">  timerTaskList.add(taskEntry);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>看起来非常完美，但是问题来了，这个tick函数，怎么个运行策略呢？</p><p>如果要要跑的非常精确的话，必须要有个线程去单独驱动是肯定的，线程里还得这么跑</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//1</span></span><br><span class="line"><span class="function">func <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">    timer.tick()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//2</span></span><br><span class="line"><span class="function">func <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">    timer.tick()</span><br><span class="line">    sleep(timer.tickms)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>有方案1和方案2两种，第二种肯定是有问题的，如果出现了FullGC的情况，那么整个时间轮就不准了。</p><p>只能选择第一种方案，那么第一种肯定是不行的，这样CPU就是100%了，即使时间轮中没有任何任务，很多时间都是无用功，太浪费CPU了。</p><p>其实这里还有个很严重的问题，我们没有考虑overflowWheel。</p><p>正常情况下，在overflowWheel中的任务，如果已经到了下一层TimingWheel的interval范围内，是需要手动放到下一层的。</p><p>如果是这种实现的话，对于overflowWheel的处理会更加的复杂。</p><h3 id="Kafka中的实现"><a href="#Kafka中的实现" class="headerlink" title="Kafka中的实现"></a>Kafka中的实现</h3><p>菜鸡的猜想方案是不行的，面试都是直接挂的节奏。</p><p>所以这种思路是不成立的，那么我们能不能换个思路呢？</p><p>我们沿用最基本的最小堆来实现延迟任务的思路，建立一个优先权队列</p><p>但是队列中的元素不再是TimerTask了，而是TimerTaskList，相比较最原始的方案，队列中的元素少了一个数量级。</p><p>这样，每次单独的线程进行Tick的时候，选出最早需要执行的TimerTaskList，如果还没到执行时间，就可以进行Sleep，而不是占满CPU。</p><p>所以在TimingWheel中增加一个数据结构</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">var queue = <span class="keyword">new</span> PriorityQueue&lt;TimerTaskList&gt;()</span><br></pre></td></tr></table></figure><p>每次进行add时，除了把TaskEntry添加到TimerTaskEntry中，还将TimerTaskList添加到queue中。</p><p>这样线程的驱动函数就是这么写：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">func <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">    var timerTaskList = timer.queue.poll();</span><br><span class="line">    <span class="keyword">if</span> (timerTaskList.expiration &lt; System.time) &#123;</span><br><span class="line">      sleep(System.time - timerTaskList.expiration);</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>虽然也使用了插入是O(logn)的最小堆结构，但是堆中元素不再是全量的Task了，而是TaskList，所以时间复杂度其实类似于O(1)了。</p><p>那么对于overflowWheel里面的Task怎么处理呢？</p><p>很简单，和第一层的timingWheel一样，将overFlowWheel中的TimerTaskList也加到queue中</p><p>但是从Queue取出的时候，就不是立即执行了，而是再走一遍add程序</p><p>下面是源码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">//类似于源代码中nextBuckets的作用，这里是绝对时间，startMs是时间轮的开始的绝对时间，这里计算成tickMs的整数倍</span><br><span class="line">private[this] var currentTime = startMs - (startMs % tickMs)</span><br><span class="line"></span><br><span class="line">//向时间轮中加入任务</span><br><span class="line">def add(timerTaskEntry: TimerTaskEntry): Boolean = &#123;</span><br><span class="line">   val expiration = timerTaskEntry.expirationMs</span><br><span class="line">   if (timerTaskEntry.cancelled) &#123;</span><br><span class="line">     //如果任务已经取消，添加失败，可以直接实行</span><br><span class="line">     false</span><br><span class="line">   &#125; else if (expiration &lt; currentTime + tickMs) &#123;</span><br><span class="line">     //如果已经到执行时间，那么也是可以直接执行</span><br><span class="line">     false</span><br><span class="line">   &#125; else if (expiration &lt; currentTime + interval) &#123;</span><br><span class="line">           //这里其实还挺难理解的，如果我们按照钟表的概念，指针每隔一段时间去转动一下，就很难理解下面的代码</span><br><span class="line">           //这里其实就是每隔tickMs，指针不转，整个表顺时针转tickMs圈</span><br><span class="line">     val virtualId = expiration / tickMs</span><br><span class="line">     val bucket = buckets((virtualId % wheelSize.toLong).toInt)</span><br><span class="line">     bucket.add(timerTaskEntry)</span><br><span class="line"></span><br><span class="line">     if (bucket.setExpiration(virtualId * tickMs)) &#123;</span><br><span class="line">       //如果Bucket的失效时间设置成功，就把这个TimerTaskList加入到queue中</span><br><span class="line">       queue.offer(bucket)</span><br><span class="line">     &#125;</span><br><span class="line">     true</span><br><span class="line">   &#125; else &#123;</span><br><span class="line">     //放不下，建立overflowWheel，overflowWheel和当前timingWheel公用一个queue</span><br><span class="line">     if (overflowWheel == null) addOverflowWheel()</span><br><span class="line">     overflowWheel.add(timerTaskEntry)</span><br><span class="line">   &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>timingWheel的advanceClock代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def advanceClock(timeMs: Long): Unit = &#123;</span><br><span class="line">  if (timeMs &gt;= currentTime + tickMs) &#123;</span><br><span class="line">    currentTime = timeMs - (timeMs % tickMs)</span><br><span class="line">    if (overflowWheel != null) overflowWheel.advanceClock(currentTime)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>主要就是调整下currentTime，其实currentTime在有了queue之后，就没有其他作用了，主要就是在add方法中拦住即将过期或者已经过期的任务</p><p>下面是伪代码中的run方法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">def advanceClock(timeoutMs: Long): Boolean = &#123;</span><br><span class="line">   var bucket = delayQueue.poll(timeoutMs, TimeUnit.MILLISECONDS)</span><br><span class="line">   if (bucket != null) &#123;</span><br><span class="line">     writeLock.lock()</span><br><span class="line">     try &#123;</span><br><span class="line">       while (bucket != null) &#123;</span><br><span class="line">         timingWheel.advanceClock(bucket.getExpiration())</span><br><span class="line">         //这里不能把bucket中的任务全部执行，因为可能是overFlowWheel中的TimerTaskList，还没到执行时间，直接再走一遍add程序</span><br><span class="line">         bucket.flush(reinsert)</span><br><span class="line">         bucket = delayQueue.poll()</span><br><span class="line">       &#125;</span><br><span class="line">     &#125; finally &#123;</span><br><span class="line">       writeLock.unlock()</span><br><span class="line">     &#125;</span><br><span class="line">     true</span><br><span class="line">   &#125; else &#123;</span><br><span class="line">     false</span><br><span class="line">   &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>注意一下这里的delayQueue，其中poll方法返回的是过期的任务，并不是集合中第一个元素。</p><p>也就是说，即使queue中元素，但是没有元素要过期，返回的也是null。</p><p>当时作者在哪儿晕了半天。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;Kafka延迟任务的实现&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kafka指南" scheme="https://blog.lovezhy.cc/categories/Kafka%E6%8C%87%E5%8D%97/"/>
    
    
      <category term="kafka" scheme="https://blog.lovezhy.cc/tags/kafka/"/>
    
      <category term="TimeWheel" scheme="https://blog.lovezhy.cc/tags/TimeWheel/"/>
    
      <category term="时间轮" scheme="https://blog.lovezhy.cc/tags/%E6%97%B6%E9%97%B4%E8%BD%AE/"/>
    
  </entry>
  
  <entry>
    <title>HotSpot原理指南-分层编译</title>
    <link href="https://blog.lovezhy.cc/2020/01/04/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-%E5%88%86%E5%B1%82%E7%BC%96%E8%AF%91/"/>
    <id>https://blog.lovezhy.cc/2020/01/04/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-%E5%88%86%E5%B1%82%E7%BC%96%E8%AF%91/</id>
    <published>2020-01-03T16:00:00.000Z</published>
    <updated>2020-02-29T14:36:30.467Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>HotSpot的初衷是将运行环境分为Client和Server，并且为他们定制了不同的JIT策略以及不同的JIT编译器（C1和C2）。</p><p>设计出ClientMode的年代，个人PC的性能还比较低，无论是CPU资源还是内存资源都比较稀少且价格较高，所以C1节约资源的快速编译是很有必要的。</p><p>随着时代的发展，个人计算机的配置在慢慢升级，同时价格也在慢慢降低，在这种环境下，ClientMode并不是那么适用了，所以HotSpot也就慢慢放弃了ClientMode，在个人计算机上默认采用Server模式。</p><a id="more"></a><h2 id="Oracle的想法"><a href="#Oracle的想法" class="headerlink" title="Oracle的想法"></a>Oracle的想法</h2><p>所有的场景都默认使用Server模式自然是没有什么问题的，但是Oracle并不甘心（作者脑补的），主要不甘心在两个方面：</p><ul><li>默认使用Server模式，那么相当于放弃了开发了很久的C1编译器</li><li>由于Server模式JIT编译策略问题，会导致应用的Warm-Up时间较长</li></ul><p>那么有没有什么方法可以结合C1和C2呢？</p><p>比如用C1解决Warm-Up时间过长的问题。</p><h2 id="分层编译"><a href="#分层编译" class="headerlink" title="分层编译"></a>分层编译</h2><p>前面提到过，Oracle想用C1解决Server模式中Warm-Up时间过长的问题，于是引入了分层编译的概念。</p><p>如下图所示：</p><p><img src="/images/HotSpot原理指南-分层编译/c1c2.png" alt=""></p><p>解释阶段主要是为了收集运行时Profile，Profile收集的越多，对JIT编译出的代码性能帮助越大。</p><p>先看上半部分图，如果我们采用传统的ServerMode运行，在一段时间X内，只能收集300份Profile，然后将这些Profile丢给C2去进行编译。</p><p>我们可以减少解释模式的运行时间，尽快用C1把字节码编译成机器码，用机器码去收集Profile。这就如下半部分图所示：</p><p>收集了100份Profile后，运行C1编译后的代码，在一段时间内，可以收集到更多的Profile。</p><p>上面是限制了收集Profile的时间是一定的，如果我们反过来，<strong>收集Profile的样本数是一定的</strong>：</p><ul><li>传统的Server模式，可能需要花费更多的时间进行收集到指定次数的样本</li><li>先利用C1进行代码编译，提升方法的运行速度，相对可以花费更少的时间进行收集</li></ul><p>如上的思想就是引入C1解决传统的ServerMode热身时间较少的问题，也就是分层编译：先采用C1进行编译，再采用C2进行编译。</p><p>具体的时间对比如下两张图所示：只使用C2 VS 分层编译</p><p><img src="/images/HotSpot原理指南-分层编译/only-c2.png" alt=""><br><img src="/images/HotSpot原理指南-分层编译/tier.png" alt=""></p><h2 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h2><p>分层编译在JDK7中就引入了，但是默认是不开启的</p><p>如果运行环境还是JDK7，可以使用<code>-XX:+TieredCompilation</code>开启</p><p>在JDK8中，分层编译就默认开启了，如果要关闭它，可以使用<code>-XX:-TieredCompilation</code>关闭</p><h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><p>正常的话，只要理解到上面就够了，分层大概分为两层，先是C1，然后是C2。</p><p>但是事实上，我们如果查看以Tier开头的HotSpot参数的话，会发现其包含的参数很多很多</p><p><img src="/images/HotSpot原理指南-分层编译/参数.png" alt=""></p><p>笔者第一次搜索出来时，实在是吃了一惊。<br>经过研究，其实发现分层编译，并不是分了两层，而是足足分了<strong>4</strong>层。</p><ul><li>第0层：解释阶段</li><li>第1-3层：C1编译<ul><li>第1层：C1编译出的<strong>不收集任何Profile</strong>的机器码</li><li>第2层：C1编译出的<strong>仅仅收集方法调用计数</strong>的机器码</li><li>第3层：C1编译出的<strong>收集全部Profile</strong>的机器码</li></ul></li><li>第4层：C2编译</li></ul><p>可以看到，在C1编译的阶段，还拆分成了三个小的阶段。<br>同时，对于这三个小的阶段，需要理解的是，<strong>运行上并不是递进关系</strong>，也就是说并不是先运行第1层，再运行第2层，再运行第3层。具体怎么运行，其实和很多因素有关。<br>我们先看看有哪些经典的分层流程：</p><p><img src="/images/HotSpot原理指南-分层编译/4个阶段.png" alt=""><br>如上图所示。</p><ul><li>流程1：正常的方法的编译流程，先是解释执行，然后直接跳到第3阶段，也就是C1编译出的收集全部Profile的机器码。然后再跳到第4层，也就是C2编译。深色的框表示是编译的终止阶段。</li><li>流程2：但是，如果第3层的等待队列太长，可能就先提交到第2层进行编译，等待一段时间后，再提交给第3层</li><li>流程3：如果该方法比较简单，是个Trivial方法，比如Getter方法，这种方法去收集Profile其实没有什么Profile，给C2去进行编译纯属于浪费资源，所以提交给第3层后，直接给第1层，然后终止。</li><li>流程4：同样也是Trivial方法，如果在解释阶段就发现其比较简单，也可以直接提交给第1层编译</li></ul><p>以上是一些经典的流程，还有一些流程，比如从解释阶段可以直接提交给C2等。</p><p>所以，虽说是分层编译，但是具体的编译流程是不确定的，这个各个编译器的状态以及方法的属性有关。</p><h2 id="C1和C2编译线程数"><a href="#C1和C2编译线程数" class="headerlink" title="C1和C2编译线程数"></a>C1和C2编译线程数</h2><p>各个编译的状态，最简单的就是负责编译的线程数<br>HotSpot分配给C1和C2编译器的线程数，和<strong>指定的启动参数</strong>以及<strong>机器的核心数</strong>有关。</p><p>启动参数：影响线程数的参数有CICompilerCount和CICompilerCountPerCPU两个，默认值如下，一般不会去改这些<br><img src="/images/HotSpot原理指南-分层编译/启动参数.png" alt=""></p><p>有了参数之后，具体的分配代码如下：<br><img src="/images/HotSpot原理指南-分层编译/启动参数2.png" alt=""></p><p>简单聊聊分配策略：</p><ul><li>C1+C2的总的线程数：log2(log2(CoreNum)) * 3 / 2</li><li>C1 / C2 = 1 / 2</li><li>C1和C2至少有一个线程</li></ul><p>下面表格简单显示了一些常见情况</p><table><thead><tr><th>CPU Core</th><th>C1</th><th>C2</th></tr></thead><tbody><tr><td>4</td><td>1</td><td>2</td></tr><tr><td>8</td><td>1</td><td>3</td></tr><tr><td>16</td><td>4</td><td>8</td></tr><tr><td>32</td><td>5</td><td>10</td></tr><tr><td>64</td><td>6</td><td>12</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;HotSpot的初衷是将运行环境分为Client和Server，并且为他们定制了不同的JIT策略以及不同的JIT编译器（C1和C2）。&lt;/p&gt;
&lt;p&gt;设计出ClientMode的年代，个人PC的性能还比较低，无论是CPU资源还是内存资源都比较稀少且价格较高，所以C1节约资源的快速编译是很有必要的。&lt;/p&gt;
&lt;p&gt;随着时代的发展，个人计算机的配置在慢慢升级，同时价格也在慢慢降低，在这种环境下，ClientMode并不是那么适用了，所以HotSpot也就慢慢放弃了ClientMode，在个人计算机上默认采用Server模式。&lt;/p&gt;
    
    </summary>
    
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/categories/HotSpot/"/>
    
    
      <category term="Java" scheme="https://blog.lovezhy.cc/tags/Java/"/>
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/tags/HotSpot/"/>
    
      <category term="JVM" scheme="https://blog.lovezhy.cc/tags/JVM/"/>
    
      <category term="JIT" scheme="https://blog.lovezhy.cc/tags/JIT/"/>
    
  </entry>
  
  <entry>
    <title>HotSpot原理指南-JIT触发条件</title>
    <link href="https://blog.lovezhy.cc/2019/12/14/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-JIT%E8%A7%A6%E5%8F%91%E6%9D%A1%E4%BB%B6/"/>
    <id>https://blog.lovezhy.cc/2019/12/14/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-JIT%E8%A7%A6%E5%8F%91%E6%9D%A1%E4%BB%B6/</id>
    <published>2019-12-13T16:00:00.000Z</published>
    <updated>2020-02-29T14:36:09.667Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>通过前面我们知道，对于每个方法，HotSpot都维护两个计数器</p><ul><li>Invocation Counter：方法被调用次数，每被调用一次都会+1</li><li>BackEdge Counter：专业的说法就是字节码在执行时的回跳次数。通俗点说就是，在For或者While循环中，每执行一次，都会+1。</li></ul><p>并且我们知道对于一个方法，JIT有两种不同的编译方式</p><ul><li>完整的原方法编译，就是把原本的方法逻辑进行编译。入参和运行结果和解释运行都是一致的。</li><li>OSR编译，OSR后的方法入参以及运行流程和原方法有较大差异。</li></ul><p>很自然得我们就会想到，其实计数器和编译方式之间是有对应关系的。</p><ul><li>Invocation Counter -&gt; 完整的原方法编译</li><li>BackEdge Counter  -&gt; OSR编译</li></ul><p>当对应的方法计数器达到一定的次数，就会触发响应的编译</p><a id="more"></a><h2 id="编译流程图"><a href="#编译流程图" class="headerlink" title="编译流程图"></a>编译流程图</h2><p>完整的编译流程如下：</p><p><img src="/images/HotSpot原理指南-JIT触发条件/编译流程.png" alt=""></p><p><strong>注：该图引自R大的JVM分享PPT，如有侵权，请联系我删除</strong></p><p>图中的流程非常的清晰，这里提几个小点：</p><ul><li><p>问：对于同一方法，是否两种编译方式都可能会执行？</p><p>答：是的，而且两种代码可能同时被运行，但是正常情况下，只要运行的够久，都会运行完整的原方法编译后的代码。</p></li><li><p>问：具体哪种编译方式先触发？</p><p>答：其实无法确定，看哪个计数器先达到阈值</p></li></ul><h2 id="触发阈值"><a href="#触发阈值" class="headerlink" title="触发阈值"></a>触发阈值</h2><p>可能你还想更直观的了解下两个计数器的触发阈值到底是多少。</p><p>在HotSpot源码中，有这样两个参数：</p><ul><li><blockquote><p>intx CompileThreshold = 10000</p><p>globals.hpp &gt; ”number of interpreted method invocations before (re-)compiling” </p></blockquote></li><li><blockquote><p>intx BackEdgeThreshold = 100000</p><p>globals.hpp &gt; “Interpreter Back edge threshold at which an OSR compilation is invoked”</p></blockquote></li></ul><p>数值可能根据不同的发行版本略有不同，上面的数值是JDK7版本中的。</p><p>那么你可能以为</p><ul><li>当Invocation Counter &gt; Compile Threshold时，就会触发原来方法的JIT</li><li>当BackEdge Counter &gt; BackEdge Threshold时，就会触发方法的OSR编译</li></ul><p>但是事实并不是如此。</p><p>问题出在哪儿呢？难道官方的定义还会有错吗？</p><p>是的，问题出在BackEdgeThreshold上，虽然HotSpot中确实定义了该参数，描述中似乎也证实了该参数的作用，但是这个参数并没有实际使用过。</p><p>对于BackEdgeThreshold的计算，是另外一套公示。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (ProfileInterpreter) &#123;</span><br><span class="line">  InterpreterBackwardBranchLimit = </span><br><span class="line">                 (CompileThreshold * (OnStackReplacePercentage - InterpreterProfilePercentage)) / <span class="number">100</span>;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  InterpreterBackwardBranchLimit = </span><br><span class="line">                ((CompileThreshold * OnStackReplacePercentage) / <span class="number">100</span>) &lt;&lt; number_of_noncount_bits;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>首先解释下<code>ProfileInterpreter</code>参数，这个参数也是在HotSpot中定义的，之前在文章<code>HotSpot原理指南-C1和C2介绍</code>中也讲解过，就是是否在运行时收集方法的Profile信息，这个字段在Server模式默认是开启的。</p><p>所以大部分情况下，除非你的计算机比较老，都会根据第一个公示进行计算</p><p><code>(CompileThreshold * (OnStackReplacePercentage - InterpreterProfilePercentage)) / 100</code></p><p>其中<strong>OnStackReplacePercentage</strong>默认值是140，<strong>InterpreterProfilePercentage</strong>默认值是33。</p><p>由此我们可以计算出真实的BackEdge Invocation阈值大概是10700左右。</p><h2 id="衰减"><a href="#衰减" class="headerlink" title="衰减"></a>衰减</h2><p>假如方法计数器不会根据时间进行衰减的话，那么只要服务器运行的时间足够长，再罕见被调用的函数，也会触发到阈值，然后被JIT编译。</p><p>这显然是不合理的，因为我们知道JIT后的机器码数据，还是会保存在内存中的，这样相当于一段逻辑在内存中又保存了字节码，又保存了一份机器码，十分的浪费内存。</p><p>所以对于Invocation Counter而言，经过一段时间，个数就会进行减少。</p><p>具体的减少逻辑，读者有兴趣的可以自己去探索。</p><p>但是注意：对于BackEdge Counter，是不会作衰减的。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;通过前面我们知道，对于每个方法，HotSpot都维护两个计数器&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Invocation Counter：方法被调用次数，每被调用一次都会+1&lt;/li&gt;
&lt;li&gt;BackEdge Counter：专业的说法就是字节码在执行时的回跳次数。通俗点说就是，在For或者While循环中，每执行一次，都会+1。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;并且我们知道对于一个方法，JIT有两种不同的编译方式&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;完整的原方法编译，就是把原本的方法逻辑进行编译。入参和运行结果和解释运行都是一致的。&lt;/li&gt;
&lt;li&gt;OSR编译，OSR后的方法入参以及运行流程和原方法有较大差异。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;很自然得我们就会想到，其实计数器和编译方式之间是有对应关系的。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Invocation Counter -&amp;gt; 完整的原方法编译&lt;/li&gt;
&lt;li&gt;BackEdge Counter  -&amp;gt; OSR编译&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当对应的方法计数器达到一定的次数，就会触发响应的编译&lt;/p&gt;
    
    </summary>
    
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/categories/HotSpot/"/>
    
    
      <category term="Java" scheme="https://blog.lovezhy.cc/tags/Java/"/>
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/tags/HotSpot/"/>
    
      <category term="JIT" scheme="https://blog.lovezhy.cc/tags/JIT/"/>
    
  </entry>
  
  <entry>
    <title>银行报考指北</title>
    <link href="https://blog.lovezhy.cc/2019/11/30/%E9%93%B6%E8%A1%8C%E6%8A%A5%E8%80%83%E6%8C%87%E5%8C%97/"/>
    <id>https://blog.lovezhy.cc/2019/11/30/%E9%93%B6%E8%A1%8C%E6%8A%A5%E8%80%83%E6%8C%87%E5%8C%97/</id>
    <published>2019-11-29T16:00:00.000Z</published>
    <updated>2020-02-29T14:44:02.280Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>看到标题，你可能会疑问，为什么我会去报考银行，我不是在互联网公司上班吗？难道是想逃离互联网回家养老去了？</p><a id="more"></a><p>当然，这个是个多因一果的事情。我确实报考了银行，并且顺利拿到了Offer。但是我并不是想逃离互联网，而是一次尝试，很大程度上只是去看看，顺便敷衍一下我妈。</p><p>当我说到敷衍我妈时，其实我比较伤心的，因为我妈一直觉得做技术太苦了，天天加班，不仅压力大，而且到了35岁会面临辞退的危险，所以希望我回家安安稳稳的过日子。</p><p>讲道理，我也有这种疑虑，但是目前并没有回家养老的意思，所以还是会继续留在南京上班。</p><p>扯了一堆，这次报考流程也算是踩了一次坑，这里记录下来，留给后人参考。</p><h2 id="报名"><a href="#报名" class="headerlink" title="报名"></a>报名</h2><p>一般我不会关注银行的招聘的，但是消息是我妈发给我的</p><p><a href="http://www.yinhangzhaopin.com/yzrcb/2019/0929/85386.html" target="_blank" rel="noopener">http://www.yinhangzhaopin.com/yzrcb/2019/0929/85386.html</a></p><p>后来我才发现原来有个网站专门就是收集各种银行招聘的信息。</p><p>报名在51Job上报名，上去填写一些资料就行了。</p><p>然后它会审核你的资料，算是一个初审，初审过了之后，会再发一封邮件给你告诉你初审过了，可以去缴费了。</p><p><img src="/images/银行报考指北/资料审核通过.png" alt=""></p><p>但是这个缴费网站，要到一定时间才会开通。</p><p>等到开通之后，登录到这个网站，付报名费，大概100块左右，然后选择考场。</p><p>这个考场并不是你报哪儿就必须去哪儿考试的。</p><p>比如我在南京，但是我报的是扬州的农商行，并不是一定要去扬州考试。他在每个城市都会有考点的。</p><p>在南京有4个考点，我记得有林业大学考点，金陵科技学院考点，还有两个记不得了。</p><p>我报的是金陵科技学院的考点。</p><p>好消息就是它考试是在周末考，这样如果是上学或者是上班的话，就不用请假了。</p><p>交完费之后，它还会给你一封邮件，让你准备笔试。</p><p><img src="/images/银行报考指北/笔试通知.png" alt=""></p><h2 id="考试"><a href="#考试" class="headerlink" title="考试"></a>考试</h2><p>周末那一天考试是从9：00到11：30。时间还是挺长的。</p><p>准考证需要提前打印好，然后考试带自己身份证就行了。也可以带一支笔，因为题目可能有数学题。</p><p>写到这个章节，你可能最想知道的是考试考什么题目。</p><p>题目其实是分岗位的，通用岗的我不是很清楚，我报的是科技岗，而且可能各个银行之间又不太一样。</p><p>首先题量很大。题型主要分为：</p><ul><li>找病句</li><li>句子排序</li><li>数学题。比如一排数字，让你找规律那种，那种题基本看一会儿看不出来就过吧</li><li>图形题。和公务员那种差不多，给三个奇怪的组合图形，然后让你选下一个和他们属性一致的图形是什么，这个看一会儿看不出来也过吧</li><li><p>材料题。给一些数据的图标，然后给4个选择题，让你从图标中找答案。还挺难找的。题量少。</p></li><li><p>英语题，缺词填空那种。大概有20道</p></li><li>计算机专业的题目。设计网络，操作系统，Java等。大概有80题。</li><li>考验智商的。比如给你个矩阵，会随机出现几个图形，5秒后消失，然后让你点击刚才出现的图形的位置。</li></ul><p>总而言之，有几点值得关注</p><ul><li>题量大。如果每道题都细做肯定来不及的，有点数学题不会就直接瞎选的。</li><li>不需要专业知识。我考之前有人和我说要很多经济学知识的，其实发现并不需要。</li></ul><p>我当时高估了自己，再加上其实去的意愿不高，做了一个半小时就赶紧溜了去上班了。</p><p>大概百分之60的题目，我都是瞎选的。</p><h2 id="面试"><a href="#面试" class="headerlink" title="面试"></a>面试</h2><p>其实我笔试考完觉得自己肯定挂了，但是过了两天打电话告诉我过了。</p><p>过了就过了吧，大概就是通知我去面试了。</p><p>让我周六去扬州交材料，周日面试。</p><p>我正好有朋友在扬州，所以就打算去顺便找他玩一下。</p><p>交材料的话，需要毕业证的复印件。身份证的正反面复印件，学信网的电子备案表的打印件。</p><p>周六去交了材料，顺便问了我的成绩。</p><p>傍晚的时候发短信通知我明天中午去面试。</p><p>我中午到的时候，发现大家都是穿正装来的，就我穿的花里胡哨的。心想大概率是凉了。</p><p>哈哈，所以这里提醒大家最好穿正装去面试，没有正装也穿个黑色的衣服去。</p><p>然后就是签到。</p><p>到了时间又让我们做了一个半小时的题目，题目大概和笔试的差不多，不知道这个是什么套路。</p><p>这个题目并不包括计算机的题目，我估计通用的和科技岗的都一样。</p><p>做完题目，需要把手机交上去，然后排队去面试。</p><p>流程是这样的，一个一个进去面试，当一个人进去时，后面一个人去等候区，等候区就一个人，有张桌子，上面有张纸，记着三个题目，有人给你计时4分钟，你看完题目想想怎么回答。</p><p>然后前一个出来时，你进去，然后对面三个面试官，面试官不会多对你说什么，你就把三个问题的答案说一遍就行。每个题目计时2分钟，说完也没有其他的问题，你就可以直接走了。</p><p>具体的题目其实和计算机的关系不大，属于需要总结概括的题目，需要的话可能私聊我。</p><p>面完就直接回去了，也没管什么。</p><h2 id="体检"><a href="#体检" class="headerlink" title="体检"></a>体检</h2><p>其实我面完之后感觉自己肯定差不多挂了，下面应该没后续流程了。</p><p>然后过了两天，大概是周二的时候，银行打电话告诉我过了面试。</p><p>下面的流程是体检，而且就在明天，银行的人问我能不能去。</p><p>我一想这也太突然了，我今天就得再去扬州，这也不太可能啊，所以我直接拒绝了。</p><p>以为这个机会就没了，但是她告诉我明天不去，那就等下一批的通知吧。</p><p>感情原来体检还是分批来的，我说好的。</p><p>其实我比较奇怪的地方是为什么直接去体检了，而不是先谈工资待遇啥的，这是明摆着面试通过了大家就肯定先去吗？</p><p>然后我问了在银行工作的同学，似乎他们都是这样的，都不知道具体的待遇什么的，都是上了一个月的班才知道具体的工资是多少。</p><p>这就有点坑了。</p><p>我回去也和我爸妈商量了下，我说我其实不太想回去。我爸妈也表示明白。</p><p>然后下一次打电话来的时候，我就直接拒绝了。</p><p>我以为银行的人会问问为什么，结果她直接说好的。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这次的银行面试经历就是如上了，我顺利的度过了笔试和面试，中间决定不去了。</p><p>整体上的体验一般般，流程拉的太长了，而且面试和体检都是在固定的地方，所以导致体验不会太好。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;看到标题，你可能会疑问，为什么我会去报考银行，我不是在互联网公司上班吗？难道是想逃离互联网回家养老去了？&lt;/p&gt;
    
    </summary>
    
    
      <category term="我的生活" scheme="https://blog.lovezhy.cc/categories/%E6%88%91%E7%9A%84%E7%94%9F%E6%B4%BB/"/>
    
    
      <category term="生活" scheme="https://blog.lovezhy.cc/tags/%E7%94%9F%E6%B4%BB/"/>
    
  </entry>
  
  <entry>
    <title>HotSpot原理指南-OSR是什么</title>
    <link href="https://blog.lovezhy.cc/2019/11/30/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-OSR%E6%98%AF%E4%BB%80%E4%B9%88/"/>
    <id>https://blog.lovezhy.cc/2019/11/30/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-OSR%E6%98%AF%E4%BB%80%E4%B9%88/</id>
    <published>2019-11-29T16:00:00.000Z</published>
    <updated>2020-02-29T14:36:16.869Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>前面我们讲解了C1和C2的基本知识，但是我们还未触及一个核心的策略，就是<strong>什么时候触发即使编译</strong>，也就是<strong>when</strong>的问题。</p><p>对于when的问题，相信大家多多少少都大概知道，每个方法都会有一个调用次数的计数器，当这个计数器的次数到达一定的次数时，就会被认为是热点方法，继而触发JIT编译。</p><p>但是本文要科普另外一种触发条件，和方法计数器类似。</p><a id="more"></a><h2 id="方法计数器的问题"><a href="#方法计数器的问题" class="headerlink" title="方法计数器的问题"></a>方法计数器的问题</h2><p>大部分人看来，维护一个方法被调用次数计数器当然是一个很完美的方案</p><p>但是有一类方法，即使在我们认知范围内，属于热点方法，但是却无法享受到这个计数器的好处。</p><p>如下代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OSRExample</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">200000</span>; i++) &#123;</span><br><span class="line">            <span class="comment">//do a lot of things</span></span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(sum);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在Main函数中，有一个循环，在循环中并没有调用某个方法，而是一直在线性执行一些逻辑。</p><p>假如我们把循环中的逻辑看做一个函数，这个函数肯定是热点函数，需要进行JIT编译的，但是在这种场景下，并不是一个函数，也就是无法进行JIT。</p><p>如果JIT无法处理这种情况，将是非常可惜的。</p><h2 id="Hot-Loop优化"><a href="#Hot-Loop优化" class="headerlink" title="Hot Loop优化"></a>Hot Loop优化</h2><p>但是如果我们构造一个上面的代码的情况，并且使用计数器给每次循环的执行时间进行计时。</p><p>会发现下面这张时间和次数的图</p><p><img src="/images/HotSpot原理指南-OSR是什么/hotLoop耗时.png" alt=""></p><p>从图中我们可以看出，大概在150次的时候，整个Loop的耗时突发的大大降低。</p><p>说明在HotSpot的JIT中，是可以处理这种情况的。</p><p>那么HotSpot究竟是怎么做的呢？</p><p>前面我们提到过，如果在Loop中调用的是方法，将不会存在上述的问题，但是实际的情况并不是调用的方法。</p><p>那么，我们能不能，把它包装成一个函数呢？</p><p>举个例子，原方法如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OSRExample</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">20000</span>; i++) &#123;</span><br><span class="line">            sum += i;</span><br><span class="line">          sum *= sum;</span><br><span class="line">          sum |= sum;</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(sum);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们把它改成如下的方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OSRExample</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">20000</span>; i++) &#123;</span><br><span class="line">sum = doLoop(sum);</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(sum);</span><br><span class="line">    &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">doLoop</span><span class="params">(<span class="keyword">int</span> sum)</span> </span>&#123;</span><br><span class="line">      sum += i;</span><br><span class="line">      sum *= sum;</span><br><span class="line">      sum |= sum;</span><br><span class="line">      <span class="keyword">return</span> sum;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样可以不可以呢？</p><p>当然是可以的。</p><p>但是！这是作者的猜测，HotSpot真实的情况并不是这样。</p><p>事实上，这种割裂整个main方法，动态把一部分代码进行修改的操作似乎消耗太大了，性价比并不高。</p><p>HotSpot并不会把Loop的内容动态生成一个函数，然后对该函数进行JIT。</p><p>而是对包含这个Loop的<strong>整个方法进行了JIT</strong>。</p><p>什么？对整个方法进行JIT？</p><p>要知道，这个方法在运行中啊，可能再也不会运行第二次，对整个方法进行JIT有什么意义呢？</p><p>稍安勿躁，虽然对整个方法进行了JIT，但是JIT后的代码和原来的函数其实还是有区别的。</p><p>如果我们需要将运行到一半的函数，从一个源代码替换到另外一个源代码，遇到的问题是什么呢？</p><p>首先，这个方法的循环执行到一半，这个i的具体数值肯定不是0了，是一个不可预测的值。</p><p>同时这个sum的值，肯定也是一个不好预测的值。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">20000</span>; i++) &#123;</span><br><span class="line">sum = doLoop(sum);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果要进行替换，需要把替换时的i和sum的值记录下来，那么替换后的源代码大概就长这样</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">public static void main#jit(int i, int sum) &#123;</span><br><span class="line"><span class="keyword">for</span> (; i &lt; <span class="number">20000</span>; i++) &#123;</span><br><span class="line">        sum += i;</span><br><span class="line">      sum *= sum;</span><br><span class="line">      sum |= sum;</span><br><span class="line">    &#125;</span><br><span class="line">    System.out.println(sum);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>没错！把运行中动态的值作为参数传给JIT后的函数，就是HotSpot的JIT对于这种HotLoop的优化。</p><h2 id="OSR"><a href="#OSR" class="headerlink" title="OSR"></a>OSR</h2><p>OSR的全称是On-Stack-Replacement。也就是栈上替换。</p><p>从上一节我们了解的可以知道，对于main函数，JIT进行编译的时候，直接把运行中的main函数源代码进行了替换，替换成了修改后的main函数。那么之前的main函数栈帧其实就完全失效了，被替换成了新的函数的栈帧。</p><p>这种JIT编译的方式就叫OSR编译。</p><p>这种栈上替换的方式其实并不是HotSpot独有的，很多其他的语言中也有这样的优化，如V8。</p><h2 id="后续问题"><a href="#后续问题" class="headerlink" title="后续问题"></a>后续问题</h2><p>OSR能够解决HotLoop的优化问题，但是其实在HotSpot中还是有几个值得深究的点。</p><ol><li><p>如果这个main函数方法非常大，Loop只是很小的一部分，那么把整个函数进行JIT编译的性价比就值得商榷了。核心问题其实是，为什么必须要编译整个方法呢？</p><p>这个问题R大也给了我们解释，详细看文章</p><p><a href="https://github.com/AdoptOpenJDK/jitwatch/wiki/Understanding-the-On-Stack-Replacement-(OSR)-optimisation-in-the-HotSpot-C1-compiler" target="_blank" rel="noopener">https://github.com/AdoptOpenJDK/jitwatch/wiki/Understanding-the-On-Stack-Replacement-(OSR)-optimisation-in-the-HotSpot-C1-compiler</a></p></li><li><p>OSR其实并不是完美的解决方案，在某些场景下它会生成非常丑陋的代码，如果有多个Loop或者Loop进行嵌套的方法。</p><p>HotSpot在一篇文章中进行了解释，有兴趣可以看文章</p><p><a href="https://www.h2o.ai/blog/what-the-heck-is-osr-and-why-is-it-bad-or-good/" target="_blank" rel="noopener">What ths heck is osr and why is it bad or good?</a></p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;前面我们讲解了C1和C2的基本知识，但是我们还未触及一个核心的策略，就是&lt;strong&gt;什么时候触发即使编译&lt;/strong&gt;，也就是&lt;strong&gt;when&lt;/strong&gt;的问题。&lt;/p&gt;
&lt;p&gt;对于when的问题，相信大家多多少少都大概知道，每个方法都会有一个调用次数的计数器，当这个计数器的次数到达一定的次数时，就会被认为是热点方法，继而触发JIT编译。&lt;/p&gt;
&lt;p&gt;但是本文要科普另外一种触发条件，和方法计数器类似。&lt;/p&gt;
    
    </summary>
    
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/categories/HotSpot/"/>
    
    
      <category term="Java" scheme="https://blog.lovezhy.cc/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>HotSpot原理指南-内联</title>
    <link href="https://blog.lovezhy.cc/2019/11/28/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-%E5%86%85%E8%81%94/"/>
    <id>https://blog.lovezhy.cc/2019/11/28/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-%E5%86%85%E8%81%94/</id>
    <published>2019-11-27T16:00:00.000Z</published>
    <updated>2020-02-29T14:36:23.516Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>内联是编程语言编译器中常规的优化操作，几乎所有的语言在编译时或者在执行时都会有内联操作。</p><p>内联的本质是把几个方法合并成一个方法</p><p>从一方面讲，内联减少了函数调用的栈帧创建和销毁的时间消耗</p><p>从另一方面讲，内联为很多其他的优化方法提供了更多的可能，比如逃逸分析，无用代码消除，虚函数优化等，这也是内联被叫做<strong>优化之母</strong>（The Mother Of All Optimization）的原因。</p><a id="more"></a><h2 id="HotSpot-JIT"><a href="#HotSpot-JIT" class="headerlink" title="HotSpot-JIT"></a>HotSpot-JIT</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>对于HotSpot的JIT而言，内联是一个渐进的过程，这个渐进表现在两方面</p><ul><li>C1和C2两个JIT编译器的内联策略不同，C2可能更加激进一些</li><li>内联策略和很多因素有关<ul><li>内联发起函数大小，被内联函数大小</li><li>被内联函数的调用次数</li><li>内联深度</li><li>中间表示的NodeCount</li><li>函数方法签名</li></ul></li></ul><h3 id="初步体验"><a href="#初步体验" class="headerlink" title="初步体验"></a>初步体验</h3><p>先看一段代码，初步的了解下HotSpot的内联，以下代码的执行参数<code>-XX:CompileCommand=exclude,Inline.main</code></p><p>这个参数的意义是禁止<code>main</code>函数内联<code>inline</code>方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Inline</span> </span>&#123;</span><br><span class="line">  </span><br><span class="line"><span class="keyword">static</span> Random random = <span class="keyword">new</span> Random();</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span> ; i &lt; <span class="number">1000000</span>; i++) &#123;</span><br><span class="line">            inline();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">inline</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> add(random.nextInt(), </span><br><span class="line">               random.nextInt());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> a, <span class="keyword">int</span> b)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> a + b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="/images/HotSpot原理指南-内联/inline.png" alt="inline"></p><p>上图中展示了经过C2编译后，整个<code>inline</code>函数的内联状态</p><p>可以看到不仅仅内联了<code>random.nextInt()</code>方法，还将<code>nextInt</code>方法中的<code>next</code>方法等等好几个再下层的方法也内联了进来</p><h3 id="HotSpot参数"><a href="#HotSpot参数" class="headerlink" title="HotSpot参数"></a>HotSpot参数</h3><p><code>java -XX:+PrintFlagsFinal | grep &quot;Inlin&quot;</code></p><p><img src="/images/HotSpot原理指南-内联/内联参数.png" alt="内联参数"></p><p>可以看到HotSpot可以控制内联的参数很多很多，从侧面也表示HotSpot的内联策略是非常复杂的。</p><p>笔者也无法精通所有的内联策略，所以只挑选出比较重要的几个参数来讲解。</p><p>主要讲解如下几个参数</p><table><thead><tr><th>参数</th><th>默认值</th></tr></thead><tbody><tr><td>MaxTrivialSize</td><td>6</td></tr><tr><td>MaxInlineSize</td><td>35</td></tr><tr><td>FreqInlineSize</td><td>350</td></tr><tr><td>MinInliningThreshold</td><td>250</td></tr><tr><td>InlineSmallCode</td><td>1000(No-Tier)  2000(Tier)</td></tr><tr><td>MaxInlineLevel</td><td>9</td></tr><tr><td>MaxRecursiveInlineLevel</td><td>1</td></tr></tbody></table><h2 id="内联策略"><a href="#内联策略" class="headerlink" title="内联策略"></a>内联策略</h2><h3 id="MaxTrivialSize"><a href="#MaxTrivialSize" class="headerlink" title="MaxTrivialSize"></a>MaxTrivialSize</h3><p>对于Trivial方法，在HotSpot中有着严格的定义</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">bool</span> SimpleThresholdPolicy::is_trivial(Method* method) &#123;</span><br><span class="line">  <span class="keyword">if</span> (method-&gt;is_accessor() ||</span><br><span class="line">      method-&gt;is_constant_getter()) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (method-&gt;has_loops() || method-&gt;code_size() &gt;= <span class="number">15</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  MethodData* mdo = method-&gt;method_data();</span><br><span class="line">  <span class="keyword">if</span> (mdo != <span class="literal">NULL</span> &amp;&amp; !mdo-&gt;would_profile() &amp;&amp;</span><br><span class="line">      (method-&gt;code_size() &lt; <span class="number">5</span>  || (mdo-&gt;num_blocks() &lt; <span class="number">4</span>))) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从上面的代码可以看出，常见的Getter方法，肯定是trivial方法</p><p>而函数中有循环，或者函数大小超过15bytes，则不是trivial方法</p><p>对于trivial方法，如果它的函数字节码小于<strong>MaxTrivialSize</strong>，那么即使它在调用方至今一次也没有被执行过，HotSpot也会将它内联进来。</p><p>这是对于C1而言，对于C2而言，则不会进行内联，而是会生成<code>UnCommon Trap</code></p><h3 id="MaxInlineSize"><a href="#MaxInlineSize" class="headerlink" title="MaxInlineSize"></a>MaxInlineSize</h3><p>我们了解了MaxTrivialSize，那么对于MaxInlineSize则很容易理解。</p><p>对于调用方至少执行过一次的方法，如果它的大小小于MaxInlineSize，那么就会考虑将它内联进去</p><h3 id="FreqInlineSize和MinInliningThreshold"><a href="#FreqInlineSize和MinInliningThreshold" class="headerlink" title="FreqInlineSize和MinInliningThreshold"></a>FreqInlineSize和MinInliningThreshold</h3><p>了解了以上两个参数后，你可能会问，如果被调用的函数既不符合Trivial方法，大小也大于MaxInlineSize，但是这个方法非常的Hot，就没有机会被内联了吗</p><p>并不是，FreqInlineSize和MinInliningThreshold这两个参数就是为这种方法设置的。</p><p>当一个方法既不是Trivial方法，而且大于MaxInlineSize，如果他的调用次数大于MinInliningThreshold，也就是250次，且它的大小小于FreqInlineSize，那么它也会被内联</p><h3 id="InlineSmallCode"><a href="#InlineSmallCode" class="headerlink" title="InlineSmallCode"></a>InlineSmallCode</h3><p>我们知道，调用方进行方法内联的时候，函数本身的大小会越来越大。</p><p>这时候你又会问了，那调用方内联可以无限内联吗，内联后的大小肯定会有限制的吧。</p><p>对的！InlineSmallCode就是限制的大小</p><p>如果是非分层编译的环境，阈值是1000bytes</p><p>如果是分层编译的环境，那么阈值是2000bytes</p><h3 id="MaxInlineLevel"><a href="#MaxInlineLevel" class="headerlink" title="MaxInlineLevel"></a>MaxInlineLevel</h3><p>对于一个函数进行其他函数的内联，除了内联后的大小限制，内联的深度也是有限制的。</p><p>在HotSpot中，默认的内联最大深度是MaxInlineLevel控制，也就是9层。</p><p>为什么要限制内联的最大深度呢？</p><p>在stackoverflow上有个我认为比较中肯的答案</p><p><a href="https://stackoverflow.com/questions/32503669/why-does-the-jvm-have-a-maximum-inline-depth" target="_blank" rel="noopener">Why does the JVM have a maximum inline depth?</a></p><blockquote><p>Not exactly, but I guess the basic reason is to keep things simple. Unlimited inlining depth would increase complexity, the compilation time and memory usage might be less predictable (that is OK for AOT compilers, but not for JIT). Also mind that compiled code should keep track of the whole inlining tree at run-time (to be able to unwind and deoptimize). Though I think the default value of 9 is outdated. It has not been changed for ages, but nowadays, with much more resources available, with streams and lamdas in mind, there is definitely a place for improvement</p></blockquote><p>总结一下答案：</p><ul><li>为了保持内联的简单性。无限制的内联会增加复杂度。</li><li>内联后的编译代码，需要记录整个内联树。</li><li>编译时间和内存消耗会变得不可预测。</li></ul><p>当然，作者也认为默认值9已经很久没有改动了，随着计算机资源变得不再那么昂贵，完全可以适当调大这个值。</p><h3 id="MaxRecursiveInlineLevel"><a href="#MaxRecursiveInlineLevel" class="headerlink" title="MaxRecursiveInlineLevel"></a>MaxRecursiveInlineLevel</h3><p>对于递归的方法，它内联自己最多只能内联MaxRecursiveInlineLevel层，也就是1次。</p><h2 id="查看内联结果"><a href="#查看内联结果" class="headerlink" title="查看内联结果"></a>查看内联结果</h2><p>如果想要知道我们的代码在编译时，内联了哪些方法，那么可以加上参数</p><p><code>java -XX:+UnlockDiagnosticVMOptions -XX:+PrintInlining</code></p><p>对于上面的inline.java的结果输出如下</p><p><img src="/images/HotSpot原理指南-内联/内联输出结果.png" alt="内联输出结果"></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;内联是编程语言编译器中常规的优化操作，几乎所有的语言在编译时或者在执行时都会有内联操作。&lt;/p&gt;
&lt;p&gt;内联的本质是把几个方法合并成一个方法&lt;/p&gt;
&lt;p&gt;从一方面讲，内联减少了函数调用的栈帧创建和销毁的时间消耗&lt;/p&gt;
&lt;p&gt;从另一方面讲，内联为很多其他的优化方法提供了更多的可能，比如逃逸分析，无用代码消除，虚函数优化等，这也是内联被叫做&lt;strong&gt;优化之母&lt;/strong&gt;（The Mother Of All Optimization）的原因。&lt;/p&gt;
    
    </summary>
    
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/categories/HotSpot/"/>
    
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/tags/HotSpot/"/>
    
      <category term="JVM" scheme="https://blog.lovezhy.cc/tags/JVM/"/>
    
      <category term="内联" scheme="https://blog.lovezhy.cc/tags/%E5%86%85%E8%81%94/"/>
    
  </entry>
  
  <entry>
    <title>HotSpot原理指南-C1和C2编译流程</title>
    <link href="https://blog.lovezhy.cc/2019/11/27/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-C1%E5%92%8CC2%E7%BC%96%E8%AF%91%E6%B5%81%E7%A8%8B/"/>
    <id>https://blog.lovezhy.cc/2019/11/27/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-C1%E5%92%8CC2%E7%BC%96%E8%AF%91%E6%B5%81%E7%A8%8B/</id>
    <published>2019-11-26T16:00:00.000Z</published>
    <updated>2020-02-29T14:36:21.235Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>前文讲述了C1和C2的功能定位，以及引出了Client和Server模式的区别。</p><p>这回抛开功能和定位的角度，简单看看从设计与实现角度的区别。</p><a id="more"></a><h2 id="前导知识"><a href="#前导知识" class="headerlink" title="前导知识"></a>前导知识</h2><p>要讲解设计与实现角度的区别，需要了解很多的编译原理知识。</p><p>😄编译原理是科班必学的一门课，当时作者上的迷迷糊糊的，觉得没什么用，也没怎么听。</p><p>现在看到C1和C2的东西，真的是一筹莫展。</p><p>相信很多科班和非科班的人也是。</p><p>不过大家不用担心，作者水平有限，更是不会瞎写自己根本不会的东西，所以涉及到编译原理的东西讲的都很简单。</p><h3 id="IR"><a href="#IR" class="headerlink" title="IR"></a>IR</h3><p>IR，中文中间表示，全称是intermediate representation。</p><p>其实它和中间语言的定义类似，但是中间语言的定义更加狭义，只规定必须是某种语言，而中间表示则扩宽了范围，可以是树类型或者是图类型的表示。</p><p>在维基百科上，中间语言的定义是</p><blockquote><p><strong>中间语言</strong>（英语：Intermediate language），在计算机科学中，是指一种应用于抽象机器（abstract machine）的编程语言，它设计的目的，是用来帮助我们分析计算机程序。这个术语源自于编译器，在编译器将源代码编译为目的码的过程中，会先将源代码转换为一个或多个的中间表述，以方便编译器进行最佳化，并产生出目的机器的机器语言</p></blockquote><p>其实更简单的定义，我觉得就是源代码的另一种表达形式。</p><p>比如Java代码，会被编译成字节码，字节码也是一种IR，是Java代码的中间表示。</p><p>IR在编译原理中的作用个人理解其实起到两种：</p><ul><li>统一后端语言。比如JRuby，Scala，Kotlin等，他们的解释器其实都是JVM。但是他们的源代码都是不一样的。倘若对于每种语言的处理都是不一样的，那其实JVM的实现就没什么意义了，所以将所有语言的源代码都编译成同一种IR，然后JVM不用关心源语言是什么，只要符合该IR定义的都可以执行。</li><li>方便优化。很多的优化技术，其实人眼可以简单看出的，很难归一化到程序去理解。但是通过一些IR的表示，使用特定的规则，就可以进行优化。就行我们在拼魔方时的公式一样。那为什么有这么多种IR呢，很大一个程度的区别就是他们在解决一些特定优化时各有优势。比如SSA在进行复制传播时就很方便。</li></ul><h3 id="寄存器分配"><a href="#寄存器分配" class="headerlink" title="寄存器分配"></a>寄存器分配</h3><p>一个解释器执行的程序和以机器码执行的程序的一个很大的区别就是对于系统寄存器的使用。</p><p>比如对于下面的函数</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> i, <span class="keyword">int</span> j)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> k = i + j;</span><br><span class="line">    k += <span class="number">2</span>;</span><br><span class="line">    k *= <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">return</span> i + j;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果是以解释的形式而言，则需要把k存在内存的变量中，然后再进行运算，每一步的运算都要把k的值写回到内存中。</p><p>但是如果是C++的话，完全可以给k分配一个寄存器，把k放到寄存器中，然后直接对寄存器中的值进行运算就行。</p><p>所以，如果能够很好的利用系统现有的寄存器，那么程序执行的性能将提升一个档次。</p><p>对于寄存器的分配算法，有很多论文可以参考，作者水平有限，还没能学会一种。</p><p>读者有兴趣可以自己去搜索相关论文进行了解。</p><h2 id="C1流程"><a href="#C1流程" class="headerlink" title="C1流程"></a>C1流程</h2><p><img src="/images/HotSpot原理指南-C1和C2流程/C1流程.png" alt=""></p><p>C1的流程较为简单，如上图所示。</p><p>首先，字节码会经过转换，变成HIR，也就是High Level的IR，高级中间表示。</p><p>在HIR中，会进行一些优化，比如</p><ul><li>GVN优化</li><li>基本块优化</li><li>null检查消除</li><li>…</li></ul><p>经过HIR优化之后，转换成LIR，也就是Low-Level的IR，低级中间表示。</p><p>这个阶段的IR其实已经很接近机器码了</p><p>在LIR时，进行</p><ul><li>寄存器分配。这里的寄存器分配算法是线性扫描，时间消耗短，但是分配效果有限</li><li>窥孔优化</li></ul><p>在LIR的优化过后，就是机器码的生成。</p><p>对于C1的更详细的流程，笔者也从网上找到了当时作者的一个PPT，有兴趣的可以自行下载</p><p><a href="http://compilers.cs.uni-saarland.de/ssasem/talks/Christian.Wimmer.pdf" target="_blank" rel="noopener">http://compilers.cs.uni-saarland.de/ssasem/talks/Christian.Wimmer.pdf</a></p><p>同时，如果有人对线性扫描寄存器分配算法有兴趣，也可以参照论文</p><p><a href="http://web.cs.ucla.edu/~palsberg/course/cs132/linearscan.pdf" target="_blank" rel="noopener">http://web.cs.ucla.edu/~palsberg/course/cs132/linearscan.pdf</a></p><h2 id="C2流程"><a href="#C2流程" class="headerlink" title="C2流程"></a>C2流程</h2><p>通过前面我们已经知道C2相对于C1编译过程，更加的耗时，这个耗时可以体现在两方面</p><ul><li>比C1有更多的优化</li><li>同一种优化使用的算法不同，C2的结果更好</li></ul><p>对于C2而言，它的IR只有一种，叫<code>Sea Of Nodes</code></p><p>就笔者了解到的知识来看，这个IR非常的牛逼，在V8引擎中，也是使用的这种IR。</p><p>不过这种IR的资料似乎非常少，笔者也仅仅是搜到了论文，没什么更深层次的讲解。</p><p>如果有人想要了解Sea Of Nodes的原理，那么大家可以从网上搜集资料来看。</p><p><strong>比C1拥有更多的优化</strong></p><p>相比较于C1，C2几乎会做所有的经典优化。如下图所示</p><p><img src="/images/HotSpot原理指南-C1和C2流程/C2优化.png" alt=""></p><p><strong>同一种优化使用不同的算法</strong></p><p>这个体现在寄存器分配算法上，我们知道对于C1而言，使用的较为简单的线性扫描的分配算法，执行较快。</p><p>而C2使用了叫图染色的算法，消耗的时间更久，但是产生的解法比线性扫描更优。</p><p>对于图染色算法，在经典的编译原理书中都有解答。</p><p>笔者这里就不赘述了（其实是笔者也没看懂）</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;前文讲述了C1和C2的功能定位，以及引出了Client和Server模式的区别。&lt;/p&gt;
&lt;p&gt;这回抛开功能和定位的角度，简单看看从设计与实现角度的区别。&lt;/p&gt;
    
    </summary>
    
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/categories/HotSpot/"/>
    
    
      <category term="Java" scheme="https://blog.lovezhy.cc/tags/Java/"/>
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/tags/HotSpot/"/>
    
      <category term="JVM" scheme="https://blog.lovezhy.cc/tags/JVM/"/>
    
      <category term="C1和C2" scheme="https://blog.lovezhy.cc/tags/C1%E5%92%8CC2/"/>
    
  </entry>
  
  <entry>
    <title>HotSpot原理指南-C1和C2介绍</title>
    <link href="https://blog.lovezhy.cc/2019/11/24/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-C1%E5%92%8CC2%E4%BB%8B%E7%BB%8D/"/>
    <id>https://blog.lovezhy.cc/2019/11/24/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-C1%E5%92%8CC2%E4%BB%8B%E7%BB%8D/</id>
    <published>2019-11-23T16:00:00.000Z</published>
    <updated>2020-02-29T14:36:19.131Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>HotSpot是一款Java虚拟机的实现，除了基本的解释功能以外，该虚拟机还拥有将字节码编译成机器码的并执行的能力，我们知道，直接执行机器码肯定比解释更快。</p><p>HotSpot最初会通过解释的方式执行程序，当它发现某个方法运行得特别频繁时，就会将这些热点（Hot Spot）代码进行编译，编译成平台相关的机器码。这个过程也叫做JIT（Just In Time），与之相对的是AOT（Ahead Of Time），比较典型的是C和C++语言。</p><p>HotSpot进行JIT编译的编译器有两个，分别叫做<strong>C1</strong>和<strong>C2</strong>，或者也可以叫做<strong>Client Compiler</strong>和<strong>Server Compiler</strong>。这两种编译器编译策略不同，运用在不同的场景，下面会详细的说明。</p><a id="more"></a><h2 id="JIT编译"><a href="#JIT编译" class="headerlink" title="JIT编译"></a>JIT编译</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Add</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">200</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">long</span> start = System.nanoTime();</span><br><span class="line">            add();</span><br><span class="line">            <span class="keyword">long</span> end = System.nanoTime();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">add</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1000</span>; i++) &#123;</span><br><span class="line">            sum += i;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> sum;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面这段代码，我们有一个<code>add</code>方法，如果我们对改方法进行时间统计，我们会得到下面的曲线。</p><p>X轴是次数，Y轴是时间的log2。</p><p><img src="/images/HotSpot原理指南-C1和C2/add.png" alt=""></p><p>从这个曲线我们可以看出，在第大概100次的时间，时间消耗会下滑，也就是性能提升了一个档次。</p><p>由此我们可以猜到，前100次的add方法是由解释执行的，在100次后，执行的是由JIT编译器编译过的机器码。所以性能会有较大的提升。</p><h2 id="Profile"><a href="#Profile" class="headerlink" title="Profile"></a>Profile</h2><p>在详细讲述C1和C2之前，我们还有一个内容需要科普，就是方法的Profile信息。</p><p>除了最基本的用于判定某个方法是否是HotSpot的方法调用次数（Invocation Counter）信息外，对于某个方法，还有一些信息是会在运行时进行收集的。</p><p>比如我们看下面这段代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">record</span><span class="params">(List&lt;String&gt; list)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (list != <span class="keyword">null</span>) &#123;</span><br><span class="line">list.add(<span class="string">"大骚包卢布"</span>);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    log.warn(<span class="string">"我不是大骚包"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>record</code>函数的功能很简单，入参是一个List，如果List不为空，那么就把<code>大骚包卢布</code>这个字符串传递进去。不然的话就打出一个warn级别的日志<code>我不是大骚包</code>。</p><p>那么在调用这个方法的时候，HotSpot还会记录哪些信息呢</p><ul><li>List的真实类。因为List在Java中是一个接口，具体的传入可能是ArrayList或者LinkedList或者其他的。HotSpot需要记录具体的类为了以后的优化。</li><li>Log的真实类，理由和List一样。</li><li>进入if的次数，以及进入else的次数，更通俗的说是条件选择的实际情况。</li></ul><p>有人可能会问统计这些Profile有什么用。</p><p>举个最简单的例子，如果我们需要对<code>list.add</code>做内联，那么我们到底内联那个实现呢，这个就需要我们收集list的真实实现是什么。</p><h2 id="C1和C2"><a href="#C1和C2" class="headerlink" title="C1和C2"></a>C1和C2</h2><table><thead><tr><th></th><th>C1</th><th>C2</th></tr></thead><tbody><tr><td>编译时间</td><td>快</td><td>慢（x4）</td></tr><tr><td>执行时间</td><td>慢</td><td>快（30%）</td></tr><tr><td>输出代码</td><td>多</td><td>少</td></tr></tbody></table><p>上表是C1和C2在编译时间，执行时间，输出代码的区别</p><ul><li>编译时间：同样一段代码，C1需要时间比C2短，也就是需求的CPU资源较少</li><li>执行时间：C1编译时间短，通常意味着优化不如C2，所以C2编译出的机器码执行效率较高</li><li>输出代码：C1编译时间短，最终也就导致输出的机器码占用的内存要比C2多的</li></ul><p>总结：同一段代码，C1消耗的CPU资源较少，但是输出的代码质量不如C2。但是毋庸置疑的事，无论是C1还是C2输出的机器码，执行效率肯定都比解释快的。</p><p>C1又称<strong>Client Compiler</strong>，C2又称<strong>Server Compiler</strong>，不是没有历史渊源的。</p><p>或许我们都听过java在启动的时候可以执行是<code>client</code>模式还是<code>server</code>模式。</p><p>当我们使用client模式时，一般运行的是应用程序，比如java swing，awt之类的图形软件，对于这些桌面软件，作为使用者而言，并不希望哪个桌面应用占用大量的CPU，所以非常适合C1的场景</p><ul><li>编译速度快</li><li>占用CPU资源少</li></ul><p>而对于Server模式而言，一般是公司的服务器上跑的稳定的服务应用，服务器的资源一般较为丰富，同时一个应用并不会像桌面应用一样频繁的开关，一般都要跑几周或者几个月甚至几年。这种应用，当然速度越快越好。所以非常适合C2的场景</p><ul><li>编译消耗更多的CPU资源</li><li>代码质量更高，也就是性能更好</li></ul><h2 id="C1和C2和Profile"><a href="#C1和C2和Profile" class="headerlink" title="C1和C2和Profile"></a>C1和C2和Profile</h2><p>前面提到过的Profile信息，你可能会疑惑这个和C1和C2有什么联系。</p><p>其实我们需要先明白一个概念，就是收集那些Profile不仅仅会占用程序以外的更多的内容，而且会占用很多的CPU消耗。同样一段代码，插入了收集Profile逻辑和没有插入收集Profile逻辑，执行性能是不同的。</p><p>结合我们提到的C1和C2的使用场景的区别，可以得出这样的结论，这个收集Profile的消耗，对于桌面应用而言，是非常<strong>不合适</strong>的。</p><p>但是C2则需要这些Profile去做更好的性能优化。</p><p>所以对于Client模式的应用而言，解释器不会去收集程序的Profile信息，而Server模式在解释器阶段，则会进行Profile的收集，这也就导致了Client模式的起步性能是比Server模式的起步性能要好很多。</p><h2 id="启动模式"><a href="#启动模式" class="headerlink" title="启动模式"></a>启动模式</h2><p>在JDK1.6之前，指定是<code>client</code>还是<code>server</code>模式，我们在java程序启动时直接加参数就行了</p><p><code>java -client Hello</code></p><p><strong>但是</strong></p><p>注意我这个但是</p><p>其实自从JDK6的某个版本开始，你已经控制不了这个参数了</p><p><a href="https://docs.oracle.com/javase/7/docs/technotes/guides/vm/server-class.html" target="_blank" rel="noopener">https://docs.oracle.com/javase/7/docs/technotes/guides/vm/server-class.html</a></p><p>从这个网站可以看到，默认如果你是64位的机器并且至少有2G内存和2核心的CPU，默认都是Server模式了。</p><p><code>-client</code>这个参数会被忽略</p><p>但是也并不是没有办法指定client模式</p><p>不仅仅要在启动参数中加上<code>-client</code></p><p>还需要去修改文件<code>jre/lib/jvm.cfg</code></p><p>比如我的文件中默认是这个状态</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">-server KNOWN</span><br><span class="line">-client IGNORE</span><br><span class="line">-hotspot ERROR</span><br><span class="line">-classic WARN</span><br><span class="line">-native ERROR</span><br><span class="line">-green ERROR</span><br></pre></td></tr></table></figure><p>注意到我的<code>-client</code>后面跟的是<code>IGNORE</code>，所以我指定<code>-client</code>模式其实是不生效的</p><p>我需要改成<code>-client KNOWN</code>才行。</p><p>当然Oracle选择忽略<code>-client</code>模式也不是没有道理的</p><ul><li>Java的桌面应用已经很少了，Swing基本已经死了</li><li>现在大家的笔记本的CPU和内容资源都很充足</li></ul><p>所以全部使用<code>server</code>模式也没问题。</p><h2 id="后续"><a href="#后续" class="headerlink" title="后续"></a>后续</h2><p>当然C1和C2的故事并没有这么简单</p><p>同时JIT编译的策略也不是非C1就是C2，在JDK7中引入了分层编译，结合了C1和C2的优点。</p><p>这些会在后面的文章讲述。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;HotSpot是一款Java虚拟机的实现，除了基本的解释功能以外，该虚拟机还拥有将字节码编译成机器码的并执行的能力，我们知道，直接执行机器码肯定比解释更快。&lt;/p&gt;
&lt;p&gt;HotSpot最初会通过解释的方式执行程序，当它发现某个方法运行得特别频繁时，就会将这些热点（Hot Spot）代码进行编译，编译成平台相关的机器码。这个过程也叫做JIT（Just In Time），与之相对的是AOT（Ahead Of Time），比较典型的是C和C++语言。&lt;/p&gt;
&lt;p&gt;HotSpot进行JIT编译的编译器有两个，分别叫做&lt;strong&gt;C1&lt;/strong&gt;和&lt;strong&gt;C2&lt;/strong&gt;，或者也可以叫做&lt;strong&gt;Client Compiler&lt;/strong&gt;和&lt;strong&gt;Server Compiler&lt;/strong&gt;。这两种编译器编译策略不同，运用在不同的场景，下面会详细的说明。&lt;/p&gt;
    
    </summary>
    
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/categories/HotSpot/"/>
    
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/tags/HotSpot/"/>
    
  </entry>
  
  <entry>
    <title>给RedisTemplate插入Cat打点</title>
    <link href="https://blog.lovezhy.cc/2019/11/08/%E7%BB%99RedisTemplate%E6%8F%92%E5%85%A5Cat%E6%89%93%E7%82%B9/"/>
    <id>https://blog.lovezhy.cc/2019/11/08/%E7%BB%99RedisTemplate%E6%8F%92%E5%85%A5Cat%E6%89%93%E7%82%B9/</id>
    <published>2019-11-07T16:00:00.000Z</published>
    <updated>2020-03-14T14:57:53.851Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Cat是美团开源的一套监控系统，功能非常强大<br>一般对方法进行打点，它会自动生成每个方法的耗时，同时也会记录全链路的每个调用方法的耗时</p><p>对于查系统的性能瓶颈和稳定性有非常大的帮助</p><a id="more"></a><p>基本用法<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Transaction tranx = Cat.newTransaction(<span class="string">"Cache"</span>, <span class="string">"get"</span>);</span><br><span class="line">tranx.addData(<span class="string">"key"</span>, <span class="string">"name"</span>);</span><br><span class="line"><span class="comment">//do something</span></span><br><span class="line">tranx.setStatus(<span class="string">"0"</span>);</span><br><span class="line">tranx.complete();</span><br></pre></td></tr></table></figure></p><p>上面的方法就是对中间的代码执行进行耗时打点，这里假设的是我们对Redis的get方法进行打点</p><ul><li>第一句：new一个Transaction出来，Type是Cache，也就是Transaction属于Cache，然后具体的方法是get</li><li>第二句：addData，在执行过程中进行关键日志的记录，我们这里记录了get的key是name，方面查询长耗时的方法，增加一些提示性的参数</li><li>第三句：执行具体的方法</li><li>第四句：执行成功，设置status=0，0表示成功的意思，当然也有失败的方法，可以把具体的Exception传递进去</li><li>第五句：标记Transaction完成</li></ul><h2 id="框架集成"><a href="#框架集成" class="headerlink" title="框架集成"></a>框架集成</h2><p>Cat只是提供了一些工具，并没有直接提供方法与常见的方法集成，让我们在业务代码的每个方法都手动编码上面这些流程肯定不现实，可以借助于很多的方法进行隐式的插入逻辑。</p><h3 id="与Dubbo集成"><a href="#与Dubbo集成" class="headerlink" title="与Dubbo集成"></a>与Dubbo集成</h3><p>Dubbo提供了Filter机制，可以声明一个Filter进行对Dubbo服务方法的打点</p><p><a href="https://github.com/dianping/cat/tree/master/integration/dubbo" target="_blank" rel="noopener">Dubbo</a></p><p>在Cat的官方仓库中收集了此集成方式，可以直接使用</p><h2 id="与Mybatis集成"><a href="#与Mybatis集成" class="headerlink" title="与Mybatis集成"></a>与Mybatis集成</h2><p>和Dubbo一个，Mybatis也提供了Filter插件</p><p><a href="https://github.com/dianping/cat/tree/master/integration/mybatis" target="_blank" rel="noopener">Mybatis</a></p><p>在Cat的官方仓库中收集了此集成方式，可以直接使用</p><p>上面两种插件几乎是最常用的两个了，但是Redis的需求也比较强烈</p><h2 id="Redis打点"><a href="#Redis打点" class="headerlink" title="Redis打点"></a>Redis打点</h2><p>Cat的官方仓库并没有提供Redis的打点插件，借着Filter的简单的逻辑，我准备找找现有框架的逻辑插入方法</p><p>在正常的SpringBoot应用中，默认的Redis使用类是RedisTemplate，如果具体到某个操作，在内部声明了多个具体的类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedisTemplate</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt;    </span>&#123;</span><br><span class="line">  <span class="comment">// cache singleton objects (where possible)</span></span><br><span class="line">    <span class="keyword">private</span> <span class="meta">@Nullable</span> ValueOperations&lt;K, V&gt; valueOps;</span><br><span class="line">    <span class="keyword">private</span> <span class="meta">@Nullable</span> ListOperations&lt;K, V&gt; listOps;</span><br><span class="line">    <span class="keyword">private</span> <span class="meta">@Nullable</span> SetOperations&lt;K, V&gt; setOps;</span><br><span class="line">    <span class="keyword">private</span> <span class="meta">@Nullable</span> ZSetOperations&lt;K, V&gt; zSetOps;</span><br><span class="line">    <span class="keyword">private</span> <span class="meta">@Nullable</span> GeoOperations&lt;K, V&gt; geoOps;</span><br><span class="line">    <span class="keyword">private</span> <span class="meta">@Nullable</span> HyperLogLogOperations&lt;K, V&gt; hllOps;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>比如当我们调用</p><p><code>redisTemplate.opsForSet().members(cacheName)</code>时，</p><p>调用的是</p><p><code>DefaultSetOperations.members(K key)</code>方法</p><p>所以我们只要对上面提到的具体操作的类的一些方法进行打点就行</p><p>但是很可惜，RedisTemplate并没有提供</p><h2 id="方案一"><a href="#方案一" class="headerlink" title="方案一"></a>方案一</h2><p>直接使用SpringAop对具体的类进行代理</p><p>这当时是我觉得最简单的方法，但是很遗憾</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DefaultSetOperations</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">AbstractOperations</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; <span class="keyword">implements</span> <span class="title">SetOperations</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; </span>&#123;&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DefaultValueOperations</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">AbstractOperations</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; <span class="keyword">implements</span> <span class="title">ValueOperations</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; </span>&#123;&#125;</span><br></pre></td></tr></table></figure><p>这些具体实现类都不是public的，对这些方法进行切面处理是处理不了的</p><h2 id="方案二"><a href="#方案二" class="headerlink" title="方案二"></a>方案二</h2><p>最简单的方法被否决了，于是只能找一些其他的方法</p><p>当时看到Java的Agent可以在类被加载时进行一些修改，于是产生了写一个javaagent的方法</p><p>目标效果</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">get</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> execute(<span class="keyword">new</span> ValueDeserializingRedisCallback(key) &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">protected</span> <span class="keyword">byte</span>[] inRedis(<span class="keyword">byte</span>[] rawKey, RedisConnection connection) &#123;</span><br><span class="line">            <span class="keyword">return</span> connection.get(rawKey);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;, <span class="keyword">true</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">=&gt;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">get</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">    Transaction tranx = Cat.newTransaction(<span class="string">"Cache"</span>, <span class="string">"get"</span>); </span><br><span class="line">    tranx.addData(<span class="string">"key"</span>, key);</span><br><span class="line">    V res = execute(<span class="keyword">new</span> ValueDeserializingRedisCallback(key) &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">protected</span> <span class="keyword">byte</span>[] inRedis(<span class="keyword">byte</span>[] rawKey, RedisConnection connection) &#123;</span><br><span class="line">            <span class="keyword">return</span> connection.get(rawKey);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;, <span class="keyword">true</span>);</span><br><span class="line">    </span><br><span class="line">    tranx.setStatus(<span class="string">"0"</span>);</span><br><span class="line">    tranx.complete();</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>但是为了得到失败的效果，同时防止Cat方法抛出异常影响正常逻辑，需要多加几个try catch</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">get</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">    Transaction tranx = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      tranx = Cat.newTransaction(<span class="string">"Cache"</span>, <span class="string">"get"</span>);</span><br><span class="line">      tranx.addData(<span class="string">"key"</span>, key);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable e) &#123;&#125;</span><br><span class="line">    </span><br><span class="line">    V res = <span class="keyword">null</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        V res = execute(<span class="keyword">new</span> ValueDeserializingRedisCallback(key) &#123;</span><br><span class="line"></span><br><span class="line">              <span class="meta">@Override</span></span><br><span class="line">              <span class="keyword">protected</span> <span class="keyword">byte</span>[] inRedis(<span class="keyword">byte</span>[] rawKey, RedisConnection connection) &#123;</span><br><span class="line">                  <span class="keyword">return</span> connection.get(rawKey);</span><br><span class="line">              &#125;</span><br><span class="line">          &#125;, <span class="keyword">true</span>);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">       <span class="keyword">try</span> &#123;</span><br><span class="line">         <span class="keyword">if</span> (tranx != <span class="keyword">null</span>) &#123;</span><br><span class="line">           tranx.setStatus(e);</span><br><span class="line">           tranx.complete();</span><br><span class="line">         &#125;</span><br><span class="line">       &#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">         </span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">throw</span> e;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (tranx != <span class="keyword">null</span>) &#123;</span><br><span class="line">        tranx.setStatus(<span class="string">"0"</span>);</span><br><span class="line">        tranx.complete();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span>(Throwable e) &#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到，代码非常长，但是不用担心性能，经过编译优化之后很多其实都被优化掉了</p><h2 id="java-lang-instrument包"><a href="#java-lang-instrument包" class="headerlink" title="java.lang.instrument包"></a>java.lang.instrument包</h2><blockquote><p>Provides services that allow Java programming language agents to instrument programs running on the JVM. The mechanism for instrumentation is modification of the byte-codes of methods.<br>Package Specification</p></blockquote><p>Oracle的官网上对这个包的定义如上，简单的说就是给与我们能力动态的修改Java类的字节码<br>一般可以用来监控，织入类似于AOP的逻辑</p><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p>当时选择了javaassit进行字节码的织入，但是javaassit有一个很大的局限就是不能使用本地变量</p><p>比如<code>Transaction tranx</code>这个我们在声明出来之后，在下面的代码就获取不到这个变量了</p><p>但是整个方法不会触及多线程的场景，所以想到的方案就是放在一个ThreadLocal中</p><p>先构造出一个ThreadLocal的类进行封装</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedisCatLog</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> ThreadLocal&lt;RedisCatLog&gt; THREAD_LOCAL_CAT_LOG = <span class="keyword">new</span> ThreadLocal&lt;&gt;();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">startLog</span><span class="params">(String action, Object data)</span> </span>&#123;</span><br><span class="line">        THREAD_LOCAL_CAT_LOG.remove();</span><br><span class="line">        RedisCatLog redisCatLog = <span class="keyword">new</span> RedisCatLog(action);</span><br><span class="line">        redisCatLog.before(String.valueOf(data));</span><br><span class="line">        THREAD_LOCAL_CAT_LOG.set(redisCatLog);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">endLog</span><span class="params">(<span class="keyword">boolean</span> success)</span> </span>&#123;</span><br><span class="line">        RedisCatLog redisCatLog = THREAD_LOCAL_CAT_LOG.get();</span><br><span class="line">        <span class="keyword">if</span> (Objects.nonNull(redisCatLog)) &#123;</span><br><span class="line">            redisCatLog.after(success);</span><br><span class="line">            THREAD_LOCAL_CAT_LOG.remove();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String action;</span><br><span class="line">    <span class="keyword">private</span> Transaction tranx;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">RedisCatLog</span><span class="params">(String action)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.action = action;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">before</span><span class="params">(String data)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.tranx = Cat.newTransaction(<span class="string">"Cache."</span>, <span class="keyword">this</span>.action);</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>.tranx <span class="keyword">instanceof</span> NullMessage) &#123;</span><br><span class="line">            log.error(<span class="string">"is null message"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">this</span>.tranx.addData(<span class="string">"key"</span>, data);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">after</span><span class="params">(<span class="keyword">boolean</span> success)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (!success) &#123;</span><br><span class="line">            <span class="keyword">this</span>.tranx.setStatus(<span class="string">"failed"</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">this</span>.tranx.setStatus(<span class="string">"0"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">this</span>.tranx.complete();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样，有了这个类之后，我们的织入代码就比较简单了</p><ul><li>给现有方法的开始加入RedisCatLog.startLog()</li><li>给方法的结尾加上RedisCatLog.endLog()</li><li>给原有的完整代码加上try catch</li></ul><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">public V get(Object key) &#123;</span><br><span class="line">    try &#123;RedisCatLog.startLog("get", key);&#125; catch(Throwable e) &#123;&#125;</span><br><span class="line">  </span><br><span class="line">    try &#123;</span><br><span class="line">        V res = execute(new ValueDeserializingRedisCallback(key) &#123;</span><br><span class="line">              @Override</span><br><span class="line">              protected byte[] inRedis(byte[] rawKey, RedisConnection connection) &#123;</span><br><span class="line">                  return connection.get(rawKey);</span><br><span class="line">              &#125;</span><br><span class="line">          &#125;, true);</span><br><span class="line">    &#125; catch(Throwable e) &#123;</span><br><span class="line">        try &#123;RedisCatLog.endLog(false);&#125; catch(Throwable e) &#123;&#125;</span><br><span class="line">        throw e;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    try &#123;RedisCatLog.endLog(true);&#125; catch(Throwable e) &#123;&#125;</span><br><span class="line">    return res;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>整体来看是不是简单的了很多</p><p>下面就是具体的javaassit代码编写了</p><p>在编写时参考了文档，并没有系统的学习javaassit</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">String methodName = methods[i].getName();</span><br><span class="line">CtClass etype = ClassPool.getDefault().get(<span class="string">"java.lang.Throwable"</span>);</span><br><span class="line">methods[i].addCatch(<span class="string">"&#123; RedisCatLog.endLog(false); throw $e; &#125;"</span>, etype);</span><br><span class="line">methods[i].insertBefore(before(classMethodNameInfo.getType() + <span class="string">"-"</span> + methodName));</span><br><span class="line">methods[i].insertAfter(after());</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">before</span><span class="params">(String action)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> String.format(<span class="string">"try &#123; RedisCatLog.startLog(\"%s\", $1); &#125; catch (Throwable e) &#123;&#125;"</span>, action);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">after</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="string">"try&#123; RedisCatLog.endLog(true);&#125; catch (Throwable e) &#123;&#125;"</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>大概的整体逻辑如下</p><p>项目我传到了Github上，<a href="https://github.com/zhyzhyzhy/CatRedisLogAspect" target="_blank" rel="noopener">https://github.com/zhyzhyzhy/CatRedisLogAspect</a></p><p>大家可以参考文档进行使用</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;Cat是美团开源的一套监控系统，功能非常强大&lt;br&gt;一般对方法进行打点，它会自动生成每个方法的耗时，同时也会记录全链路的每个调用方法的耗时&lt;/p&gt;
&lt;p&gt;对于查系统的性能瓶颈和稳定性有非常大的帮助&lt;/p&gt;
    
    </summary>
    
    
      <category term="Spring和SpringBoot" scheme="https://blog.lovezhy.cc/categories/Spring%E5%92%8CSpringBoot/"/>
    
    
      <category term="Spring" scheme="https://blog.lovezhy.cc/tags/Spring/"/>
    
      <category term="Cat" scheme="https://blog.lovezhy.cc/tags/Cat/"/>
    
  </entry>
  
  <entry>
    <title>Raft实现指北</title>
    <link href="https://blog.lovezhy.cc/2019/09/05/Raft%E5%AE%9E%E7%8E%B0%E6%8C%87%E5%8C%97/"/>
    <id>https://blog.lovezhy.cc/2019/09/05/Raft%E5%AE%9E%E7%8E%B0%E6%8C%87%E5%8C%97/</id>
    <published>2019-09-04T16:00:00.000Z</published>
    <updated>2020-02-29T14:53:02.382Z</updated>
    
    <content type="html"><![CDATA[<p>Raft实现指北<br><a id="more"></a></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>自己陆陆续续花了一些时间完成了一个Raft的库，目前基本的流程都完成了，下面要继续做的话，就是要进行一些优化的逻辑了。<br><a href="https://github.com/zhyzhyzhy/Rub-Raft" target="_blank" rel="noopener">Rub-Raft</a><br>取名叫Rub，就是卢布的意思，纪念雯姐今年去世的花枝鼠[2016-2019]。<br>卢布是我见过最乖的鼠，很聪明，她喜欢睡在吊床上，不会像其他的鼠去啃吊床的线。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>一个很好的博文<br><a href="https://lichuang.github.io/post/20180921-raft/" target="_blank" rel="noopener">https://lichuang.github.io/post/20180921-raft/</a>  </p><p>《CONSENSUS: BRIDGING THEORY AND PRACTICE》论文<br><a href="https://ramcloud.stanford.edu/~ongaro/thesis.pdf" target="_blank" rel="noopener">https://ramcloud.stanford.edu/~ongaro/thesis.pdf</a>  </p><p>动画讲解<br><a href="https://raft.github.io/" target="_blank" rel="noopener">https://raft.github.io/</a></p><h2 id="整体流程"><a href="#整体流程" class="headerlink" title="整体流程"></a>整体流程</h2><p>集群的整体状态一般分为三种</p><ul><li>选举</li><li>日志添加<ul><li>正常添加</li><li>非正常添加</li><li>新节点获取日志</li></ul></li><li>新增节点</li></ul><p>我可能不太会对所有流程做详细的阐述，只是一些简单的问答和心得。</p><p>整个RPC的方法其实只要4个就可以完成Raft，前两个和选举有关，后两个和日志有关</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">VoteResponse <span class="title">requestPreVote</span><span class="params">(VoteRequest voteRequest)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function">VoteResponse <span class="title">requestVote</span><span class="params">(VoteRequest voteRequest)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function">ReplicatedLogResponse <span class="title">requestAppendLog</span><span class="params">(ReplicatedLogRequest replicatedLogRequest)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function">InstallSnapshotResponse <span class="title">requestInstallSnapShot</span><span class="params">(InstallSnapshotRequest installSnapShotRequest)</span></span>;</span><br></pre></td></tr></table></figure><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><h3 id="需要节点的自动注册和发现吗"><a href="#需要节点的自动注册和发现吗" class="headerlink" title="需要节点的自动注册和发现吗"></a>需要节点的自动注册和发现吗</h3><p>一开始我还是RPC的实现思路，以为需要一个自动的节点注册和发现机制<br>当然其实并不需要，集群启动的时候，只要我们把初始的节点信息写死在启动Config文件中就好  </p><p>那么可不可以有呢，我理解是不可以的，因为选举的时候，节点需要知道当前节点的个数，来判断自己得到的选票是不是已经有集群节点的一半了。<br>如果你还搞个节点自动注册，那么到底集群有几个节点呢？</p><h2 id="节点的RPC连接"><a href="#节点的RPC连接" class="headerlink" title="节点的RPC连接"></a>节点的RPC连接</h2><p>讲道理其实RPC连接并不是什么大问题，但是我们不能先入为主的当做DUBBO这种RPC框架去实现我们的RPC框架。<br>这个问题的根源是：正常的RPC模型并不是互相问答的模式<br>都是C/S模型<br>一个节点一般会开一个Server，让其他的节点来连接，并提出请求，这个Server并不会主动向其他的Node发送消息。 </p><p>这个时候会想到，我们每个节点都当做是一个Server，然后对每个其他的Node，开对应的Client连接。我就是这么实现的，这样的情况其实对于两个节点而言，互相的连接通过了两个不同的Channel来实现。</p><p>后来发现其实这样还有问题。<br>问题是在无法重新连接的情况<br>假设这样的情形，3Node互相连接，过程中Node1断开，其他两个Node互相连接，过一阵子，Node1又启动，开启自己的RpcServer，并顺利连接到其他两个Node的RpcServer<br>而其他两个Node并不会主动的去连接Node1的RpcServer</p><p>这个就需要一种机制，当其他的节点连接上自己的RpcServer的时候，获得感知，然后自己也去连接对方的RpcServer</p><p>那么这个感知机制，放在哪里去做呢。<br>放在Rpc层面吗？我感觉侵入性很大，一方面作为一个Rpc并不需要这种机制，需要的话，也是一个抽象度很高的东西，类似于连接上的回调之类。</p><p>我这里另外开了一个RPC方法，叫<code>requestConnect</code>，当每个节点RPCClient或者RPCServer启动的时候，都会向其他的节点发送<code>requestConnect</code>请求，其他节点接收到这个请求，会检查自己与发送请求的节点的链路是否已经失效，如果失效，则请求重新连接。</p><p>这样完成的很好，但是就是RPC请求的次数会有点多。</p><h2 id="RPC请求的异步与同步"><a href="#RPC请求的异步与同步" class="headerlink" title="RPC请求的异步与同步"></a>RPC请求的异步与同步</h2><p>这个问题不是很复杂，但是我们如果自己实现RPC的话，要注意的一点就是不能不支持异步的方式。<br>我的RPC的实现中，支持3种请求方式</p><ul><li>SYNC 同步请求</li><li>ASYNC 异步请求</li><li>ONE_WAY 不需要返回的请求</li></ul><p>不过异步请求说白了就是RPC框架帮你封装好了SYNC的Future的方式</p><p>上面提到了Raft的需要的5种方法，那些需要异步呢</p><ul><li>requestConnect =&gt; ONE_WAY</li><li>requestPreVote =&gt; ASYCN</li><li>requestVote =&gt; ASYNC</li><li>requestAppendLog =&gt; SYNC</li><li>requestInstallSnapShot =&gt; SYNC</li></ul><h2 id="选举"><a href="#选举" class="headerlink" title="选举"></a>选举</h2><h3 id="节点启动顺序"><a href="#节点启动顺序" class="headerlink" title="节点启动顺序"></a>节点启动顺序</h3><p>节点启动的顺序要注意什么吗？<br>还是不需要，选举要得到一般的选票才能成为Leader，即使有一个节点最后启动，此时集群中已经选举出一个Leader了，最后启动的那个节点收到AppendLog的消息，就会自动变成Follower。</p><h3 id="节点初始化"><a href="#节点初始化" class="headerlink" title="节点初始化"></a>节点初始化</h3><p>节点初始化要做的事不多，就是设置自己的状态为<code>Follower</code><br>然后启动一个选举超时的定时器</p><h3 id="选举超时时间"><a href="#选举超时时间" class="headerlink" title="选举超时时间"></a>选举超时时间</h3><p>节点刚启动的状态是<code>Follower</code>，并且启动一个超时定时器，当时间到了的时候开始进行选举<br>那么这个超时的时间是多少呢？论文中给出的范围是150 - 300ms[章节3.4]  </p><h3 id="超时期间收到Request"><a href="#超时期间收到Request" class="headerlink" title="超时期间收到Request"></a>超时期间收到Request</h3><p>我们知道当选举超时之后，节点把自己的状态设为<code>pre_candidate</code>，并且发送消息给其他节点进行选举。<br>如果超时期间收到消息呢<br>论文中写，<code>A server remains in follower state as long as it receives valid RPCs from a leader or candidate.</code></p><p>很明晰，超时期间收到其他节点的Request，那么就不会进入选举流程，依然是一个Follower。</p><h3 id="超时方法什么时候调用"><a href="#超时方法什么时候调用" class="headerlink" title="超时方法什么时候调用"></a>超时方法什么时候调用</h3><p>在接收到PreVote，Vote，AppendLog的RPC请求接收到之后都要开始调用  </p><h3 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h3><p>要加锁吗，当然是要的<br>上一个我们提到<br>节点超时，开始发起选举RPC之前，启动超时，如果到超时结束，还没有选举出一个Leader，那么就把自己的term加一再次发起选举</p><p>这个过程中有两个事件需要一些条件的同步</p><ul><li>超时线程：没有收到Leader的信息和其他节点的选举信息，就执行，也就是心跳有更新</li><li>接收vote线程：收到Leader和其他节点的信息，还在超时未完成状态，就更新心跳信息</li></ul><p>如果分为两个方法的话，最简单的就是给整个方法都加锁<br>但是这样锁的粒度太大了，能不能把条件抽象出来呢</p><p>我想的是对Node的状态进行cas的修改<br>超时线程，首先判断心跳有没有更新，如果有更新就不进行选举，如果没有更新，就加锁的对NodeStatus进行CAS更新，从Follower更新到Pre_Candidate<br>接收Vote线程，首先对NodeStatus进行CAS的更新，从Follower更新到Follower，然后更新心跳时间<br>我们分析两个线程的流程<br>超时线程</p><ul><li>1.判断心跳有没有更新</li><li>2.NodeStatus从Follower更新到Pre_Candidate</li></ul><p>接收Vote线程</p><ul><li>3.首先对NodeStatus进行CAS的更新，从Follower更新到Follower</li><li>4.更新心跳时间</li></ul><p>如果不加锁，流程从3 - 1 - 2 - 4就出问题了</p><p>这个思路很麻烦</p><p>我们再换个思路</p><p>超时线程进行vote的时候，需要对term进行+1<br>接收Vote线程，如果成功接收其他节点的信息维持Follower的话，那么对面的term肯定比自己大的，那么也就是需要对Term进行加1</p><p>所以我们对Term进行cas操作，谁成功了谁进行操作</p><h3 id="PreVote"><a href="#PreVote" class="headerlink" title="PreVote"></a>PreVote</h3><p>其实论文中并没有很直观的提到PreVote的阶段<br>需要PreVote的原因也不复杂，可以百度一下。</p><h3 id="VoteFor可以进行修改吗"><a href="#VoteFor可以进行修改吗" class="headerlink" title="VoteFor可以进行修改吗"></a>VoteFor可以进行修改吗</h3><p><code>Vote</code>阶段<br>假设这样一种场景：<br>我们有节点1 2 3<br>2最后启动<br>1，3同时超时，且3的请求先到2<br>3，term = 1，2投票给他，1拒绝，于是3变成leader<br>1，term=1，2拒绝了他，3也拒绝了他</p><p>这个时候Term2其实已经有Leader了，是3，那么1也要变成Follower<br>这个时候1收到HeartBeat就要把自己变成Follower<br>那么这里的1的Term=1的votedfor其实已经设置为自己了<br>所以VotedFor还是可以进行修改的  </p><h3 id="Leader发现更高任期的Server"><a href="#Leader发现更高任期的Server" class="headerlink" title="Leader发现更高任期的Server"></a>Leader发现更高任期的Server</h3><p>这种情况也是会发现的，就是Leader进行了STW的GC，然后其他的节点进行了超时选举，选出了Leader。<br>这种时候，原来的Leader的GC结束，进行进行AppendLogRequest，就会发现更高任期的Server<br>这种情况直接自己变成Follower就行</p><h3 id="日志比较的原则"><a href="#日志比较的原则" class="headerlink" title="日志比较的原则"></a>日志比较的原则</h3><p><a href="https://zhuanlan.zhihu.com/p/32052223" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/32052223</a><br>日志比较的原则是，如果本地的最后一条log entry的term更大，则term大的更新，如果term一样大，则Log Index更大的更新</p><h3 id="选举模型"><a href="#选举模型" class="headerlink" title="选举模型"></a>选举模型</h3><p>5个节点中，如果有两个节点同意，那么就可以成为Leader<br>但是反过来说，如果3个节点拒绝了，那么就不能成为Leader</p><p>第一个条件我们可以使用Latch<br>第二个条件我们还是可以使用Latch</p><p>那么怎么组合这两个Latch呢<br>答案就是<br>所以总而言之，不能用Latch<br>只能加锁唤醒了</p><p>我这里自己实现了一个类专门用来进行选举的计数。</p><h2 id="日志复制"><a href="#日志复制" class="headerlink" title="日志复制"></a>日志复制</h2><h3 id="Peer状态管理"><a href="#Peer状态管理" class="headerlink" title="Peer状态管理"></a>Peer状态管理</h3><p>这个也是我实现的时候遇到的比较棘手的问题<br>一开始也没有什么好的解决思路</p><p>因为每个节点的任务执行的状态在同一个时刻肯定是不一致的，有可能这个快一点，那个慢一点</p><p>也有可能就是有的是正常发送心跳，有的则是刚刚重启需要进行日志的同步  </p><p>但是有一个很明确的点就是每个Follower节点都是不同的状态管理</p><p>同时我们再关注下Leader向Follower节点发送心跳或者AppendLogRequest的频率，会发现每次只能有一个请求过去，当这个请求没有返回或者未超时失败时，是不能够发送下一个Rpc的。</p><p><img src="/images/raft/peer.png" alt=""></p><p>综合以上两点，我的设计就是为每个PeerNode分配一个任务队列，每个PeerNode都有一个单独的线程去拿队列的第一个任务，然后同步的执行。</p><p>当Leader需要进行发送心跳或者AppendLogRequest或者其他的请求时，直接Append一个Task到PeerNode的任务队列就行。</p><h3 id="除了AppendLog还要做什么"><a href="#除了AppendLog还要做什么" class="headerlink" title="除了AppendLog还要做什么"></a>除了AppendLog还要做什么</h3><p>这个也是一个误区，因为心跳的RpcRequest就是一个空的AppendLogRequest<br>我开始的实现中，会判断如果需要Append的Log为空，那么就重置一下选举定时器，然后就直接返回了。  </p><p>这个其实是错误的，我们对每一个AppendLogRequest都要进行日志的比对，把还没有Commit的日志，如果需要，给删了或者覆盖了。  </p><p>这么说可能不太明白，假设这样一种场景。<br>一共三个节点，Node1是Leader，三个节点的日志都是1，2，3，一致的。<br><img src="/images/raft/log.png" alt="">  </p><p>然后发生了网络分区，Leader被隔绝了，但是Node1并不知道，同时客户端的请求也过来了，虽然日志无法commit，但是还是Append到了Node1中。  </p><p>如果网络分区结束，Node2变成了Leader，Node2给Node1发送心跳的时候，这时候就需要根据Log的index和Leader的commitIndex，把4和5删掉。<br>这个BUG我也是找了很久，当初图省事简单也没考虑到这些。  </p><h3 id="ReplicatedLogResponse的变更"><a href="#ReplicatedLogResponse的变更" class="headerlink" title="ReplicatedLogResponse的变更"></a>ReplicatedLogResponse的变更</h3><p>如果是节点Down了之后重启，Leader发现nextIndex对不上的时候，会一步一步的退一个NextIndex把日志发送过去，但是每次都发送后续的全量的Log，开销会很大，所以这里可能可以加一个优化，就是在ReplicatedLogResponse加上自己的lastCommitIndex，让Leader可以一次定位到matchIndex。</p><h2 id="成员变更"><a href="#成员变更" class="headerlink" title="成员变更"></a>成员变更</h2><p>论文中讲了，如果3台节点中突然加了两台，可能出现两个Leader，一个通过新配置，一个通过旧配置。</p><p>所以一般的实现是一次只增加一个节点，这个增加的行为其实是人为控制的。</p><p>这个地方的实现也有一些坑点存在。</p><p>比如论文中写新配置是通过日志的形式进行Append进去的，那么这个日志的格式是啥样的呢。<br>一开始我们定义成了增加节点和删除节点的形式，比如<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ClusterChangeLog</span> </span>&#123;</span><br><span class="line">Type type; <span class="comment">//表示是增加节点还是删除节点</span></span><br><span class="line">NodeId nodeId; <span class="comment">//需要增加的节点Id或者删除的节点Id</span></span><br><span class="line">EndPoint endPoint; <span class="comment">//需要增加的节点Id或者删除的节点Id的IP和端口地址</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>像这种形式的日志进行Append，但是其实是不行的。</p><p>我们需要的Log要包含新的集群的所有的节点信息，是否是删除还是增加，删除还是增加的节点信息由节点的日志模块自己去解析。<br>所以正确的形式应该是这样<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ClusterChangeLog</span> </span>&#123;</span><br><span class="line">List&lt;NodeConfig&gt; nodeConfigs;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>为什么说第一种的形式是行不通的或者说实现起来有BUG呢？<br>主要的问题还是在要新增的那个节点上，</p><ul><li>首先新增的节点会有个像Leader获取日志的情况，在获取日志的时候，新增的节点还不属于集群，也就是说，在日志中并没有体现，除了Leader节点，其他的follower节点并不知道该节点的存在。也就是说，我们在开启新增的节点的时候，是不能够将现有的集群的配置写给他启动的，不然就自动连接到其他的节点上去了。</li><li>第二种情况就是，如果我们把当前的集群配置写给新增的那个节点，然后启动它，再把新的集群配置写给Leader，在Leader还没发送时，Leader挂了，那么这个新增的节点咋办呢，能办也能办，但是搞起来会很复杂</li></ul><p>所以我们需要在启动新的节点时，不给它写当前的集群的配置，然后把新增的集群信息写给Leader，Leader也不会立即写日志，而是会进行日志的同步，</p><ul><li>如果日志同步的过程中，Leader挂了，那么没关系，因为新的配置还没写日志，挂了就人为的再写给新的Leader就行，不会影响当前的集群</li><li>日志同步结束之后，把日志进行Append，然后发送给所有的节点，包括新增的节点，那么即使这中间Leader挂了，因为集群更改日志是只要Append就生效的，按照日志最新的才能当前Leader的原则，新的Leader出现之后，会把更改日志再同步到其他的节点，包括新增的节点。</li></ul><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>好的，代码写完了，那么你怎么测试你的代码的正确性呢。<br>这个是我当初头疼的一点，没什么办法进行测试，我到底有没有写对。</p><p>首先这是个分布式的应用，我们除了模拟分布式的环境，还要模拟网络的各种情况，这些肯定不是我们真实模拟硬件和网络情况的，所以肯定要侵入代码的。<br>但是这种需要侵入代码的方法，没有一个方法论在里面的话很容易写乱。</p><p>这里我参考了MIT6.824的课程代码<br><a href="https://github.com/chaozh/MIT-6.824/blob/master/src/raft/test_test.go" target="_blank" rel="noopener">MIT-6.824/blob/master/src/raft/test_tes</a> </p><p>这里模拟了诸多情况</p><ul><li>Leader断网</li><li>Leader断网又恢复</li><li>集群整体掉线恢复</li><li>网络分区</li></ul><p>等诸多情况</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Raft实现指北&lt;br&gt;
    
    </summary>
    
    
      <category term="分布式" scheme="https://blog.lovezhy.cc/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
      <category term="raft" scheme="https://blog.lovezhy.cc/tags/raft/"/>
    
  </entry>
  
</feed>
