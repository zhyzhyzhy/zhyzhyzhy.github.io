<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>LoveZhy</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://blog.lovezhy.cc/"/>
  <updated>2020-02-23T10:25:40.419Z</updated>
  <id>https://blog.lovezhy.cc/</id>
  
  <author>
    <name>zhy</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Kafka源码导入Idea</title>
    <link href="https://blog.lovezhy.cc/2020/02/23/Kafka%E6%BA%90%E7%A0%81%E5%AF%BC%E5%85%A5Idea/"/>
    <id>https://blog.lovezhy.cc/2020/02/23/Kafka%E6%BA%90%E7%A0%81%E5%AF%BC%E5%85%A5Idea/</id>
    <published>2020-02-22T16:00:00.000Z</published>
    <updated>2020-02-23T10:25:40.419Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>虽然网上教程很多，但是我依然要写系列<br>因为我踩到的坑有的是网上没有遇到过的</p><a id="more"></a><h2 id="详细步骤"><a href="#详细步骤" class="headerlink" title="详细步骤"></a>详细步骤</h2><h3 id="克隆源码"><a href="#克隆源码" class="headerlink" title="克隆源码"></a>克隆源码</h3><p><code>git clone https://github.com/apache/kafka.git</code></p><p><strong>这个时候切记不能先用idea直接打开项目！</strong><br><strong>这个时候切记不能先用idea直接打开项目！</strong><br><strong>这个时候切记不能先用idea直接打开项目！</strong></p><h3 id="打包环境"><a href="#打包环境" class="headerlink" title="打包环境"></a>打包环境</h3><p>kafka自带了一些Gradle的Task，可以生成出导入Eclipse或者Idea配置。<br>在Kafka目录下执行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./gradlew jar</span><br><span class="line">./gradlew idea</span><br></pre></td></tr></table></figure><p>这个时候目录下会出现一个文件叫<code>kafka.ipr</code><br>在finder中双击这个文件，idea会自动打开并导入项目。<br><strong>注：也就是这个时候才会打开Idea</strong></p><h3 id="配置Gradle"><a href="#配置Gradle" class="headerlink" title="配置Gradle"></a>配置Gradle</h3><p>一般Idea打开会，右下角会弹出一个框，大致意思是：</p><blockquote><p>我们检测出这个是Gradle项目，需要导入Gradle的配置吗？</p></blockquote><p>这个时候，点击确认就行。</p><p>如果打开Idea啥也没发生，那么就需要我们自己打开文件<code>build.gradle</code><br>然后进行刷新之类的操作，具体我也忘了怎么操作的。</p><h3 id="修改配置"><a href="#修改配置" class="headerlink" title="修改配置"></a>修改配置</h3><p>一些配置的修改是比较重要的</p><ol><li>文件build.gradle<br>第一处修改：<br>找到<code>tasks.withType(ScalaCompile) {</code>这一行<br>修改<code>scalaCompileOptions.additionalParameters</code>的配置<figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">    scalaCompileOptions.additionalParameters = [</span><br><span class="line">      <span class="string">"-nowarn"</span>,  <span class="comment">//新增</span></span><br><span class="line">      <span class="string">"-deprecation"</span>,</span><br><span class="line">      <span class="string">"-unchecked"</span>,</span><br><span class="line">      <span class="string">"-encoding"</span>, <span class="string">"utf8"</span>,</span><br><span class="line">      <span class="string">"-Xlog-reflective-calls"</span>,</span><br><span class="line">      <span class="string">"-feature"</span>,</span><br><span class="line">      <span class="string">"-language:postfixOps"</span>,</span><br><span class="line">      <span class="string">"-language:implicitConversions"</span>,</span><br><span class="line">      <span class="string">"-language:existentials"</span>,</span><br><span class="line"><span class="comment">//      "-Xlint:constant",  //注释</span></span><br><span class="line"><span class="comment">//      "-Xlint:delayedinit-select",</span></span><br><span class="line"><span class="comment">//      "-Xlint:doc-detached",</span></span><br><span class="line"><span class="comment">//      "-Xlint:missing-interpolator",</span></span><br><span class="line"><span class="comment">//      "-Xlint:nullary-override",</span></span><br><span class="line"><span class="comment">//      "-Xlint:nullary-unit",</span></span><br><span class="line"><span class="comment">//      "-Xlint:option-implicit",</span></span><br><span class="line"><span class="comment">//      "-Xlint:package-object-classes",</span></span><br><span class="line"><span class="comment">//      "-Xlint:poly-implicit-overload",</span></span><br><span class="line"><span class="comment">//      "-Xlint:private-shadow",</span></span><br><span class="line"><span class="comment">//      "-Xlint:stars-align",</span></span><br><span class="line"><span class="comment">//      "-Xlint:type-parameter-shadow",</span></span><br><span class="line"><span class="comment">//      "-Xlint:unused"</span></span><br><span class="line">    ]</span><br></pre></td></tr></table></figure></li></ol><p>第二处修改：<br>还有<code>tasks.withType(JavaCompile) {</code>这一行<br>修改为<br><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">  tasks.withType(JavaCompile) &#123;</span><br><span class="line">    <span class="keyword">options</span>.encoding = <span class="string">'UTF-8'</span></span><br><span class="line"><span class="comment">//    options.compilerArgs &lt;&lt; "-Xlint:all"</span></span><br><span class="line">    <span class="comment">// temporary exclusions until all the warnings are fixed</span></span><br><span class="line"><span class="comment">//    options.compilerArgs &lt;&lt; "-Xlint:-rawtypes"</span></span><br><span class="line"><span class="comment">//    options.compilerArgs &lt;&lt; "-Xlint:-serial"</span></span><br><span class="line"><span class="comment">//    options.compilerArgs &lt;&lt; "-Xlint:-try"</span></span><br><span class="line"><span class="comment">//    options.compilerArgs &lt;&lt; "-Werror"</span></span><br><span class="line">    <span class="comment">// --release is the recommended way to select the target release, but it's only supported in Java 9 so we also</span></span><br><span class="line">    <span class="comment">// set --source and --target via `sourceCompatibility` and `targetCompatibility`. If/when Gradle supports `--release`</span></span><br><span class="line">    <span class="comment">// natively (https://github.com/gradle/gradle/issues/2510), we should switch to that.</span></span><br><span class="line">    <span class="keyword">if</span> (JavaVersion.current().isJava9Compatible())</span><br><span class="line">      <span class="keyword">options</span>.compilerArgs &lt;&lt; <span class="string">"--release"</span> &lt;&lt; minJavaVersion</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p><p><strong>上面两个修改主要是为了Idea启动时编译，会把一堆warn当做Error报出来，Gradle不给启动</strong></p><p>第三处修改：<br>找到<code>project(&#39;:core&#39;) {</code>这一行<br>下面会有一堆<br><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">dependencies</span> &#123;</span><br><span class="line">  <span class="keyword">compile</span> <span class="keyword">project</span>(<span class="string">':clients'</span>)</span><br><span class="line">  <span class="keyword">compile</span> libs.jacksonDatabind</span><br><span class="line">  <span class="keyword">compile</span> libs.jacksonModuleScala</span><br><span class="line">~~~</span><br></pre></td></tr></table></figure></p><p>这种配置<br>在<code>compileOnly libs.log4j</code>这一行的下面，加上<br><code>compile libs.slf4jlog4j</code></p><p><strong>这个修改主要是终端启动Kafka的时候日志打印不出来的问题</strong></p><blockquote><p>很多的网上的答案都是让自己把两个依赖加进去，但是我发现其实Kafka配置了两个依赖，但是却没有Compile，所以不需要自己加进去，只要加上这行配置就行</p></blockquote><ol><li>配置log4j文件<br>第一步：把config目录下的log4j.properties文件复制到core/src/main/resources目录下<br>需要创建rescources目录<br>如图所示：<br><img src="/images/Kafka源码导入Idea/log4j1.png" alt=""></li></ol><p><strong>并不是很多网上说的复制到/scala目录下</strong></p><p>第二步：修改log4j.properties文件<br>主要是把很多的<code>${kafka.logs.dir}</code>这种变量去掉，换成自己电脑上的绝对路径</p><h2 id="启动配置"><a href="#启动配置" class="headerlink" title="启动配置"></a>启动配置</h2><p>下面就是启动配置了，这个网上都有，我就直接复制一下</p><p><strong>首先得自己启动一个Zookeeper进程</strong></p><h3 id="Broker"><a href="#Broker" class="headerlink" title="Broker"></a>Broker</h3><p><img src="/images/Kafka源码导入Idea/Kafka.png" alt=""></p><h3 id="Consumer"><a href="#Consumer" class="headerlink" title="Consumer"></a>Consumer</h3><p><strong>Program arguments可根据自己的情况修改</strong><br><img src="/images/Kafka源码导入Idea/consumer.png" alt=""></p><h3 id="produer"><a href="#produer" class="headerlink" title="produer"></a>produer</h3><p><strong>Program arguments可根据自己的情况修改</strong><br><img src="/images/Kafka源码导入Idea/producer.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;虽然网上教程很多，但是我依然要写系列&lt;br&gt;因为我踩到的坑有的是网上没有遇到过的&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kafka" scheme="https://blog.lovezhy.cc/categories/Kafka/"/>
    
    
      <category term="Kafka" scheme="https://blog.lovezhy.cc/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Kafka时间轮实现</title>
    <link href="https://blog.lovezhy.cc/2020/01/11/Kafka%E6%97%B6%E9%97%B4%E8%BD%AE%E5%AE%9E%E7%8E%B0/"/>
    <id>https://blog.lovezhy.cc/2020/01/11/Kafka%E6%97%B6%E9%97%B4%E8%BD%AE%E5%AE%9E%E7%8E%B0/</id>
    <published>2020-01-10T16:00:00.000Z</published>
    <updated>2020-02-23T10:27:41.079Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Kafka延迟任务的实现</p><a id="more"></a><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>延迟任务的实现，一般是利用有序队列，按照执行时间的顺序排列，然后有个线程不断的去取第一个元素，如果到了需要执行的时间，就去执行。</p><p>伪代码：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Delay</span> </span>&#123;</span><br><span class="line">    Queue&lt;Comparable&gt; taskQueue;</span><br><span class="line">    </span><br><span class="line">    <span class="function">func <span class="title">add</span><span class="params">(Comparable task)</span> </span>&#123;</span><br><span class="line">        taskQueue.add(task);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function">func <span class="title">pollAndRun</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">                var task = taskQueue.peek();</span><br><span class="line">                <span class="keyword">if</span> (task.expireTime &lt;= System.currentTime) &#123;</span><br><span class="line">                    run(taskQueue.poll());</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    Thread.sleep(task.expireTime - System.currentTime);</span><br><span class="line">                &#125;</span><br><span class="line">        &#125; </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><strong>注意：这里的伪代码不完善，在add方法中，一般来说在某种情况下要interrupt执行pollAndRun的线程。</strong></p><p>目前聚焦的主要问题是Queue是怎么个实现法。<br>在Java中有优先权队列可以进行排序，底层是基于最小堆做的，插入和删除的时间复杂度是O(logn)</p><p>当然正常情况下，这种实现可以了，Java中的标准实现也是这样。</p><p>但是呢，Kafka中有大量的<strong>低延迟</strong>的任务，如果都用最小堆去做，难免性能不太好<br>所以Kafka中实现了时间轮的算法，将插入和删除的时间复杂度降低到了O(1)。</p><p>下面细讲下实现：</p><h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><p>源码路径在：<code>package kafka.utils.timer</code>下。</p><h3 id="TimerTask"><a href="#TimerTask" class="headerlink" title="TimerTask"></a>TimerTask</h3><p>Task是队列中的执行元素</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">trait TimerTask extends Runnable &#123;</span><br><span class="line">    val delayMs: Long </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>实现了Runnable接口，delayMs是指的需要被执行的时间戳，不是相对时间</p><h3 id="TimerTaskList"><a href="#TimerTaskList" class="headerlink" title="TimerTaskList"></a>TimerTaskList</h3><p>看名字就知道是存储Task的集合类</p><p>但是其实它的定义并没有我开始想的那么简单</p><p>TimerTask在TimerTaskList内部的存储形式是双向链表</p><p>所以TimerTask其实被TimerTaskEntry的类包装了一层，增加了Prev和Next指针。</p><p><img src="/images/Kafka时间轮/TimerTaskList.png"></p><p>但是注意哦，这里虽然TimerTask实现了Comparable接口，但是TimerTaskList内部其实就是个简单的双向列表，并不会根据TimerTask的expireTime进行排序。</p><p>恰恰相反，TimerTaskList也实现了Comparable接口。</p><p>在TimerTaskList内部，有一个变量</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[<span class="keyword">this</span>] val expiration = <span class="keyword">new</span> AtomicLong(-<span class="number">1L</span>)</span><br></pre></td></tr></table></figure><p>从名字中看出其实是存放的是到期时间，TimerTask有过期时间我们可以理解，那么为什么TimerTaskList也有个过期时间？</p><p>这个过期时间是怎么定的，有什么用？</p><h3 id="TimingWheel"><a href="#TimingWheel" class="headerlink" title="TimingWheel"></a>TimingWheel</h3><p>来了，时间轮最主要的数据结构来了。</p><p><img src="/images/Kafka时间轮/TimerWheel.png"></p><p>首先，看图中，模仿了一个钟表的运行图。<br>每tick一下，就把当前指针指向下一个格子。<br>其中每个格子对应着一个TimerTaskList</p><p>格子在Kafka中叫bucket<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val buckets = Array.tabulate[TimerTaskList](wheelSize) &#123; _ =&gt; <span class="keyword">new</span> TimerTaskList(taskCounter) &#125;</span><br></pre></td></tr></table></figure></p><p>每一格代表的时间叫TickMs，整个表最长的跨度叫Interval。</p><p>如果TickMs=5，Bucket=4，就表示这个时间轮有4个格子，总共能执行20ms内的延迟任务，同时TickMs也就是该时间轮保证的延迟任务的延迟执行的单位。</p><p>什么意思呢？就是说如果一个任务是2ms后执行，一个是4ms后执行，但是整个时间轮的TickMs是5ms，那么这两个任务在时间轮看来其实是没区别，是同时执行。</p><p>所以时间轮的TickMs最小，时间就越精确。</p><p>如果延迟时间超过了该时间轮的Interval怎么办？</p><p>比如执行50ms后才运行的任务，则需要建立跨度更大的时间轮。</p><p>而Kafka中会自动建立跨度更大的时间轮，叫overflowWheel，<strong>更大的时间轮的TickMs是下一层的Interval</strong>。</p><p>看到这里，其实可以解答TimerTaskList中的expiration有什么用了。</p><p>这里的expiration其实就是整个TimerTaskList的过期时间，是TickMs的整数倍</p><p>与在TimerTaskList中每个Task的具体延迟时间关系是</p><p><code>TimerTaskList.expiration &lt;= Task.expiration &lt;= TimerTaskList.expiration + TickMs</code></p><p>在Kafka中，默认的时间轮配置TickMs=1，Bucket=20，也就是20MS内的延迟任务。</p><h2 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h2><p>讲完了数据结构，下面需要讲怎么运行了。<br>TimingWheel的运行，交给了Timer来操作。<br>Timer有两个方法<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//往时间轮中加入任务</span></span><br><span class="line"><span class="function">def <span class="title">add</span><span class="params">(timerTask: TimerTask)</span></span>&#123;&#125;</span><br><span class="line"><span class="comment">//驱动时间轮向前Tick</span></span><br><span class="line"><span class="function">def <span class="title">advanceClock</span><span class="params">(timeoutMs: Long)</span></span>&#123;&#125;</span><br></pre></td></tr></table></figure></p><h3 id="菜鸡的猜想方案"><a href="#菜鸡的猜想方案" class="headerlink" title="菜鸡的猜想方案"></a>菜鸡的猜想方案</h3><p>让我们暂时脱离源码，猜猜时间轮怎么运行的。</p><p><img src="/images/Kafka时间轮/tick.png" alt=""></p><p>正常来说，我们把任务分到具体的Bucket中，每隔一个TickMs，将当前的指针向下运行一格。</p><p>找到这一格中的TimerTaskList，将里面的任务全部拿出来run一遍。</p><p>伪代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">List&lt;TimerTaskList&gt; buckets;</span><br><span class="line"><span class="keyword">int</span> nextBucket;</span><br><span class="line"><span class="function">func <span class="title">tick</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  var timerTaskList = buckets.get(nextBucket % buckets.length)</span><br><span class="line">  <span class="keyword">if</span> (timerTaskList.expiration &lt;= System.currentTime) &#123;</span><br><span class="line">    timerTaskList.timerTaskEntrys.foreach(entry -&gt; entry.run()));</span><br><span class="line">    timerTaskList.timerTaskEntrys.foreach(TimerTaskList::remove);</span><br><span class="line">    nextBucket++;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在add元素的时候，先需要判断当前的时间轮是否能承载延迟时间，如果不能，则建立overflowWheel，加到overflowWheel中。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">List&lt;TimerTaskList&gt; buckets;</span><br><span class="line"><span class="function">func <span class="title">add</span><span class="params">(taskEntry)</span> </span>&#123;</span><br><span class="line">  var targetBucketId = (taskEntry.expiration - System.time) / tickMs + nextBucket;</span><br><span class="line">  var timerTaskList = buckets.get(targetBucketId % buckets.length)</span><br><span class="line">  timerTaskList.add(taskEntry);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>看起来非常完美，但是问题来了，这个tick函数，怎么个运行策略呢？</p><p>如果要要跑的非常精确的话，必须要有个线程去单独驱动是肯定的，线程里还得这么跑</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//1</span></span><br><span class="line"><span class="function">func <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">    timer.tick()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//2</span></span><br><span class="line"><span class="function">func <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">    timer.tick()</span><br><span class="line">    sleep(timer.tickms)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>有方案1和方案2两种，第二种肯定是有问题的，如果出现了FullGC的情况，那么整个时间轮就不准了。</p><p>只能选择第一种方案，那么第一种肯定是不行的，这样CPU就是100%了，即使时间轮中没有任何任务，很多时间都是无用功，太浪费CPU了。</p><p>其实这里还有个很严重的问题，我们没有考虑overflowWheel。</p><p>正常情况下，在overflowWheel中的任务，如果已经到了下一层TimingWheel的interval范围内，是需要手动放到下一层的。</p><p>如果是这种实现的话，对于overflowWheel的处理会更加的复杂。</p><h3 id="Kafka中的实现"><a href="#Kafka中的实现" class="headerlink" title="Kafka中的实现"></a>Kafka中的实现</h3><p>菜鸡的猜想方案是不行的，面试都是直接挂的节奏。</p><p>所以这种思路是不成立的，那么我们能不能换个思路呢？</p><p>我们沿用最基本的最小堆来实现延迟任务的思路，建立一个优先权队列</p><p>但是队列中的元素不再是TimerTask了，而是TimerTaskList，相比较最原始的方案，队列中的元素少了一个数量级。</p><p>这样，每次单独的线程进行Tick的时候，选出最早需要执行的TimerTaskList，如果还没到执行时间，就可以进行Sleep，而不是占满CPU。</p><p>所以在TimingWheel中增加一个数据结构</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">var queue = <span class="keyword">new</span> PriorityQueue&lt;TimerTaskList&gt;()</span><br></pre></td></tr></table></figure><p>每次进行add时，除了把TaskEntry添加到TimerTaskEntry中，还将TimerTaskList添加到queue中。</p><p>这样线程的驱动函数就是这么写：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">func <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">    var timerTaskList = timer.queue.poll();</span><br><span class="line">    <span class="keyword">if</span> (timerTaskList.expiration &lt; System.time) &#123;</span><br><span class="line">      sleep(System.time - timerTaskList.expiration);</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>虽然也使用了插入是O(logn)的最小堆结构，但是堆中元素不再是全量的Task了，而是TaskList，所以时间复杂度其实类似于O(1)了。</p><p>那么对于overflowWheel里面的Task怎么处理呢？</p><p>很简单，和第一层的timingWheel一样，将overFlowWheel中的TimerTaskList也加到queue中</p><p>但是从Queue取出的时候，就不是立即执行了，而是再走一遍add程序</p><p>下面是源码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">//类似于源代码中nextBuckets的作用，这里是绝对时间，startMs是时间轮的开始的绝对时间，这里计算成tickMs的整数倍</span><br><span class="line">private[this] var currentTime = startMs - (startMs % tickMs)</span><br><span class="line"></span><br><span class="line">//向时间轮中加入任务</span><br><span class="line">def add(timerTaskEntry: TimerTaskEntry): Boolean = &#123;</span><br><span class="line">   val expiration = timerTaskEntry.expirationMs</span><br><span class="line">   if (timerTaskEntry.cancelled) &#123;</span><br><span class="line">     //如果任务已经取消，添加失败，可以直接实行</span><br><span class="line">     false</span><br><span class="line">   &#125; else if (expiration &lt; currentTime + tickMs) &#123;</span><br><span class="line">     //如果已经到执行时间，那么也是可以直接执行</span><br><span class="line">     false</span><br><span class="line">   &#125; else if (expiration &lt; currentTime + interval) &#123;</span><br><span class="line">           //这里其实还挺难理解的，如果我们按照钟表的概念，指针每隔一段时间去转动一下，就很难理解下面的代码</span><br><span class="line">           //这里其实就是每隔tickMs，指针不转，整个表顺时针转tickMs圈</span><br><span class="line">     val virtualId = expiration / tickMs</span><br><span class="line">     val bucket = buckets((virtualId % wheelSize.toLong).toInt)</span><br><span class="line">     bucket.add(timerTaskEntry)</span><br><span class="line"></span><br><span class="line">     if (bucket.setExpiration(virtualId * tickMs)) &#123;</span><br><span class="line">       //如果Bucket的失效时间设置成功，就把这个TimerTaskList加入到queue中</span><br><span class="line">       queue.offer(bucket)</span><br><span class="line">     &#125;</span><br><span class="line">     true</span><br><span class="line">   &#125; else &#123;</span><br><span class="line">     //放不下，建立overflowWheel，overflowWheel和当前timingWheel公用一个queue</span><br><span class="line">     if (overflowWheel == null) addOverflowWheel()</span><br><span class="line">     overflowWheel.add(timerTaskEntry)</span><br><span class="line">   &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>timingWheel的advanceClock代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def advanceClock(timeMs: Long): Unit = &#123;</span><br><span class="line">  if (timeMs &gt;= currentTime + tickMs) &#123;</span><br><span class="line">    currentTime = timeMs - (timeMs % tickMs)</span><br><span class="line">    if (overflowWheel != null) overflowWheel.advanceClock(currentTime)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>主要就是调整下currentTime，其实currentTime在有了queue之后，就没有其他作用了，主要就是在add方法中拦住即将过期或者已经过期的任务</p><p>下面是伪代码中的run方法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">def advanceClock(timeoutMs: Long): Boolean = &#123;</span><br><span class="line">   var bucket = delayQueue.poll(timeoutMs, TimeUnit.MILLISECONDS)</span><br><span class="line">   if (bucket != null) &#123;</span><br><span class="line">     writeLock.lock()</span><br><span class="line">     try &#123;</span><br><span class="line">       while (bucket != null) &#123;</span><br><span class="line">         timingWheel.advanceClock(bucket.getExpiration())</span><br><span class="line">         //这里不能把bucket中的任务全部执行，因为可能是overFlowWheel中的TimerTaskList，还没到执行时间，直接再走一遍add程序</span><br><span class="line">         bucket.flush(reinsert)</span><br><span class="line">         bucket = delayQueue.poll()</span><br><span class="line">       &#125;</span><br><span class="line">     &#125; finally &#123;</span><br><span class="line">       writeLock.unlock()</span><br><span class="line">     &#125;</span><br><span class="line">     true</span><br><span class="line">   &#125; else &#123;</span><br><span class="line">     false</span><br><span class="line">   &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>注意一下这里的delayQueue，其中poll方法返回的是过期的任务，并不是集合中第一个元素。</p><p>也就是说，即使queue中元素，但是没有元素要过期，返回的也是null。</p><p>当时作者在哪儿晕了半天。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;Kafka延迟任务的实现&lt;/p&gt;
    
    </summary>
    
    
      <category term="Kafka" scheme="https://blog.lovezhy.cc/categories/Kafka/"/>
    
    
      <category term="kafka" scheme="https://blog.lovezhy.cc/tags/kafka/"/>
    
      <category term="TimeWheel" scheme="https://blog.lovezhy.cc/tags/TimeWheel/"/>
    
      <category term="时间轮" scheme="https://blog.lovezhy.cc/tags/%E6%97%B6%E9%97%B4%E8%BD%AE/"/>
    
  </entry>
  
  <entry>
    <title>HotSpot原理指南-分层编译</title>
    <link href="https://blog.lovezhy.cc/2020/01/04/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-%E5%88%86%E5%B1%82%E7%BC%96%E8%AF%91/"/>
    <id>https://blog.lovezhy.cc/2020/01/04/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-%E5%88%86%E5%B1%82%E7%BC%96%E8%AF%91/</id>
    <published>2020-01-03T16:00:00.000Z</published>
    <updated>2020-02-23T10:29:32.477Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>HotSpot的初衷是将运行环境分为Client和Server，并且为他们定制了不同的JIT策略以及不同的JIT编译器（C1和C2）。</p><p>设计出ClientMode的年代，个人PC的性能还比较低，无论是CPU资源还是内存资源都比较稀少且价格较高，所以C1节约资源的快速编译是很有必要的。</p><p>随着时代的发展，个人计算机的配置在慢慢升级，同时价格也在慢慢降低，在这种环境下，ClientMode并不是那么适用了，所以HotSpot也就慢慢放弃了ClientMode，在个人计算机上默认采用Server模式。</p><a id="more"></a><h2 id="Oracle的想法"><a href="#Oracle的想法" class="headerlink" title="Oracle的想法"></a>Oracle的想法</h2><p>所有的场景都默认使用Server模式自然是没有什么问题的，但是Oracle并不甘心（作者脑补的），主要不甘心在两个方面：</p><ul><li>默认使用Server模式，那么相当于放弃了开发了很久的C1编译器</li><li>由于Server模式JIT编译策略问题，会导致应用的Warm-Up时间较长</li></ul><p>那么有没有什么方法可以结合C1和C2呢？</p><p>比如用C1解决Warm-Up时间过长的问题。</p><h2 id="分层编译"><a href="#分层编译" class="headerlink" title="分层编译"></a>分层编译</h2><p>前面提到过，Oracle想用C1解决Server模式中Warm-Up时间过长的问题，于是引入了分层编译的概念。</p><p>如下图所示：</p><p><img src="/images/HotSpot原理指南-分层编译/c1c2.png" alt=""></p><p>解释阶段主要是为了收集运行时Profile，Profile收集的越多，对JIT编译出的代码性能帮助越大。</p><p>先看上半部分图，如果我们采用传统的ServerMode运行，在一段时间X内，只能收集300份Profile，然后将这些Profile丢给C2去进行编译。</p><p>我们可以减少解释模式的运行时间，尽快用C1把字节码编译成机器码，用机器码去收集Profile。这就如下半部分图所示：</p><p>收集了100份Profile后，运行C1编译后的代码，在一段时间内，可以收集到更多的Profile。</p><p>上面是限制了收集Profile的时间是一定的，如果我们反过来，<strong>收集Profile的样本数是一定的</strong>：</p><ul><li>传统的Server模式，可能需要花费更多的时间进行收集到指定次数的样本</li><li>先利用C1进行代码编译，提升方法的运行速度，相对可以花费更少的时间进行收集</li></ul><p>如上的思想就是引入C1解决传统的ServerMode热身时间较少的问题，也就是分层编译：先采用C1进行编译，再采用C2进行编译。</p><p>具体的时间对比如下两张图所示：只使用C2 VS 分层编译</p><p><img src="/images/HotSpot原理指南-分层编译/only-c2.png" alt=""><br><img src="/images/HotSpot原理指南-分层编译/tier.png" alt=""></p><h2 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h2><p>分层编译在JDK7中就引入了，但是默认是不开启的</p><p>如果运行环境还是JDK7，可以使用<code>-XX:+TieredCompilation</code>开启</p><p>在JDK8中，分层编译就默认开启了，如果要关闭它，可以使用<code>-XX:-TieredCompilation</code>关闭</p><h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><p>正常的话，只要理解到上面就够了，分层大概分为两层，先是C1，然后是C2。</p><p>但是事实上，我们如果查看以Tier开头的HotSpot参数的话，会发现其包含的参数很多很多</p><p><img src="/images/HotSpot原理指南-分层编译/参数.png" alt=""></p><p>笔者第一次搜索出来时，实在是吃了一惊。<br>经过研究，其实发现分层编译，并不是分了两层，而是足足分了<strong>4</strong>层。</p><ul><li>第0层：解释阶段</li><li>第1-3层：C1编译<ul><li>第1层：C1编译出的<strong>不收集任何Profile</strong>的机器码</li><li>第2层：C1编译出的<strong>仅仅收集方法调用计数</strong>的机器码</li><li>第3层：C1编译出的<strong>收集全部Profile</strong>的机器码</li></ul></li><li>第4层：C2编译</li></ul><p>可以看到，在C1编译的阶段，还拆分成了三个小的阶段。<br>同时，对于这三个小的阶段，需要理解的是，<strong>运行上并不是递进关系</strong>，也就是说并不是先运行第1层，再运行第2层，再运行第3层。具体怎么运行，其实和很多因素有关。<br>我们先看看有哪些经典的分层流程：</p><p><img src="/images/HotSpot原理指南-分层编译/4个阶段.png" alt=""><br>如上图所示。</p><ul><li>流程1：正常的方法的编译流程，先是解释执行，然后直接跳到第3阶段，也就是C1编译出的收集全部Profile的机器码。然后再跳到第4层，也就是C2编译。深色的框表示是编译的终止阶段。</li><li>流程2：但是，如果第3层的等待队列太长，可能就先提交到第2层进行编译，等待一段时间后，再提交给第3层</li><li>流程3：如果该方法比较简单，是个Trivial方法，比如Getter方法，这种方法去收集Profile其实没有什么Profile，给C2去进行编译纯属于浪费资源，所以提交给第3层后，直接给第1层，然后终止。</li><li>流程4：同样也是Trivial方法，如果在解释阶段就发现其比较简单，也可以直接提交给第1层编译</li></ul><p>以上是一些经典的流程，还有一些流程，比如从解释阶段可以直接提交给C2等。</p><p>所以，虽说是分层编译，但是具体的编译流程是不确定的，这个各个编译器的状态以及方法的属性有关。</p><h2 id="C1和C2编译线程数"><a href="#C1和C2编译线程数" class="headerlink" title="C1和C2编译线程数"></a>C1和C2编译线程数</h2><p>各个编译的状态，最简单的就是负责编译的线程数<br>HotSpot分配给C1和C2编译器的线程数，和<strong>指定的启动参数</strong>以及<strong>机器的核心数</strong>有关。</p><p>启动参数：影响线程数的参数有CICompilerCount和CICompilerCountPerCPU两个，默认值如下，一般不会去改这些<br><img src="/images/HotSpot原理指南-分层编译/启动参数.png" alt=""></p><p>有了参数之后，具体的分配代码如下：<br><img src="/images/HotSpot原理指南-分层编译/启动参数2.png" alt=""></p><p>简单聊聊分配策略：</p><ul><li>C1+C2的总的线程数：log2(log2(CoreNum)) * 3 / 2</li><li>C1 / C2 = 1 / 2</li><li>C1和C2至少有一个线程</li></ul><p>下面表格简单显示了一些常见情况</p><table><thead><tr><th>CPU Core</th><th>C1</th><th>C2</th></tr></thead><tbody><tr><td>4</td><td>1</td><td>2</td></tr><tr><td>8</td><td>1</td><td>3</td></tr><tr><td>16</td><td>4</td><td>8</td></tr><tr><td>32</td><td>5</td><td>10</td></tr><tr><td>64</td><td>6</td><td>12</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;HotSpot的初衷是将运行环境分为Client和Server，并且为他们定制了不同的JIT策略以及不同的JIT编译器（C1和C2）。&lt;/p&gt;
&lt;p&gt;设计出ClientMode的年代，个人PC的性能还比较低，无论是CPU资源还是内存资源都比较稀少且价格较高，所以C1节约资源的快速编译是很有必要的。&lt;/p&gt;
&lt;p&gt;随着时代的发展，个人计算机的配置在慢慢升级，同时价格也在慢慢降低，在这种环境下，ClientMode并不是那么适用了，所以HotSpot也就慢慢放弃了ClientMode，在个人计算机上默认采用Server模式。&lt;/p&gt;
    
    </summary>
    
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/categories/HotSpot/"/>
    
    
      <category term="Java" scheme="https://blog.lovezhy.cc/tags/Java/"/>
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/tags/HotSpot/"/>
    
      <category term="JIT" scheme="https://blog.lovezhy.cc/tags/JIT/"/>
    
      <category term="JVM" scheme="https://blog.lovezhy.cc/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>HotSpot原理指南-JIT触发条件</title>
    <link href="https://blog.lovezhy.cc/2019/12/14/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-JIT%E8%A7%A6%E5%8F%91%E6%9D%A1%E4%BB%B6/"/>
    <id>https://blog.lovezhy.cc/2019/12/14/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-JIT%E8%A7%A6%E5%8F%91%E6%9D%A1%E4%BB%B6/</id>
    <published>2019-12-13T16:00:00.000Z</published>
    <updated>2020-02-23T10:29:45.890Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>通过前面我们知道，对于每个方法，HotSpot都维护两个计数器</p><ul><li>Invocation Counter：方法被调用次数，每被调用一次都会+1</li><li>BackEdge Counter：专业的说法就是字节码在执行时的回跳次数。通俗点说就是，在For或者While循环中，每执行一次，都会+1。</li></ul><p>并且我们知道对于一个方法，JIT有两种不同的编译方式</p><ul><li>完整的原方法编译，就是把原本的方法逻辑进行编译。入参和运行结果和解释运行都是一致的。</li><li>OSR编译，OSR后的方法入参以及运行流程和原方法有较大差异。</li></ul><p>很自然得我们就会想到，其实计数器和编译方式之间是有对应关系的。</p><ul><li>Invocation Counter -&gt; 完整的原方法编译</li><li>BackEdge Counter  -&gt; OSR编译</li></ul><p>当对应的方法计数器达到一定的次数，就会触发响应的编译</p><a id="more"></a><h2 id="编译流程图"><a href="#编译流程图" class="headerlink" title="编译流程图"></a>编译流程图</h2><p>完整的编译流程如下：</p><p><img src="/images/HotSpot原理指南-JIT触发条件/编译流程.png" alt=""></p><p><strong>注：该图引自R大的JVM分享PPT，如有侵权，请联系我删除</strong></p><p>图中的流程非常的清晰，这里提几个小点：</p><ul><li><p>问：对于同一方法，是否两种编译方式都可能会执行？</p><p>答：是的，而且两种代码可能同时被运行，但是正常情况下，只要运行的够久，都会运行完整的原方法编译后的代码。</p></li><li><p>问：具体哪种编译方式先触发？</p><p>答：其实无法确定，看哪个计数器先达到阈值</p></li></ul><h2 id="触发阈值"><a href="#触发阈值" class="headerlink" title="触发阈值"></a>触发阈值</h2><p>可能你还想更直观的了解下两个计数器的触发阈值到底是多少。</p><p>在HotSpot源码中，有这样两个参数：</p><ul><li><blockquote><p>intx CompileThreshold = 10000</p><p>globals.hpp &gt; ”number of interpreted method invocations before (re-)compiling” </p></blockquote></li><li><blockquote><p>intx BackEdgeThreshold = 100000</p><p>globals.hpp &gt; “Interpreter Back edge threshold at which an OSR compilation is invoked”</p></blockquote></li></ul><p>数值可能根据不同的发行版本略有不同，上面的数值是JDK7版本中的。</p><p>那么你可能以为</p><ul><li>当Invocation Counter &gt; Compile Threshold时，就会触发原来方法的JIT</li><li>当BackEdge Counter &gt; BackEdge Threshold时，就会触发方法的OSR编译</li></ul><p>但是事实并不是如此。</p><p>问题出在哪儿呢？难道官方的定义还会有错吗？</p><p>是的，问题出在BackEdgeThreshold上，虽然HotSpot中确实定义了该参数，描述中似乎也证实了该参数的作用，但是这个参数并没有实际使用过。</p><p>对于BackEdgeThreshold的计算，是另外一套公示。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (ProfileInterpreter) &#123;</span><br><span class="line">  InterpreterBackwardBranchLimit = </span><br><span class="line">                 (CompileThreshold * (OnStackReplacePercentage - InterpreterProfilePercentage)) / <span class="number">100</span>;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  InterpreterBackwardBranchLimit = </span><br><span class="line">                ((CompileThreshold * OnStackReplacePercentage) / <span class="number">100</span>) &lt;&lt; number_of_noncount_bits;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>首先解释下<code>ProfileInterpreter</code>参数，这个参数也是在HotSpot中定义的，之前在文章<code>HotSpot原理指南-C1和C2介绍</code>中也讲解过，就是是否在运行时收集方法的Profile信息，这个字段在Server模式默认是开启的。</p><p>所以大部分情况下，除非你的计算机比较老，都会根据第一个公示进行计算</p><p><code>(CompileThreshold * (OnStackReplacePercentage - InterpreterProfilePercentage)) / 100</code></p><p>其中<strong>OnStackReplacePercentage</strong>默认值是140，<strong>InterpreterProfilePercentage</strong>默认值是33。</p><p>由此我们可以计算出真实的BackEdge Invocation阈值大概是10700左右。</p><h2 id="衰减"><a href="#衰减" class="headerlink" title="衰减"></a>衰减</h2><p>假如方法计数器不会根据时间进行衰减的话，那么只要服务器运行的时间足够长，再罕见被调用的函数，也会触发到阈值，然后被JIT编译。</p><p>这显然是不合理的，因为我们知道JIT后的机器码数据，还是会保存在内存中的，这样相当于一段逻辑在内存中又保存了字节码，又保存了一份机器码，十分的浪费内存。</p><p>所以对于Invocation Counter而言，经过一段时间，个数就会进行减少。</p><p>具体的减少逻辑，读者有兴趣的可以自己去探索。</p><p>但是注意：对于BackEdge Counter，是不会作衰减的。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;通过前面我们知道，对于每个方法，HotSpot都维护两个计数器&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Invocation Counter：方法被调用次数，每被调用一次都会+1&lt;/li&gt;
&lt;li&gt;BackEdge Counter：专业的说法就是字节码在执行时的回跳次数。通俗点说就是，在For或者While循环中，每执行一次，都会+1。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;并且我们知道对于一个方法，JIT有两种不同的编译方式&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;完整的原方法编译，就是把原本的方法逻辑进行编译。入参和运行结果和解释运行都是一致的。&lt;/li&gt;
&lt;li&gt;OSR编译，OSR后的方法入参以及运行流程和原方法有较大差异。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;很自然得我们就会想到，其实计数器和编译方式之间是有对应关系的。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Invocation Counter -&amp;gt; 完整的原方法编译&lt;/li&gt;
&lt;li&gt;BackEdge Counter  -&amp;gt; OSR编译&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当对应的方法计数器达到一定的次数，就会触发响应的编译&lt;/p&gt;
    
    </summary>
    
    
      <category term="编程" scheme="https://blog.lovezhy.cc/categories/%E7%BC%96%E7%A8%8B/"/>
    
    
      <category term="Java" scheme="https://blog.lovezhy.cc/tags/Java/"/>
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/tags/HotSpot/"/>
    
      <category term="JIT" scheme="https://blog.lovezhy.cc/tags/JIT/"/>
    
  </entry>
  
  <entry>
    <title>HotSpot原理指南-OSR是什么</title>
    <link href="https://blog.lovezhy.cc/2019/11/30/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-OSR%E6%98%AF%E4%BB%80%E4%B9%88/"/>
    <id>https://blog.lovezhy.cc/2019/11/30/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-OSR%E6%98%AF%E4%BB%80%E4%B9%88/</id>
    <published>2019-11-29T16:00:00.000Z</published>
    <updated>2020-02-23T10:29:52.967Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>前面我们讲解了C1和C2的基本知识，但是我们还未触及一个核心的策略，就是<strong>什么时候触发即使编译</strong>，也就是<strong>when</strong>的问题。</p><p>对于when的问题，相信大家多多少少都大概知道，每个方法都会有一个调用次数的计数器，当这个计数器的次数到达一定的次数时，就会被认为是热点方法，继而触发JIT编译。</p><p>但是本文要科普另外一种触发条件，和方法计数器类似。</p><a id="more"></a><h2 id="方法计数器的问题"><a href="#方法计数器的问题" class="headerlink" title="方法计数器的问题"></a>方法计数器的问题</h2><p>大部分人看来，维护一个方法被调用次数计数器当然是一个很完美的方案</p><p>但是有一类方法，即使在我们认知范围内，属于热点方法，但是却无法享受到这个计数器的好处。</p><p>如下代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OSRExample</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">200000</span>; i++) &#123;</span><br><span class="line">            <span class="comment">//do a lot of things</span></span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(sum);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在Main函数中，有一个循环，在循环中并没有调用某个方法，而是一直在线性执行一些逻辑。</p><p>假如我们把循环中的逻辑看做一个函数，这个函数肯定是热点函数，需要进行JIT编译的，但是在这种场景下，并不是一个函数，也就是无法进行JIT。</p><p>如果JIT无法处理这种情况，将是非常可惜的。</p><h2 id="Hot-Loop优化"><a href="#Hot-Loop优化" class="headerlink" title="Hot Loop优化"></a>Hot Loop优化</h2><p>但是如果我们构造一个上面的代码的情况，并且使用计数器给每次循环的执行时间进行计时。</p><p>会发现下面这张时间和次数的图</p><p><img src="/images/HotSpot原理指南-OSR是什么/hotLoop耗时.png" alt=""></p><p>从图中我们可以看出，大概在150次的时候，整个Loop的耗时突发的大大降低。</p><p>说明在HotSpot的JIT中，是可以处理这种情况的。</p><p>那么HotSpot究竟是怎么做的呢？</p><p>前面我们提到过，如果在Loop中调用的是方法，将不会存在上述的问题，但是实际的情况并不是调用的方法。</p><p>那么，我们能不能，把它包装成一个函数呢？</p><p>举个例子，原方法如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OSRExample</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">20000</span>; i++) &#123;</span><br><span class="line">            sum += i;</span><br><span class="line">          sum *= sum;</span><br><span class="line">          sum |= sum;</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(sum);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们把它改成如下的方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OSRExample</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">20000</span>; i++) &#123;</span><br><span class="line">sum = doLoop(sum);</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(sum);</span><br><span class="line">    &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">doLoop</span><span class="params">(<span class="keyword">int</span> sum)</span> </span>&#123;</span><br><span class="line">      sum += i;</span><br><span class="line">      sum *= sum;</span><br><span class="line">      sum |= sum;</span><br><span class="line">      <span class="keyword">return</span> sum;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样可以不可以呢？</p><p>当然是可以的。</p><p>但是！这是作者的猜测，HotSpot真实的情况并不是这样。</p><p>事实上，这种割裂整个main方法，动态把一部分代码进行修改的操作似乎消耗太大了，性价比并不高。</p><p>HotSpot并不会把Loop的内容动态生成一个函数，然后对该函数进行JIT。</p><p>而是对包含这个Loop的<strong>整个方法进行了JIT</strong>。</p><p>什么？对整个方法进行JIT？</p><p>要知道，这个方法在运行中啊，可能再也不会运行第二次，对整个方法进行JIT有什么意义呢？</p><p>稍安勿躁，虽然对整个方法进行了JIT，但是JIT后的代码和原来的函数其实还是有区别的。</p><p>如果我们需要将运行到一半的函数，从一个源代码替换到另外一个源代码，遇到的问题是什么呢？</p><p>首先，这个方法的循环执行到一半，这个i的具体数值肯定不是0了，是一个不可预测的值。</p><p>同时这个sum的值，肯定也是一个不好预测的值。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">20000</span>; i++) &#123;</span><br><span class="line">sum = doLoop(sum);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果要进行替换，需要把替换时的i和sum的值记录下来，那么替换后的源代码大概就长这样</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">public static void main#jit(int i, int sum) &#123;</span><br><span class="line"><span class="keyword">for</span> (; i &lt; <span class="number">20000</span>; i++) &#123;</span><br><span class="line">        sum += i;</span><br><span class="line">      sum *= sum;</span><br><span class="line">      sum |= sum;</span><br><span class="line">    &#125;</span><br><span class="line">    System.out.println(sum);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>没错！把运行中动态的值作为参数传给JIT后的函数，就是HotSpot的JIT对于这种HotLoop的优化。</p><h2 id="OSR"><a href="#OSR" class="headerlink" title="OSR"></a>OSR</h2><p>OSR的全称是On-Stack-Replacement。也就是栈上替换。</p><p>从上一节我们了解的可以知道，对于main函数，JIT进行编译的时候，直接把运行中的main函数源代码进行了替换，替换成了修改后的main函数。那么之前的main函数栈帧其实就完全失效了，被替换成了新的函数的栈帧。</p><p>这种JIT编译的方式就叫OSR编译。</p><p>这种栈上替换的方式其实并不是HotSpot独有的，很多其他的语言中也有这样的优化，如V8。</p><h2 id="后续问题"><a href="#后续问题" class="headerlink" title="后续问题"></a>后续问题</h2><p>OSR能够解决HotLoop的优化问题，但是其实在HotSpot中还是有几个值得深究的点。</p><ol><li><p>如果这个main函数方法非常大，Loop只是很小的一部分，那么把整个函数进行JIT编译的性价比就值得商榷了。核心问题其实是，为什么必须要编译整个方法呢？</p><p>这个问题R大也给了我们解释，详细看文章</p><p><a href="https://github.com/AdoptOpenJDK/jitwatch/wiki/Understanding-the-On-Stack-Replacement-(OSR)-optimisation-in-the-HotSpot-C1-compiler" target="_blank" rel="noopener">https://github.com/AdoptOpenJDK/jitwatch/wiki/Understanding-the-On-Stack-Replacement-(OSR)-optimisation-in-the-HotSpot-C1-compiler</a></p></li><li><p>OSR其实并不是完美的解决方案，在某些场景下它会生成非常丑陋的代码，如果有多个Loop或者Loop进行嵌套的方法。</p><p>HotSpot在一篇文章中进行了解释，有兴趣可以看文章</p><p><a href="https://www.h2o.ai/blog/what-the-heck-is-osr-and-why-is-it-bad-or-good/" target="_blank" rel="noopener">What ths heck is osr and why is it bad or good?</a></p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;前面我们讲解了C1和C2的基本知识，但是我们还未触及一个核心的策略，就是&lt;strong&gt;什么时候触发即使编译&lt;/strong&gt;，也就是&lt;strong&gt;when&lt;/strong&gt;的问题。&lt;/p&gt;
&lt;p&gt;对于when的问题，相信大家多多少少都大概知道，每个方法都会有一个调用次数的计数器，当这个计数器的次数到达一定的次数时，就会被认为是热点方法，继而触发JIT编译。&lt;/p&gt;
&lt;p&gt;但是本文要科普另外一种触发条件，和方法计数器类似。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Java" scheme="https://blog.lovezhy.cc/categories/Java/"/>
    
    
      <category term="Java" scheme="https://blog.lovezhy.cc/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>银行报考指北</title>
    <link href="https://blog.lovezhy.cc/2019/11/30/%E9%93%B6%E8%A1%8C%E6%8A%A5%E8%80%83%E6%8C%87%E5%8C%97/"/>
    <id>https://blog.lovezhy.cc/2019/11/30/%E9%93%B6%E8%A1%8C%E6%8A%A5%E8%80%83%E6%8C%87%E5%8C%97/</id>
    <published>2019-11-29T16:00:00.000Z</published>
    <updated>2020-02-23T10:28:41.472Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>看到标题，你可能会疑问，为什么我会去报考银行，我不是在互联网公司上班吗？难道是想逃离互联网回家养老去了？</p><a id="more"></a><p>当然，这个是个多因一果的事情。我确实报考了银行，并且顺利拿到了Offer。但是我并不是想逃离互联网，而是一次尝试，很大程度上只是去看看，顺便敷衍一下我妈。</p><p>当我说到敷衍我妈时，其实我比较伤心的，因为我妈一直觉得做技术太苦了，天天加班，不仅压力大，而且到了35岁会面临辞退的危险，所以希望我回家安安稳稳的过日子。</p><p>讲道理，我也有这种疑虑，但是目前并没有回家养老的意思，所以还是会继续留在南京上班。</p><p>扯了一堆，这次报考流程也算是踩了一次坑，这里记录下来，留给后人参考。</p><h2 id="报名"><a href="#报名" class="headerlink" title="报名"></a>报名</h2><p>一般我不会关注银行的招聘的，但是消息是我妈发给我的</p><p><a href="http://www.yinhangzhaopin.com/yzrcb/2019/0929/85386.html" target="_blank" rel="noopener">http://www.yinhangzhaopin.com/yzrcb/2019/0929/85386.html</a></p><p>后来我才发现原来有个网站专门就是收集各种银行招聘的信息。</p><p>报名在51Job上报名，上去填写一些资料就行了。</p><p>然后它会审核你的资料，算是一个初审，初审过了之后，会再发一封邮件给你告诉你初审过了，可以去缴费了。</p><p><img src="/images/银行报考指北/资料审核通过.png" alt=""></p><p>但是这个缴费网站，要到一定时间才会开通。</p><p>等到开通之后，登录到这个网站，付报名费，大概100块左右，然后选择考场。</p><p>这个考场并不是你报哪儿就必须去哪儿考试的。</p><p>比如我在南京，但是我报的是扬州的农商行，并不是一定要去扬州考试。他在每个城市都会有考点的。</p><p>在南京有4个考点，我记得有林业大学考点，金陵科技学院考点，还有两个记不得了。</p><p>我报的是金陵科技学院的考点。</p><p>好消息就是它考试是在周末考，这样如果是上学或者是上班的话，就不用请假了。</p><p>交完费之后，它还会给你一封邮件，让你准备笔试。</p><p><img src="/images/银行报考指北/笔试通知.png" alt=""></p><h2 id="考试"><a href="#考试" class="headerlink" title="考试"></a>考试</h2><p>周末那一天考试是从9：00到11：30。时间还是挺长的。</p><p>准考证需要提前打印好，然后考试带自己身份证就行了。也可以带一支笔，因为题目可能有数学题。</p><p>写到这个章节，你可能最想知道的是考试考什么题目。</p><p>题目其实是分岗位的，通用岗的我不是很清楚，我报的是科技岗，而且可能各个银行之间又不太一样。</p><p>首先题量很大。题型主要分为：</p><ul><li>找病句</li><li>句子排序</li><li>数学题。比如一排数字，让你找规律那种，那种题基本看一会儿看不出来就过吧</li><li>图形题。和公务员那种差不多，给三个奇怪的组合图形，然后让你选下一个和他们属性一致的图形是什么，这个看一会儿看不出来也过吧</li><li><p>材料题。给一些数据的图标，然后给4个选择题，让你从图标中找答案。还挺难找的。题量少。</p></li><li><p>英语题，缺词填空那种。大概有20道</p></li><li>计算机专业的题目。设计网络，操作系统，Java等。大概有80题。</li><li>考验智商的。比如给你个矩阵，会随机出现几个图形，5秒后消失，然后让你点击刚才出现的图形的位置。</li></ul><p>总而言之，有几点值得关注</p><ul><li>题量大。如果每道题都细做肯定来不及的，有点数学题不会就直接瞎选的。</li><li>不需要专业知识。我考之前有人和我说要很多经济学知识的，其实发现并不需要。</li></ul><p>我当时高估了自己，再加上其实去的意愿不高，做了一个半小时就赶紧溜了去上班了。</p><p>大概百分之60的题目，我都是瞎选的。</p><h2 id="面试"><a href="#面试" class="headerlink" title="面试"></a>面试</h2><p>其实我笔试考完觉得自己肯定挂了，但是过了两天打电话告诉我过了。</p><p>过了就过了吧，大概就是通知我去面试了。</p><p>让我周六去扬州交材料，周日面试。</p><p>我正好有朋友在扬州，所以就打算去顺便找他玩一下。</p><p>交材料的话，需要毕业证的复印件。身份证的正反面复印件，学信网的电子备案表的打印件。</p><p>周六去交了材料，顺便问了我的成绩。</p><p>傍晚的时候发短信通知我明天中午去面试。</p><p>我中午到的时候，发现大家都是穿正装来的，就我穿的花里胡哨的。心想大概率是凉了。</p><p>哈哈，所以这里提醒大家最好穿正装去面试，没有正装也穿个黑色的衣服去。</p><p>然后就是签到。</p><p>到了时间又让我们做了一个半小时的题目，题目大概和笔试的差不多，不知道这个是什么套路。</p><p>这个题目并不包括计算机的题目，我估计通用的和科技岗的都一样。</p><p>做完题目，需要把手机交上去，然后排队去面试。</p><p>流程是这样的，一个一个进去面试，当一个人进去时，后面一个人去等候区，等候区就一个人，有张桌子，上面有张纸，记着三个题目，有人给你计时4分钟，你看完题目想想怎么回答。</p><p>然后前一个出来时，你进去，然后对面三个面试官，面试官不会多对你说什么，你就把三个问题的答案说一遍就行。每个题目计时2分钟，说完也没有其他的问题，你就可以直接走了。</p><p>具体的题目其实和计算机的关系不大，属于需要总结概括的题目，需要的话可能私聊我。</p><p>面完就直接回去了，也没管什么。</p><h2 id="体检"><a href="#体检" class="headerlink" title="体检"></a>体检</h2><p>其实我面完之后感觉自己肯定差不多挂了，下面应该没后续流程了。</p><p>然后过了两天，大概是周二的时候，银行打电话告诉我过了面试。</p><p>下面的流程是体检，而且就在明天，银行的人问我能不能去。</p><p>我一想这也太突然了，我今天就得再去扬州，这也不太可能啊，所以我直接拒绝了。</p><p>以为这个机会就没了，但是她告诉我明天不去，那就等下一批的通知吧。</p><p>感情原来体检还是分批来的，我说好的。</p><p>其实我比较奇怪的地方是为什么直接去体检了，而不是先谈工资待遇啥的，这是明摆着面试通过了大家就肯定先去吗？</p><p>然后我问了在银行工作的同学，似乎他们都是这样的，都不知道具体的待遇什么的，都是上了一个月的班才知道具体的工资是多少。</p><p>这就有点坑了。</p><p>我回去也和我爸妈商量了下，我说我其实不太想回去。我爸妈也表示明白。</p><p>然后下一次打电话来的时候，我就直接拒绝了。</p><p>我以为银行的人会问问为什么，结果她直接说好的。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这次的银行面试经历就是如上了，我顺利的度过了笔试和面试，中间决定不去了。</p><p>整体上的体验一般般，流程拉的太长了，而且面试和体检都是在固定的地方，所以导致体验不会太好。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;看到标题，你可能会疑问，为什么我会去报考银行，我不是在互联网公司上班吗？难道是想逃离互联网回家养老去了？&lt;/p&gt;
    
    </summary>
    
    
      <category term="生活" scheme="https://blog.lovezhy.cc/categories/%E7%94%9F%E6%B4%BB/"/>
    
    
      <category term="生活" scheme="https://blog.lovezhy.cc/tags/%E7%94%9F%E6%B4%BB/"/>
    
  </entry>
  
  <entry>
    <title>HotSpot原理指南-内联</title>
    <link href="https://blog.lovezhy.cc/2019/11/28/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-%E5%86%85%E8%81%94/"/>
    <id>https://blog.lovezhy.cc/2019/11/28/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-%E5%86%85%E8%81%94/</id>
    <published>2019-11-27T16:00:00.000Z</published>
    <updated>2020-02-23T10:29:35.212Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>内联是编程语言编译器中常规的优化操作，几乎所有的语言在编译时或者在执行时都会有内联操作。</p><p>内联的本质是把几个方法合并成一个方法</p><p>从一方面讲，内联减少了函数调用的栈帧创建和销毁的时间消耗</p><p>从另一方面讲，内联为很多其他的优化方法提供了更多的可能，比如逃逸分析，无用代码消除，虚函数优化等，这也是内联被叫做<strong>优化之母</strong>（The Mother Of All Optimization）的原因。</p><a id="more"></a><h2 id="HotSpot-JIT"><a href="#HotSpot-JIT" class="headerlink" title="HotSpot-JIT"></a>HotSpot-JIT</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>对于HotSpot的JIT而言，内联是一个渐进的过程，这个渐进表现在两方面</p><ul><li>C1和C2两个JIT编译器的内联策略不同，C2可能更加激进一些</li><li>内联策略和很多因素有关<ul><li>内联发起函数大小，被内联函数大小</li><li>被内联函数的调用次数</li><li>内联深度</li><li>中间表示的NodeCount</li><li>函数方法签名</li></ul></li></ul><h3 id="初步体验"><a href="#初步体验" class="headerlink" title="初步体验"></a>初步体验</h3><p>先看一段代码，初步的了解下HotSpot的内联，以下代码的执行参数<code>-XX:CompileCommand=exclude,Inline.main</code></p><p>这个参数的意义是禁止<code>main</code>函数内联<code>inline</code>方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Inline</span> </span>&#123;</span><br><span class="line">  </span><br><span class="line"><span class="keyword">static</span> Random random = <span class="keyword">new</span> Random();</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span> ; i &lt; <span class="number">1000000</span>; i++) &#123;</span><br><span class="line">            inline();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">inline</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> add(random.nextInt(), </span><br><span class="line">               random.nextInt());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> a, <span class="keyword">int</span> b)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> a + b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="/images/HotSpot原理指南-内联/inline.png" alt="inline"></p><p>上图中展示了经过C2编译后，整个<code>inline</code>函数的内联状态</p><p>可以看到不仅仅内联了<code>random.nextInt()</code>方法，还将<code>nextInt</code>方法中的<code>next</code>方法等等好几个再下层的方法也内联了进来</p><h3 id="HotSpot参数"><a href="#HotSpot参数" class="headerlink" title="HotSpot参数"></a>HotSpot参数</h3><p><code>java -XX:+PrintFlagsFinal | grep &quot;Inlin&quot;</code></p><p><img src="/images/HotSpot原理指南-内联/内联参数.png" alt="内联参数"></p><p>可以看到HotSpot可以控制内联的参数很多很多，从侧面也表示HotSpot的内联策略是非常复杂的。</p><p>笔者也无法精通所有的内联策略，所以只挑选出比较重要的几个参数来讲解。</p><p>主要讲解如下几个参数</p><table><thead><tr><th>参数</th><th>默认值</th></tr></thead><tbody><tr><td>MaxTrivialSize</td><td>6</td></tr><tr><td>MaxInlineSize</td><td>35</td></tr><tr><td>FreqInlineSize</td><td>350</td></tr><tr><td>MinInliningThreshold</td><td>250</td></tr><tr><td>InlineSmallCode</td><td>1000(No-Tier)  2000(Tier)</td></tr><tr><td>MaxInlineLevel</td><td>9</td></tr><tr><td>MaxRecursiveInlineLevel</td><td>1</td></tr></tbody></table><h2 id="内联策略"><a href="#内联策略" class="headerlink" title="内联策略"></a>内联策略</h2><h3 id="MaxTrivialSize"><a href="#MaxTrivialSize" class="headerlink" title="MaxTrivialSize"></a>MaxTrivialSize</h3><p>对于Trivial方法，在HotSpot中有着严格的定义</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">bool</span> SimpleThresholdPolicy::is_trivial(Method* method) &#123;</span><br><span class="line">  <span class="keyword">if</span> (method-&gt;is_accessor() ||</span><br><span class="line">      method-&gt;is_constant_getter()) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (method-&gt;has_loops() || method-&gt;code_size() &gt;= <span class="number">15</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  MethodData* mdo = method-&gt;method_data();</span><br><span class="line">  <span class="keyword">if</span> (mdo != <span class="literal">NULL</span> &amp;&amp; !mdo-&gt;would_profile() &amp;&amp;</span><br><span class="line">      (method-&gt;code_size() &lt; <span class="number">5</span>  || (mdo-&gt;num_blocks() &lt; <span class="number">4</span>))) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从上面的代码可以看出，常见的Getter方法，肯定是trivial方法</p><p>而函数中有循环，或者函数大小超过15bytes，则不是trivial方法</p><p>对于trivial方法，如果它的函数字节码小于<strong>MaxTrivialSize</strong>，那么即使它在调用方至今一次也没有被执行过，HotSpot也会将它内联进来。</p><p>这是对于C1而言，对于C2而言，则不会进行内联，而是会生成<code>UnCommon Trap</code></p><h3 id="MaxInlineSize"><a href="#MaxInlineSize" class="headerlink" title="MaxInlineSize"></a>MaxInlineSize</h3><p>我们了解了MaxTrivialSize，那么对于MaxInlineSize则很容易理解。</p><p>对于调用方至少执行过一次的方法，如果它的大小小于MaxInlineSize，那么就会考虑将它内联进去</p><h3 id="FreqInlineSize和MinInliningThreshold"><a href="#FreqInlineSize和MinInliningThreshold" class="headerlink" title="FreqInlineSize和MinInliningThreshold"></a>FreqInlineSize和MinInliningThreshold</h3><p>了解了以上两个参数后，你可能会问，如果被调用的函数既不符合Trivial方法，大小也大于MaxInlineSize，但是这个方法非常的Hot，就没有机会被内联了吗</p><p>并不是，FreqInlineSize和MinInliningThreshold这两个参数就是为这种方法设置的。</p><p>当一个方法既不是Trivial方法，而且大于MaxInlineSize，如果他的调用次数大于MinInliningThreshold，也就是250次，且它的大小小于FreqInlineSize，那么它也会被内联</p><h3 id="InlineSmallCode"><a href="#InlineSmallCode" class="headerlink" title="InlineSmallCode"></a>InlineSmallCode</h3><p>我们知道，调用方进行方法内联的时候，函数本身的大小会越来越大。</p><p>这时候你又会问了，那调用方内联可以无限内联吗，内联后的大小肯定会有限制的吧。</p><p>对的！InlineSmallCode就是限制的大小</p><p>如果是非分层编译的环境，阈值是1000bytes</p><p>如果是分层编译的环境，那么阈值是2000bytes</p><h3 id="MaxInlineLevel"><a href="#MaxInlineLevel" class="headerlink" title="MaxInlineLevel"></a>MaxInlineLevel</h3><p>对于一个函数进行其他函数的内联，除了内联后的大小限制，内联的深度也是有限制的。</p><p>在HotSpot中，默认的内联最大深度是MaxInlineLevel控制，也就是9层。</p><p>为什么要限制内联的最大深度呢？</p><p>在stackoverflow上有个我认为比较中肯的答案</p><p><a href="https://stackoverflow.com/questions/32503669/why-does-the-jvm-have-a-maximum-inline-depth" target="_blank" rel="noopener">Why does the JVM have a maximum inline depth?</a></p><blockquote><p>Not exactly, but I guess the basic reason is to keep things simple. Unlimited inlining depth would increase complexity, the compilation time and memory usage might be less predictable (that is OK for AOT compilers, but not for JIT). Also mind that compiled code should keep track of the whole inlining tree at run-time (to be able to unwind and deoptimize). Though I think the default value of 9 is outdated. It has not been changed for ages, but nowadays, with much more resources available, with streams and lamdas in mind, there is definitely a place for improvement</p></blockquote><p>总结一下答案：</p><ul><li>为了保持内联的简单性。无限制的内联会增加复杂度。</li><li>内联后的编译代码，需要记录整个内联树。</li><li>编译时间和内存消耗会变得不可预测。</li></ul><p>当然，作者也认为默认值9已经很久没有改动了，随着计算机资源变得不再那么昂贵，完全可以适当调大这个值。</p><h3 id="MaxRecursiveInlineLevel"><a href="#MaxRecursiveInlineLevel" class="headerlink" title="MaxRecursiveInlineLevel"></a>MaxRecursiveInlineLevel</h3><p>对于递归的方法，它内联自己最多只能内联MaxRecursiveInlineLevel层，也就是1次。</p><h2 id="查看内联结果"><a href="#查看内联结果" class="headerlink" title="查看内联结果"></a>查看内联结果</h2><p>如果想要知道我们的代码在编译时，内联了哪些方法，那么可以加上参数</p><p><code>java -XX:+UnlockDiagnosticVMOptions -XX:+PrintInlining</code></p><p>对于上面的inline.java的结果输出如下</p><p><img src="/images/HotSpot原理指南-内联/内联输出结果.png" alt="内联输出结果"></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;内联是编程语言编译器中常规的优化操作，几乎所有的语言在编译时或者在执行时都会有内联操作。&lt;/p&gt;
&lt;p&gt;内联的本质是把几个方法合并成一个方法&lt;/p&gt;
&lt;p&gt;从一方面讲，内联减少了函数调用的栈帧创建和销毁的时间消耗&lt;/p&gt;
&lt;p&gt;从另一方面讲，内联为很多其他的优化方法提供了更多的可能，比如逃逸分析，无用代码消除，虚函数优化等，这也是内联被叫做&lt;strong&gt;优化之母&lt;/strong&gt;（The Mother Of All Optimization）的原因。&lt;/p&gt;
    
    </summary>
    
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/categories/HotSpot/"/>
    
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/tags/HotSpot/"/>
    
  </entry>
  
  <entry>
    <title>HotSpot原理指南-C1和C2编译流程</title>
    <link href="https://blog.lovezhy.cc/2019/11/27/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-C1%E5%92%8CC2%E7%BC%96%E8%AF%91%E6%B5%81%E7%A8%8B/"/>
    <id>https://blog.lovezhy.cc/2019/11/27/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-C1%E5%92%8CC2%E7%BC%96%E8%AF%91%E6%B5%81%E7%A8%8B/</id>
    <published>2019-11-26T16:00:00.000Z</published>
    <updated>2020-02-23T10:29:38.017Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>前文讲述了C1和C2的功能定位，以及引出了Client和Server模式的区别。</p><p>这回抛开功能和定位的角度，简单看看从设计与实现角度的区别。</p><a id="more"></a><h2 id="前导知识"><a href="#前导知识" class="headerlink" title="前导知识"></a>前导知识</h2><p>要讲解设计与实现角度的区别，需要了解很多的编译原理知识。</p><p>😄编译原理是科班必学的一门课，当时作者上的迷迷糊糊的，觉得没什么用，也没怎么听。</p><p>现在看到C1和C2的东西，真的是一筹莫展。</p><p>相信很多科班和非科班的人也是。</p><p>不过大家不用担心，作者水平有限，更是不会瞎写自己根本不会的东西，所以涉及到编译原理的东西讲的都很简单。</p><h3 id="IR"><a href="#IR" class="headerlink" title="IR"></a>IR</h3><p>IR，中文中间表示，全称是intermediate representation。</p><p>其实它和中间语言的定义类似，但是中间语言的定义更加狭义，只规定必须是某种语言，而中间表示则扩宽了范围，可以是树类型或者是图类型的表示。</p><p>在维基百科上，中间语言的定义是</p><blockquote><p><strong>中间语言</strong>（英语：Intermediate language），在计算机科学中，是指一种应用于抽象机器（abstract machine）的编程语言，它设计的目的，是用来帮助我们分析计算机程序。这个术语源自于编译器，在编译器将源代码编译为目的码的过程中，会先将源代码转换为一个或多个的中间表述，以方便编译器进行最佳化，并产生出目的机器的机器语言</p></blockquote><p>其实更简单的定义，我觉得就是源代码的另一种表达形式。</p><p>比如Java代码，会被编译成字节码，字节码也是一种IR，是Java代码的中间表示。</p><p>IR在编译原理中的作用个人理解其实起到两种：</p><ul><li>统一后端语言。比如JRuby，Scala，Kotlin等，他们的解释器其实都是JVM。但是他们的源代码都是不一样的。倘若对于每种语言的处理都是不一样的，那其实JVM的实现就没什么意义了，所以将所有语言的源代码都编译成同一种IR，然后JVM不用关心源语言是什么，只要符合该IR定义的都可以执行。</li><li>方便优化。很多的优化技术，其实人眼可以简单看出的，很难归一化到程序去理解。但是通过一些IR的表示，使用特定的规则，就可以进行优化。就行我们在拼魔方时的公式一样。那为什么有这么多种IR呢，很大一个程度的区别就是他们在解决一些特定优化时各有优势。比如SSA在进行复制传播时就很方便。</li></ul><h3 id="寄存器分配"><a href="#寄存器分配" class="headerlink" title="寄存器分配"></a>寄存器分配</h3><p>一个解释器执行的程序和以机器码执行的程序的一个很大的区别就是对于系统寄存器的使用。</p><p>比如对于下面的函数</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> i, <span class="keyword">int</span> j)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> k = i + j;</span><br><span class="line">    k += <span class="number">2</span>;</span><br><span class="line">    k *= <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">return</span> i + j;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果是以解释的形式而言，则需要把k存在内存的变量中，然后再进行运算，每一步的运算都要把k的值写回到内存中。</p><p>但是如果是C++的话，完全可以给k分配一个寄存器，把k放到寄存器中，然后直接对寄存器中的值进行运算就行。</p><p>所以，如果能够很好的利用系统现有的寄存器，那么程序执行的性能将提升一个档次。</p><p>对于寄存器的分配算法，有很多论文可以参考，作者水平有限，还没能学会一种。</p><p>读者有兴趣可以自己去搜索相关论文进行了解。</p><h2 id="C1流程"><a href="#C1流程" class="headerlink" title="C1流程"></a>C1流程</h2><p><img src="/images/HotSpot原理指南-C1和C2流程/C1流程.png" alt=""></p><p>C1的流程较为简单，如上图所示。</p><p>首先，字节码会经过转换，变成HIR，也就是High Level的IR，高级中间表示。</p><p>在HIR中，会进行一些优化，比如</p><ul><li>GVN优化</li><li>基本块优化</li><li>null检查消除</li><li>…</li></ul><p>经过HIR优化之后，转换成LIR，也就是Low-Level的IR，低级中间表示。</p><p>这个阶段的IR其实已经很接近机器码了</p><p>在LIR时，进行</p><ul><li>寄存器分配。这里的寄存器分配算法是线性扫描，时间消耗短，但是分配效果有限</li><li>窥孔优化</li></ul><p>在LIR的优化过后，就是机器码的生成。</p><p>对于C1的更详细的流程，笔者也从网上找到了当时作者的一个PPT，有兴趣的可以自行下载</p><p><a href="http://compilers.cs.uni-saarland.de/ssasem/talks/Christian.Wimmer.pdf" target="_blank" rel="noopener">http://compilers.cs.uni-saarland.de/ssasem/talks/Christian.Wimmer.pdf</a></p><p>同时，如果有人对线性扫描寄存器分配算法有兴趣，也可以参照论文</p><p><a href="http://web.cs.ucla.edu/~palsberg/course/cs132/linearscan.pdf" target="_blank" rel="noopener">http://web.cs.ucla.edu/~palsberg/course/cs132/linearscan.pdf</a></p><h2 id="C2流程"><a href="#C2流程" class="headerlink" title="C2流程"></a>C2流程</h2><p>通过前面我们已经知道C2相对于C1编译过程，更加的耗时，这个耗时可以体现在两方面</p><ul><li>比C1有更多的优化</li><li>同一种优化使用的算法不同，C2的结果更好</li></ul><p>对于C2而言，它的IR只有一种，叫<code>Sea Of Nodes</code></p><p>就笔者了解到的知识来看，这个IR非常的牛逼，在V8引擎中，也是使用的这种IR。</p><p>不过这种IR的资料似乎非常少，笔者也仅仅是搜到了论文，没什么更深层次的讲解。</p><p>如果有人想要了解Sea Of Nodes的原理，那么大家可以从网上搜集资料来看。</p><p><strong>比C1拥有更多的优化</strong></p><p>相比较于C1，C2几乎会做所有的经典优化。如下图所示</p><p><img src="/images/HotSpot原理指南-C1和C2流程/C2优化.png" alt=""></p><p><strong>同一种优化使用不同的算法</strong></p><p>这个体现在寄存器分配算法上，我们知道对于C1而言，使用的较为简单的线性扫描的分配算法，执行较快。</p><p>而C2使用了叫图染色的算法，消耗的时间更久，但是产生的解法比线性扫描更优。</p><p>对于图染色算法，在经典的编译原理书中都有解答。</p><p>笔者这里就不赘述了（其实是笔者也没看懂）</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;前文讲述了C1和C2的功能定位，以及引出了Client和Server模式的区别。&lt;/p&gt;
&lt;p&gt;这回抛开功能和定位的角度，简单看看从设计与实现角度的区别。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Java" scheme="https://blog.lovezhy.cc/categories/Java/"/>
    
    
      <category term="Java" scheme="https://blog.lovezhy.cc/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>HotSpot原理指南-C1和C2介绍</title>
    <link href="https://blog.lovezhy.cc/2019/11/24/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-C1%E5%92%8CC2%E4%BB%8B%E7%BB%8D/"/>
    <id>https://blog.lovezhy.cc/2019/11/24/HotSpot%E5%8E%9F%E7%90%86%E6%8C%87%E5%8D%97-C1%E5%92%8CC2%E4%BB%8B%E7%BB%8D/</id>
    <published>2019-11-23T16:00:00.000Z</published>
    <updated>2020-02-23T10:29:40.512Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>HotSpot是一款Java虚拟机的实现，除了基本的解释功能以外，该虚拟机还拥有将字节码编译成机器码的并执行的能力，我们知道，直接执行机器码肯定比解释更快。</p><p>HotSpot最初会通过解释的方式执行程序，当它发现某个方法运行得特别频繁时，就会将这些热点（Hot Spot）代码进行编译，编译成平台相关的机器码。这个过程也叫做JIT（Just In Time），与之相对的是AOT（Ahead Of Time），比较典型的是C和C++语言。</p><p>HotSpot进行JIT编译的编译器有两个，分别叫做<strong>C1</strong>和<strong>C2</strong>，或者也可以叫做<strong>Client Compiler</strong>和<strong>Server Compiler</strong>。这两种编译器编译策略不同，运用在不同的场景，下面会详细的说明。</p><a id="more"></a><h2 id="JIT编译"><a href="#JIT编译" class="headerlink" title="JIT编译"></a>JIT编译</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Add</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">200</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">long</span> start = System.nanoTime();</span><br><span class="line">            add();</span><br><span class="line">            <span class="keyword">long</span> end = System.nanoTime();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">add</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1000</span>; i++) &#123;</span><br><span class="line">            sum += i;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> sum;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面这段代码，我们有一个<code>add</code>方法，如果我们对改方法进行时间统计，我们会得到下面的曲线。</p><p>X轴是次数，Y轴是时间的log2。</p><p><img src="/images/HotSpot原理指南-C1和C2/add.png" alt=""></p><p>从这个曲线我们可以看出，在第大概100次的时间，时间消耗会下滑，也就是性能提升了一个档次。</p><p>由此我们可以猜到，前100次的add方法是由解释执行的，在100次后，执行的是由JIT编译器编译过的机器码。所以性能会有较大的提升。</p><h2 id="Profile"><a href="#Profile" class="headerlink" title="Profile"></a>Profile</h2><p>在详细讲述C1和C2之前，我们还有一个内容需要科普，就是方法的Profile信息。</p><p>除了最基本的用于判定某个方法是否是HotSpot的方法调用次数（Invocation Counter）信息外，对于某个方法，还有一些信息是会在运行时进行收集的。</p><p>比如我们看下面这段代码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">record</span><span class="params">(List&lt;String&gt; list)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (list != <span class="keyword">null</span>) &#123;</span><br><span class="line">list.add(<span class="string">"大骚包卢布"</span>);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    log.warn(<span class="string">"我不是大骚包"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>record</code>函数的功能很简单，入参是一个List，如果List不为空，那么就把<code>大骚包卢布</code>这个字符串传递进去。不然的话就打出一个warn级别的日志<code>我不是大骚包</code>。</p><p>那么在调用这个方法的时候，HotSpot还会记录哪些信息呢</p><ul><li>List的真实类。因为List在Java中是一个接口，具体的传入可能是ArrayList或者LinkedList或者其他的。HotSpot需要记录具体的类为了以后的优化。</li><li>Log的真实类，理由和List一样。</li><li>进入if的次数，以及进入else的次数，更通俗的说是条件选择的实际情况。</li></ul><p>有人可能会问统计这些Profile有什么用。</p><p>举个最简单的例子，如果我们需要对<code>list.add</code>做内联，那么我们到底内联那个实现呢，这个就需要我们收集list的真实实现是什么。</p><h2 id="C1和C2"><a href="#C1和C2" class="headerlink" title="C1和C2"></a>C1和C2</h2><table><thead><tr><th></th><th>C1</th><th>C2</th></tr></thead><tbody><tr><td>编译时间</td><td>快</td><td>慢（x4）</td></tr><tr><td>执行时间</td><td>慢</td><td>快（30%）</td></tr><tr><td>输出代码</td><td>多</td><td>少</td></tr></tbody></table><p>上表是C1和C2在编译时间，执行时间，输出代码的区别</p><ul><li>编译时间：同样一段代码，C1需要时间比C2短，也就是需求的CPU资源较少</li><li>执行时间：C1编译时间短，通常意味着优化不如C2，所以C2编译出的机器码执行效率较高</li><li>输出代码：C1编译时间短，最终也就导致输出的机器码占用的内存要比C2多的</li></ul><p>总结：同一段代码，C1消耗的CPU资源较少，但是输出的代码质量不如C2。但是毋庸置疑的事，无论是C1还是C2输出的机器码，执行效率肯定都比解释快的。</p><p>C1又称<strong>Client Compiler</strong>，C2又称<strong>Server Compiler</strong>，不是没有历史渊源的。</p><p>或许我们都听过java在启动的时候可以执行是<code>client</code>模式还是<code>server</code>模式。</p><p>当我们使用client模式时，一般运行的是应用程序，比如java swing，awt之类的图形软件，对于这些桌面软件，作为使用者而言，并不希望哪个桌面应用占用大量的CPU，所以非常适合C1的场景</p><ul><li>编译速度快</li><li>占用CPU资源少</li></ul><p>而对于Server模式而言，一般是公司的服务器上跑的稳定的服务应用，服务器的资源一般较为丰富，同时一个应用并不会像桌面应用一样频繁的开关，一般都要跑几周或者几个月甚至几年。这种应用，当然速度越快越好。所以非常适合C2的场景</p><ul><li>编译消耗更多的CPU资源</li><li>代码质量更高，也就是性能更好</li></ul><h2 id="C1和C2和Profile"><a href="#C1和C2和Profile" class="headerlink" title="C1和C2和Profile"></a>C1和C2和Profile</h2><p>前面提到过的Profile信息，你可能会疑惑这个和C1和C2有什么联系。</p><p>其实我们需要先明白一个概念，就是收集那些Profile不仅仅会占用程序以外的更多的内容，而且会占用很多的CPU消耗。同样一段代码，插入了收集Profile逻辑和没有插入收集Profile逻辑，执行性能是不同的。</p><p>结合我们提到的C1和C2的使用场景的区别，可以得出这样的结论，这个收集Profile的消耗，对于桌面应用而言，是非常<strong>不合适</strong>的。</p><p>但是C2则需要这些Profile去做更好的性能优化。</p><p>所以对于Client模式的应用而言，解释器不会去收集程序的Profile信息，而Server模式在解释器阶段，则会进行Profile的收集，这也就导致了Client模式的起步性能是比Server模式的起步性能要好很多。</p><h2 id="启动模式"><a href="#启动模式" class="headerlink" title="启动模式"></a>启动模式</h2><p>在JDK1.6之前，指定是<code>client</code>还是<code>server</code>模式，我们在java程序启动时直接加参数就行了</p><p><code>java -client Hello</code></p><p><strong>但是</strong></p><p>注意我这个但是</p><p>其实自从JDK6的某个版本开始，你已经控制不了这个参数了</p><p><a href="https://docs.oracle.com/javase/7/docs/technotes/guides/vm/server-class.html" target="_blank" rel="noopener">https://docs.oracle.com/javase/7/docs/technotes/guides/vm/server-class.html</a></p><p>从这个网站可以看到，默认如果你是64位的机器并且至少有2G内存和2核心的CPU，默认都是Server模式了。</p><p><code>-client</code>这个参数会被忽略</p><p>但是也并不是没有办法指定client模式</p><p>不仅仅要在启动参数中加上<code>-client</code></p><p>还需要去修改文件<code>jre/lib/jvm.cfg</code></p><p>比如我的文件中默认是这个状态</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">-server KNOWN</span><br><span class="line">-client IGNORE</span><br><span class="line">-hotspot ERROR</span><br><span class="line">-classic WARN</span><br><span class="line">-native ERROR</span><br><span class="line">-green ERROR</span><br></pre></td></tr></table></figure><p>注意到我的<code>-client</code>后面跟的是<code>IGNORE</code>，所以我指定<code>-client</code>模式其实是不生效的</p><p>我需要改成<code>-client KNOWN</code>才行。</p><p>当然Oracle选择忽略<code>-client</code>模式也不是没有道理的</p><ul><li>Java的桌面应用已经很少了，Swing基本已经死了</li><li>现在大家的笔记本的CPU和内容资源都很充足</li></ul><p>所以全部使用<code>server</code>模式也没问题。</p><h2 id="后续"><a href="#后续" class="headerlink" title="后续"></a>后续</h2><p>当然C1和C2的故事并没有这么简单</p><p>同时JIT编译的策略也不是非C1就是C2，在JDK7中引入了分层编译，结合了C1和C2的优点。</p><p>这些会在后面的文章讲述。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;HotSpot是一款Java虚拟机的实现，除了基本的解释功能以外，该虚拟机还拥有将字节码编译成机器码的并执行的能力，我们知道，直接执行机器码肯定比解释更快。&lt;/p&gt;
&lt;p&gt;HotSpot最初会通过解释的方式执行程序，当它发现某个方法运行得特别频繁时，就会将这些热点（Hot Spot）代码进行编译，编译成平台相关的机器码。这个过程也叫做JIT（Just In Time），与之相对的是AOT（Ahead Of Time），比较典型的是C和C++语言。&lt;/p&gt;
&lt;p&gt;HotSpot进行JIT编译的编译器有两个，分别叫做&lt;strong&gt;C1&lt;/strong&gt;和&lt;strong&gt;C2&lt;/strong&gt;，或者也可以叫做&lt;strong&gt;Client Compiler&lt;/strong&gt;和&lt;strong&gt;Server Compiler&lt;/strong&gt;。这两种编译器编译策略不同，运用在不同的场景，下面会详细的说明。&lt;/p&gt;
    
    </summary>
    
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/categories/HotSpot/"/>
    
    
      <category term="HotSpot" scheme="https://blog.lovezhy.cc/tags/HotSpot/"/>
    
  </entry>
  
  <entry>
    <title>给RedisTemplate插入Cat打点</title>
    <link href="https://blog.lovezhy.cc/2019/11/08/%E7%BB%99RedisTemplate%E6%8F%92%E5%85%A5Cat%E6%89%93%E7%82%B9/"/>
    <id>https://blog.lovezhy.cc/2019/11/08/%E7%BB%99RedisTemplate%E6%8F%92%E5%85%A5Cat%E6%89%93%E7%82%B9/</id>
    <published>2019-11-07T16:00:00.000Z</published>
    <updated>2020-02-23T10:28:07.408Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Cat是美团开源的一套监控系统，功能非常强大<br>一般对方法进行打点，它会自动生成每个方法的耗时，同时也会记录全链路的每个调用方法的耗时</p><p>对于查系统的性能瓶颈和稳定性有非常大的帮助</p><a id="more"></a><p>基本用法<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Transaction tranx = Cat.newTransaction(<span class="string">"Cache"</span>, <span class="string">"get"</span>);</span><br><span class="line">tranx.addData(<span class="string">"key"</span>, <span class="string">"name"</span>);</span><br><span class="line"><span class="comment">//do something</span></span><br><span class="line">tranx.setStatus(<span class="string">"0"</span>);</span><br><span class="line">tranx.complete();</span><br></pre></td></tr></table></figure></p><p>上面的方法就是对中间的代码执行进行耗时打点，这里假设的是我们对Redis的get方法进行打点</p><ul><li>第一句：new一个Transaction出来，Type是Cache，也就是Transaction属于Cache，然后具体的方法是get</li><li>第二句：addData，在执行过程中进行关键日志的记录，我们这里记录了get的key是name，方面查询长耗时的方法，增加一些提示性的参数</li><li>第三句：执行具体的方法</li><li>第四句：执行成功，设置status=0，0表示成功的意思，当然也有失败的方法，可以把具体的Exception传递进去</li><li>第五句：标记Transaction完成</li></ul><h2 id="框架集成"><a href="#框架集成" class="headerlink" title="框架集成"></a>框架集成</h2><p>Cat只是提供了一些工具，并没有直接提供方法与常见的方法集成，让我们在业务代码的每个方法都手动编码上面这些流程肯定不现实，可以借助于很多的方法进行隐式的插入逻辑。</p><h3 id="与Dubbo集成"><a href="#与Dubbo集成" class="headerlink" title="与Dubbo集成"></a>与Dubbo集成</h3><p>Dubbo提供了Filter机制，可以声明一个Filter进行对Dubbo服务方法的打点</p><p><a href="https://github.com/dianping/cat/tree/master/integration/dubbo" target="_blank" rel="noopener">Dubbo</a></p><p>在Cat的官方仓库中收集了此集成方式，可以直接使用</p><h2 id="与Mybatis集成"><a href="#与Mybatis集成" class="headerlink" title="与Mybatis集成"></a>与Mybatis集成</h2><p>和Dubbo一个，Mybatis也提供了Filter插件</p><p><a href="https://github.com/dianping/cat/tree/master/integration/mybatis" target="_blank" rel="noopener">Mybatis</a></p><p>在Cat的官方仓库中收集了此集成方式，可以直接使用</p><p>上面两种插件几乎是最常用的两个了，但是Redis的需求也比较强烈</p><h2 id="Redis打点"><a href="#Redis打点" class="headerlink" title="Redis打点"></a>Redis打点</h2><p>Cat的官方仓库并没有提供Redis的打点插件，借着Filter的简单的逻辑，我准备找找现有框架的逻辑插入方法</p><p>在正常的SpringBoot应用中，默认的Redis使用类是RedisTemplate，如果具体到某个操作，在内部声明了多个具体的类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedisTemplate</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt;    </span>&#123;</span><br><span class="line">  <span class="comment">// cache singleton objects (where possible)</span></span><br><span class="line">    <span class="keyword">private</span> <span class="meta">@Nullable</span> ValueOperations&lt;K, V&gt; valueOps;</span><br><span class="line">    <span class="keyword">private</span> <span class="meta">@Nullable</span> ListOperations&lt;K, V&gt; listOps;</span><br><span class="line">    <span class="keyword">private</span> <span class="meta">@Nullable</span> SetOperations&lt;K, V&gt; setOps;</span><br><span class="line">    <span class="keyword">private</span> <span class="meta">@Nullable</span> ZSetOperations&lt;K, V&gt; zSetOps;</span><br><span class="line">    <span class="keyword">private</span> <span class="meta">@Nullable</span> GeoOperations&lt;K, V&gt; geoOps;</span><br><span class="line">    <span class="keyword">private</span> <span class="meta">@Nullable</span> HyperLogLogOperations&lt;K, V&gt; hllOps;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>比如当我们调用</p><p><code>redisTemplate.opsForSet().members(cacheName)</code>时，</p><p>调用的是</p><p><code>DefaultSetOperations.members(K key)</code>方法</p><p>所以我们只要对上面提到的具体操作的类的一些方法进行打点就行</p><p>但是很可惜，RedisTemplate并没有提供</p><h2 id="方案一"><a href="#方案一" class="headerlink" title="方案一"></a>方案一</h2><p>直接使用SpringAop对具体的类进行代理</p><p>这当时是我觉得最简单的方法，但是很遗憾</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DefaultSetOperations</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">AbstractOperations</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; <span class="keyword">implements</span> <span class="title">SetOperations</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; </span>&#123;&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DefaultValueOperations</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">AbstractOperations</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; <span class="keyword">implements</span> <span class="title">ValueOperations</span>&lt;<span class="title">K</span>, <span class="title">V</span>&gt; </span>&#123;&#125;</span><br></pre></td></tr></table></figure><p>这些具体实现类都不是public的，对这些方法进行切面处理是处理不了的</p><h2 id="方案二"><a href="#方案二" class="headerlink" title="方案二"></a>方案二</h2><p>最简单的方法被否决了，于是只能找一些其他的方法</p><p>当时看到Java的Agent可以在类被加载时进行一些修改，于是产生了写一个javaagent的方法</p><p>目标效果</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">get</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> execute(<span class="keyword">new</span> ValueDeserializingRedisCallback(key) &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">protected</span> <span class="keyword">byte</span>[] inRedis(<span class="keyword">byte</span>[] rawKey, RedisConnection connection) &#123;</span><br><span class="line">            <span class="keyword">return</span> connection.get(rawKey);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;, <span class="keyword">true</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">=&gt;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">get</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">    Transaction tranx = Cat.newTransaction(<span class="string">"Cache"</span>, <span class="string">"get"</span>); </span><br><span class="line">    tranx.addData(<span class="string">"key"</span>, key);</span><br><span class="line">    V res = execute(<span class="keyword">new</span> ValueDeserializingRedisCallback(key) &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">protected</span> <span class="keyword">byte</span>[] inRedis(<span class="keyword">byte</span>[] rawKey, RedisConnection connection) &#123;</span><br><span class="line">            <span class="keyword">return</span> connection.get(rawKey);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;, <span class="keyword">true</span>);</span><br><span class="line">    </span><br><span class="line">    tranx.setStatus(<span class="string">"0"</span>);</span><br><span class="line">    tranx.complete();</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>但是为了得到失败的效果，同时防止Cat方法抛出异常影响正常逻辑，需要多加几个try catch</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">get</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">    Transaction tranx = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      tranx = Cat.newTransaction(<span class="string">"Cache"</span>, <span class="string">"get"</span>);</span><br><span class="line">      tranx.addData(<span class="string">"key"</span>, key);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable e) &#123;&#125;</span><br><span class="line">    </span><br><span class="line">    V res = <span class="keyword">null</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        V res = execute(<span class="keyword">new</span> ValueDeserializingRedisCallback(key) &#123;</span><br><span class="line"></span><br><span class="line">              <span class="meta">@Override</span></span><br><span class="line">              <span class="keyword">protected</span> <span class="keyword">byte</span>[] inRedis(<span class="keyword">byte</span>[] rawKey, RedisConnection connection) &#123;</span><br><span class="line">                  <span class="keyword">return</span> connection.get(rawKey);</span><br><span class="line">              &#125;</span><br><span class="line">          &#125;, <span class="keyword">true</span>);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">       <span class="keyword">try</span> &#123;</span><br><span class="line">         <span class="keyword">if</span> (tranx != <span class="keyword">null</span>) &#123;</span><br><span class="line">           tranx.setStatus(e);</span><br><span class="line">           tranx.complete();</span><br><span class="line">         &#125;</span><br><span class="line">       &#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">         </span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">throw</span> e;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (tranx != <span class="keyword">null</span>) &#123;</span><br><span class="line">        tranx.setStatus(<span class="string">"0"</span>);</span><br><span class="line">        tranx.complete();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span>(Throwable e) &#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到，代码非常长，但是不用担心性能，经过编译优化之后很多其实都被优化掉了</p><h2 id="java-lang-instrument包"><a href="#java-lang-instrument包" class="headerlink" title="java.lang.instrument包"></a>java.lang.instrument包</h2><blockquote><p>Provides services that allow Java programming language agents to instrument programs running on the JVM. The mechanism for instrumentation is modification of the byte-codes of methods.<br>Package Specification</p></blockquote><p>Oracle的官网上对这个包的定义如上，简单的说就是给与我们能力动态的修改Java类的字节码<br>一般可以用来监控，织入类似于AOP的逻辑</p><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p>当时选择了javaassit进行字节码的织入，但是javaassit有一个很大的局限就是不能使用本地变量</p><p>比如<code>Transaction tranx</code>这个我们在声明出来之后，在下面的代码就获取不到这个变量了</p><p>但是整个方法不会触及多线程的场景，所以想到的方案就是放在一个ThreadLocal中</p><p>先构造出一个ThreadLocal的类进行封装</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedisCatLog</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> ThreadLocal&lt;RedisCatLog&gt; THREAD_LOCAL_CAT_LOG = <span class="keyword">new</span> ThreadLocal&lt;&gt;();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">startLog</span><span class="params">(String action, Object data)</span> </span>&#123;</span><br><span class="line">        THREAD_LOCAL_CAT_LOG.remove();</span><br><span class="line">        RedisCatLog redisCatLog = <span class="keyword">new</span> RedisCatLog(action);</span><br><span class="line">        redisCatLog.before(String.valueOf(data));</span><br><span class="line">        THREAD_LOCAL_CAT_LOG.set(redisCatLog);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">endLog</span><span class="params">(<span class="keyword">boolean</span> success)</span> </span>&#123;</span><br><span class="line">        RedisCatLog redisCatLog = THREAD_LOCAL_CAT_LOG.get();</span><br><span class="line">        <span class="keyword">if</span> (Objects.nonNull(redisCatLog)) &#123;</span><br><span class="line">            redisCatLog.after(success);</span><br><span class="line">            THREAD_LOCAL_CAT_LOG.remove();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String action;</span><br><span class="line">    <span class="keyword">private</span> Transaction tranx;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">RedisCatLog</span><span class="params">(String action)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.action = action;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">before</span><span class="params">(String data)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.tranx = Cat.newTransaction(<span class="string">"Cache."</span>, <span class="keyword">this</span>.action);</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>.tranx <span class="keyword">instanceof</span> NullMessage) &#123;</span><br><span class="line">            log.error(<span class="string">"is null message"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">this</span>.tranx.addData(<span class="string">"key"</span>, data);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">after</span><span class="params">(<span class="keyword">boolean</span> success)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (!success) &#123;</span><br><span class="line">            <span class="keyword">this</span>.tranx.setStatus(<span class="string">"failed"</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">this</span>.tranx.setStatus(<span class="string">"0"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">this</span>.tranx.complete();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样，有了这个类之后，我们的织入代码就比较简单了</p><ul><li>给现有方法的开始加入RedisCatLog.startLog()</li><li>给方法的结尾加上RedisCatLog.endLog()</li><li>给原有的完整代码加上try catch</li></ul><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">public V get(Object key) &#123;</span><br><span class="line">    try &#123;RedisCatLog.startLog("get", key);&#125; catch(Throwable e) &#123;&#125;</span><br><span class="line">  </span><br><span class="line">    try &#123;</span><br><span class="line">        V res = execute(new ValueDeserializingRedisCallback(key) &#123;</span><br><span class="line">              @Override</span><br><span class="line">              protected byte[] inRedis(byte[] rawKey, RedisConnection connection) &#123;</span><br><span class="line">                  return connection.get(rawKey);</span><br><span class="line">              &#125;</span><br><span class="line">          &#125;, true);</span><br><span class="line">    &#125; catch(Throwable e) &#123;</span><br><span class="line">        try &#123;RedisCatLog.endLog(false);&#125; catch(Throwable e) &#123;&#125;</span><br><span class="line">        throw e;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    try &#123;RedisCatLog.endLog(true);&#125; catch(Throwable e) &#123;&#125;</span><br><span class="line">    return res;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>整体来看是不是简单的了很多</p><p>下面就是具体的javaassit代码编写了</p><p>在编写时参考了文档，并没有系统的学习javaassit</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">String methodName = methods[i].getName();</span><br><span class="line">CtClass etype = ClassPool.getDefault().get(<span class="string">"java.lang.Throwable"</span>);</span><br><span class="line">methods[i].addCatch(<span class="string">"&#123; RedisCatLog.endLog(false); throw $e; &#125;"</span>, etype);</span><br><span class="line">methods[i].insertBefore(before(classMethodNameInfo.getType() + <span class="string">"-"</span> + methodName));</span><br><span class="line">methods[i].insertAfter(after());</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">before</span><span class="params">(String action)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> String.format(<span class="string">"try &#123; RedisCatLog.startLog(\"%s\", $1); &#125; catch (Throwable e) &#123;&#125;"</span>, action);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">after</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="string">"try&#123; RedisCatLog.endLog(true);&#125; catch (Throwable e) &#123;&#125;"</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>大概的整体逻辑如下</p><p>项目我传到了Github上，<a href="https://github.com/zhyzhyzhy/CatRedisLogAspect" target="_blank" rel="noopener">https://github.com/zhyzhyzhy/CatRedisLogAspect</a></p><p>大家可以参考文档进行使用</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;Cat是美团开源的一套监控系统，功能非常强大&lt;br&gt;一般对方法进行打点，它会自动生成每个方法的耗时，同时也会记录全链路的每个调用方法的耗时&lt;/p&gt;
&lt;p&gt;对于查系统的性能瓶颈和稳定性有非常大的帮助&lt;/p&gt;
    
    </summary>
    
    
      <category term="SpringBoot" scheme="https://blog.lovezhy.cc/categories/SpringBoot/"/>
    
    
      <category term="Spring" scheme="https://blog.lovezhy.cc/tags/Spring/"/>
    
  </entry>
  
  <entry>
    <title>Raft实现指北</title>
    <link href="https://blog.lovezhy.cc/2019/09/05/Raft%E5%AE%9E%E7%8E%B0%E6%8C%87%E5%8C%97/"/>
    <id>https://blog.lovezhy.cc/2019/09/05/Raft%E5%AE%9E%E7%8E%B0%E6%8C%87%E5%8C%97/</id>
    <published>2019-09-04T16:00:00.000Z</published>
    <updated>2019-09-05T03:15:46.679Z</updated>
    
    <content type="html"><![CDATA[<p>Raft实现指北<br><a id="more"></a></p><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>自己陆陆续续花了一些时间完成了一个Raft的库，目前基本的流程都完成了，下面要继续做的话，就是要进行一些优化的逻辑了。<br><a href="https://github.com/zhyzhyzhy/Rub-Raft" target="_blank" rel="noopener">Rub-Raft</a><br>取名叫Rub，就是卢布的意思，纪念雯姐今年去世的花枝鼠[2016-2019]。<br>卢布是我见过最乖的鼠，很聪明，她喜欢睡在吊床上，不会像其他的鼠去啃吊床的线。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>一个很好的博文<br><a href="https://lichuang.github.io/post/20180921-raft/" target="_blank" rel="noopener">https://lichuang.github.io/post/20180921-raft/</a>  </p><p>《CONSENSUS: BRIDGING THEORY AND PRACTICE》论文<br><a href="https://ramcloud.stanford.edu/~ongaro/thesis.pdf" target="_blank" rel="noopener">https://ramcloud.stanford.edu/~ongaro/thesis.pdf</a>  </p><p>动画讲解<br><a href="https://raft.github.io/" target="_blank" rel="noopener">https://raft.github.io/</a></p><h2 id="整体流程"><a href="#整体流程" class="headerlink" title="整体流程"></a>整体流程</h2><p>集群的整体状态一般分为三种</p><ul><li>选举</li><li>日志添加<ul><li>正常添加</li><li>非正常添加</li><li>新节点获取日志</li></ul></li><li>新增节点</li></ul><p>我可能不太会对所有流程做详细的阐述，只是一些简单的问答和心得。</p><p>整个RPC的方法其实只要4个就可以完成Raft，前两个和选举有关，后两个和日志有关</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">VoteResponse <span class="title">requestPreVote</span><span class="params">(VoteRequest voteRequest)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function">VoteResponse <span class="title">requestVote</span><span class="params">(VoteRequest voteRequest)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function">ReplicatedLogResponse <span class="title">requestAppendLog</span><span class="params">(ReplicatedLogRequest replicatedLogRequest)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function">InstallSnapshotResponse <span class="title">requestInstallSnapShot</span><span class="params">(InstallSnapshotRequest installSnapShotRequest)</span></span>;</span><br></pre></td></tr></table></figure><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><h3 id="需要节点的自动注册和发现吗"><a href="#需要节点的自动注册和发现吗" class="headerlink" title="需要节点的自动注册和发现吗"></a>需要节点的自动注册和发现吗</h3><p>一开始我还是RPC的实现思路，以为需要一个自动的节点注册和发现机制<br>当然其实并不需要，集群启动的时候，只要我们把初始的节点信息写死在启动Config文件中就好  </p><p>那么可不可以有呢，我理解是不可以的，因为选举的时候，节点需要知道当前节点的个数，来判断自己得到的选票是不是已经有集群节点的一半了。<br>如果你还搞个节点自动注册，那么到底集群有几个节点呢？</p><h2 id="节点的RPC连接"><a href="#节点的RPC连接" class="headerlink" title="节点的RPC连接"></a>节点的RPC连接</h2><p>讲道理其实RPC连接并不是什么大问题，但是我们不能先入为主的当做DUBBO这种RPC框架去实现我们的RPC框架。<br>这个问题的根源是：正常的RPC模型并不是互相问答的模式<br>都是C/S模型<br>一个节点一般会开一个Server，让其他的节点来连接，并提出请求，这个Server并不会主动向其他的Node发送消息。 </p><p>这个时候会想到，我们每个节点都当做是一个Server，然后对每个其他的Node，开对应的Client连接。我就是这么实现的，这样的情况其实对于两个节点而言，互相的连接通过了两个不同的Channel来实现。</p><p>后来发现其实这样还有问题。<br>问题是在无法重新连接的情况<br>假设这样的情形，3Node互相连接，过程中Node1断开，其他两个Node互相连接，过一阵子，Node1又启动，开启自己的RpcServer，并顺利连接到其他两个Node的RpcServer<br>而其他两个Node并不会主动的去连接Node1的RpcServer</p><p>这个就需要一种机制，当其他的节点连接上自己的RpcServer的时候，获得感知，然后自己也去连接对方的RpcServer</p><p>那么这个感知机制，放在哪里去做呢。<br>放在Rpc层面吗？我感觉侵入性很大，一方面作为一个Rpc并不需要这种机制，需要的话，也是一个抽象度很高的东西，类似于连接上的回调之类。</p><p>我这里另外开了一个RPC方法，叫<code>requestConnect</code>，当每个节点RPCClient或者RPCServer启动的时候，都会向其他的节点发送<code>requestConnect</code>请求，其他节点接收到这个请求，会检查自己与发送请求的节点的链路是否已经失效，如果失效，则请求重新连接。</p><p>这样完成的很好，但是就是RPC请求的次数会有点多。</p><h2 id="RPC请求的异步与同步"><a href="#RPC请求的异步与同步" class="headerlink" title="RPC请求的异步与同步"></a>RPC请求的异步与同步</h2><p>这个问题不是很复杂，但是我们如果自己实现RPC的话，要注意的一点就是不能不支持异步的方式。<br>我的RPC的实现中，支持3种请求方式</p><ul><li>SYNC 同步请求</li><li>ASYNC 异步请求</li><li>ONE_WAY 不需要返回的请求</li></ul><p>不过异步请求说白了就是RPC框架帮你封装好了SYNC的Future的方式</p><p>上面提到了Raft的需要的5种方法，那些需要异步呢</p><ul><li>requestConnect =&gt; ONE_WAY</li><li>requestPreVote =&gt; ASYCN</li><li>requestVote =&gt; ASYNC</li><li>requestAppendLog =&gt; SYNC</li><li>requestInstallSnapShot =&gt; SYNC</li></ul><h2 id="选举"><a href="#选举" class="headerlink" title="选举"></a>选举</h2><h3 id="节点启动顺序"><a href="#节点启动顺序" class="headerlink" title="节点启动顺序"></a>节点启动顺序</h3><p>节点启动的顺序要注意什么吗？<br>还是不需要，选举要得到一般的选票才能成为Leader，即使有一个节点最后启动，此时集群中已经选举出一个Leader了，最后启动的那个节点收到AppendLog的消息，就会自动变成Follower。</p><h3 id="节点初始化"><a href="#节点初始化" class="headerlink" title="节点初始化"></a>节点初始化</h3><p>节点初始化要做的事不多，就是设置自己的状态为<code>Follower</code><br>然后启动一个选举超时的定时器</p><h3 id="选举超时时间"><a href="#选举超时时间" class="headerlink" title="选举超时时间"></a>选举超时时间</h3><p>节点刚启动的状态是<code>Follower</code>，并且启动一个超时定时器，当时间到了的时候开始进行选举<br>那么这个超时的时间是多少呢？论文中给出的范围是150 - 300ms[章节3.4]  </p><h3 id="超时期间收到Request"><a href="#超时期间收到Request" class="headerlink" title="超时期间收到Request"></a>超时期间收到Request</h3><p>我们知道当选举超时之后，节点把自己的状态设为<code>pre_candidate</code>，并且发送消息给其他节点进行选举。<br>如果超时期间收到消息呢<br>论文中写，<code>A server remains in follower state as long as it receives valid RPCs from a leader or candidate.</code></p><p>很明晰，超时期间收到其他节点的Request，那么就不会进入选举流程，依然是一个Follower。</p><h3 id="超时方法什么时候调用"><a href="#超时方法什么时候调用" class="headerlink" title="超时方法什么时候调用"></a>超时方法什么时候调用</h3><p>在接收到PreVote，Vote，AppendLog的RPC请求接收到之后都要开始调用  </p><h3 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h3><p>要加锁吗，当然是要的<br>上一个我们提到<br>节点超时，开始发起选举RPC之前，启动超时，如果到超时结束，还没有选举出一个Leader，那么就把自己的term加一再次发起选举</p><p>这个过程中有两个事件需要一些条件的同步</p><ul><li>超时线程：没有收到Leader的信息和其他节点的选举信息，就执行，也就是心跳有更新</li><li>接收vote线程：收到Leader和其他节点的信息，还在超时未完成状态，就更新心跳信息</li></ul><p>如果分为两个方法的话，最简单的就是给整个方法都加锁<br>但是这样锁的粒度太大了，能不能把条件抽象出来呢</p><p>我想的是对Node的状态进行cas的修改<br>超时线程，首先判断心跳有没有更新，如果有更新就不进行选举，如果没有更新，就加锁的对NodeStatus进行CAS更新，从Follower更新到Pre_Candidate<br>接收Vote线程，首先对NodeStatus进行CAS的更新，从Follower更新到Follower，然后更新心跳时间<br>我们分析两个线程的流程<br>超时线程</p><ul><li>1.判断心跳有没有更新</li><li>2.NodeStatus从Follower更新到Pre_Candidate</li></ul><p>接收Vote线程</p><ul><li>3.首先对NodeStatus进行CAS的更新，从Follower更新到Follower</li><li>4.更新心跳时间</li></ul><p>如果不加锁，流程从3 - 1 - 2 - 4就出问题了</p><p>这个思路很麻烦</p><p>我们再换个思路</p><p>超时线程进行vote的时候，需要对term进行+1<br>接收Vote线程，如果成功接收其他节点的信息维持Follower的话，那么对面的term肯定比自己大的，那么也就是需要对Term进行加1</p><p>所以我们对Term进行cas操作，谁成功了谁进行操作</p><h3 id="PreVote"><a href="#PreVote" class="headerlink" title="PreVote"></a>PreVote</h3><p>其实论文中并没有很直观的提到PreVote的阶段<br>需要PreVote的原因也不复杂，可以百度一下。</p><h3 id="VoteFor可以进行修改吗"><a href="#VoteFor可以进行修改吗" class="headerlink" title="VoteFor可以进行修改吗"></a>VoteFor可以进行修改吗</h3><p><code>Vote</code>阶段<br>假设这样一种场景：<br>我们有节点1 2 3<br>2最后启动<br>1，3同时超时，且3的请求先到2<br>3，term = 1，2投票给他，1拒绝，于是3变成leader<br>1，term=1，2拒绝了他，3也拒绝了他</p><p>这个时候Term2其实已经有Leader了，是3，那么1也要变成Follower<br>这个时候1收到HeartBeat就要把自己变成Follower<br>那么这里的1的Term=1的votedfor其实已经设置为自己了<br>所以VotedFor还是可以进行修改的  </p><h3 id="Leader发现更高任期的Server"><a href="#Leader发现更高任期的Server" class="headerlink" title="Leader发现更高任期的Server"></a>Leader发现更高任期的Server</h3><p>这种情况也是会发现的，就是Leader进行了STW的GC，然后其他的节点进行了超时选举，选出了Leader。<br>这种时候，原来的Leader的GC结束，进行进行AppendLogRequest，就会发现更高任期的Server<br>这种情况直接自己变成Follower就行</p><h3 id="日志比较的原则"><a href="#日志比较的原则" class="headerlink" title="日志比较的原则"></a>日志比较的原则</h3><p><a href="https://zhuanlan.zhihu.com/p/32052223" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/32052223</a><br>日志比较的原则是，如果本地的最后一条log entry的term更大，则term大的更新，如果term一样大，则Log Index更大的更新</p><h3 id="选举模型"><a href="#选举模型" class="headerlink" title="选举模型"></a>选举模型</h3><p>5个节点中，如果有两个节点同意，那么就可以成为Leader<br>但是反过来说，如果3个节点拒绝了，那么就不能成为Leader</p><p>第一个条件我们可以使用Latch<br>第二个条件我们还是可以使用Latch</p><p>那么怎么组合这两个Latch呢<br>答案就是<br>所以总而言之，不能用Latch<br>只能加锁唤醒了</p><p>我这里自己实现了一个类专门用来进行选举的计数。</p><h2 id="日志复制"><a href="#日志复制" class="headerlink" title="日志复制"></a>日志复制</h2><h3 id="Peer状态管理"><a href="#Peer状态管理" class="headerlink" title="Peer状态管理"></a>Peer状态管理</h3><p>这个也是我实现的时候遇到的比较棘手的问题<br>一开始也没有什么好的解决思路</p><p>因为每个节点的任务执行的状态在同一个时刻肯定是不一致的，有可能这个快一点，那个慢一点</p><p>也有可能就是有的是正常发送心跳，有的则是刚刚重启需要进行日志的同步  </p><p>但是有一个很明确的点就是每个Follower节点都是不同的状态管理</p><p>同时我们再关注下Leader向Follower节点发送心跳或者AppendLogRequest的频率，会发现每次只能有一个请求过去，当这个请求没有返回或者未超时失败时，是不能够发送下一个Rpc的。</p><p><img src="/images/raft/peer.png" alt=""></p><p>综合以上两点，我的设计就是为每个PeerNode分配一个任务队列，每个PeerNode都有一个单独的线程去拿队列的第一个任务，然后同步的执行。</p><p>当Leader需要进行发送心跳或者AppendLogRequest或者其他的请求时，直接Append一个Task到PeerNode的任务队列就行。</p><h3 id="除了AppendLog还要做什么"><a href="#除了AppendLog还要做什么" class="headerlink" title="除了AppendLog还要做什么"></a>除了AppendLog还要做什么</h3><p>这个也是一个误区，因为心跳的RpcRequest就是一个空的AppendLogRequest<br>我开始的实现中，会判断如果需要Append的Log为空，那么就重置一下选举定时器，然后就直接返回了。  </p><p>这个其实是错误的，我们对每一个AppendLogRequest都要进行日志的比对，把还没有Commit的日志，如果需要，给删了或者覆盖了。  </p><p>这么说可能不太明白，假设这样一种场景。<br>一共三个节点，Node1是Leader，三个节点的日志都是1，2，3，一致的。<br><img src="/images/raft/log.png" alt="">  </p><p>然后发生了网络分区，Leader被隔绝了，但是Node1并不知道，同时客户端的请求也过来了，虽然日志无法commit，但是还是Append到了Node1中。  </p><p>如果网络分区结束，Node2变成了Leader，Node2给Node1发送心跳的时候，这时候就需要根据Log的index和Leader的commitIndex，把4和5删掉。<br>这个BUG我也是找了很久，当初图省事简单也没考虑到这些。  </p><h3 id="ReplicatedLogResponse的变更"><a href="#ReplicatedLogResponse的变更" class="headerlink" title="ReplicatedLogResponse的变更"></a>ReplicatedLogResponse的变更</h3><p>如果是节点Down了之后重启，Leader发现nextIndex对不上的时候，会一步一步的退一个NextIndex把日志发送过去，但是每次都发送后续的全量的Log，开销会很大，所以这里可能可以加一个优化，就是在ReplicatedLogResponse加上自己的lastCommitIndex，让Leader可以一次定位到matchIndex。</p><h2 id="成员变更"><a href="#成员变更" class="headerlink" title="成员变更"></a>成员变更</h2><p>论文中讲了，如果3台节点中突然加了两台，可能出现两个Leader，一个通过新配置，一个通过旧配置。</p><p>所以一般的实现是一次只增加一个节点，这个增加的行为其实是人为控制的。</p><p>这个地方的实现也有一些坑点存在。</p><p>比如论文中写新配置是通过日志的形式进行Append进去的，那么这个日志的格式是啥样的呢。<br>一开始我们定义成了增加节点和删除节点的形式，比如<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ClusterChangeLog</span> </span>&#123;</span><br><span class="line">Type type; <span class="comment">//表示是增加节点还是删除节点</span></span><br><span class="line">NodeId nodeId; <span class="comment">//需要增加的节点Id或者删除的节点Id</span></span><br><span class="line">EndPoint endPoint; <span class="comment">//需要增加的节点Id或者删除的节点Id的IP和端口地址</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>像这种形式的日志进行Append，但是其实是不行的。</p><p>我们需要的Log要包含新的集群的所有的节点信息，是否是删除还是增加，删除还是增加的节点信息由节点的日志模块自己去解析。<br>所以正确的形式应该是这样<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ClusterChangeLog</span> </span>&#123;</span><br><span class="line">List&lt;NodeConfig&gt; nodeConfigs;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>为什么说第一种的形式是行不通的或者说实现起来有BUG呢？<br>主要的问题还是在要新增的那个节点上，</p><ul><li>首先新增的节点会有个像Leader获取日志的情况，在获取日志的时候，新增的节点还不属于集群，也就是说，在日志中并没有体现，除了Leader节点，其他的follower节点并不知道该节点的存在。也就是说，我们在开启新增的节点的时候，是不能够将现有的集群的配置写给他启动的，不然就自动连接到其他的节点上去了。</li><li>第二种情况就是，如果我们把当前的集群配置写给新增的那个节点，然后启动它，再把新的集群配置写给Leader，在Leader还没发送时，Leader挂了，那么这个新增的节点咋办呢，能办也能办，但是搞起来会很复杂</li></ul><p>所以我们需要在启动新的节点时，不给它写当前的集群的配置，然后把新增的集群信息写给Leader，Leader也不会立即写日志，而是会进行日志的同步，</p><ul><li>如果日志同步的过程中，Leader挂了，那么没关系，因为新的配置还没写日志，挂了就人为的再写给新的Leader就行，不会影响当前的集群</li><li>日志同步结束之后，把日志进行Append，然后发送给所有的节点，包括新增的节点，那么即使这中间Leader挂了，因为集群更改日志是只要Append就生效的，按照日志最新的才能当前Leader的原则，新的Leader出现之后，会把更改日志再同步到其他的节点，包括新增的节点。</li></ul><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>好的，代码写完了，那么你怎么测试你的代码的正确性呢。<br>这个是我当初头疼的一点，没什么办法进行测试，我到底有没有写对。</p><p>首先这是个分布式的应用，我们除了模拟分布式的环境，还要模拟网络的各种情况，这些肯定不是我们真实模拟硬件和网络情况的，所以肯定要侵入代码的。<br>但是这种需要侵入代码的方法，没有一个方法论在里面的话很容易写乱。</p><p>这里我参考了MIT6.824的课程代码<br><a href="https://github.com/chaozh/MIT-6.824/blob/master/src/raft/test_test.go" target="_blank" rel="noopener">MIT-6.824/blob/master/src/raft/test_tes</a> </p><p>这里模拟了诸多情况</p><ul><li>Leader断网</li><li>Leader断网又恢复</li><li>集群整体掉线恢复</li><li>网络分区</li></ul><p>等诸多情况</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Raft实现指北&lt;br&gt;
    
    </summary>
    
    
      <category term="编程" scheme="https://blog.lovezhy.cc/categories/%E7%BC%96%E7%A8%8B/"/>
    
    
      <category term="raft" scheme="https://blog.lovezhy.cc/tags/raft/"/>
    
  </entry>
  
  <entry>
    <title>JVM杂记</title>
    <link href="https://blog.lovezhy.cc/2019/07/26/JVM%E6%9D%82%E8%AE%B0/"/>
    <id>https://blog.lovezhy.cc/2019/07/26/JVM%E6%9D%82%E8%AE%B0/</id>
    <published>2019-07-25T16:00:00.000Z</published>
    <updated>2020-02-23T10:30:17.951Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>作为写了好几年Java的人，自然想去深入了解一下JVM的构造，它的具体实现。</p><p>Clone了代码，运行了起来，看了《HotSpot实战》和《揭秘Java虚拟机-JVM设计原理与实现》，但是能力一般，水平有限，对JVM还是知之甚少，发现继续研究下去将是一种苦修，要做好看很久代码都毫无进展的准备。但是本人志不在此，还是想去研究分布式与数据库，精力有限，只有暂且放弃JVM的深入研究。</p><p>如此直接放弃还是有点可惜，虽然目前学到的不成体系，但是还是想写一篇Blog记录一下。</p><p>所以此博客是上文提到的两本书的摘要+自己的一些学习理解，内容会很散，同时为了省力，摘要部分不特别标出。</p><a id="more"></a><h2 id="源码目录"><a href="#源码目录" class="headerlink" title="源码目录"></a>源码目录</h2><p>HotSpot源码目录较多，有几个是比较重要的</p><ul><li>/c1 =&gt; 客户端解释器</li><li>/classfile =&gt; Class文件解析</li><li>/gc =&gt; gc相关</li><li>/interpreter =&gt; C++解释器和模板解释器都在里面</li><li>/oops =&gt; Java的类模型，也就是OOP-KLASS模型</li><li>/opto =&gt; c2解释器，也就是服务端解释器</li><li>/prims =&gt; 供外部程序访问JVM的通道，比如JNI，Perf，JMX等</li><li>/runtime =&gt; 运行时模块，包括frame，thread，VMOptions等</li><li>/shark =&gt; 基于LLVM实现的JIT编译器</li></ul><h2 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h2><p>JMM开头的方法，和Memory没关系，指的是Management的意思</p><h2 id="命令行选项"><a href="#命令行选项" class="headerlink" title="命令行选项"></a>命令行选项</h2><p>JRockit JVM中命令行选项分为三种</p><ul><li>系统属性，-D开头</li><li>标准选项，-X,-Xms其实我觉得全拼是-X:memory-start?</li><li>非标准选项,-XX</li></ul><h2 id="Class文件解析"><a href="#Class文件解析" class="headerlink" title="Class文件解析"></a>Class文件解析</h2><p>Class文件的解析的代码都在/classfile目录下</p><p><img src="/images/JVM杂记/class文件格式.jpg" alt=""></p><p>HotSpot构建了一个叫systemDictionary的字典，结构是<code>[class name,class loader] -&gt; class</code>，用来存储系统中已经加载的类，从这个Map中我们可以看到一些类加载器的条件，双亲委派的概念。</p><p>在classFileParser.cpp中，宏定义了Class文件开头的MagicWord和Java_Version的对应关系<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> JAVA_CLASSFILE_MAGIC              0xCAFEBABE</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> JAVA_MIN_SUPPORTED_VERSION        45</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> JAVA_MAX_SUPPORTED_VERSION        53</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> JAVA_MAX_SUPPORTED_MINOR_VERSION  0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> JAVA_1_5_VERSION                  49</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> JAVA_6_VERSION                    50</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> JAVA_7_VERSION                    51</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> JAVA_8_VERSION                    52</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> JAVA_9_VERSION                    53</span></span><br></pre></td></tr></table></figure></p><p>文件解析后，各个Class文件是独立的，而各个类之间的联系其实是通过符号引用来串联在一起，JVM在进行符号引用的解析之后，就可以进行类型的相互引用和方法调用</p><p>JVM的链接分为三个部分：</p><ul><li>验证：对方法进行一系列的检查，方法的访问控制，参数和静态类型检查等</li><li>准备：为类静态变量分配内存空间，但是不会初始化值</li><li>解析：将常量池中的4类符号引用转换为直接引用(用常量池项表示的字符串 -&gt; 实际内存地址)<ul><li>类</li><li>接口</li><li>字段</li><li>类方法和接口方法</li></ul></li></ul><p>链接完之后就是进行初始化，也就是调用static {}方法</p><p>对于方法的链接，运用的是链接解析器，LinkResolver对方法进行解析和查找<br>对一个方法进行解析时，需要对instanceKlass中的method表进行查找，找到目标方法后转换成MethodHandle类型句柄返回<br>对方法的权限检查（public，private这种）是在找到之后进行</p><h2 id="runtime模块与Shutdown-Hook"><a href="#runtime模块与Shutdown-Hook" class="headerlink" title="runtime模块与Shutdown Hook"></a>runtime模块与Shutdown Hook</h2><p>runtime模块主要定义HotSpot运行时数据</p><p><code>frame.hpp</code>定义了栈帧的结构，包括Java栈帧，C栈帧。</p><p><code>destroy_vm</code>的退出流程中，会运行JVM层的关闭钩子函数。<br>这里的关闭钩子函数就是提到的<code>Runtime.getRuntime().addShutdownHook();</code><br>书中提到的File.deleteOnExit方法，也是调用的这个，但是获取方式看起来不太一样<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sun.misc.SharedSecrets.getJavaLangAccess()</span><br><span class="line">            .registerShutdownHook(<span class="number">2</span> <span class="comment">/* Shutdown hook invocation order */</span>,</span><br><span class="line">                <span class="keyword">true</span> <span class="comment">/* register even if shutdown in progress */</span>,</span><br><span class="line">                <span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">                    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                       runHooks();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br></pre></td></tr></table></figure></p><p>而且参数也是不止一个，看起来还可以指定顺序<br>但是不管咋样，最后两种方式其实都是调用的<code>Shutdown.add</code>方法<br>Runtime中的调用<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Shutdown.add(<span class="number">1</span> <span class="comment">/* shutdown hook invocation order */</span>,</span><br><span class="line">               <span class="keyword">false</span> <span class="comment">/* not registered if shutdown in progress */</span>,</span><br><span class="line">               <span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">                   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                       runHooks();</span><br><span class="line">                   &#125;</span><br><span class="line">               &#125;</span><br><span class="line">           );</span><br></pre></td></tr></table></figure></p><p>看Order的参数来说的话，其实Runtime的优先级更高，而File.deleteOnExit的优先级第二。</p><h2 id="synchronized实现"><a href="#synchronized实现" class="headerlink" title="synchronized实现"></a>synchronized实现</h2><p>synchronized方法或者代码块，会生成两个特殊的字节码  </p><ul><li>monitorenter  </li><li>monitorexit<br>对于解释器而言，具体的执行逻辑在<br><code>intercepter/bytecodeIntercepter.cpp 1803行 JDK9</code><br>也就是<code>CASE(_monitorenter)</code>中<br>具体的实现分为偏向锁，轻量级锁，重量级锁<br>最后会调用<code>InterpreterRuntime::monitorenter</code>方法，这个方法定义在<code>interpreter/interpreterRuntime.cpp</code>中<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">IRT_ENTRY_NO_ASYNC(<span class="keyword">void</span>, InterpreterRuntime::monitorenter(JavaThread* thread, BasicObjectLock* elem))</span><br><span class="line">...</span><br><span class="line">  <span class="keyword">if</span> (PrintBiasedLockingStatistics) &#123;</span><br><span class="line">    Atomic::inc(BiasedLocking::slow_path_entry_count_addr());</span><br><span class="line">  &#125;</span><br><span class="line">  Handle h_obj(thread, elem-&gt;obj());</span><br><span class="line">  assert(Universe::heap()-&gt;is_in_reserved_or_null(h_obj()),</span><br><span class="line">         <span class="string">"must be NULL or an object"</span>);</span><br><span class="line">  <span class="keyword">if</span> (UseBiasedLocking) &#123;</span><br><span class="line">    <span class="comment">// Retry fast entry if bias is revoked to avoid unnecessary inflation</span></span><br><span class="line">    ObjectSynchronizer::fast_enter(h_obj, elem-&gt;lock(), <span class="literal">true</span>, CHECK);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    ObjectSynchronizer::slow_enter(h_obj, elem-&gt;lock(), CHECK);</span><br><span class="line">  &#125;</span><br><span class="line"> ...</span><br></pre></td></tr></table></figure></li></ul><p>仔细看会使用到<code>ObjectSynchronizer</code>的两个方法，如果使用了偏向锁，那么就是<code>fast_enter</code>，如果不允许偏向锁，那么就是<code>slow_enter</code></p><p>在<code>slow_enter</code>的最后，如果还是不行，就会进入锁膨胀的状态，也就是重量级锁</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ObjectSynchronizer::inflate(THREAD,</span><br><span class="line">                            obj(),</span><br><span class="line">                            inflate_cause_monitor_enter)-&gt;enter(THREAD);</span><br></pre></td></tr></table></figure><p>这个时候就要用到<code>ObjectMonitor</code>类中的方法，最后还会涉及到<code>ObjectWaiter</code>类，这个类就是设计了一个链表，类似于<code>ReententLock</code>中的等待链表。</p><p>最后还是很好奇最终的互斥锁到底是怎么实现的，代码在<code>runtime/mutex.cpp</code>中，仔细看了一下，并没有使用到c语言中的Mutex库，最终还是依赖于CAS实现的。</p><p>其实说到底，最后所有的锁都是基于CAS + 链表。</p><p>这里有一个概念上的观念，就是<a href="https://stackoverflow.com/questions/1898374/does-the-jvm-create-a-mutex-for-every-object-in-order-to-implement-the-synchron" target="_blank" rel="noopener">https://stackoverflow.com/questions/1898374/does-the-jvm-create-a-mutex-for-every-object-in-order-to-implement-the-synchron</a>该问题中提到的</p><blockquote><p>Ask: Using only CAS instructions, how do you get the OS scheduler to put a thread to sleep? </p><p>Answer: you don’t. You only use CAS to acquire / release the lock in the uninflated / uncontended case. If contention is detected, the locking/unlocking code would then do the relevant thread scheduling syscalls … or whatever.</p></blockquote><p>如果你查看ReentrentLock的最后将等待的线程放入等待链表中，对线程调用的是<code>LockSupport.park()</code>方法，这是一个native方法，要去源码中找实现，在<code>hotspot/src/os/linux/vm/os_linux.cpp</code>中，可以看到这里为了让线程能够进入os的调度，也就是放弃CPU资源，还是需要进行<code>pthread_cond_wait</code>的调用的。最后对线程的唤醒，还是需要进行notify的。</p><p>在synchronized的底层实现中，最后也是进行park，调用的是<code>os::PlatformEvent::park</code>方法，使用的类是</p><p><code>class ParkEvent : public os::PlatformEvent</code></p><p>所以，(CAS+链表+pthread_mutex)才是真正的实现机制。</p><p>而如果是多线程争用的情况，其实最终的目的还是要保证原子释放CPU资源。</p><p>说了一堆，其实核心在锁的实现上，基本都放弃了直接使用pthread_mutex的方法，而是运用<strong>CAS的方式进行自旋</strong>，而pthread_mutex的使用仅仅是为了将线程进行操作系统的重新调度。</p><p>参考文章：</p><ul><li><a href="https://github.com/farmerjohngit/myblog/issues/15" target="_blank" rel="noopener">https://github.com/farmerjohngit/myblog/issues/15</a></li><li><a href="https://www.jianshu.com/p/c5058b6fe8e5" target="_blank" rel="noopener">https://www.jianshu.com/p/c5058b6fe8e5</a></li></ul><p>偏向锁<br>这个名词看名字不是那么容易理解，在JRockit中描述为延迟解锁</p><p><img src="/images/JVM杂记/锁转换.png" alt=""></p><blockquote><p>在上图中，有三种锁类型，其中胖锁和瘦锁在之前中介绍过，这里新增了延迟锁，用来解释 锁在大部分情况下都只作用于线程局部场景下的情况。<br>正如之前介绍过的，对象首先是未加锁状态的，然后线程 T1 执行 monitorenter 指令，使 之进入延迟加锁状态。但如果线程 T1 在该对象上执行了 monitorexit 指令，这时系统会假装 已经解锁了，但实际上仍是锁定状态，锁对象的锁字中仍记录着线程 T1 的线程 ID。在此之后， 线程 T1 如果再执行加锁操作，就不用再执行相关操作了。<br>如果另一个线程 T2 试图获取同一个锁，则之前所做“该锁绝大部分被线 T1 程使用”的假 设不再成立，会受到性能惩罚，将锁字中的线程 ID 由线程 T1 的 ID 替换为线程 T2 的。如果这 种情况经常出现，那么可能会禁用该对象作为延迟锁，并将该对象作为普通的瘦锁使用。假设这 是线程 T2 第一次在该对象上调用 monitorenter 指令，则程序会进入瘦锁控制流程。在上图中， 被禁用于延迟解锁的对象用星号(*)做了标记。此时，当线程 T3 试图在某个已被禁用于延迟解 锁的对象上加锁，如果该对象还未被锁定，则此时仍会使用瘦锁。<br>使用瘦锁时，如果竞争激烈，或者在锁对象上调用了 wait 方法或 notify 方法，则瘦锁会 膨胀为胖锁，需要等待队列来处理。从图中可以看到，处于延迟解锁状态的对象直接调用 wait 方法或 notify 方法的话，也会膨胀为胖锁</p></blockquote><p>单例模式的双重校验锁的实现其实是有问题的，加了volatile能解决问题，但是会带来略微的性能问题</p><h2 id="内存-OOP"><a href="#内存-OOP" class="headerlink" title="内存 OOP"></a>内存 OOP</h2><p>虚拟机中内存空间按照内存的用途，可以划分为<strong>堆和非堆</strong></p><ul><li>堆：用于对象的分配空间</li><li>非堆：包括方法区和Code Cache</li></ul><p>Perf Data区域，有perfMemory模块管理<br>为了支持虚拟机性能监控，在虚拟机中开辟了一块共享内存，专门存储一些性能指标<br>虚拟机使用共享内存方式向外部进程提供了一种通信手段，允许外部监控进程attach至虚拟机进程，从共享内存中读取这些perf Data</p><p>oop-klass模型<br>这个感觉是比较重要的点了<br>还是一个老生长谈的问题，why的问题<br>运用C++的基础模型去实现有没有问题呢？<br>其实我感觉是没有问题的，但是相对于C++的模型，Java这种方式，其实主要是更省内存。<br>同一个类的所有对象维护同一个VTable，其次就是和C++的多态方式不同，Java是模型每一个函数都是可以被子类覆盖的，而C++的只有是虚函数才能，换句话说，Java里面每个函数都是虚函数。<br>虚函数暴增的情况下，显然这种方式更加的省内存。<br>//fixMe</p><blockquote><p>而且我感觉还和Java的类加载机制有关，因为Java的符号引用转换为直接引用的解析过程，是可以再运行中才进行的，如果父类的方法被动态改变了，函数的地址肯定也需要进行相应的改变，而现有子类的对于这个方法的指向，只要改变一次Klass就行。</p></blockquote><p>在该模型中，Java的method也作为一种OOP存在</p><p><img src="/images/JVM杂记/markword.jpg" alt=""></p><p>实例对象的创建 分为快速分配和慢速分配  </p><ul><li>快速分配就是必须是该类已经被加载和正确解析 因为类的解析，就是符号引用变直接引用的过程不一定就是ClassLoader的时候进行，HotSpot是类第一次被使用的时候解析<br>快速分配就是可以在TLAB，就是线程缓存中分配，而不必先分配到Eden区，如果开启了TLAB选项</li><li>慢速分配就是需要先解析，然后在Eden区分配</li></ul><p>对象在内存中的布局，也就是OOP对象，可以分为连续的两部分，也就是MarkWord对象头和实例数据部分<br>而在Klass模型中，存储着对象的每个变量在实例数据部分的偏移量和长度</p><p>Klass中，有一个和Java类对应的mirror成员</p><p>JVM为每个线程分配一个PC寄存器，在真实机器中，往往提供一个PC寄存器专门用来保存程序运行的指令在内存中的位置，在HotSpot的实现中，为每个线程分配了一个字长的存储空间，以实现类似硬件级的PC寄存器<br>如果当前执行方法不是本地方法，那么PC寄存器就保存的是JVM正在执行的字节码指令的地址，如果是本地方法，那么PC寄存器的值是未定义的，因为本地方法的执行依赖硬件PC寄存器，其值是由操作系统维护</p><p>Java虚拟机栈的作用：存储方法执行中的局部变量，中间演算结果以及方法返回结果</p><p>JVM允许Java虚拟机栈被实现为固定大小和动态收缩</p><ul><li><p>固定大小，顾名思义，如果超过，抛出StackOverflowError异常</p></li><li><p>动态扩展：OOM异常</p></li></ul><p>虚拟机规范对方法区实现的位置并没有明确要求，在HotSpot中，位于永久代中。<br>HotSpot会收集方法区，主要是常量池的收集和类的卸载<br>在HotSpot内部，Java方法也是由一个内部对象表示的，对象的类型是methodOop，是Java方法在JVM内部的表示方式<br>methodOop内部有指向所在类的运行时常量池的指针<br>methodOop内部有个_constMethod指针，类型是constMethodOop，用来存储和定位方法中的只读数据，如字节码，方法引用，方法名，方法签名，异常表等信息</p><p>Perf Data区域，有perfMemory模块管理<br>为了支持虚拟机性能监控，在虚拟机中开辟了一块共享内存，专门存储一些性能指标<br>虚拟机使用共享内存方式向外部进程提供了一种通信手段，允许外部监控进程attach至虚拟机进程，从共享内存中读取这些perf Data</p><p>Java类的生命周期的第一个阶段，加载，就是为了在JVM内部创建一个与Java类结构对等的数据对象</p><p>如果想要破坏双亲委派的机制，自定义类加载器加载核心类库，还是会被拒绝，因为在defineClass方法中，会提供保护，对类名为Java开头的类，直接抛出异常</p><p>同样的，类型转换需要两个类都是同一个类加载器加载的，不然会报错，上次那个Dubbo的问题就这样，报错是两个一样的类，无法进行cast</p><h2 id="GC"><a href="#GC" class="headerlink" title="GC"></a>GC</h2><p>GC的几个策略</p><ul><li>GC工作线程：串行还是并行</li><li>GC工作线程和应用线程：并发执行还是暂停应用</li><li>基本收集算法：压缩，非压缩还是拷贝</li></ul><p>吞吐量：应用程序运行时间/(应用程序运行时间 + 垃圾收集时间)</p><p>HotSpot每个线程在Eden区都有自己的一小块区域，用于TLAB分配<br>通常情况下，系统中有大量连续的内存块可以用来进行分配的话，碰撞指针算法进行分配，效率很高。思路就是记录上一次分配对象的位置，当有新对象要分配的时候，只需要一次移动位置就可以完成内存的分配<br>在TLAB中进行分配，也就是碰撞指针(bump-the-pointer)分配，效率很高</p><p>不然就需要全局锁进行在Eden区分配</p><p>还有另外一种优化，叫栈上分配</p><p>栈上分配需要对方法的对象进行逃逸分析<br>如果局部变量的作用域仅限于方法内部，则JVM直接在栈帧内分配对象，避免在堆中分配<br>但是这里引用R大的话</p><blockquote><p>嗯但是Oracle/Sun的HotSpot VM从来没在产品里实现过栈上分配，而只实现过它的一种特殊形式——标量替换（scalar replacement）。这俩是不一样的喔。栈上分配还是要分配完整的对象结构，只不过是在栈帧里而不在GC堆里分配；标量替换则不分配完整的对象，直接把对象的字段打散看作方法的局部变量，也就是说标量替换后就没有对象头了，也不需要把该对象的字段打包为一个整体。<br><a href="https://book.douban.com/people/RednaxelaFX/annotation/25847620/" target="_blank" rel="noopener">https://book.douban.com/people/RednaxelaFX/annotation/25847620/</a></p></blockquote><p>有个类叫GCCause，里面定义了一些枚举，就是引起GC的一些情况<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum</span> Cause &#123;</span><br><span class="line"><span class="comment">/* public */</span></span><br><span class="line">_java_lang_system_gc,</span><br><span class="line">_full_gc_alot,</span><br><span class="line">_scavenge_alot,</span><br><span class="line">_allocation_profiler,</span><br><span class="line">_jvmti_force_gc,</span><br><span class="line">_gc_locker,</span><br><span class="line">_heap_inspection,</span><br><span class="line">_heap_dump,</span><br><span class="line">_wb_young_gc,</span><br><span class="line">_wb_conc_mark,</span><br><span class="line">_wb_full_gc,</span><br><span class="line">_update_allocation_context_stats_inc,</span><br><span class="line">_update_allocation_context_stats_full,</span><br><span class="line"></span><br><span class="line"><span class="comment">/* implementation independent, but reserved for GC use */</span></span><br><span class="line">_no_gc,</span><br><span class="line">_no_cause_specified,</span><br><span class="line">_allocation_failure,</span><br><span class="line"></span><br><span class="line"><span class="comment">/* implementation specific */</span></span><br><span class="line"></span><br><span class="line">_tenured_generation_full,</span><br><span class="line">_metadata_GC_threshold,</span><br><span class="line">_metadata_GC_clear_soft_refs,</span><br><span class="line"></span><br><span class="line">_cms_generation_full,</span><br><span class="line">_cms_initial_mark,</span><br><span class="line">_cms_final_remark,</span><br><span class="line">_cms_concurrent_mark,</span><br><span class="line"></span><br><span class="line">_old_generation_expanded_on_last_scavenge,</span><br><span class="line">_old_generation_too_full_to_scavenge,</span><br><span class="line">_adaptive_size_policy,</span><br><span class="line"></span><br><span class="line">_g1_inc_collection_pause,</span><br><span class="line">_g1_humongous_allocation,</span><br><span class="line"></span><br><span class="line">_dcmd_gc_run,</span><br><span class="line"></span><br><span class="line">_last_gc_cause</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><p>收集算法</p><ul><li>标记-清除 Mark-Sweep</li><li>复制算法 Copying</li><li>标记-压缩算法 Mark-Compact</li></ul><p>堆的类型</p><p>不同的收集器可能对应着不同类型的堆</p><p><code>CollectedHeap &lt;- ParallelScavengeHeap</code></p><p><code>CollectedHeap &lt;- SharedHeap &lt;- G1CollectedHeap</code></p><p>CMS的创新之处在于把标记分为两个阶段，初始标记和并发标记</p><p>但是引入了新的缺点，就是并发收集失败的问题，在并发标记时，内存使用过度，只有STW，采取线性标记和收集</p><p>而且只能由于并发清除的问题，只能进行标记-清除，将产生内存碎片，而新生代由于其特殊性，将产生更多的内存碎片，所以CMS在新生代并不适用，只运用在老年代</p><p>安全点</p><blockquote><p>由于JVM系统运行期间的复杂性，不可能做到随时暂停，因此引入了安全点（safepoint）：程序只有在运行到安全点的时候，才准暂停下来。HotSpot采取主动中断的方式，让执行线程在运行时轮询是否需要暂停的标识，若需要则中断挂起。</p></blockquote><p>//fixme<br>其实我觉得这里说的不对，应该不是不可能做到随时暂停，而是随时暂停的消耗太大了，因为后面也写到是主动中断的方式，如果在每个字节码后面都插入check是否需要中断的代码，则消耗确实是太大了<br>参考文章：<a href="https://www.jianshu.com/p/c79c5e02ebe6" target="_blank" rel="noopener">https://www.jianshu.com/p/c79c5e02ebe6</a></p><p>G1收集器<br>G1重新定义了堆空间，打破了原有的分代模型，将堆划分为一个个区域<br>在进行收集的时候，不必在全堆的范围内进行，好吃就是带来了停顿时间的可预测<br>G1会通过一个合理的计算模型，计算出每个region的收集成本并量化</p><p>分代模型的写屏障<br>这个是比较重要的一个，一开始是比较难理解的<br><img src="/images/JVM杂记/写屏障.png" alt=""><br>我们从正常的新生代的GC开始说，从图中看到，如果只从GCRoot出发，其实是扫描不到F的，如果扫描不到，说明F是需要被清除的<br>但是其实F被老年代的E所引用，也就是说他不能被清除<br>这就是说，GCRoot需要包含新生代中的被老年代引用的对象。<br>但是如果要实现这个功能，可能要扫描所有的老年代对象了，如果每次进行新生代的GC时都扫描老年代，那么分代GC的意义就不是那么明显了<br>所以这里用了一个写屏障，底层使用的是卡表的概念进行标记。<br>简单的说就是每当有老年代对象引用新生代对象时，就把老年代对象所在的位置标记一下，然后进行新生代GC时，把老年代标记了的位置进行扫描进行，而不用全部扫描<br><a href="https://juejin.im/post/5c39920b6fb9a049e82bbf94" target="_blank" rel="noopener">https://juejin.im/post/5c39920b6fb9a049e82bbf94</a></p><p>压缩指针<br>指针的大小一般是平台的决定的，但是在64位的机器上，但是还是可以进行一些优化，优化的基础是内存的申请是一下子一大片连续的内存<br>举个例子就是在64位机器上，如果我们要申请的一块内存小于4G，那么完全可以只用32位就可以进行指针的保存</p><p>JRockit里面提到了一种伪优化<br>就是对象池，有人认为，保留一个存活对象池来重新使用已创建的对象可以提升垃圾回收的性能</p><blockquote><p>但实际上，对象池不仅增加了应用程序的复杂度，还很容易出错。对于现代垃圾收集器来说，使用 java.lang. ref.Reference 系列类实现缓存，或者直接将无用对象的引用置为 null 就好了，不用多操心。<br>此外，长期持有无用的对象其实是个大麻烦，分代式垃圾回收器可以很好地处理临时对象，但如果这些临时对象被人为保存下来，无法被回收掉的话，最终就会被提升到老年代，并将其挤满。</p></blockquote><h2 id="栈帧"><a href="#栈帧" class="headerlink" title="栈帧"></a>栈帧</h2><p>如果函数要返回整数或者指针的话，寄存器%eax可以用来返回值<br>寄存器eax，edx，ecx被划分为调用者保存<br>而寄存器ebx，esi，edi寄存器划分为被调用者保存<br>栈是以帧为单位保存当前线程的运行状态<br>当线程执行一个方法时，它会跟踪当前常量池<br>栈帧存储了方法的局部变量表，操作数栈，动态链接和方法返回地址</p><p><img src="/images/JVM杂记/栈帧结构.png" alt=""><br><img src="/images/JVM杂记/解释器帧.png" alt=""></p><p>局部变量表</p><ul><li>局部变量表被组织为一个字长为单位，从0开始计数的数组</li><li>存储时以slot为单位，一个slot一般为32位，short，byte，char在存入表中要先转换为int</li><li>一般会存储的类型除了基本类型和引用，还有returnAddress类型，它指向了一个字节码指令的地址</li><li>参数值到参数变量列表的传递依赖于局部变量表</li><li>第0位索引的slot默认是用于传递方法所属对象实例的引用</li></ul><p>局部变量表的描述</p><ul><li>start_pc，length：描述局部变量的作用域</li><li>name_index：描述局部变量名的常量池索引，对应Class文件中的Name</li><li>descriptor_index:描述局部变量类型的常量池索引，对应Class文件中的Signature</li><li>index：描述局部变量在当前栈帧的局部变量索引</li></ul><p>局部变量表的大小在编译期就可以确定，在Code属性中明确了大小</p><p>操作数栈</p><ul><li>操作数栈的深度由Code属性max_stacks在编译期确定</li><li>和局部变量表不同的是，操作数栈不是通过索引来访问的，而是通过入栈和出栈来访问</li><li>还有一个比较重要的点，就是操作数栈和下一个栈帧的参数列表是可以复用的，不然我们在HSDB调试操作数栈的时候看起来会比较迷惑</li></ul><p>异常表<br>为了处理Java方法中的异常情况，帧数据区还必须保存一个对此方法异常表的引用，当异常抛出时，JVM给catch块中的代码<br>如果没发现，方法立即终止，然后JVM用帧区数据的信息回复发起调用的方法的帧，然后再发起调用方法的上下文重新抛出同样的异常</p><p>Hotspot解释器执行引擎在执行字节码时，实际上是执行一段已经被编译成本地机器直接运行的指令<br>在JVM启动期间，解释器模块就会将每个字节码转换成与之等价的机器指令，放在Code Cache中<br>所以HotSpot充分利用了计算机的资源，包括寄存器</p><h2 id="JavaCalls"><a href="#JavaCalls" class="headerlink" title="JavaCalls"></a>JavaCalls</h2><p>JavaCalls，说白了就是JVM调用Java方法</p><p>然后CallStub，是一个函数指针，在调用Java程序的Main函数时，需要使用这个函数指针</p><p>但是CallStub指向的函数是一个entry_point，是一个例程</p><p>当然这里其实是有歧义的例程在JVM的概念就是提前用机器码写好的函数，而entry_point虽然也是例程，然后它主要突出entry这个词，主要是在方法调用切换时进行调用的例程</p><p>再说回CallStub，它指向的例程，就是为所有Java程序的唯一一个Main方法构造他的前一个栈帧</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;&#125;</span><br></pre></td></tr></table></figure><p>最直接的就是参数args，在栈中需要使用CallStub指向的例程构建好，然后CallStub的函数指针的函数中，还需要传入一个entry_point，这个就是在进行Java函数调用的时候，需要进行寄存器的保存等之类的操作，而这些操作由不同的entry_point来操作。</p><p>//fix me</p><p>个人理解就是在各种invoke的字节码指令中，会频繁的调用这些不同的entry_point。</p><h2 id="常量池"><a href="#常量池" class="headerlink" title="常量池"></a>常量池</h2><p>其实JVM中常量池有两种不同的概念<br>第一种是Class文件的常量池<br>虚拟机在创建一个类或者接口时候，按照Class文件的定义创建相应的常量池，也就是Class文件中的constant_pool表。<br>第二种是方法区中的常量池，虚拟机在对类进行解析和连接之后，将在内存中为该类生成一套运行时常量池，常量池在运行时动态分配<br>第三种是代码中我们提到的常量池，也就是String常量池，JVM中创建了一个String的Table</p><p>参考<a href="https://blog.csdn.net/zm13007310400/article/details/77534349" target="_blank" rel="noopener">https://blog.csdn.net/zm13007310400/article/details/77534349</a></p><p>那么为什么要有常量池呢<br>Answer：</p><blockquote><p>常量池的出现，解决了JVM定位字段和方法的问题，它在不破坏指令集的简洁性的前提下，仅仅通过少量字节就能定位到目标。<br>更详细的说，以字符串数据aVeryLongFunctionName为例，如果在编译时每次都要重新避免这个字符串的话，那么字节码就谈不上压缩了</p></blockquote><p>但是每次字段或者方法的访问都需要解析常量池项的话，将不可避免的造成性能下降<br>对于类文件的运行时常量池，JVM内还会有它的高速缓冲ConstantPoolCache</p><h2 id="解释器"><a href="#解释器" class="headerlink" title="解释器"></a>解释器</h2><p>HotSpot的解释器分为了两种<br>一种是CPP解释器，也就是最原始的解释器，类似于Case，Case这种形式，文件是intercepter/bytecodeIntercepter.cpp<br>一种是模板解释器，现在默认是这样，这种是在JVM启动时对每一个字节码都进行了当前平台的机器码转换，具体的是维护了一个平台相关TemplateTable，可以在cpu/x86/vm中的templateTable_XX.cpp中找到，相对于CPP解释器，其实这也是一种解释的方法，虽然第一种最终执行的也是C++编译成的机器码，但是模板解释器相对于CPP解释器，机器码是手动写的，可以进行一些优化，比如TOS，还有就是对于取出下一个执行进行运行，也可以直接插入到当前字节码的机器码中</p><p>对于模板解释器的取指令的操作，其实在写在每一个字节码指令的最后。<br>HotSpot在为每一个字节码指令生成其机器逻辑指令时，会同时为该字节码指令生成其取址逻辑</p><p>PC计数器，在x86平台上就是esi寄存器，所以在JVM中并不是完全不使用CPU的寄存器</p><p>面向栈式的指令，可以省去很多的操作数，所以一定程度上也减少了代码体积<br>这话其实不对，因为相对于寄存器式的指令，寄存器式的一个指令就能完成的事，其实栈式需要多个指令</p><p>栈帧重叠<br>就是前面提到的上一个方法的操作数栈可以直接成为下一个方法的参数表</p><p>栈上替换 OSR<br>个人理解就是在一个方法里遇到了Loop非常久的情况，对方法进行了JIT编译，但是由于这个Loop非常长，JIT编译完还未结束，所以为了将当前方法替换到新的栈帧，使用栈上替换<br>具体的解释在R大这儿<br><a href="https://www.zhihu.com/question/45910849" target="_blank" rel="noopener">OSR（On-Stack Replacement）是怎样的机制？</a><br>JRockit没有实现OSR，因为太复杂了</p><p>JIT编译器<br>为什么不直接全部aot编译一下，而是选择了解释+JIT的方式<br>R大这里也回答了[<a href="https://www.zhihu.com/question/37389356)(https://www.zhihu.com/question/37389356" target="_blank" rel="noopener">https://www.zhihu.com/question/37389356)(https://www.zhihu.com/question/37389356</a>)<br>我总结一下</p><ul><li>时间开销，aot的启动时间肯定很慢</li><li>空间开销，字节码到机器码会代码膨胀</li><li>编译时机，一些profile的收集对编译有很大的影响<blockquote><p>JIT是一个充满希望的方向，因为它可以搜集到程序在AOT编译时得不到的runtime数据，在优化时，有更多的上下文可以依靠，理论上应该有更好的优化特性</p></blockquote></li></ul><p>在JRockit中，讲了aot其实在90年代就已经出现了，但是这种方式虽然快了很多，但是抛弃了很多Java的动态特性，提到了一个很重要的场景，就是在JSP的应用中，我们知道JSP其实就是b被编译成class文件，做的事也仅仅是疯狂的sout，如果aot一下，效率不会提高太多，但是代码体积会提高很多</p><p>其实aot与全部JIT编译并不是一个概念，一个好的办法是，给JIT的编译加上不同层级的编译，一开始可能是优化不高的，后面收集到profile后再进行深层次的profile</p><p>判断热方法</p><ul><li>counter，但是会降低效率</li><li>基于软件的线程采样，周期性的获取活动线程的上下文</li></ul><p>JVM字节码的表现力其实比Java语言强，所以需要对字节码进行校验，防止一些恶意的技巧</p><h2 id="TOS"><a href="#TOS" class="headerlink" title="TOS"></a>TOS</h2><p>TosState的取值范围为0-8，共计9种</p><ul><li>byte，bool</li><li>char</li><li>short</li><li>int</li><li>long</li><li>float</li><li>double</li><li>object</li><li>void</li></ul><p>最后一种其实就是空，参见R大的笔记，HotSpot实战中写的是tos类型，我还去百度了tos类型是啥类型😓 </p><h2 id="VM选项"><a href="#VM选项" class="headerlink" title="VM选项"></a>VM选项</h2><table><thead><tr><th>配置</th><th>解释</th><th>备注</th></tr></thead><tbody><tr><td>-XX:UseG1GC</td><td>配置G1收集器</td><td></td></tr><tr><td>-Xint</td><td>配置虚拟机以纯解释方式运行</td><td></td></tr><tr><td>-XX:+MaxFDLimit</td><td>最大文件描述符数量</td><td></td></tr><tr><td>-XX:DisableExplicitGC</td><td>Parallel Scanvenge收集器的配置，屏蔽System.gc()</td></tr></tbody></table><h2 id="Tools"><a href="#Tools" class="headerlink" title="Tools"></a>Tools</h2><p>实际的性能分析可以查看《HotSpot实战》的5.3小节，讲的很详细</p><ul><li>HSDB：可以用来看JVM的运行时数据，查看线程栈，对象的数据</li><li>jps：查看Java进程信息</li><li>jinfo：</li><li>jmap：</li><li>jhat：</li><li>jstat：</li><li>jstack：</li></ul><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://book.douban.com/people/RednaxelaFX/annotation/25847620/?start=0" target="_blank" rel="noopener">RednaxelaFX对《HotSpot实战》的笔记</a><br><a href="https://book.douban.com/subject/25847620/" target="_blank" rel="noopener">HotSpot实战</a><br><a href="https://book.douban.com/subject/30394745/" target="_blank" rel="noopener">JRockit权威指南：深入理解JVM</a><br><a href="https://book.douban.com/subject/27086821/" target="_blank" rel="noopener">https://book.douban.com/subject/27086821/</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;作为写了好几年Java的人，自然想去深入了解一下JVM的构造，它的具体实现。&lt;/p&gt;
&lt;p&gt;Clone了代码，运行了起来，看了《HotSpot实战》和《揭秘Java虚拟机-JVM设计原理与实现》，但是能力一般，水平有限，对JVM还是知之甚少，发现继续研究下去将是一种苦修，要做好看很久代码都毫无进展的准备。但是本人志不在此，还是想去研究分布式与数据库，精力有限，只有暂且放弃JVM的深入研究。&lt;/p&gt;
&lt;p&gt;如此直接放弃还是有点可惜，虽然目前学到的不成体系，但是还是想写一篇Blog记录一下。&lt;/p&gt;
&lt;p&gt;所以此博客是上文提到的两本书的摘要+自己的一些学习理解，内容会很散，同时为了省力，摘要部分不特别标出。&lt;/p&gt;
    
    </summary>
    
    
      <category term="JVM" scheme="https://blog.lovezhy.cc/categories/JVM/"/>
    
    
      <category term="JVM" scheme="https://blog.lovezhy.cc/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>Java中FileLock的实现细节</title>
    <link href="https://blog.lovezhy.cc/2019/03/29/Java%E4%B8%ADFileLock%E7%9A%84%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82/"/>
    <id>https://blog.lovezhy.cc/2019/03/29/Java%E4%B8%ADFileLock%E7%9A%84%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82/</id>
    <published>2019-03-28T16:00:00.000Z</published>
    <updated>2020-02-23T10:30:12.584Z</updated>
    
    <content type="html"><![CDATA[<h2 id="起因"><a href="#起因" class="headerlink" title="起因"></a>起因</h2><p>开始看Lucene源代码，找了个最简单的FSLockFactory开始看。<br>然而还是看出了不明白的地方  </p><p>在NativeFSLockFactory的close方法中有这么一段注释</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// <span class="doctag">NOTE:</span> we don't validate, as unlike SimpleFSLockFactory, we can't break others locks</span></span><br></pre></td></tr></table></figure><p>我从网上找到了当初的Bug的讨论帖<br><a href="https://issues.apache.org/jira/browse/LUCENE-6507" target="_blank" rel="noopener">https://issues.apache.org/jira/browse/LUCENE-6507</a>  </p><p>从里面讨论了NativeFSLock了一些关于这个文件锁的实现的问题</p><a id="more"></a><h2 id="JDK的BUG"><a href="#JDK的BUG" class="headerlink" title="JDK的BUG"></a>JDK的BUG</h2><blockquote><p>On some systems, closing a channel releases all locks held by the Java virtual machine on the underlying file regardless of whether the locks were acquired via that channel or via another channel open on the same file. It is strongly recommended that, within a program, a unique channel be used to acquire all locks on any given file. </p></blockquote><p>这个JDK的文档中写的就是这么一种场景，在某些操作系统上，如果我们把channel直接关闭，那么其他的在这个文件上的Lock会直接失效，当然前提是在同一个JVM进程中</p><p>如果没有这个BUG，我们会怎么写这个LOCK的获取代码呢<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">FileChannel channel = <span class="keyword">null</span>;</span><br><span class="line">FileLock lock = <span class="keyword">null</span>;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">    channel = FileChannel.open(realPath, StandardOpenOption.CREATE, StandardOpenOption.WRITE);</span><br><span class="line">    lock = channel.tryLock();</span><br><span class="line">    <span class="keyword">if</span> (lock != <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">new</span> NativeFSLock(lock, channel, realPath, creationTime);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> LockObtainFailedException(<span class="string">"Lock held by another program: "</span> + realPath);</span><br><span class="line">    &#125;</span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (lock == <span class="keyword">null</span>) &#123; <span class="comment">// not successful - clear up and move out</span></span><br><span class="line">      IOUtils.closeWhileHandlingException(channel); <span class="comment">// <span class="doctag">TODO:</span> addSuppressed</span></span><br><span class="line">      clearLockHeld(realPath);  <span class="comment">// clear LOCK_HELD last </span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>很简单的，就是先拿channel，然后tryLock，如果失败，就是记得关闭channel就行了。</p><p>但是有个JDK的这个问题，还能直接关闭吗？<br>显然是不能的，你关闭channel，会把其他在这个channel的锁给invalid掉。</p><h2 id="Lucene的实现"><a href="#Lucene的实现" class="headerlink" title="Lucene的实现"></a>Lucene的实现</h2><p>这个帖子最后的解决方案，就是加了一个类似于双重校验锁的东西。<br>在同一个进程中，设置一个<br><code>Set&lt;String&gt; LOCK_HELD</code></p><p>要想获取文件锁，首先得成功把LockName加个Lock_HELD中。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://github.com/frohoff/jdk8u-dev-jdk/blob/master/src/share/classes/java/nio/channels/FileLock.java" target="_blank" rel="noopener"><code>java.nio.channel.FileLock</code>注释</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;起因&quot;&gt;&lt;a href=&quot;#起因&quot; class=&quot;headerlink&quot; title=&quot;起因&quot;&gt;&lt;/a&gt;起因&lt;/h2&gt;&lt;p&gt;开始看Lucene源代码，找了个最简单的FSLockFactory开始看。&lt;br&gt;然而还是看出了不明白的地方  &lt;/p&gt;
&lt;p&gt;在NativeFSLockFactory的close方法中有这么一段注释&lt;/p&gt;
&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// &lt;span class=&quot;doctag&quot;&gt;NOTE:&lt;/span&gt; we don&#39;t validate, as unlike SimpleFSLockFactory, we can&#39;t break others locks&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;我从网上找到了当初的Bug的讨论帖&lt;br&gt;&lt;a href=&quot;https://issues.apache.org/jira/browse/LUCENE-6507&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://issues.apache.org/jira/browse/LUCENE-6507&lt;/a&gt;  &lt;/p&gt;
&lt;p&gt;从里面讨论了NativeFSLock了一些关于这个文件锁的实现的问题&lt;/p&gt;
    
    </summary>
    
    
      <category term="Lucene" scheme="https://blog.lovezhy.cc/categories/Lucene/"/>
    
    
      <category term="Lucene" scheme="https://blog.lovezhy.cc/tags/Lucene/"/>
    
  </entry>
  
  <entry>
    <title>h2database的MVStore解析</title>
    <link href="https://blog.lovezhy.cc/2019/02/18/H2database%E7%9A%84MVStore%E8%A7%A3%E6%9E%90/"/>
    <id>https://blog.lovezhy.cc/2019/02/18/H2database%E7%9A%84MVStore%E8%A7%A3%E6%9E%90/</id>
    <published>2019-02-17T16:00:00.000Z</published>
    <updated>2019-02-28T14:06:05.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>MVStore是h2数据库的底层的存储文件格式<br>在1.4版本之前底层的文件存储都是<code>org.h2.store.*</code>包中的<br>然后1.4之后默认改为了<code>org.h2.mvstore.*</code>包中的  </p><p>官方的介绍说是根据<code>Log Structed FS</code>设计的，顺序写提高性能</p><p>MV的意思是<code>multi-version</code></p><p>同类型的项目有个叫<code>mapDB</code>的项目<br><a href="https://github.com/jankotek/mapdb" target="_blank" rel="noopener">https://github.com/jankotek/mapdb</a>  </p><p>还有一个Apache的项目<code>mavibot</code><br><a href="http://directory.apache.org/mavibot/downloads.html" target="_blank" rel="noopener">http://directory.apache.org/mavibot/downloads.html</a>  </p><a id="more"></a><h1 id="简单使用"><a href="#简单使用" class="headerlink" title="简单使用"></a>简单使用</h1><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.h2.mvstore.*;</span><br><span class="line"></span><br><span class="line"><span class="comment">// open the store (in-memory if fileName is null)</span></span><br><span class="line">MVStore s = MVStore.open(fileName);</span><br><span class="line"></span><br><span class="line"><span class="comment">// create/get the map named "data"</span></span><br><span class="line">MVMap&lt;Integer, String&gt; map = s.openMap(<span class="string">"data"</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// add and read some data</span></span><br><span class="line">map.put(<span class="number">1</span>, <span class="string">"Hello World"</span>);</span><br><span class="line">System.out.println(map.get(<span class="number">1</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// close the store (this will persist changes)</span></span><br><span class="line">s.close();</span><br></pre></td></tr></table></figure><p>来自官网的例子<br>就当做一个普通的Map使用就行，不过这里支持持久化到磁盘上</p><h1 id="文件格式"><a href="#文件格式" class="headerlink" title="文件格式"></a>文件格式</h1><p>在参考文档中有详细的讲述，不过和最新的代码版本有一些出入<br><img src="/images/mvstore/fileformat.png" alt=""></p><p>先谈谈<code>block</code>的概念<br><code>block</code>是一个扇区的大小，也就是磁盘一次读取的大小。<br>所以H2里定为<strong>4k</strong>，然后无论是<code>file header</code>还是<code>chunk</code>，都是对齐到<code>block</code>的整数倍 </p><h2 id="总体"><a href="#总体" class="headerlink" title="总体"></a>总体</h2><p><code>[ file header 1 ] [ file header 2 ] [ chunk ] [ chunk ] ... [ chunk ]</code></p><p>整个文件的格式是这样<br>其中<code>file header</code>是个KV的格式，<strong>大小是一个<code>block</code></strong><br>形如<br><code>H:2,blockSize:1000,created:167a11ebf8d,format:1,fletcher:9f80997e</code></p><ul><li><code>H:2</code>:固定的，表示这个是h2数据库文件</li><li><code>blockSize:1000</code>：<code>block</code>的大小，size是16进制的，换成存储的就是4K</li><li><code>created:167a11ebf8d</code>：创建时间，v也是16进制的</li><li><code>format:1</code>：文件格式版本，为了防止后续如果新版本文件格式更改，现在都是1</li><li><code>fletcher:9f80997e</code>：checkSum</li></ul><p><code>file header</code>写了两份，header1和header2内容是一样的，官网的描述是防止文件损坏破坏了一份，也是有道理的。</p><h2 id="Chunk"><a href="#Chunk" class="headerlink" title="Chunk"></a>Chunk</h2><p>由于是Version的概念，所以每一次Commit，都会把这个阶段进行了修改的Page都放在新的Chunk中，Version++ （当然如果这段时间内没有修改，就不会commit）</p><p>每次Commit结束，只保留RootPage，把Children的Page缓存全部清空</p><p>下面的<code>chunk</code>是真正存储数据的地方，格式如下：<br><code>[ header ] [ page ] [ page ] ... [ page ] [ footer ]</code></p><p><code>Chunk</code>的大小是不固定的，但是肯定是<code>block</code>的整数倍大小  </p><p>header也是KV的格式，长度限定了最大值<code>Chunk.MAX_HEADER_LENGTH = 1k</code><br>header的header生成来自函数<code>Chunk#asString</code><br>结果是header形如：<br><code>chunk:5,block:5,len:1,map:c,max:980,next:6,pages:5,root:14000016194,time:102cc,version:5</code></p><ul><li><code>chunk:5</code>: 每个chunk都有一个id，这里的id为5，id是原子自增的</li><li><code>block:5</code>：chunk开始的block，用<code>5*blockSize</code>就可以定为到chunk在file中的offset</li><li><code>len:1</code>:chunk的长度，单位为block</li><li><code>map:c</code>：最新的map的id，这里是16进制，每新建一个Map都会分配一个id，自增的，其实我觉得是记录map的个数</li><li><code>max:980</code>:每个Page有个MaxLen（见下面Page的格式)，这里是chunk中所有的maxLen加起来的值</li><li><code>next:6</code>：预测的下一个chunk的开始位置，单位为block</li><li><code>pages:5</code>：此chunk中的包含的page的个数</li><li><code>root:14000016194</code>: MetaMap Root Page的位置，但不是指在文件中的绝对位置，参见Page中的Children编码，一般是chunkId+offset来表示</li><li><code>time:102cc</code>：时间戳，16进制，从文件创建后到chunk写入的时间差</li><li><code>version:5</code>：版本号，一般来说一个commit就会创建一个chunk，每个chunk都是一个新的版本号，这里的chunk包含的数据版本是5</li></ul><p>除了上面这些，可能还有</p><ul><li><code>liveMax</code>:  回去看max的含义，是每个Page的MaxLen的和，就是无论这个Page是否还被使用，liveMax就是所有还在被使用的Page的MaxLen的和</li><li><code>livePages</code>：和上面的Pages的对应，也是还在被使用的Page的个数，而Pages统计的是所有<br>那么统计上面这个两个参数有啥含义呢，当我们回收一个Chunk的时候，如果其中Pages很多，但是目前还在被使用的极少，那么就会进行compact，把还在使用的移动到新的Chunk中，然后回收这个Chunk</li></ul><p>footer的信息和header其实和一部分是一样的<br>写入footer我感觉是为了文件初始化的时候直接从文件末尾开始构建MetaMap准备的<br><code>chunk:5,block:5,version:5,checkSum:{checkSum}</code></p><h2 id="Page"><a href="#Page" class="headerlink" title="Page"></a>Page</h2><p><code>page</code><br>page是进行数据读写和操作的最小单位<br>但是和其他的框架中的Page定义不同的是，这里的<strong>page的大小并不一定</strong>，虽然不固定，但是也有一个阈值的<br>当超过阈值条件后，会进行页分裂，关于页分裂的参见下文</p><p>每一个Map的底层都是一个B+树，然后每一个节点都是一个Page<br>但是其实不是标准的B+树，是一种变形，叫<code>Counted B+ Tree</code><br>这个奇怪的结构，网上并没有找到介绍，但是其实就是进行了B+Tree的优化<br>参见我的另一个文章<strong>Counted-B+Tree原理</strong></p><p>一个Page的结构是<br><code>[length][checkSum][mapId][len][type][children][childCount][keys][values]</code></p><ul><li><code>length</code>：page的大小，int类型</li><li><code>checkSum</code>: checkSum，计算方式是<code>chunkId ^ page在chunk中的offset ^ length</code>，short类型</li><li><code>mapId</code>：page所属的map的id，variable size int类型 </li><li><code>len</code>：key的个数，variable size int类型</li><li><code>type</code>：page的类型，0代表叶子节点，1代表内部节点，如果值+2了表示key和value进行了LZF压缩，如果值+6表示key和value进行了Deflate压缩，byte类型</li><li><code>children</code>：long[]类型，值为子节点的位置，其中<ul><li>26bit为chunkId，</li><li>32bit为page在chunk中的offset，</li><li>5bit位lengthCode，标志page的maxLen<ul><li>0 =&gt; 32bytes</li><li>1 =&gt; 48bytes</li><li>2 =&gt; 64bytes</li><li>3 =&gt; 96bytes</li><li>…</li></ul></li><li>1bit为children的type，叶子节点还是内部节点</li></ul></li><li><code>childCount</code>：表示子节点中的key个数，类型是variable size long数组</li><li><code>keys</code>:放的是key，byte[]类型</li><li><code>values</code>：只有子节点有，放的是值，byte[]类型</li></ul><p>问：为什么不用绝对位置的信息来存放Page的位置呢<br>答：这样灵活性更大，可以移动整个chunk而不用进行Page位置的修改<br>问：什么时候会移动Chunk呢<br>答：目前没看到</p><h1 id="metaMap"><a href="#metaMap" class="headerlink" title="metaMap"></a>metaMap</h1><p>在文件初始化的时候，会创建一个metaMap<br>这个Map中存放的是文件的一些元信息<br>每次Chunk进行写入的时候，最后写入metaMap的Page的信息</p><p>metaMap中存放着这些信息</p><ul><li><code>name.{mapName}</code> =&gt; mapId，由map的名字对应MapId，mapId是16进制</li><li><code>map.{id}</code> =&gt; <code>name:{mapName}</code></li><li><code>root.{mapId}</code>：mapId所指的map的RootPage的位置</li><li><code>chunk.{chunkId}</code> =&gt; <code>chunk:2,block:3,len:1,liveMax:100,livePages:1,map:1,max:3c0,next:4,pages:5,root:800000be0a,time:824,version:2</code> 表示chunk为id的信息</li></ul><p>但是整个MVStore会进行GC的，就是定期清除那些有用的Page不多的Chunk，然后把空出来的空间放新的Chunk。<br>这就导致了一个问题，就是<strong>最新的Chunk不一定就是就在文件的最后</strong><br>所以怎么找到最新的MetaMap的地址呢<br>记得每个Chunk里有个next的KV吗，在MVStore进行初始化的时候，会直接读取最后一个Chunk，然后依次根据他的next值寻找下去，从而找到最后一个Chunk。</p><h1 id="文件新建"><a href="#文件新建" class="headerlink" title="文件新建"></a>文件新建</h1><p>h2抽象出了操作文件接口和上层的业务<br>文件的实现都是在<code>org.h2.store.fs.*</code>中，读写接口是FileChannel。<br>当我们调用</p><p><code>MVStore s = MVStore.open(&quot;/Users/zhuyichen/h2/data.mv&quot;);</code></p><p>时，MVStore会打开一个新的文件，当然是文件不存在的时候<br>写上<code>file header</code>部分，写两份<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">storeHeader.put(<span class="string">"H"</span>, <span class="number">2</span>);</span><br><span class="line">storeHeader.put(<span class="string">"blockSize"</span>, BLOCK_SIZE); <span class="comment">//BLOCK_SIZE = 4 * 1024</span></span><br><span class="line">storeHeader.put(<span class="string">"format"</span>, FORMAT_WRITE);  <span class="comment">//FORMAT_WRITE = 1</span></span><br><span class="line">storeHeader.put(<span class="string">"created"</span>, creationTime);</span><br></pre></td></tr></table></figure></p><h1 id="文件打开"><a href="#文件打开" class="headerlink" title="文件打开"></a>文件打开</h1><p>如果是打开旧的文件，那么会分为下面几个步骤</p><ul><li>读取Header信息</li><li>读取最后一个Chunk的Footer信息</li><li>读取最后一个Chunk的Header信息</li><li>定位MetaMap的位置</li><li>读取MetaMap的信息，定位所有Map的RootPage的信息</li></ul><p>所以其实整个核心就是找到MetaMap的位置，然后读取，只要得到MetaMap的信息，就可以找到所有的Map的位置了</p><p>这里还是略复杂，为了讲清楚，我们举例子<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">MVStore s = MVStore.open(<span class="string">"/Users/zhuyichen/h2/data.mv"</span>);</span><br><span class="line">MVMap&lt;Integer, String&gt; map1 = s.openMap(<span class="string">"data1"</span>);</span><br><span class="line">MVMap&lt;Integer, String&gt; map2 = s.openMap(<span class="string">"data2"</span>);</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++) &#123;</span><br><span class="line">    map1.put(i, <span class="string">"Hello1"</span>);</span><br><span class="line">    map2.put(i, <span class="string">"hello2"</span>);</span><br><span class="line">&#125;</span><br><span class="line">s.commit();</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">50</span>; i++) &#123;</span><br><span class="line">    map1.put(i, <span class="string">"hi1"</span>);</span><br><span class="line">    map2.put(i, <span class="string">"hi2"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">s.close();</span><br></pre></td></tr></table></figure></p><p>我们在运行上面的代码之后，会产生两个Chunk<br><img src="/images/mvstore/fileformat2.png" alt=""><br>如上图<br>第一个Chunk中包含了两个B+树  每一个RootPage包含四个Leaf Page<br>在第二次修改中，我们只修改了50个元素，所以没有动到第4个Leaf Page的数据<br>当我们进行commit之后，只save了3个Page，第4个没有动Page，我们还是指向了Chunk1的数据  具体的基于Page的B+树，请看下面</p><p>这里我们知道了文件的布局，下面看看文件的打开流程<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MVStore s = MVStore.open(<span class="string">"/Users/zhuyichen/h2/data.mv"</span>);</span><br></pre></td></tr></table></figure></p><p>当我们调用这句话的时候</p><h1 id="新建Map"><a href="#新建Map" class="headerlink" title="新建Map"></a>新建Map</h1><p>打开文件之后，新建一个Map实例</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MVMap&lt;String, String&gt; map = mvStore.openMap(<span class="string">"data"</span>);</span><br></pre></td></tr></table></figure><p>其实还有第二个参数，是Map的一些可配置参数<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">MVMap.Builder&lt;Integer, String&gt; mvMapConfig = <span class="keyword">new</span> MVMap.Builder&lt;&gt;();</span><br><span class="line">MVMap&lt;Integer, String&gt; map = s.openMap(<span class="string">"data1"</span>, mvMapConfig);</span><br></pre></td></tr></table></figure></p><p>参数列表</p><ul><li>keyType:  默认是ObjectDataType</li><li>valueType:  默认是ObjectDataType</li><li>singleWriter: </li></ul><p>我们假设文件是新建的，也就是metaMap中查询不到这个Map的信息<br>然后会给这个Map分配一个唯一的ID<br>然后向metaMap中写入自己的信息</p><p>然后新建一个空Leaf作为Map的RootPage，keys和values都是长度为0的数组</p><h1 id="基于Page的B-树"><a href="#基于Page的B-树" class="headerlink" title="基于Page的B+树"></a>基于Page的B+树</h1><p>每个Page上能放的key的个数是限制的</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">map.put(<span class="string">"key1"</span>, <span class="string">"value1"</span>);</span><br></pre></td></tr></table></figure><p>假设我们这么进行写入<br>假设我们是新打开的Map，那么此时Map上只有一个空的Leaf数组  </p><p>在进行写入之前，会对整个MVStore进行一个检查，检查文件的有效性<br>类似于JVM会检查Class文件的MagicWord，cafebabe一样。</p><p>下面就是查找过程，由于是Empty-Leaf，所以找到的index是-1。<br>继而把这个Leaf进行扩容，把<code>key1</code>放到Page对应的keys数组中<br>既然扩容values，把<code>value1</code>放到数组中</p><h2 id="页分裂"><a href="#页分裂" class="headerlink" title="页分裂"></a>页分裂</h2><p>页分裂的条件<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(keyCount = p.getKeyCount()) &gt; store.getKeysPerPage() || </span><br><span class="line">p.getMemory() &gt; store.getMaxPageSize() &amp;&amp; keyCount &gt; (p.isLeaf() ? <span class="number">1</span> : <span class="number">2</span>)</span><br></pre></td></tr></table></figure></p><p>看起来还是挺简单的</p><p>store.getKeysPerPage默认是48<br>store.getMaxPageSize和Cache有关，不过默认是64K<br>如果Page是Leaf的话，还必须至少有一个Value，是Node的话，至少有两个子节点<br>但是我理解的话，如果是因为内存过大而分裂，那么Node节点其实是不太可能的</p><h1 id="持久化流程"><a href="#持久化流程" class="headerlink" title="持久化流程"></a>持久化流程</h1><p>和正常的数据库一样，当我们读取和写入数据的时候，都会先从磁盘上把该数据所在的Page加载到内存中<br>然后持久化的最小单位也是Page<br>也就是说，如果Chunk 1中的Leaf Page中有48个KeyValue，但是我们只修改了<strong>一个Value</strong>，然后整个Page还是会持久化到Chunk 2中  </p><h2 id="手动持久化"><a href="#手动持久化" class="headerlink" title="手动持久化"></a>手动持久化</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mvStore.commit();</span><br><span class="line">mvStore.close();</span><br></pre></td></tr></table></figure><p>当我们手动进行commit或者直接close的时候，其实就是告诉MVStore进行一次Version的持久化<br>结果就是创建一个<code>Version = currentVersion</code>的Chunk</p><p>写chunk的时候，首先写入header<br>然后开始写Page的信息</p><p>写完用户的Map的Page信息之后，最后写入MetaMap的Pages</p><h2 id="后台定时持久化"><a href="#后台定时持久化" class="headerlink" title="后台定时持久化"></a>后台定时持久化</h2><p>在MVStore进行初始化之后，会启动一个后台线程<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">BackgroundWriterThread</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">while</span> (store.backgroundWriterThread != <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">synchronized</span> (sync) &#123;</span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        sync.wait(sleep);</span><br><span class="line">                    &#125; <span class="keyword">catch</span> (InterruptedException ignore) &#123;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (store.backgroundWriterThread == <span class="keyword">null</span>) &#123;</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                store.writeInBackground();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>同时传递给它一个sleep的time，每隔sleepTime，就进行一次commit，默认的sleep的时间是1000ms<br>当他醒来之后，如果发现数据有改变，就会进行一次commit</p><p>由于时间很短，所以正常情况下，不需要手动进行commit</p><p>在我们调用<code>MVStore#close</code>的时候，也会调用一次进行commit</p><h1 id="GC"><a href="#GC" class="headerlink" title="GC"></a>GC</h1><p>随着使用时间变长，肯定不会没有限制的创建Chunk的，MVStore也有回收机制，去回收很久之前的版本的Chunk<br>在官方文档中写的是</p><blockquote><p>Old data is kept for at least 45 seconds (configurable), so that there are no explicit sync operations required to guarantee data consistency. An application can also sync explicitly when needed. To reuse disk space, the chunks with the lowest amount of live data are compacted (the live data is stored again in the next chunk). To improve data locality and disk space usage, the plan is to automatically defragment and compact data.  </p></blockquote><p>我们知道MVStore不会保存所有的Version，很久之前的Version肯定会清除<br>那么就需要一个文件空间标记机制，标记那一块没有被使用已经被Free了，然后下面的Chunk进行写入的时候，可以复写那一块磁盘地址  </p><p>这个机制在MVStore的底层文件操作类FileStore中<br>底层使用了BitSet来表示，单位为BLOCK_SIZE<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">#FileStore</span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">final</span> FreeSpaceBitSet freeSpace =</span><br><span class="line">            <span class="keyword">new</span> FreeSpaceBitSet(<span class="number">2</span>, MVStore.BLOCK_SIZE);</span><br><span class="line">            </span><br><span class="line">            </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">markUsed</span><span class="params">(<span class="keyword">long</span> pos, <span class="keyword">int</span> length)</span> </span>&#123;</span><br><span class="line">        freeSpace.markUsed(pos, length);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="comment">//这个是核心方法，从FileStore中寻找length长度的位置</span></span><br><span class="line"><span class="comment">//注意，不是直接从文件末尾找一块地方</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">allocate</span><span class="params">(<span class="keyword">int</span> length)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> freeSpace.allocate(length);</span><br><span class="line">    &#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">predictAllocation</span><span class="params">(<span class="keyword">int</span> length)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> freeSpace.predictAllocation(length);</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">//free从pos开始的空间</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">free</span><span class="params">(<span class="keyword">long</span> pos, <span class="keyword">int</span> length)</span> </span>&#123;</span><br><span class="line">        freeSpace.free(pos, length);</span><br><span class="line">    &#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getFillRate</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> freeSpace.getFillRate();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">long</span> <span class="title">getFirstFree</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> freeSpace.getFirstFree();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">long</span> <span class="title">getFileLengthInUse</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> freeSpace.getLastFree();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p><p>在我们进行store的时候<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">MVStore#storeNow()</span><br><span class="line"><span class="keyword">long</span> filePos = allocateFileSpace(length, !reuseSpace);</span><br></pre></td></tr></table></figure></p><p>就能看到分配的逻辑在里面</p><p>同时我们还能看到Free的方法在里面，就是标记一块Chunk所在的地方已经可以进行reuse<br>那么怎么进行判定了，从上图我们可以知道其实即使在Chunk2中，还是有Page是引用的Chunk1</p><p>MVStore解决的方法也比较简单，就是DFS<br>遍历所有的Map的Node和Page，找到一个Chunk，就把ChunkId放在一个Map中，最后遍历当前文件中的所有Chunk，如果在Map中未找到，那么就是可以回收的<br>有点类似引用计数的方法，但是会不会出现循环引用呢<br>由于所有的Map的RootMap都是存在最新的Chunk中，所有不会出现循环引用的情况</p><p>方法在<code>MVStore#collectReferencedChunks</code><br>这里为了加速DFS的速度，还启动了一个线程池</p><p>带来的问题：<br>GC的机制也带来了问题，就是最新的Chunk在哪儿的问题<br>我们知道如果真的是Log Structed FS的格式的话，那么最新写入的肯定是在最后，而MetaMap的Root Page是在最新的Chunk中的<br>所以我们需要一个机制在打开文件的时候，找到最新的Chunk的位置<br>这个查找的过程，前面已经描述了一遍了</p><h1 id="Compact"><a href="#Compact" class="headerlink" title="Compact"></a>Compact</h1><p>当一个Chunk中LivePages比较少的时候，H2会进行Compact<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MVStore#compact</span><br></pre></td></tr></table></figure></p><p>Compact的方式<br>我只能表示非常的tricky<br>把LivePages中比较少的Page上的数据，全部replace了一遍，这样Chunk1指向chunk0的数据相当于全部update了一遍，但是数据没有变化</p><p>等Compact完之后，再进行上面一步</p><h1 id="Page-Cache"><a href="#Page-Cache" class="headerlink" title="Page Cache"></a>Page Cache</h1><p>Page的Cache机制不是LRU，而是LIRS<br>说实话这种Cache机制我是第一次见</p><h1 id="Debug技巧"><a href="#Debug技巧" class="headerlink" title="Debug技巧"></a>Debug技巧</h1><h2 id="源码环境导入Idea"><a href="#源码环境导入Idea" class="headerlink" title="源码环境导入Idea"></a>源码环境导入Idea</h2><p>会出现提示<code>configure OSGI</code>，<strong>别点</strong></p><h2 id="dump-file"><a href="#dump-file" class="headerlink" title="dump file"></a>dump file</h2><p>如果想要观察Commit发生了什么<br>可以把<code>BackgroundWriterThread</code>给关闭了，防止在背后每隔1s自己<code>commit</code><br>h2的作者提供了一个dump方法<br><code>MVStoreTool.dump()</code><br>可以把文件的内容打印出来</p><h1 id="PR"><a href="#PR" class="headerlink" title="PR"></a>PR</h1><p>在阅读MVStore源码的过程中，还发现了一个comment的错误<br>已经提了PR进行了修复</p><h1 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h1><ul><li><a href="http://www.h2database.com/html/mvstore.html" target="_blank" rel="noopener">http://www.h2database.com/html/mvstore.html</a></li><li><a href="https://en.wikipedia.org/wiki/Variable-length_quantity" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Variable-length_quantity</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;MVStore是h2数据库的底层的存储文件格式&lt;br&gt;在1.4版本之前底层的文件存储都是&lt;code&gt;org.h2.store.*&lt;/code&gt;包中的&lt;br&gt;然后1.4之后默认改为了&lt;code&gt;org.h2.mvstore.*&lt;/code&gt;包中的  &lt;/p&gt;
&lt;p&gt;官方的介绍说是根据&lt;code&gt;Log Structed FS&lt;/code&gt;设计的，顺序写提高性能&lt;/p&gt;
&lt;p&gt;MV的意思是&lt;code&gt;multi-version&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;同类型的项目有个叫&lt;code&gt;mapDB&lt;/code&gt;的项目&lt;br&gt;&lt;a href=&quot;https://github.com/jankotek/mapdb&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://github.com/jankotek/mapdb&lt;/a&gt;  &lt;/p&gt;
&lt;p&gt;还有一个Apache的项目&lt;code&gt;mavibot&lt;/code&gt;&lt;br&gt;&lt;a href=&quot;http://directory.apache.org/mavibot/downloads.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://directory.apache.org/mavibot/downloads.html&lt;/a&gt;  &lt;/p&gt;
    
    </summary>
    
    
      <category term="数据库" scheme="https://blog.lovezhy.cc/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="h2" scheme="https://blog.lovezhy.cc/tags/h2/"/>
    
  </entry>
  
  <entry>
    <title>oop-klass模型</title>
    <link href="https://blog.lovezhy.cc/2019/02/16/oop-klass%E6%A8%A1%E5%9E%8B/"/>
    <id>https://blog.lovezhy.cc/2019/02/16/oop-klass%E6%A8%A1%E5%9E%8B/</id>
    <published>2019-02-15T16:00:00.000Z</published>
    <updated>2019-02-17T05:50:21.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>看任何JVM的书，oop-klass总是绕不去的坎<br>我一直想理解这些，但是就是理解不了，但是也说不出哪里不明白。</p><p>这篇文章不会对这个模型做系统的阐述，假设读者已经看过oop-klass模型，但是还是有点一知半解的状态。</p><h2 id="oop-klass"><a href="#oop-klass" class="headerlink" title="oop-klass"></a>oop-klass</h2><p><strong>为什么要这么设计？</strong><br>其实很多书也提到，既然HotSpot完全基于C++去编写，要实现多态完全可以进行C++层面的转换就行。<br>但是C++的多态其实每一个对象都维护了一个VTable，就是虚函数表，函数表可以理解为一个函数指针的数组，这个数组在内存上和一个对象是一起的。<br>但是很多书中提到，为了避免每个对象都有一个VTable，JVM定义了oop-klass模型，其中oop就是保存数据结构的，而klass则担当了一部分VTable的功能，这样的话，<strong>VTable就是每个类只存在一个</strong>。<br>也就是说，对oop而言，它对应的klass是单例的，而Java层面每New一个对象，都会在JVM生成一个oop。</p><p>所以在Java中，类和对象的关系更像是这样:<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Student student1 = <span class="keyword">new</span> Student(<span class="string">"zhang"</span>, <span class="number">19</span>);</span><br><span class="line">        Student student2 = <span class="keyword">new</span> Student(<span class="string">"wang"</span>, <span class="number">20</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> age;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Student</span><span class="params">(String name, <span class="keyword">int</span> age)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">        <span class="keyword">this</span>.age = age;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><img src="/images/oop-klass/oop1.png" alt="">  </p><h2 id="动态绑定与VTable"><a href="#动态绑定与VTable" class="headerlink" title="动态绑定与VTable"></a>动态绑定与VTable</h2><p>这里再提一个我对动态绑定的理解。<br>其实动态绑定这个概念，大家都知道大概是个什么意思，但是再详细的说，就理不清很多细节。 </p><p>现在我们都知道动态绑定是和虚表有关，在Java字节码中，需要动态绑定的指令是<code>invokevirtual</code>。<br><a href="https://cs.au.dk/~mis/dOvs/jvmspec/ref--35.html" target="_blank" rel="noopener">https://cs.au.dk/~mis/dOvs/jvmspec/ref–35.html</a><br>这个ref中讲的是，动态绑定需要一个寻找函数的过程</p><blockquote><p>invokevirtual retrieves the Java class for objectref, and searches the list of methods defined by that class and then its superclasses, looking for a method called methodname, whose descriptor is descriptor.</p></blockquote><p>这当然我感觉是一种很扯淡的说法，要是这么来，运行时时间都花在匹配函数上去了。<br>而寻找函数的过程，我理解<strong>完全可以放在编译期去完成</strong>。<br>我更认同是这种方式，就是不需要进行运行时的函数匹配，动态绑定的意思是需要在运行时改变代码段的函数指针，类似于下面文章中提到的<br><a href="https://www.jianshu.com/p/fa50296b301c" target="_blank" rel="noopener">https://www.jianshu.com/p/fa50296b301c</a></p><blockquote><p>编译器内部会发生转换，产生类似下面的代码：<br>( <em>( p-&gt;vptr )[0] ) (p);  //</em>( p-&gt;vptr )[0]是函数入口地址</p></blockquote><p>这段代码的生成，对于C++而言是编译时，对于Java则是ClassLoader的时候，并不是运行时。</p><p>关于动态绑定，还有一些其他模棱两可的说法<br>比如这个文章中<br><a href="https://zhuanlan.zhihu.com/p/24317613" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/24317613</a></p><p>它提到在<code>invokevirtual</code>的调用过程，需要去查父类的方法表</p><blockquote><p>(2) 在Father类型的方法表中查找方法f1，如果找到，则将方法f1在方法表中的索引项11(如上图)记录到AutoCall类的常量池中第15个常量表中(常量池解析 )。这里有一点要注意：如果Father类型方法表中没有方法f1，那么即使Son类型中方法表有，编译的时候也通过不了。因为调用方法f1的类的对象father的声明为Father类型。</p></blockquote><p>这我也是觉得是脱裤子放屁的说法，为啥要去查父类的方法表，要知道父类的方法表，是在另外一个Klass对象里，要是继承链比较长，那么需要很多次指针寻址才能找到。</p><p>其实这个和另外一个比较经典的动态绑定的解释很像：</p><blockquote><p>如果子类Son中定义了 method() 的方法，则直接调用子类中的相应方法；如果子类Son中没有定义相应的方法，则到其父类中寻找method()方法。</p></blockquote><p>很多人把这个过程理解为动态绑定，这个的问题也是一样的，它的假设是子类的Klass对象中没有父类的方法指针，所以需要去父类的Klass的VTable中去找。</p><p>但是通过一些文章我们可以看出，其实子类的VTable完全的Copy了一份父类的VTable。<br><a href="https://stackoverflow.com/questions/18082651/how-does-dynamic-binding-happens-in-jvm" target="_blank" rel="noopener">https://stackoverflow.com/questions/18082651/how-does-dynamic-binding-happens-in-jvm</a><br><a href="https://cloud.tencent.com/developer/article/1180981" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/1180981</a>  </p><p>所以至此，整个动态绑定的过程我们就已经理解，所谓动态绑定，就是比静态绑定多了一个指针寻址，去Klass中找VTable的过程。</p><h2 id="1-7到1-8"><a href="#1-7到1-8" class="headerlink" title="1.7到1.8"></a>1.7到1.8</h2><p>很多书中都提到，oop-klass模型在1.8中改变较大。<br>原因是1.8中去掉了永久代（Perm），而改为了元空间(MetaSpace)。</p><p>我们先看看1.7中的oop-klass的继承链<br><a href="https://github.com/openjdk-mirror/jdk7u-hotspot/blob/master/src/share/vm/oops/oopsHierarchy.hpp" target="_blank" rel="noopener">https://github.com/openjdk-mirror/jdk7u-hotspot/blob/master/src/share/vm/oops/oopsHierarchy.hpp</a>   </p><p>oop继承链<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">typedef <span class="class"><span class="keyword">class</span> <span class="title">oopDesc</span>*                            <span class="title">oop</span></span>;</span><br><span class="line">typedef <span class="class"><span class="keyword">class</span>   <span class="title">instanceOopDesc</span>*            <span class="title">instanceOop</span></span>;</span><br><span class="line">typedef <span class="class"><span class="keyword">class</span>   <span class="title">methodOopDesc</span>*                    <span class="title">methodOop</span></span>;</span><br><span class="line">typedef <span class="class"><span class="keyword">class</span>   <span class="title">constMethodOopDesc</span>*            <span class="title">constMethodOop</span></span>;</span><br><span class="line">typedef <span class="class"><span class="keyword">class</span>   <span class="title">methodDataOopDesc</span>*            <span class="title">methodDataOop</span></span>;</span><br><span class="line">typedef <span class="class"><span class="keyword">class</span>   <span class="title">arrayOopDesc</span>*                    <span class="title">arrayOop</span></span>;</span><br><span class="line">typedef <span class="class"><span class="keyword">class</span>     <span class="title">objArrayOopDesc</span>*            <span class="title">objArrayOop</span></span>;</span><br><span class="line">typedef <span class="class"><span class="keyword">class</span>     <span class="title">typeArrayOopDesc</span>*            <span class="title">typeArrayOop</span></span>;</span><br><span class="line">typedef <span class="class"><span class="keyword">class</span>   <span class="title">constantPoolOopDesc</span>*            <span class="title">constantPoolOop</span></span>;</span><br><span class="line">typedef <span class="class"><span class="keyword">class</span>   <span class="title">constantPoolCacheOopDesc</span>*   <span class="title">constantPoolCacheOop</span></span>;</span><br><span class="line">typedef <span class="class"><span class="keyword">class</span>   <span class="title">klassOopDesc</span>*                    <span class="title">klassOop</span></span>;</span><br><span class="line">typedef <span class="class"><span class="keyword">class</span>   <span class="title">markOopDesc</span>*                    <span class="title">markOop</span></span>;</span><br><span class="line">typedef <span class="class"><span class="keyword">class</span>   <span class="title">compiledICHolderOopDesc</span>*    <span class="title">compiledICHolderOop</span></span>;</span><br></pre></td></tr></table></figure></p><p>klass继承链<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Klass</span></span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span>   <span class="title">instanceKlass</span></span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span>     <span class="title">instanceMirrorKlass</span></span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span>     <span class="title">instanceRefKlass</span></span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span>   <span class="title">methodKlass</span></span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span>   <span class="title">constMethodKlass</span></span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span>   <span class="title">methodDataKlass</span></span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span>   <span class="title">klassKlass</span></span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span>     <span class="title">instanceKlassKlass</span></span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span>     <span class="title">arrayKlassKlass</span></span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span>       <span class="title">objArrayKlassKlass</span></span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span>       <span class="title">typeArrayKlassKlass</span></span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span>   <span class="title">arrayKlass</span></span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span>     <span class="title">objArrayKlass</span></span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span>     <span class="title">typeArrayKlass</span></span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span>   <span class="title">constantPoolKlass</span></span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span>   <span class="title">constantPoolCacheKlass</span></span>;</span><br><span class="line"><span class="class"><span class="keyword">class</span>   <span class="title">compiledICHolderKlass</span></span>;</span><br></pre></td></tr></table></figure></p><p>可以说是非常多</p><p>但是到了1.8中，就变的很少<br>oop继承链<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">class</span> <span class="title">oopDesc</span>*                            <span class="title">oop</span>;</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">class</span>   <span class="title">instanceOopDesc</span>*            <span class="title">instanceOop</span>;</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">class</span>   <span class="title">arrayOopDesc</span>*                    <span class="title">arrayOop</span>;</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">class</span>     <span class="title">objArrayOopDesc</span>*            <span class="title">objArrayOop</span>;</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">class</span>     <span class="title">typeArrayOopDesc</span>*            <span class="title">typeArrayOop</span>;</span></span><br></pre></td></tr></table></figure></p><p>klass继承链<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Klass</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span>   <span class="title">InstanceKlass</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span>     <span class="title">InstanceMirrorKlass</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span>     <span class="title">InstanceClassLoaderKlass</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span>     <span class="title">InstanceRefKlass</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span>   <span class="title">ArrayKlass</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span>     <span class="title">ObjArrayKlass</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span>     <span class="title">TypeArrayKlass</span>;</span></span><br></pre></td></tr></table></figure></p><p>而少掉的那部分，其实只是换了个名字，叫做Metadata<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//      class MetaspaceObj</span></span><br><span class="line"><span class="class"><span class="keyword">class</span>   <span class="title">ConstMethod</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span>   <span class="title">ConstantPoolCache</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span>   <span class="title">MethodData</span>;</span></span><br><span class="line"><span class="comment">//      class Metadata</span></span><br><span class="line"><span class="class"><span class="keyword">class</span>   <span class="title">Method</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span>   <span class="title">ConstantPool</span>;</span></span><br><span class="line"><span class="comment">//      class CHeapObj</span></span><br><span class="line"><span class="class"><span class="keyword">class</span>   <span class="title">CompiledICHolder</span>;</span></span><br></pre></td></tr></table></figure></p><p>可能你已经猜到了，Metadata的这部分，已经全部转移到了元空间。</p><p>以下是 JDK 1.7 中的类在 JDK 1.8 中的存在形式：</p><ul><li>klassOop -&gt; Klass*</li><li>klassKlass 不再需要</li><li>methodOop -&gt; Method*</li><li>methodDataOop -&gt; MethodData*</li><li>constMethodOop -&gt; ConstMethod*</li><li>constantPoolOop -&gt; ConstantPool*</li><li>constantPoolCacheOop -&gt; ConstantPoolCache*</li></ul><p>Klass少掉的部分，还可以理解，但是为啥oop会少了这么多。</p><p>这里就牵扯到永久代和元空间的区别了。</p><p>首先的问题是，为什么撤销永久代而换成元空间<br>我找到了当初的JEP<br><a href="http://openjdk.java.net/jeps/122?spm=a2c4e.11153940.blogcont20279.13.13fd33dbw7ltIv" target="_blank" rel="noopener">http://openjdk.java.net/jeps/122?spm=a2c4e.11153940.blogcont20279.13.13fd33dbw7ltIv</a></p><blockquote><p>永久代的调优非常难，永久代的大小很难确定，其中涉及到太多因素，如类的总数、常量池大小和方法数量等，而且永久代的数据可能会随着每一次Full GC而发生移动。</p></blockquote><p>这里就要提到元空间的特点</p><blockquote><p>Symbols were moved to the native heap<br>Interned strings were moved to the Java Heap<br>Class statics were moved to the Java Heap</p></blockquote><ul><li>永久代属于堆，有大小限制。元空间使用堆外内存，理论上无内存限制</li><li>JDK7之前的HotSpot，字符串常量池的字符串被存储在永久代中，因此可能导致一系列的性能问题和内存溢出错误。在JDK8中，字符串常量池中只保存字符串的引用。</li></ul><p>而如果你去看JDK1.7的oopDesc的定义，你会发现一个奇怪的事<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">oopDesc</span> &#123;</span></span><br><span class="line">  <span class="keyword">friend</span> <span class="class"><span class="keyword">class</span> <span class="title">VMStructs</span>;</span></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="keyword">volatile</span> markOop  _mark;</span><br><span class="line">  <span class="keyword">union</span> _metadata &#123;</span><br><span class="line">    wideKlassOop    _klass;</span><br><span class="line">    narrowOop       _compressed_klass;</span><br><span class="line">  &#125; _metadata;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>这里的Klass，为什么是Oop对象？</p><p>这里引用R大的解释<br><a href="https://rednaxelafx.iteye.com/blog/858009" target="_blank" rel="noopener">https://rednaxelafx.iteye.com/blog/858009</a></p><blockquote><p>因为HotSpot 1.7之前，包括Class在内的元数据对象都需要被GC管理，因此这四列的对象其实都是oopDesc类型，只不过第一列是描述实例的instanceOopDes, 第二三四列为klassOopDesc；这个klassOopDesc可以看作是klass的一个wrapper，仅仅为了被gc更容易滴管理和表示，它的内部有一个klass成员来表达klass的信息。<br>所以第二列的 klassOopDesc 内部的klass 乃Integer类的klass，第三列的klass为 klassOopDesc这个对象的klass——instanceKlassKlass，那第三列这个类的klass是什么呢？由于描述instanceKlassKlass，methodKlassKlass，xxxxKlassKlass等一大票KlassKlass需要的元数据实际上是相同的，他们就是第四列的KlassKlass，第四列的KlassKlass的klass可以用它自己来描述，于是就圆满了。</p></blockquote><p>简单说就是为了偷懒，用Oop包裹一层，让GC一同管理了。<br>到了元方法区，已经不属于堆了，自然不需要这个了，自然可以去掉。</p><p>所以到了1.8，就变成了正常的状态<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">oopDesc</span> &#123;</span></span><br><span class="line">  <span class="keyword">volatile</span> markOop _mark;</span><br><span class="line">  <span class="keyword">union</span> _metadata &#123;</span><br><span class="line">    Klass*      _klass;</span><br><span class="line">    narrowKlass _compressed_klass;</span><br><span class="line">  &#125; _metadata;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="MarkOop"><a href="#MarkOop" class="headerlink" title="MarkOop"></a>MarkOop</h2><p>还有一些细节，我还是比较困惑的。<br>比如这个MarkOop的定义<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">markOopDesc</span>:</span> <span class="keyword">public</span> oopDesc &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>它是继承于oopDesc的<br>但是在oopDesc的定义中<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">oopDesc</span> &#123;</span></span><br><span class="line">  <span class="keyword">volatile</span> markOop _mark;</span><br><span class="line">  <span class="keyword">union</span> _metadata &#123;</span><br><span class="line">    Klass*      _klass;</span><br><span class="line">    narrowKlass _compressed_klass;</span><br><span class="line">  &#125; _metadata;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>又用到了markOop</p><p>好吧，这个是一件比较奇怪的是。</p><p>上面R大提到，继承与oopDesc的都是被GC管理的，<br>但是这里有个奇怪的点</p><p>MarkOop存在于OopDesc中，讲道理应该是个对象才是，但是它的作用却只是作为对象头。<br>在Java层面没有与之对应的东西。<br>更没有道理要被GC管理着啊</p><p>我翻阅文档的注释<br>发现了这么一句话<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Note that the mark is not a real oop but just a word.</span></span><br><span class="line"><span class="comment">// It is placed in the oop hierarchy for historical reasons.</span></span><br><span class="line"><span class="comment">//</span></span><br></pre></td></tr></table></figure></p><p>既然官方解释是<strong>历史原因</strong>，那就不追究这个问题了。</p><h2 id="JIT热点探测"><a href="#JIT热点探测" class="headerlink" title="JIT热点探测"></a>JIT热点探测</h2><p>这个算是一个小发现<br>我们查看oop的体系，发现Method也有对应的oop<br>在method的oop中，有个变量叫MethodCounters<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MethodCounters</span> :</span> <span class="keyword">public</span> Metadata &#123;</span><br><span class="line"> <span class="keyword">friend</span> <span class="class"><span class="keyword">class</span> <span class="title">VMStructs</span>;</span></span><br><span class="line"> <span class="keyword">friend</span> <span class="class"><span class="keyword">class</span> <span class="title">JVMCIVMStructs</span>;</span></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> INCLUDE_AOT</span></span><br><span class="line">  Method*           _method;                     <span class="comment">// Back link to Method</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> defined(COMPILER2) || INCLUDE_JVMCI</span></span><br><span class="line">  <span class="keyword">int</span>               _interpreter_invocation_count; <span class="comment">// Count of times invoked (reused as prev_event_count in tiered)</span></span><br><span class="line">  u2                _interpreter_throwout_count; <span class="comment">// Count of times method was exited via exception while interpreting</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> INCLUDE_JVMTI</span></span><br><span class="line">  u2                _number_of_breakpoints;      <span class="comment">// fullspeed debugging support</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">  InvocationCounter _invocation_counter;         <span class="comment">// Incremented before each activation of the method - used to trigger frequency-based optimizations</span></span><br><span class="line">  InvocationCounter _backedge_counter;           <span class="comment">// Incremented before each backedge taken - used to trigger frequencey-based optimizations</span></span><br></pre></td></tr></table></figure></p><p>这个类维护了几个关于方法调用次数的计数器，和JIT的热点探测有关</p><p>具体的细节可以查看<br><a href="https://www.jianshu.com/p/1ea9b3d1abb9" target="_blank" rel="noopener">https://www.jianshu.com/p/1ea9b3d1abb9</a> </p><p><a href="http://mail.openjdk.java.net/pipermail/hotspot-compiler-dev/2011-June/005750.html" target="_blank" rel="noopener">http://mail.openjdk.java.net/pipermail/hotspot-compiler-dev/2011-June/005750.html</a></p><h2 id="HSDB"><a href="#HSDB" class="headerlink" title="HSDB"></a>HSDB</h2><p>这个工具，可以用来查看运行时的oop和klass数据<br>简单的使用，网上可以随便百度到，这里介绍下怎么查看虚表<br><a href="https://cloud.tencent.com/developer/article/1180981" target="_blank" rel="noopener">https://cloud.tencent.com/developer/article/1180981</a>  </p><h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><ul><li><a href="https://www.sczyh30.com/posts/Java/jvm-klass-oop/" target="_blank" rel="noopener">https://www.sczyh30.com/posts/Java/jvm-klass-oop/</a></li><li><a href="https://book.douban.com/subject/25847620/" target="_blank" rel="noopener">《HotSpot实战》</a></li><li><a href="https://book.douban.com/subject/27086821/" target="_blank" rel="noopener">《揭秘Java虚拟机》</a></li><li><a href="https://www.cnblogs.com/paddix/p/5309550.html" target="_blank" rel="noopener">https://www.cnblogs.com/paddix/p/5309550.html</a></li><li><a href="https://www.slideshare.net/cafusic/jvm20101228?from_action=save" target="_blank" rel="noopener">R大的JVM分享，强烈推荐</a></li><li><a href="https://blogs.oracle.com/poonam/about-g1-garbage-collector,-permanent-generation-and-metaspace" target="_blank" rel="noopener">oracle文档中对元空间的解释</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;看任何JVM的书，oop-klass总是绕不去的坎&lt;br&gt;我一直想理解这些，但是就是理解不了，但是也说不出哪里不明白。&lt;/p&gt;
&lt;p&gt;这篇文
      
    
    </summary>
    
    
      <category term="JVM" scheme="https://blog.lovezhy.cc/categories/JVM/"/>
    
    
      <category term="JVM" scheme="https://blog.lovezhy.cc/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>十万嬉皮</title>
    <link href="https://blog.lovezhy.cc/2019/01/05/%E5%8D%81%E4%B8%87%E5%AC%89%E7%9A%AE/"/>
    <id>https://blog.lovezhy.cc/2019/01/05/%E5%8D%81%E4%B8%87%E5%AC%89%E7%9A%AE/</id>
    <published>2019-01-04T16:00:00.000Z</published>
    <updated>2020-02-23T10:28:21.877Z</updated>
    
    <content type="html"><![CDATA[<h1 id="十万嬉皮-万能青年旅店"><a href="#十万嬉皮-万能青年旅店" class="headerlink" title="十万嬉皮 - 万能青年旅店"></a><strong>十万嬉皮 - 万能青年旅店</strong></h1><p>大梦一场的董二千先生</p><a id="more"></a><p>推开窗户，举起望远镜</p><p>眼底映出，一阵浓烟</p><p>前已无通路，后不见归途</p><p>敌视现实，虚构远方</p><p>东张西望，一无所长</p><p>四体不勤，五谷不分</p><p>文不能测字，武不能防身</p><p>喜欢养狗，不爱洗头</p><p>不事劳作，一无所获</p><p>厌恶争执，不善言说</p><p>终于沦为沉默的帮凶</p><p>借酒浇愁，不太能喝</p><p>蛊惑他人，麻醉内心</p><p>浇上汽油，舒展眉头</p><p>纵火的青年，迫近的时间</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;十万嬉皮-万能青年旅店&quot;&gt;&lt;a href=&quot;#十万嬉皮-万能青年旅店&quot; class=&quot;headerlink&quot; title=&quot;十万嬉皮 - 万能青年旅店&quot;&gt;&lt;/a&gt;&lt;strong&gt;十万嬉皮 - 万能青年旅店&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;大梦一场的董二千先生&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Life" scheme="https://blog.lovezhy.cc/tags/Life/"/>
    
  </entry>
  
  <entry>
    <title>磁盘，IO，CPU与中断</title>
    <link href="https://blog.lovezhy.cc/2019/01/03/%E7%A3%81%E7%9B%98%EF%BC%8CIO%E4%B8%8E%E4%B8%AD%E6%96%AD/"/>
    <id>https://blog.lovezhy.cc/2019/01/03/%E7%A3%81%E7%9B%98%EF%BC%8CIO%E4%B8%8E%E4%B8%AD%E6%96%AD/</id>
    <published>2019-01-02T16:00:00.000Z</published>
    <updated>2019-02-28T14:06:16.000Z</updated>
    
    <content type="html"><![CDATA[<p>第一次写如此泛泛而谈的文章。<br>最近磁盘，IO中断的概念不断的在我脑子中，就随便写写。</p><a id="more"></a><h1 id="Speed"><a href="#Speed" class="headerlink" title="Speed"></a>Speed</h1><p>其实自己之前对内存访问，Cpu Cache和磁盘访问，网络访问的时间并没有多大的概念。<br>只知道个大概的比较<br>下面是各个操作的正常时间延迟</p><blockquote><p><img src="/images/磁盘IO与中断/速度.png" alt=""></p><pre><code>--《Redis开发与运维》</code></pre></blockquote><p>同时，目前很多的产品都用上了SSD。<br>而SSD相对于磁盘而言，访问速度和性能又上升了一个层次。</p><blockquote><p>传统磁盘的I/O寻道延迟很高，这导致它的访问延迟（～10ms）远高于内存（~100ns），并且它的随机访问性能远低于顺序访问性能，这对上层软件系统的设计产生了极大的影响。为了解决这一问题，存储器件的演进方向主要包含两类：(1) 闪存（Solid State Disk，SSD）将I/O访问延迟降低了三个数量级（~10us），并且它的随机读取性能与顺序读取性能相似<br>​                                                                                            – <a href="http://mysql.taobao.org/monthly/2018/11/01/" target="_blank" rel="noopener">http://mysql.taobao.org/monthly/2018/11/01/</a></p></blockquote><p><strong>= = 我没测过，所以不对以上数据负责。。。</strong></p><ul><li>Cpu Cache &lt;&lt; Main Memory<br>这个很典型的例子，就是ArrayList的迭代和LinkedList的迭代，哪个快问题，因为一个CacheLine是64，所以读取不足64k的话，会把目标地址的周围数据也读进去填充为一个CacheLine，这个就导致了ArrayList的迭代速度大于LinkedList</li><li>Main Memory Reference + Read 1MB sequenially from memory &lt;&lt;&lt; Disk Seek + Read 1MB sequenially from Disk<br>这个速度差距简直不忍直视，现在的很多内存数据库，比如Redis，虽然是双读双写，如果Miss了，还要读一次数据库，性能损耗很大，但是如果访问量巨大，全部命中Cache的话，那收益是巨大的。</li></ul><p>System Call<br>还有一个性能所在的地方就是系统调用<br>普通函数和系统调用的性能对比我也不是很清楚，只是知道系统调用性能消耗比较大<br><img src="/images/磁盘IO与中断/syscall.png" alt="">  </p><p>从上面看，一个轻量级的系统调用还行，但是涉及到IO的，就很慢了，比正常函数慢100 - 1000倍不等。</p><p>而如果考虑Epoll那种事件驱动的话，如果你的业务代码非阻塞，执行的非常的快的话，其实和IO事件比起来不算什么，参见Netty，可能你调用了几百个简单的函数，都不如一次Read函数花的时间多。</p><p>从数据上看Write比Read更是慢了一倍，所以NIO而言，异步的写，我感觉还是比较重要的，特别是遇到<code>Would Block</code>的错误，如果还是拼命写，那其实还不如先存起来，等待一个写事件。</p><h1 id="缓冲"><a href="#缓冲" class="headerlink" title="缓冲"></a>缓冲</h1><p>如果你再去看看主存的定义，会发现它其实是类似于缓存的东西，为磁盘服务的。<br>缓存的概念其实到处都有，主要用来处理上层和下层的速度不匹配的问题。<br>而磁盘的缓存单位一般是页，在H2Database中，一个页通常是4k，和内核的内存管理有关。<br>而数据的写入，一般是先写入主存，再写入磁盘。</p><p>而大多数人不知道的是，我们代码的数据到磁盘之间，调用write之后，并不会直接到磁盘，而是先写入内核的缓存。</p><p>所以数据的流向是这样的<br>用户态数据 -&gt; 内核态数据 -&gt; 磁盘。<br>相应的，从磁盘读取数据到用户态也是<br>磁盘 -&gt; 内核态数据 -&gt; 用户态数据</p><p>内核是以页为单位把数据从磁盘读到内核缓冲区的。</p><p>内核为啥要把数据先放到自己的缓冲区呢，个人理解答案当然还是为了缓冲。<br>就跟Cpu的CacheLine一样，你只从文件里读取一个Bit？那不行，直接拉满填充一个Page</p><p>当我们自己向文件中写入了值的时候，其实还没有写进去磁盘，具体什么时候写，由内核来定。<br>所以提供了两个函数</p><ul><li>sync</li><li>fsync</li></ul><p>sync只是把脏页数据，强制放到写磁盘的队列中<br>fsync一直到成功写入磁盘才返回<br>而write函数仅仅是写回脏页而已</p><p>而这里其实还有个问题，就是内核是不相信用户的，所以如果你要从内核的缓冲区进行Read，内核会把那一份数据<strong>拷贝</strong>一份到用户态<br>这其中的消耗其实不是那么必要的。</p><p>为此，内核还提供了一个函数mmap，就是给予用户程序能直接读取和写入数据到内核的缓冲区  </p><p>在此，如果有这样一个需求，在一个静态的httpServer，需要把index.html传送到socket，我先read出来，然后write出去，这不傻逼了吗，白白复制这么多次。<br>然后有个系统调用叫sendfile，内核帮你直接复制到socket的缓冲区。</p><h1 id="中断"><a href="#中断" class="headerlink" title="中断"></a>中断</h1><p>如果你注意思考上面的问题，你就会发现问题本质是</p><ul><li>CPU的快和其他东西慢的矛盾<br>在思考Epoll的就绪链表的时候，如果该Socket Fd上出现事件，就调用回调把自己插入到就绪链表。<br>那么再深层次一点，谁调用这个回调呢，是内核<br>再深层次一点，内核怎么知道你这个Fd上有数据<br>那就是网卡发送中断给CPU了<br><code>设备事件 - 中断 - CPU响应中断</code><br>这个简直是个完美的模型  </li></ul><p>但是上面的模型，如果基于Netty的Flux一样，并不能提高事件处理的速度，而是提高了吞吐量，提高吞吐量的关键就是不要Block住CPU，再实际一点就是不要Block住线程，让一个线程多处理事件。</p><p>而提高应用的速度和吞吐量并不是两个毫不相干的东西，在一些情况下，甚至会是互相矛盾的。<br>比如就写事件而言，如果出现了would block</p><ul><li>我还是疯狂写</li><li>注册写事件，当出现写事件再去写</li></ul><p>如果你是疯狂写，那么你就是让其他的事件去等待，恰好网络状况较好的话，这种的速度是很快的，但是吞吐量不高。<br>如果你是注册写事件，那么就是暂时放弃了这个fd，当Fd可写的时候，相对于第一种情况，已经经过了相对较长的时间了，相应的响应时间就变长了。</p><p>我曾经设想过一个，就是用Netty的时候，把EventLoop线程设置为茫茫多，像Tomcat那么多，但是其实是有问题的，因为他的模型和Tomcat不一样，Tomcat的200个线程是不处理IO事件的，但是EventLoop中每一个线程还注册了Epoll来处理IO事件。</p><h1 id="虚拟内存"><a href="#虚拟内存" class="headerlink" title="虚拟内存"></a>虚拟内存</h1><p>主存的定位是什么，Cache吗，作为CPU和磁盘的缓冲，有道理。<br>作为CPU计算的中间结果的暂存地？也有道理。<br>其实现在这种Cache大行其道的时代，你会发现主存却越来越非主流<br>从Cache的角度讲，主存的意义就是作为磁盘的高速Cache<br>但是现在你和其他人讲这个观点反而会觉得奇怪，内存怎么会和缓存是一回事呢？<br>因为现在很多东西都只在内存中，应用或者系统也没有打算写到磁盘中<br>Cache失效了？那就崩溃了，那就重启吧，不叫事。<br>但是如果你在公司不考虑缓存失效的情况，那你怕是要被开除了。</p><p>但是其实我们没有考虑过，主存到底会不会失效呢<br>我们写Java程序，往一个List里面写一个对象，运行着发现这个对象没了<br>不会考虑到操作系统的问题，而是我们代码的问题<br>所以Cache失效的问题，是操作系统来保证不会失效的的。<br>当然DRAM也算，硬件一般也不会出问题</p><p>如果你再深挖一下<br>什么？内存竟然不是我们自己来管理的？那我们平时写内存写内存是写到哪儿去了。<br>不要误以为写内存就是直接写物理内存(内存条)，其实只是提申请给操作系统，然后由操作系统写到了物理内存</p><p>那平时我们print出来的那些内存地址呢，是真的物理地址吗？<br>不是<br>那些地址是假的吗？<br>是也不是。</p><p>那么操作系统怎么管理内存的呢？<br>其实操作系统管理内存的方式更像是Cache管理的方式</p><h1 id="CPU"><a href="#CPU" class="headerlink" title="CPU"></a>CPU</h1><p>如果你参考现在的系统优化方向，大部分分两个方向</p><ul><li>架构</li><li>硬件</li></ul><p>之前我在的数据库事业部，架构上的优化，和高性能几乎没什么关系，基本都是为了CAP而来<br>但是加速执行，硬件是个大方向，而且越来越火</p><p>比如Java的Panama项目中增强的SIMD支持<br>SIMD是什么呢？这个是CPU中很早就支持的东西，但是JDK中是我们无法控制的，有HotSpot自己控制。</p><p>从数据库的查询来看，SIMD在对数组进行Project和Filter等特定算子的运行时，加速是很大的。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul><li>《Redis开发与运维》</li><li><a href="http://mysql.taobao.org/monthly/2018/11/01/" target="_blank" rel="noopener">http://mysql.taobao.org/monthly/2018/11/01/</a></li><li><a href="https://stackoverflow.com/questions/23599074/system-calls-overhead" target="_blank" rel="noopener">https://stackoverflow.com/questions/23599074/system-calls-overhead</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;第一次写如此泛泛而谈的文章。&lt;br&gt;最近磁盘，IO中断的概念不断的在我脑子中，就随便写写。&lt;/p&gt;
    
    </summary>
    
    
      <category term="编程" scheme="https://blog.lovezhy.cc/categories/%E7%BC%96%E7%A8%8B/"/>
    
    
      <category term="随想" scheme="https://blog.lovezhy.cc/tags/%E9%9A%8F%E6%83%B3/"/>
    
  </entry>
  
  <entry>
    <title>我的2018</title>
    <link href="https://blog.lovezhy.cc/2019/01/01/%E6%88%91%E7%9A%842018/"/>
    <id>https://blog.lovezhy.cc/2019/01/01/%E6%88%91%E7%9A%842018/</id>
    <published>2018-12-31T16:00:00.000Z</published>
    <updated>2020-02-23T10:28:32.041Z</updated>
    
    <content type="html"><![CDATA[<p>总结我的2018</p><a id="more"></a><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>一路坎坷的2018年终于过去了，一年12个月，我有9个月都在外面实习  </p><ul><li>2 - 4：美团实习</li><li>6 - 8：阿里实习</li><li>11 - ~：网易实习</li></ul><p>虽然其实自己感觉也没啥，但是回顾起来还是觉得满坎坷的  </p><h2 id="美团实习"><a href="#美团实习" class="headerlink" title="美团实习"></a>美团实习</h2><p>去美团实习的时候，真的是一张白纸<br>最开始去之前还是觉得很开心很激动，因为美团也算是一个大公司了，而我一个双非本科的学生，能得到这样的机会，实在是难得。 当时HR告诉我的工资，足够我在上海活下去，也终于不需要向爸妈拿钱了。<br>但是由于发生了一些事，导致这段实习其实并不是很愉快   </p><p>由于HR的原因，导致我的工资入职后才知道其实很低很低，因为HR不仅仅告诉错了我的工资，还没说日常是实习生是没有房补的。 每个月不仅仅仅靠自己的工资完全活不下去，还需要向爸妈拿钱  这个是我当时最伤心的地方   </p><p>房子租的很远，每天上班大概需要一个半小时的时间 其中走路大概需要45分钟   </p><p>由于当时春招并未开始，所以我知道自己的不足，还是在每天疯狂的学习到很晚，压力很大    </p><p>虽然有点骄傲，进去后发现其实我的水平完全够得上，并没有感觉到不能胜任的地方，但是Leader还是只给我一些小任务去做 我的意思是，我并不能学到什么新的东西 完全是自己自学   </p><p>春招正式开始后，主管以部门HC紧张为理由，拒绝给我转为暑假实习生(有房补)，让我继续保持日常实习生，然后八月份一起参加转正答辩，意味着如果我留下来，到八月份还是没有房补  </p><p>住的很偏，周围并没有什么吃的 但是爸妈一直在问我吃的好不好，让我不要省，但是我还是不好意思和他们要钱，但是我还是得吃饭，外卖又很贵。于是很多个周末我都是早饭不吃，午饭点外卖顺便把晚饭也买下来，可以最大限度的参加满减和省一次运费  </p><h2 id="春招"><a href="#春招" class="headerlink" title="春招"></a>春招</h2><p>大概3 - 4月份两个月都在不停地面试，写笔试，投简历<br>由于还是在美团上班，所以只能每次都约晚上的实习<br>好几次都顶着压力提前下班回去面试  </p><p>最狠的一次是晚上7：30到11点，面了三个公司  </p><p>第一个Offer是酷家乐的，面的其实还挺多的，最后一面是让我远程写代码，写一个命令行的管理系统，大概是一个小时的时间，我当时虽然没吃饭，但是状态不错，顺畅的写完了<br><img src="/images/2018/酷家乐.png" alt=""><br>收到Offer的时间是4.2号，那周我去虹桥的一个电影院看了<strong>玩家一号</strong>的IMAX版本  </p><p>第二个Offer来自饿了么，让我去现场面，我去了之后发现其实面试挺简单的，简单面了两面之后就发了Offer给我<br><img src="/images/2018/饿了么.png" alt="">  </p><p>第三个Offer，也就是最后一个Offer就是来自阿里<br>说来奇怪，阿里是我最早面完的，但是是发的最晚的，大概是在5.10号才发的<br>流程也是比较坎坷</p><p>期间还面了有赞，华为，腾讯等<br>有赞还去了次杭州<br>华为是乘机回了次学校<br>腾讯电话面试挂了一次，然后笔试过了，现场面试又挂了</p><h2 id="5月份"><a href="#5月份" class="headerlink" title="5月份"></a>5月份</h2><p>我在4.23号的时候，离职了美团，终于脱离了让我当时痛苦不堪的地方<br>在家短暂的呆了一段时间，然后去了学校<br>在学校玩的很开心<br>决定去阿里实习之后，按照内推人的建议开始学习Hadoop，Hive之类的一些东西 </p><h2 id="阿里实习"><a href="#阿里实习" class="headerlink" title="阿里实习"></a>阿里实习</h2><p>5.31号入职的阿里，8.25号离职的<br>学到了很多，也很感谢这一段的时光  </p><h2 id="秋招"><a href="#秋招" class="headerlink" title="秋招"></a>秋招</h2><p>秋招其实我参加的不多  </p><p>网易是当时我比较中意的公司，在8月中旬的时候，特地请假去参加了提前批，感觉面试也比较简单，和想象中的不太一样，我当时以为会问的很难。</p><p>中旬的时候回了一次学校，正好也参加了华为的优招，华为的优招投的部门是华为云，问的也比较一般。</p><p>提前批除了这两个公司，我几乎没有参加其他的，一方面是阿里实在是加班太晚了，怕自己没有时间面试，另一方面也是没有时间去做笔试题。</p><p>离职了阿里之后，那一段时间还是比较慌的，就开始疯狂投简历，但是那段时间其实很多的提前批都已经结束了，比如腾讯，百度等。</p><p>当时网易迟迟不出消息，自己都有点想考研的打算了。</p><p>在9.4号的时候，网易终于来了消息，发的offer。</p><p>这也是我秋招的第一个offer。</p><p><img src="/images/2018/网易.png" alt="">  </p><p>其实当时网易是我比较满意的offer了，一方面觉得自己是SP，不知道哪里来的自信，一方面部门是杭研，传说中的养老部门。</p><p>后面的秋招我就没怎么面试了，面了360企业安全，小米等。</p><p>最终收获了4个offer。</p><ul><li>360企业安全</li><li>小米</li><li>华为</li><li>网易</li></ul><p>选择了网易。</p><h1 id="再次实习"><a href="#再次实习" class="headerlink" title="再次实习"></a>再次实习</h1><p>在10月底的时候，我再次踏上了实习的旅程。<br>其实我不是很想去实习的，但是我妈坚持让我去，原因是提前去可以熟悉环境，和同事领导更熟悉，这样在正式工作的时候会有些优势。<br>同时网易的HR们也很推荐我们去实习，实习超过3个月可以抵两个月的试用期。</p><p>匆匆在杭州租了房子</p><p>开始了3个月的实习生涯</p><p>其实是希望破灭的开始</p><p>我对网易的向往其实是之前我在阿里的时候，一个在网易实习的同学告诉我的，网易叫猪场，食堂很好吃，而且不要钱。<br>下班也很早，不怎么加班。</p><p>然而事实上，网易上班是打卡的，而且是9.30打开。回过头看，比小米和阿里的都早。</p><p>还有个事其实可以小声哔哔下，当时部门结果刚出来的时候，我是很惊讶的，因为部门叫推荐技术部，我们都没有听过这个部门，在HR面试的时候，HR还问我对网易的时序数据库敢不敢兴趣，我以为我要去做数据库相关的东西了。<br>推荐技术部，我网上都搜不到这个部门，让我感觉很恐惧。<br>我于是和HR要了主管的微信，想要了解一下，加了之后，主管其实态度并不很热情，只是匆匆介绍了下部门是做什么的<br>然后我问我去大概是做什么，主管说都是先从运营后台做起。</p><p>万分纠结，其实我当时还挺想去小米的，但是最终还是决定去网易。<br>这个决定让我现在都后悔万分。</p><p>去实习了不久，不出我的所望，做的是一个连产品经理都看不见希望的产品。<br>实习了一半的时候，主管非常激动的说要做类似于一元抽奖的东西，并且说”这个才是拉新的重头“。</p><p>KPI项目，做出来了，当时后端就两个，我和一个同事一起做的。<br>其中也遇到了大的麻烦，Redis中间内存满了一次，导致开始随机删Key。<br>其实最奇怪的一点，让我很怀疑这个主管的能力。<br>他说，“能不能切掉Redis，让数据库抗压力”。<br>现在Redis的定位还仅仅是数据库的缓存吗？</p><p>敢问，现在哪个公司的业务Redis挂了还能正常跑的？</p><p>12月底的时候，网易开始裁员。我在这种基本凉凉的产品组当然瑟瑟发抖。<br>于是我问HR，我们会不会裁员，她信誓旦旦的说，不会的，安心干活儿。</p><p>然后过了几天她就调岗了。换了新的HR。</p><p>我在1.8号的时候离职，回学校做毕设。</p><p>到了大概过完年，组里一个和我玩的很好的产品告诉我，整个部门都要裁了。</p><p>于是我就又开始了找工作生涯。</p><p>其实写到这儿，我的2018已经结束了，下面是2019年的事了，那就等2019年再说吧。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;总结我的2018&lt;/p&gt;
    
    </summary>
    
    
      <category term="瞎说" scheme="https://blog.lovezhy.cc/categories/%E7%9E%8E%E8%AF%B4/"/>
    
    
      <category term="总结" scheme="https://blog.lovezhy.cc/tags/%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>Things I Don’t Know as of 2018</title>
    <link href="https://blog.lovezhy.cc/2019/01/01/Things%20I%20Don%E2%80%99t%20Know%20as%20of%202018/"/>
    <id>https://blog.lovezhy.cc/2019/01/01/Things%20I%20Don%E2%80%99t%20Know%20as%20of%202018/</id>
    <published>2018-12-31T16:00:00.000Z</published>
    <updated>2019-01-05T07:09:40.000Z</updated>
    
    <content type="html"><![CDATA[<p>创意来自<br><a href="https://overreacted.io/things-i-dont-know-as-of-2018/" target="_blank" rel="noopener">https://overreacted.io/things-i-dont-know-as-of-2018/</a></p><a id="more"></a><ol><li><p>Docker，K8S：自己只是简单使用过Docker，K8S更是只是听过，因为自己很少有需求去部署服务，觉得自己懂一些还是很重要的</p></li><li><p>SpringCloud，Dubbo：也仅仅是知道是什么东西，大概是NetFlix的那一套微服务的东西，但是自己真的没有去系统的学过，对降级和限流什么的，都只是一个很模糊的概念。Rpc和服务治理，之前在美团用过Pigeon，但是Dubbo确实没有尝试过。</p></li><li><p>JavaScript：虽然自己不是很想去学习这个语言，但是有些地方总无法避免的要写一些前端的代码，懂一些还是非常重要的。</p></li><li><p>Vue：虽然自己用过Vue，但是最多只是当做一个库引入JS，而不是像现在的前端的工程化，NPM的那一套东西，WIKI文档自己也没有系统的看过。</p></li><li><p>Go：虽然很早就在看教程了，但是也仅仅局限于基础的语法，一些系统库和常见的框架还是不会，自己想要去看TIDB的代码，很有必要去深入的学习一下。</p></li><li><p>Service Mesh：自己之前找时间看了一下介绍，但是还是一头雾水，不知道在讲什么。</p></li><li><p>操作系统：越来越觉得操作系统是个很重要，东西很多的东西，自己不能局限于国内学校本科教会的那些，包括cgroup等这些很重要的API的实现</p></li><li><p>ES，Lucene：自己也仅仅听过，知道其实运用很广泛。</p></li><li><p>JVM：看过深入理解JVM，但是一直想要从源码层次去学习</p></li><li><p>Kafka：看过同事用过，自己也用过，但是对原理不是很了解</p></li><li><p>Netty：源码还没看完 </p></li><li><p>Zookeeper：源码下下来了，但是还没看过</p></li><li><p>Nginx：很惭愧，这个可能连配置我都不懂</p></li><li><p>函数式：SICP我也没看得下去，一直听大佬们说monad什么的，scala也是因为找不到写代码的场景而弃了好久了</p></li><li><p>RabbitMQ：仅仅听过和看同事用过，知道消息队列的用处</p></li><li><p>HDFS：Hadoop生态中对这个最底层的文件存储很感兴趣，可以去学习一番</p></li><li><p>CodeGen：目前知道的是基于APT和ASM的实现，但是自己对APT和ASM都不甚了解</p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;创意来自&lt;br&gt;&lt;a href=&quot;https://overreacted.io/things-i-dont-know-as-of-2018/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://overreacted.io/things-i-dont-know-as-of-2018/&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="年度总结" scheme="https://blog.lovezhy.cc/categories/%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="年度总结" scheme="https://blog.lovezhy.cc/tags/%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>WebFlux性能问题和适用场景</title>
    <link href="https://blog.lovezhy.cc/2018/12/29/webflux%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98/"/>
    <id>https://blog.lovezhy.cc/2018/12/29/webflux%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98/</id>
    <published>2018-12-28T16:00:00.000Z</published>
    <updated>2019-11-30T15:24:52.540Z</updated>
    
    <content type="html"><![CDATA[<p>Spring5的主推功能可能就是WebFlux了<br>但是网上一堆人吹捧性能完爆SpringMVC似乎有点过头了</p><p>结论就是WebFlux的线程模型不同，所以适应场景也不同<br>SpringMVC并不是互相替代的关系(个人感觉)<br><a id="more"></a></p><h1 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h1><p>使用我推荐看这个视频<br><a href="https://www.youtube.com/watch?v=zVNIZXf4BG8&amp;t=2947s&amp;frags=pl%2Cwn" target="_blank" rel="noopener">https://www.youtube.com/watch?v=zVNIZXf4BG8&amp;t=2947s&amp;frags=pl%2Cwn</a></p><p>简单易懂</p><h1 id="细节问题"><a href="#细节问题" class="headerlink" title="细节问题"></a>细节问题</h1><h2 id="Web容器"><a href="#Web容器" class="headerlink" title="Web容器"></a>Web容器</h2><p>如果你同时引入的是<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-boot-starter-webflux&lt;/artifactId&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure></p><p>那么默认的Web容器就是Tomcat</p><p>如果想要使用Netty作为容器，那么可以在web模块中手动把Tomcat去除<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;</span><br><span class="line">    &lt;exclusions&gt;</span><br><span class="line">        &lt;&lt;exclusion&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt;</span><br><span class="line">        &lt;/exclusion&gt;</span><br><span class="line">    &lt;/exclusions&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure></p><h2 id="内部依赖"><a href="#内部依赖" class="headerlink" title="内部依赖"></a>内部依赖</h2><p>其实看官方的图就会很费解，为啥WebFlux吹捧的是Reactive编程，却能跑在Tomcat上  </p><p>为此我去翻看了文档</p><p>如果Web容器使用的是Tomcat，那么就是使用Reactor桥接的servlet async api<br>如果Web容器是Netty，那么就是使用的Netty，天生支持Reactive</p><p>所以官方的推荐还是使用Netty跑WebFlux  </p><p>而用Netty跑SpringMVC行不行呢，也是可以的，但是性能并不会很好，主要是Tomcat是暴力创建线程，但是Netty默认线程数量较少</p><h1 id="Reavtive代码"><a href="#Reavtive代码" class="headerlink" title="Reavtive代码"></a>Reavtive代码</h1><p>其实这是第二个误区，很多人以为只要我们在Controller中返回的是Mono或者Flux，性能就会得到提升<br>不存在的<br>如果你要使用WebFlux，那么对不起，从Dao到Service，全部都要是Mono和Flux。<br>目前官方的数据层Reactive框架只支持Redis，Mongo等几个，<strong>没有JDBC</strong><br>所以你的代码是JDBC，想要迁移到WebFlux并指望性能提升，那你可能要失望了  </p><p>不过值得庆幸的是，JDBC的Reactive正在开发中，虽然尚不成熟，但是可以关注一下  </p><h1 id="性能和迁移"><a href="#性能和迁移" class="headerlink" title="性能和迁移"></a>性能和迁移</h1><p>这个其实是值得商榷的问题<br>因为性能和很多因素有关  </p><ul><li>Web容器的线程模型  这个Tomcat和Netty不一样</li><li>Web容器的线程个数 Tomcat默认200个Nio线程，但是Netty默认可能只有核心数*2</li><li>业务代码，如果是IO操作较多，Netty模型可能比较适合，如果是业务阻塞较多，默认的Tomcat可能比较适合，Netty可能需要较多的冗余代码和调优，且性能可能不会有较大提升</li></ul><p>既然性能和这么多因素有关，所以官方也没有打包票WebFlux碾压SpringMVC</p><p>关于迁移，文档是这么写的</p><blockquote><p>If you have a Spring MVC application that works fine, there is no need to change. Imperative programming is the easiest way to write, understand, and debug code. You have maximum choice of libraries, since, historically, most are blocking.</p></blockquote><p>这句话翻译过来就是<br>如果你的代码中有任何阻塞操作，请谨慎选择WebFlux</p><p>关于性能</p><blockquote><p>Performance has many characteristics and meanings. Reactive and non-blocking generally do not make applications run faster. They can, in some cases, (for example, if using the WebClient to execute remote calls in parallel). On the whole, it requires more work to do things the non-blocking way and that can increase slightly the required processing time.</p><p>The key expected benefit of reactive and non-blocking is the ability to scale with a small, fixed number of threads and less memory. That makes applications more resilient under load, because they scale in a more predictable way. In order to observe those benefits, however, you need to have some latency (including a mix of slow and unpredictable network I/O). That is where the reactive stack begins to show its strengths, and the differences can be dramatic.  </p></blockquote><p>WebFlux并不保证应用能运行的更快，但是它主打的是scale和低内存消耗<br>它的性能需要在一些特定的场景才能展现，比如慢网络IO的情况</p><h1 id="惨痛的测试过程"><a href="#惨痛的测试过程" class="headerlink" title="惨痛的测试过程"></a>惨痛的测试过程</h1><p>看起来可能会有点乱，而且也并不是很权威，个人建议直接跳过这一节，去看结论</p><h2 id="第一轮"><a href="#第一轮" class="headerlink" title="第一轮"></a>第一轮</h2><p>其实为啥写这个文章，就是我开始很开心的想要看看WebFlux到底比SpringMVC强多少  </p><p>然后写出了下面的代码<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@GetMapping</span>(<span class="string">"/hello"</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> Map&lt;String, String&gt; <span class="title">hello</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        Thread.sleep(<span class="number">5</span>);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> Collections.singletonMap(<span class="string">"Hello"</span>, <span class="string">"world"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@GetMapping</span>(<span class="string">"/reactor"</span>)</span><br><span class="line"><span class="keyword">public</span> Mono&lt;Map&lt;String, String&gt;&gt; reactor() &#123;</span><br><span class="line">    <span class="keyword">return</span> Mono.create( sink -&gt; &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Thread.sleep(<span class="number">5</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">        sink.success(Collections.singletonMap(<span class="string">"Hello"</span>, <span class="string">"world"</span>));</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">» wrk -t30 -c3000 -d60s http://127.0.0.1:8080/hello --latency</span><br><span class="line">Running 1m <span class="built_in">test</span> @ http://127.0.0.1:8080/hello</span><br><span class="line">  30 threads and 3000 connections</span><br><span class="line">  Thread Stats   Avg      Stdev     Max   +/- Stdev</span><br><span class="line">    Latency    89.76ms   56.33ms 401.67ms   61.64%</span><br><span class="line">    Req/Sec   628.19    383.30     3.88k    81.15%</span><br><span class="line">  Latency Distribution</span><br><span class="line">     50%   89.00ms</span><br><span class="line">     75%  132.28ms</span><br><span class="line">     90%  161.62ms</span><br><span class="line">     99%  229.86ms</span><br><span class="line">  1027462 requests <span class="keyword">in</span> 1.00m, 153.02MB <span class="built_in">read</span></span><br><span class="line">  Socket errors: connect 0, <span class="built_in">read</span> 3283, write 0, timeout 0</span><br><span class="line">Requests/sec:  17095.73</span><br><span class="line">Transfer/sec:      2.55MB</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">» wrk -t30 -c3000 -d60s http://127.0.0.1:8080/reactor --latency</span><br><span class="line">Running 1m <span class="built_in">test</span> @ http://127.0.0.1:8080/reactor</span><br><span class="line">  30 threads and 3000 connections</span><br><span class="line">  Thread Stats   Avg      Stdev     Max   +/- Stdev</span><br><span class="line">    Latency   100.82ms   65.39ms 451.83ms   65.85%</span><br><span class="line">    Req/Sec   438.16    321.89     2.96k    80.20%</span><br><span class="line">  Latency Distribution</span><br><span class="line">     50%   94.37ms</span><br><span class="line">     75%  146.32ms</span><br><span class="line">     90%  185.54ms</span><br><span class="line">     99%  281.39ms</span><br><span class="line">  739620 requests <span class="keyword">in</span> 1.00m, 110.15MB <span class="built_in">read</span></span><br><span class="line">  Socket errors: connect 0, <span class="built_in">read</span> 2524, write 0, timeout 0</span><br><span class="line">Requests/sec:  12306.22</span><br><span class="line">Transfer/sec:      1.83MB</span><br></pre></td></tr></table></figure><p>发现WebFlux性能反而不如SpringMVC，这里标注一点，Mono.create里面的逻辑，还是tomcat的线程去执行的<br>其实我想了想这里进行Sleep应该不是很合理，因为sleep算是个block操作</p><p>继而我手动发布到parallel中，虽然我在官方的例子中没有看过这种写法<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@GetMapping</span>(<span class="string">"/reactor"</span>)</span><br><span class="line"><span class="keyword">public</span> Mono&lt;Map&lt;String, String&gt;&gt; reactor() &#123;</span><br><span class="line">    <span class="keyword">return</span> Mono.&lt;Map&lt;String, String&gt;&gt;create(sink -&gt; &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Thread.sleep(<span class="number">5</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">        sink.success(Collections.singletonMap(<span class="string">"Hello"</span>, <span class="string">"world"</span>));</span><br><span class="line">    &#125;).publishOn(Schedulers.parallel());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">» wrk -t30 -c3000 -d60s http://127.0.0.1:8080/reactor --latency</span><br><span class="line">Running 1m <span class="built_in">test</span> @ http://127.0.0.1:8080/reactor</span><br><span class="line">  30 threads and 3000 connections</span><br><span class="line">  Thread Stats   Avg      Stdev     Max   +/- Stdev</span><br><span class="line">    Latency   122.59ms   81.11ms 634.86ms   66.16%</span><br><span class="line">    Req/Sec   378.94    246.55     2.56k    79.17%</span><br><span class="line">  Latency Distribution</span><br><span class="line">     50%  110.07ms</span><br><span class="line">     75%  175.18ms</span><br><span class="line">     90%  236.01ms</span><br><span class="line">     99%  344.06ms</span><br><span class="line">  662844 requests <span class="keyword">in</span> 1.00m, 98.71MB <span class="built_in">read</span></span><br><span class="line">  Socket errors: connect 0, <span class="built_in">read</span> 3813, write 0, timeout 0</span><br><span class="line">Requests/sec:  11029.13</span><br><span class="line">Transfer/sec:      1.64MB</span><br></pre></td></tr></table></figure><p>可以看到性能反而变慢了，因为Schedulers.parallel()默认只有8线程在运行，于是我手动改成30</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">» wrk -t30 -c3000 -d60s http://127.0.0.1:8080/reactor --latency</span><br><span class="line">Running 1m <span class="built_in">test</span> @ http://127.0.0.1:8080/reactor</span><br><span class="line">  30 threads and 3000 connections</span><br><span class="line">  Thread Stats   Avg      Stdev     Max   +/- Stdev</span><br><span class="line">    Latency   132.54ms   87.81ms 691.34ms   69.49%</span><br><span class="line">    Req/Sec   390.05    258.97     2.97k    74.94%</span><br><span class="line">  Latency Distribution</span><br><span class="line">     50%  116.71ms</span><br><span class="line">     75%  183.79ms</span><br><span class="line">     90%  251.33ms</span><br><span class="line">     99%  401.91ms</span><br><span class="line">  678598 requests <span class="keyword">in</span> 1.00m, 101.06MB <span class="built_in">read</span></span><br><span class="line">  Socket errors: connect 0, <span class="built_in">read</span> 4059, write 0, timeout 0</span><br><span class="line">Requests/sec:  11291.03</span><br><span class="line">Transfer/sec:      1.68MB</span><br></pre></td></tr></table></figure><p>可以看到结果其实差别并不大，瓶颈应该不在这里，或者WebFlux在publicOn做了什么调用</p><h2 id="第二轮"><a href="#第二轮" class="headerlink" title="第二轮"></a>第二轮</h2><p>第二轮我修改了测试案例，换成了从Redis中取值的操作<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> ReactiveRedisTemplate&lt;String, String&gt; reactiveRedisTemplate;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> StringRedisTemplate stringRedisTemplate;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">HelloController</span><span class="params">(ReactiveRedisTemplate&lt;String, String&gt; reactiveRedisTemplate, StringRedisTemplate stringRedisTemplate)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.reactiveRedisTemplate = reactiveRedisTemplate;</span><br><span class="line">    <span class="keyword">this</span>.stringRedisTemplate = stringRedisTemplate;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> List&lt;String&gt; keys = Arrays.asList(<span class="string">"name1"</span>, <span class="string">"name2"</span>, <span class="string">"name3"</span>);</span><br><span class="line"></span><br><span class="line"><span class="meta">@GetMapping</span>(<span class="string">"/hello"</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> List&lt;String&gt; <span class="title">hello</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> stringRedisTemplate.opsForValue().multiGet(keys);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@GetMapping</span>(<span class="string">"/reactor"</span>)</span><br><span class="line"><span class="keyword">public</span> Mono&lt;List&lt;String&gt;&gt; reactor() &#123;</span><br><span class="line">    <span class="keyword">return</span> reactiveRedisTemplate.opsForValue().multiGet(keys);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">» wrk -t30 -c3000 -d60s http://127.0.0.1:8080/hello --latency</span><br><span class="line">Running 1m <span class="built_in">test</span> @ http://127.0.0.1:8080/hello</span><br><span class="line">  30 threads and 3000 connections</span><br><span class="line">  Thread Stats   Avg      Stdev     Max   +/- Stdev</span><br><span class="line">    Latency   110.62ms   57.26ms 279.77ms   65.42%</span><br><span class="line">    Req/Sec   467.92    327.19     4.65k    85.21%</span><br><span class="line">  Latency Distribution</span><br><span class="line">     50%  109.25ms</span><br><span class="line">     75%  155.67ms</span><br><span class="line">     90%  182.36ms</span><br><span class="line">     99%  234.64ms</span><br><span class="line">  808566 requests <span class="keyword">in</span> 1.00m, 128.90MB <span class="built_in">read</span></span><br><span class="line">  Socket errors: connect 0, <span class="built_in">read</span> 4070, write 0, timeout 0</span><br><span class="line">Requests/sec:  13453.13</span><br><span class="line">Transfer/sec:      2.14MB</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">» wrk -t30 -c3000 -d60s http://127.0.0.1:8080/reactor --latency</span><br><span class="line">Running 1m <span class="built_in">test</span> @ http://127.0.0.1:8080/reactor</span><br><span class="line">  30 threads and 3000 connections</span><br><span class="line">  Thread Stats   Avg      Stdev     Max   +/- Stdev</span><br><span class="line">    Latency   236.17ms  113.54ms 650.53ms   68.95%</span><br><span class="line">    Req/Sec   293.21    161.31     5.09k    81.31%</span><br><span class="line">  Latency Distribution</span><br><span class="line">     50%  251.06ms</span><br><span class="line">     75%  313.69ms</span><br><span class="line">     90%  352.13ms</span><br><span class="line">     99%  521.69ms</span><br><span class="line">  505806 requests <span class="keyword">in</span> 1.00m, 80.62MB <span class="built_in">read</span></span><br><span class="line">  Socket errors: connect 0, <span class="built_in">read</span> 3535, write 0, timeout 0</span><br><span class="line">Requests/sec:   8416.85</span><br><span class="line">Transfer/sec:      1.34MB</span><br></pre></td></tr></table></figure><p>可以看到性能还是很低，甚至差别略大  </p><p>于是我还是改成手动publish<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">» wrk -t30 -c3000 -d60s http://127.0.0.1:8080/reactor --latency</span><br><span class="line">Running 1m <span class="built_in">test</span> @ http://127.0.0.1:8080/reactor</span><br><span class="line">  30 threads and 3000 connections</span><br><span class="line">  Thread Stats   Avg      Stdev     Max   +/- Stdev</span><br><span class="line">    Latency   228.61ms  101.83ms 666.54ms   70.65%</span><br><span class="line">    Req/Sec   293.82    148.63     1.98k    75.36%</span><br><span class="line">  Latency Distribution</span><br><span class="line">     50%  237.21ms</span><br><span class="line">     75%  287.44ms</span><br><span class="line">     90%  335.04ms</span><br><span class="line">     99%  526.61ms</span><br><span class="line">  499892 requests <span class="keyword">in</span> 1.00m, 79.68MB <span class="built_in">read</span></span><br><span class="line">  Socket errors: connect 0, <span class="built_in">read</span> 3198, write 0, timeout 0</span><br><span class="line">Requests/sec:   8317.62</span><br><span class="line">Transfer/sec:      1.33MB</span><br></pre></td></tr></table></figure></p><p>发现其实区别还是不大</p><p>既然把pool改成30呢<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">» wrk -t30 -c3000 -d60s http:<span class="comment">//127.0.0.1:8080/reactor --latency</span></span><br><span class="line">Running <span class="number">1</span>m test @ http:<span class="comment">//127.0.0.1:8080/reactor</span></span><br><span class="line">  <span class="number">30</span> threads and <span class="number">3000</span> connections</span><br><span class="line">  Thread Stats   Avg      Stdev     Max   +/- Stdev</span><br><span class="line">    Latency   <span class="number">212.81</span>ms   <span class="number">94.51</span>ms <span class="number">709.88</span>ms   <span class="number">69.39</span>%</span><br><span class="line">    Req/Sec   <span class="number">290.22</span>    <span class="number">151.03</span>     <span class="number">2.57</span>k    <span class="number">77.73</span>%</span><br><span class="line">  Latency Distribution</span><br><span class="line">     <span class="number">50</span>%  <span class="number">214.93</span>ms</span><br><span class="line">     <span class="number">75</span>%  <span class="number">262.16</span>ms</span><br><span class="line">     <span class="number">90</span>%  <span class="number">317.48</span>ms</span><br><span class="line">     <span class="number">99</span>%  <span class="number">479.01</span>ms</span><br><span class="line">  <span class="number">508591</span> requests in <span class="number">1.00</span>m, <span class="number">81.07</span>MB read</span><br><span class="line">  Socket errors: connect <span class="number">0</span>, read <span class="number">3190</span>, write <span class="number">0</span>, timeout <span class="number">0</span></span><br><span class="line">Requests/sec:   <span class="number">8462.78</span></span><br><span class="line">Transfer/sec:      <span class="number">1.35</span>MB</span><br></pre></td></tr></table></figure></p><p>还是差别不大，所以问题的关键应该不在这儿。</p><h2 id="第三轮"><a href="#第三轮" class="headerlink" title="第三轮"></a>第三轮</h2><p>第三轮把容器改成了Netty<br>改为Netty之后有个要注意的就是Web容器的线程不会疯狂的进行创建了，一般就是核心数或者核心数*2</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">» wrk -t30 -c3000 -d60s http://127.0.0.1:8080/hello --latency</span><br><span class="line">Running 1m <span class="built_in">test</span> @ http://127.0.0.1:8080/hello</span><br><span class="line">  30 threads and 3000 connections</span><br><span class="line">  Thread Stats   Avg      Stdev     Max   +/- Stdev</span><br><span class="line">    Latency    63.26ms   38.60ms   1.99s    83.37%</span><br><span class="line">    Req/Sec   467.59    453.97     6.27k    85.41%</span><br><span class="line">  Latency Distribution</span><br><span class="line">     50%   65.65ms</span><br><span class="line">     75%   83.72ms</span><br><span class="line">     90%   93.78ms</span><br><span class="line">     99%  129.69ms</span><br><span class="line">  747480 requests <span class="keyword">in</span> 1.00m, 80.55MB <span class="built_in">read</span></span><br><span class="line">  Socket errors: connect 0, <span class="built_in">read</span> 4343, write 1, timeout 874</span><br><span class="line">Requests/sec:  12437.61</span><br><span class="line">Transfer/sec:      1.34MB</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">» wrk -t30 -c3000 -d60s http://127.0.0.1:8080/reactor --latency</span><br><span class="line">Running 1m <span class="built_in">test</span> @ http://127.0.0.1:8080/reactor</span><br><span class="line">  30 threads and 3000 connections</span><br><span class="line">  Thread Stats   Avg      Stdev     Max   +/- Stdev</span><br><span class="line">    Latency   156.88ms   74.43ms 527.17ms   66.33%</span><br><span class="line">    Req/Sec   431.27    207.17     5.08k    82.32%</span><br><span class="line">  Latency Distribution</span><br><span class="line">     50%  176.96ms</span><br><span class="line">     75%  211.25ms</span><br><span class="line">     90%  236.23ms</span><br><span class="line">     99%  312.83ms</span><br><span class="line">  762879 requests <span class="keyword">in</span> 1.00m, 82.21MB <span class="built_in">read</span></span><br><span class="line">  Socket errors: connect 0, <span class="built_in">read</span> 3419, write 0, timeout 0</span><br><span class="line">Requests/sec:  12694.40</span><br><span class="line">Transfer/sec:      1.37MB</span><br></pre></td></tr></table></figure><p>和上面的tomcat相比，SpringMVC会比较糟糕，这个也是可以预见的，因为Redis中阻塞的EventLoop<br>WebFlux的性能超过了SpringMVC，同时注意看WebFlux超时为0，而SpringMVC伴随着大量的超时</p><p>横向进行对比的话，SpringMVC的性能还是进行了下降<br>但是WebFlux却有很大的提升</p><p>修改默认的EventLoop大小呢<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">System.setProperty(<span class="string">"reactor.schedulers.defaultPoolSize"</span>, <span class="string">"30"</span>);</span><br></pre></td></tr></table></figure></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">» wrk -t30 -c3000 -d60s http://127.0.0.1:8080/hello --latency</span><br><span class="line">Running 1m <span class="built_in">test</span> @ http://127.0.0.1:8080/hello</span><br><span class="line">  30 threads and 3000 connections</span><br><span class="line">  Thread Stats   Avg      Stdev     Max   +/- Stdev</span><br><span class="line">    Latency    61.56ms   35.75ms   1.98s    84.77%</span><br><span class="line">    Req/Sec   484.48    503.66     8.98k    88.50%</span><br><span class="line">  Latency Distribution</span><br><span class="line">     50%   65.20ms</span><br><span class="line">     75%   80.28ms</span><br><span class="line">     90%   90.15ms</span><br><span class="line">     99%  113.19ms</span><br><span class="line">  764109 requests <span class="keyword">in</span> 1.00m, 82.34MB <span class="built_in">read</span></span><br><span class="line">  Socket errors: connect 0, <span class="built_in">read</span> 4749, write 2, timeout 916</span><br><span class="line">Requests/sec:  12713.41</span><br><span class="line">Transfer/sec:      1.37MB</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">» wrk -t30 -c3000 -d60s http://127.0.0.1:8080/reactor --latency</span><br><span class="line">Running 1m <span class="built_in">test</span> @ http://127.0.0.1:8080/reactor</span><br><span class="line">  30 threads and 3000 connections</span><br><span class="line">  Thread Stats   Avg      Stdev     Max   +/- Stdev</span><br><span class="line">    Latency   117.43ms   58.73ms 310.79ms   65.99%</span><br><span class="line">    Req/Sec   464.75    350.25     8.26k    84.65%</span><br><span class="line">  Latency Distribution</span><br><span class="line">     50%  116.12ms</span><br><span class="line">     75%  160.88ms</span><br><span class="line">     90%  192.55ms</span><br><span class="line">     99%  257.21ms</span><br><span class="line">  803283 requests <span class="keyword">in</span> 1.00m, 86.57MB <span class="built_in">read</span></span><br><span class="line">  Socket errors: connect 0, <span class="built_in">read</span> 3011, write 0, timeout 0</span><br><span class="line">Requests/sec:  13366.05</span><br><span class="line">Transfer/sec:      1.44MB</span><br></pre></td></tr></table></figure><p>可以看到SpringMVC基本没变，同时带有大量的超时<br>但是WebFlux性能有提升，同时超时个数依旧为0  </p><p>同时，发现无论怎么设置，都无法超过第二轮Tomcat的值</p><h2 id="第四轮"><a href="#第四轮" class="headerlink" title="第四轮"></a>第四轮</h2><p>比较一下Tomcat的阻塞模型和Netty的非阻塞模型，在线程差不多的情况下的性能<br>增加配置<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">server.tomcat.max-threads=<span class="number">20</span></span><br></pre></td></tr></table></figure></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">» wrk -t30 -c3000 -d60s http://127.0.0.1:8080/hello --latency</span><br><span class="line">Running 1m <span class="built_in">test</span> @ http://127.0.0.1:8080/hello</span><br><span class="line">  30 threads and 3000 connections</span><br><span class="line">  Thread Stats   Avg      Stdev     Max   +/- Stdev</span><br><span class="line">    Latency   119.35ms   73.88ms 323.07ms   61.31%</span><br><span class="line">    Req/Sec   429.58    428.04     8.30k    89.22%</span><br><span class="line">  Latency Distribution</span><br><span class="line">     50%  124.08ms</span><br><span class="line">     75%  179.28ms</span><br><span class="line">     90%  215.99ms</span><br><span class="line">     99%  268.68ms</span><br><span class="line">  713803 requests <span class="keyword">in</span> 1.00m, 113.80MB <span class="built_in">read</span></span><br><span class="line">  Socket errors: connect 0, <span class="built_in">read</span> 3452, write 0, timeout 0</span><br><span class="line">Requests/sec:  11876.60</span><br><span class="line">Transfer/sec:      1.89MB</span><br></pre></td></tr></table></figure><p>会发现WebFlux的表现要好的多</p><h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p>WebFlux相对于SpringMVC下的优点</p><ul><li>同样的性能场景消耗的资源更少</li><li>适合横向扩展</li></ul><p>所以总结一下WebFlux什么场景下可以替换SpringMVC呢</p><ul><li>想要内存和线程数较少的场景</li><li>网络较慢或者IO会经常出现问题的场景</li></ul><p>但是WebFlux需要</p><ul><li>非阻塞的业务代码，如果阻塞，需要自己开线程池去运行</li></ul><h1 id="混写"><a href="#混写" class="headerlink" title="混写"></a>混写</h1><p>其实SpringMVC和WebFlux混写个人感觉不会太好<br>因为SpringMVC一般配合的是业务阻塞较多，如果配合Netty，可能会阻塞EventLoop，编程压力较大，配合Tomcat，疯狂开线程就行<br>WebFlux还是比较适合Netty，Reactor模式，业务不能阻塞IO线程，如果业务阻塞操作较多，可能需要自己去单独开线程池去运行，编程较为复杂，所以业务那边，需要框架支持非阻塞运行<br>那WebFlux跑在Tomcat中呢，我觉得是可以的，但是感觉很变扭<br>WebClient例外，那个就是AsyncHttpClient，和Tomcat没啥关系  </p><h1 id="未来与展望"><a href="#未来与展望" class="headerlink" title="未来与展望"></a>未来与展望</h1><p>WebFlux更多的是对标的Vertx，但是没有Vertx完善<br>好在支持自己的IOC和AOP<br>等JDBC支持异步的库完善了，可以用来写纯异步的轻量级应用 </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Spring5的主推功能可能就是WebFlux了&lt;br&gt;但是网上一堆人吹捧性能完爆SpringMVC似乎有点过头了&lt;/p&gt;
&lt;p&gt;结论就是WebFlux的线程模型不同，所以适应场景也不同&lt;br&gt;SpringMVC并不是互相替代的关系(个人感觉)&lt;br&gt;
    
    </summary>
    
    
      <category term="Spring" scheme="https://blog.lovezhy.cc/categories/Spring/"/>
    
    
      <category term="Spring" scheme="https://blog.lovezhy.cc/tags/Spring/"/>
    
  </entry>
  
</feed>
